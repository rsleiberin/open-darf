import os, re
from typing import Iterable, Dict, Any, List

class Prediction:
    def __init__(self, spans: List[Dict[str, Any]], relations: List[Dict[str, Any]]):
        self.spans = spans
        self.relations = relations

class BaseAdapter:
    def __init__(self, cfg: Dict[str, Any]):
        self.cfg = cfg
    def predict(self, sents: Iterable[Dict[str, Any]]) -> Iterable[Prediction]:
        raise NotImplementedError

def _try_import_text2nkg():
    try:
        import text2nkg  # type: ignore
        return text2nkg
    except Exception:
        return None

def _has_hf_stack():
    try:
        import torch  # noqa
        import transformers  # noqa
        return True
    except Exception:
        return False

class Text2NKGAdapter(BaseAdapter):
    def __init__(self, cfg: Dict[str, Any]):
        super().__init__(cfg)
        self.impl = _try_import_text2nkg()
        if self.impl is None:
            raise RuntimeError("text2nkg package not available (prefer_text2nkg was True)")
    def predict(self, sents: Iterable[Dict[str, Any]]) -> Iterable[Prediction]:
        # TODO: wire real text2nkg inference once package is present.
        for _ in sents:
            yield Prediction(spans=[], relations=[])

class HFBaselineAdapter(BaseAdapter):
    def __init__(self, cfg: Dict[str, Any]):
        super().__init__(cfg)
        from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline
        model_path = os.path.expanduser(cfg.get("ner_model_path","~/.darf/models/scibert"))
        local_only = bool(cfg.get("local_files_only", True))
        self.tok = AutoTokenizer.from_pretrained(model_path, local_files_only=local_only)
        self.mdl = AutoModelForTokenClassification.from_pretrained(model_path, local_files_only=local_only)
        self.pipe = pipeline(
            "token-classification",
            model=self.mdl,
            tokenizer=self.tok,
            aggregation_strategy="simple",
            device=0 if cfg.get("cuda", True) else -1
        )
    def predict(self, sents: Iterable[Dict[str, Any]]) -> Iterable[Prediction]:
        for s in sents:
            text = s["text"]
            ents = self.pipe(text)
            spans=[]
            for e in ents:
                spans.append({"start": int(e["start"]), "end": int(e["end"]), "label": str(e.get("entity_group","ENT"))})
            rels=[]
            for i in range(len(spans)):
                for j in range(i+1, len(spans)):
                    rels.append({"h": i, "t": j, "type": "CO_OCCUR"})
            yield Prediction(spans=spans, relations=rels)

class HeuristicAdapter(BaseAdapter):
    """
    Deterministic, offline-only fallback:
    - Tokenize on word boundaries
    - Emit spans for tokens with length>=4 or TitleCase
    - Pairwise CO_OCCUR relations within each sentence
    """
    _word = re.compile(r"\b\w+\b", re.UNICODE)
    def predict(self, sents: Iterable[Dict[str, Any]]) -> Iterable[Prediction]:
        for s in sents:
            text = s["text"]
            spans=[]
            for m in self._word.finditer(text):
                tok = m.group(0)
                if len(tok) >= 4 or (tok[:1].isupper() and tok[1:].islower()):
                    spans.append({"start": m.start(), "end": m.end(), "label": "HEUR"})
            rels=[]
            for i in range(len(spans)):
                for j in range(i+1, min(i+6, len(spans))):  # local window to bound density
                    rels.append({"h": i, "t": j, "type": "CO_OCCUR"})
            yield Prediction(spans=spans, relations=rels)

def get_adapter(cfg: Dict[str, Any]) -> BaseAdapter:
    mode = (os.getenv("T2NKG_ADAPTER","") or str(cfg.get("force_adapter",""))).lower()
    if mode in {"heuristic","heur","h"}:
        try:
            from tools.text2nkg.adapter import HeuristicAdapter  # self-ref ok after exec
        except Exception:
            pass
        return HeuristicAdapter(cfg)
    prefer_text2nkg = cfg.get("prefer_text2nkg", True)
    if prefer_text2nkg:
        t2 = _try_import_text2nkg()
        if t2 is not None:
            return Text2NKGAdapter(cfg)
    if _has_hf_stack():
        try:
            return HFBaselineAdapter(cfg)
        except Exception:
            pass  # fall through to heuristic
    return HeuristicAdapter(cfg)

def get_adapter(cfg):
    """Return an adapter instance based on cfg.
    - default: 'hf' if ner_model_path{,_map} present, else 'heuristic'
    - robust: on HF errors, fall back to HeuristicAdapter and annotate cfg.
    """
    want = (cfg.get("adapter") or
            ("hf" if (cfg.get("ner_model_path") or cfg.get("ner_model_path_map")) else "heuristic")).lower()
    if want in {"hf","hfbaseline","hf-baseline","transformers"}:
        try:
            return HFBaselineAdapter(cfg)
        except Exception as e:
            # Do not crash scoring; record why we fell back.
            try:
                cfg["_adapter_warning"] = f"hf_fallback:{type(e).__name__}"
            except Exception:
                pass
            return HeuristicAdapter(cfg)
    # default / explicit heuristic
    return HeuristicAdapter(cfg)

# === DARF phase7a label-map wrapper (do not remove) ===
try:
    _orig_get_adapter = get_adapter
except NameError:  # if not defined yet, we will rely on HFBaselineAdapter directly
    _orig_get_adapter = None

class _LabelMappingAdapter:
    def __init__(self, inner, label_map=None, label_map_default=None):
        self._inner = inner
        self._label_map = dict(label_map or {})
        self._label_map_default = label_map_default
    def __getattr__(self, name):
        return getattr(self._inner, name)
    def _map(self, lab):
        if lab in self._label_map:
            return self._label_map[lab]
        return self._label_map_default if (self._label_map_default is not None) else lab
    def predict(self, *args, **kwargs):
        for rec in self._inner.predict(*args, **kwargs):
            spans = rec.get("spans", [])
            for s in spans:
                if "label" in s:
                    s["label"] = self._map(s["label"])
            yield rec

def get_adapter(config):
    inst = _orig_get_adapter(config) if _orig_get_adapter else None
    if inst is None:
        try:
            inst = HFBaselineAdapter(config)
        except Exception:
            return None
    cfg = config or {}
    lm = cfg.get("label_map", {})
    default = cfg.get("label_map_default", None)
    try:
        _hfb = HFBaselineAdapter
    except NameError:
        _hfb = type(inst)
    if isinstance(inst, _hfb) and (lm or (default is not None)):
        return _LabelMappingAdapter(inst, lm, default)
    return inst
# === end DARF phase7a wrapper ===

# === DARF prefer HF (appended) ===
try:
    _darf_prev_get_adapter = get_adapter
except NameError:
    _darf_prev_get_adapter = None

def get_adapter(config): # DARF prefer_hf
    cfg = config or {}
    # 1) Try HF explicitly
    try:
        inst = HFBaselineAdapter(cfg)
        # Wrap with label-map if available (cooperate with earlier wrapper if present)
        lm = cfg.get("label_map", {}); default = cfg.get("label_map_default", None)
        try:
            # If wrapper class exists, reuse it to apply mapping; else return HF directly
            _ = _LabelMappingAdapter
            return _LabelMappingAdapter(inst, lm, default)
        except Exception:
            return inst
    except Exception:
        pass
    # 2) Fallback to prior get_adapter (which may choose HeuristicAdapter)
    if _darf_prev_get_adapter:
        return _darf_prev_get_adapter(cfg)
    try:
        return HeuristicAdapter(cfg)
    except Exception:
        return None
# === end DARF prefer HF ===

# === DARF heuristic->hf delegate ===
try:
    _darforig_HeuristicAdapter = HeuristicAdapter
except Exception:
    _darforig_HeuristicAdapter = None

class HeuristicAdapter:  # shadow the name with an HF-backed wrapper
    def __init__(self, config):
        self._inner = HFBaselineAdapter(config)
    def __getattr__(self, name):
        return getattr(self._inner, name)
    def predict(self, *args, **kwargs):
        yield from self._inner.predict(*args, **kwargs)
# === end DARF heuristic->hf delegate ===

# === DARF heuristic->hf delegate SAFE ===
try:
    _darforig_HeuristicAdapter
except NameError:
    _darforig_HeuristicAdapter = None

class HeuristicAdapter(HeuristicAdapter):  # override with safe __init__
    def __init__(self, config):
        # Try HF; on failure, fall back to the original heuristic (if present)
        try:
            # Probe for transformers availability before constructing HF adapter
            import importlib
            importlib.import_module("transformers")
            super().__init__(config)  # previous delegate: builds HFBaselineAdapter
        except Exception:
            if _darforig_HeuristicAdapter is not None:
                self._inner = _darforig_HeuristicAdapter(config)
            else:
                # Last-resort: minimal shim that yields inner predictions as empty
                class _NullInner:
                    def predict(self, *args, **kwargs):
                        for rec in args[0] if args else []:
                            yield {"id": rec.get("id"), "text_len": len(rec.get("text","")), "spans": []}
                self._inner = _NullInner()
# === end DARF heuristic->hf delegate SAFE ===

# === DARF robust label-map adapter ===
try:
    _DARF_OLD_LMA = _LabelMappingAdapter
except NameError:
    _DARF_OLD_LMA = None

class _LabelMappingAdapter(_DARF_OLD_LMA if _DARF_OLD_LMA else object):
    def __init__(self, inner, label_map=None, label_map_default=None):
        if _DARF_OLD_LMA:
            try:
                super().__init__(inner, label_map, label_map_default)
                return
            except Exception:
                pass
        self._inner = inner
        self._label_map = dict(label_map or {})
        self._label_map_default = label_map_default
    def __getattr__(self, name):
        return getattr(self._inner, name)
    def _map(self, lab):
        if lab in self._label_map:
            return self._label_map[lab]
        return self._label_map_default if (self._label_map_default is not None) else lab
    def predict(self, *args, **kwargs):
        for rec in self._inner.predict(*args, **kwargs):
            # Get spans list from dict or object
            if isinstance(rec, dict):
                spans = rec.get("spans", [])
            else:
                spans = getattr(rec, "spans", [])
            if isinstance(spans, list):
                for s in spans:
                    if isinstance(s, dict):
                        if "label" in s:
                            s["label"] = self._map(s["label"])
                    else:
                        if hasattr(s, "label"):
                            try:
                                setattr(s, "label", self._map(getattr(s, "label", None)))
                            except Exception:
                                pass
            yield rec
# === end DARF robust label-map adapter ===

# === DARF final mapping enforcer (always-last get_adapter) ===
try:
    _darf_prev_get_adapter_final = get_adapter
except NameError:
    _darf_prev_get_adapter_final = None

def get_adapter(config):  # DARF final_map_enforcer
    cfg = config or {}
    # 1) Obtain whatever the previous factory would return (HF, heuristic, etc.)
    try:
        inst = _darf_prev_get_adapter_final(cfg)
    except Exception:
        try:
            inst = HeuristicAdapter(cfg)
        except Exception:
            inst = None
    # 2) If a label map/default is present, wrap with _LabelMappingAdapter; else return inst
    lm = (cfg.get("label_map") or {})
    default = cfg.get("label_map_default", None)
    try:
        if lm or (default is not None):
            return _LabelMappingAdapter(inst, lm, default)
    except NameError:
        pass
    return inst
