import os, re
from typing import Iterable, Dict, Any, List

class Prediction:
    def __init__(self, spans: List[Dict[str, Any]], relations: List[Dict[str, Any]]):
        self.spans = spans
        self.relations = relations

class BaseAdapter:
    def __init__(self, cfg: Dict[str, Any]):
        self.cfg = cfg
    def predict(self, sents: Iterable[Dict[str, Any]]) -> Iterable[Prediction]:
        raise NotImplementedError

def _try_import_text2nkg():
    try:
        import text2nkg  # type: ignore
        return text2nkg
    except Exception:
        return None

def _has_hf_stack():
    try:
        import torch  # noqa
        import transformers  # noqa
        return True
    except Exception:
        return False

class Text2NKGAdapter(BaseAdapter):
    def __init__(self, cfg: Dict[str, Any]):
        super().__init__(cfg)
        self.impl = _try_import_text2nkg()
        if self.impl is None:
            raise RuntimeError("text2nkg package not available (prefer_text2nkg was True)")
    def predict(self, sents: Iterable[Dict[str, Any]]) -> Iterable[Prediction]:
        # TODO: wire real text2nkg inference once package is present.
        for _ in sents:
            yield Prediction(spans=[], relations=[])

class HFBaselineAdapter(BaseAdapter):
    def __init__(self, cfg: Dict[str, Any]):
        super().__init__(cfg)
        from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline
        model_path = os.path.expanduser(cfg.get("ner_model_path","~/.darf/models/scibert"))
        local_only = bool(cfg.get("local_files_only", True))
        self.tok = AutoTokenizer.from_pretrained(model_path, local_files_only=local_only)
        self.mdl = AutoModelForTokenClassification.from_pretrained(model_path, local_files_only=local_only)
        self.pipe = pipeline(
            "token-classification",
            model=self.mdl,
            tokenizer=self.tok,
            aggregation_strategy="simple",
            device=0 if cfg.get("cuda", True) else -1
        )
    def predict(self, sents: Iterable[Dict[str, Any]]) -> Iterable[Prediction]:
        for s in sents:
            text = s["text"]
            ents = self.pipe(text)
            spans=[]
            for e in ents:
                spans.append({"start": int(e["start"]), "end": int(e["end"]), "label": str(e.get("entity_group","ENT"))})
            rels=[]
            for i in range(len(spans)):
                for j in range(i+1, len(spans)):
                    rels.append({"h": i, "t": j, "type": "CO_OCCUR"})
            yield Prediction(spans=spans, relations=rels)

class HeuristicAdapter(BaseAdapter):
    """
    Deterministic, offline-only fallback:
    - Tokenize on word boundaries
    - Emit spans for tokens with length>=4 or TitleCase
    - Pairwise CO_OCCUR relations within each sentence
    """
    _word = re.compile(r"\b\w+\b", re.UNICODE)
    def predict(self, sents: Iterable[Dict[str, Any]]) -> Iterable[Prediction]:
        for s in sents:
            text = s["text"]
            spans=[]
            for m in self._word.finditer(text):
                tok = m.group(0)
                if len(tok) >= 4 or (tok[:1].isupper() and tok[1:].islower()):
                    spans.append({"start": m.start(), "end": m.end(), "label": "HEUR"})
            rels=[]
            for i in range(len(spans)):
                for j in range(i+1, min(i+6, len(spans))):  # local window to bound density
                    rels.append({"h": i, "t": j, "type": "CO_OCCUR"})
            yield Prediction(spans=spans, relations=rels)

def get_adapter(cfg: Dict[str, Any]) -> BaseAdapter:
    mode = (os.getenv("T2NKG_ADAPTER","") or str(cfg.get("force_adapter",""))).lower()
    if mode in {"heuristic","heur","h"}:
        try:
            from tools.text2nkg.adapter import HeuristicAdapter  # self-ref ok after exec
        except Exception:
            pass
        return HeuristicAdapter(cfg)
    prefer_text2nkg = cfg.get("prefer_text2nkg", True)
    if prefer_text2nkg:
        t2 = _try_import_text2nkg()
        if t2 is not None:
            return Text2NKGAdapter(cfg)
    if _has_hf_stack():
        try:
            return HFBaselineAdapter(cfg)
        except Exception:
            pass  # fall through to heuristic
    return HeuristicAdapter(cfg)

def get_adapter(cfg):
    """Return an adapter instance based on cfg.
    - default: 'hf' if ner_model_path{,_map} present, else 'heuristic'
    - robust: on HF errors, fall back to HeuristicAdapter and annotate cfg.
    """
    want = (cfg.get("adapter") or
            ("hf" if (cfg.get("ner_model_path") or cfg.get("ner_model_path_map")) else "heuristic")).lower()
    if want in {"hf","hfbaseline","hf-baseline","transformers"}:
        try:
            return HFBaselineAdapter(cfg)
        except Exception as e:
            # Do not crash scoring; record why we fell back.
            try:
                cfg["_adapter_warning"] = f"hf_fallback:{type(e).__name__}"
            except Exception:
                pass
            return HeuristicAdapter(cfg)
    # default / explicit heuristic
    return HeuristicAdapter(cfg)

# === DARF minimal label-map wrapper (append-only; no subclassing) ===
import re as _re_darf
def _darf_canon(x):
    return _re_darf.sub(r'[^a-z0-9]+','', str(x).lower()) if x is not None else None

class _DARF_MapWrap:
    def __init__(self, inner, label_map=None, label_map_default=None):
        self.inner = inner
        lm = label_map or {}
        # Canonicalize keys once
        self._map = { _darf_canon(k): v for k, v in lm.items() } if isinstance(lm, dict) else {}
        self._default = label_map_default
    def _map_label(self, lab):
        key = _darf_canon(lab)
        if key in self._map: return self._map[key]
        return self._default if self._default is not None else lab
    def predict(self, sentences):
        # Expect inner.predict to yield dicts with .spans (start,end,label)
        for rec in self.inner.predict(sentences):
            d = rec if isinstance(rec, dict) else {"id": getattr(rec,"id",None),
                                                   "text_len": getattr(rec,"text_len",None),
                                                   "spans": getattr(rec,"spans",[])}
            spans = []
            for s in (d.get("spans") or []):
                if not isinstance(s, dict): 
                    # try attribute-style
                    s = {"start": getattr(s,"start",None),
                         "end": getattr(s,"end",None),
                         "label": getattr(s,"label",None)}
                spans.append({"start": s.get("start"),
                              "end": s.get("end"),
                              "label": self._map_label(s.get("label"))})
            d["spans"] = spans
            yield d

# === DARF single HF-first factory (final) ===
try:
    _darf_prev_factory = get_adapter
except NameError:
    _darf_prev_factory = None

def get_adapter(config):
    cfg = config or {}
    # Try HF baseline first
    try:
        inst = HFBaselineAdapter(cfg)
    except Exception:
        # Fallback to prior factory (may choose heuristic); else heuristic
        if _darf_prev_factory:
            try:
                inst = _darf_prev_factory(cfg)
            except Exception:
                inst = HeuristicAdapter(cfg)
        else:
            inst = HeuristicAdapter(cfg)
    # Always layer mapping if provided
    lm, default = cfg.get("label_map"), cfg.get("label_map_default")
    if (isinstance(lm, dict) and lm) or (default is not None):
        try:
            inst = _DARF_MapWrap(inst, label_map=lm, label_map_default=default)
        except Exception:
            pass
    return inst

class _DARF_MapWrap(object):
    def __init__(self, inner, label_map=None, label_map_default=None):
        self.inner = inner
        self.lmap = { (str(k).lower().strip() if k is not None else None): v for k,v in (label_map or {}).items() }
        self.lmap_default = label_map_default
    def _get_spans(self, rec):
        if isinstance(rec, dict):
            for s in rec.get("spans",[]) or []:
                if isinstance(s, dict):
                    yield {"start": s.get("start"), "end": s.get("end"), "label": s.get("label")}
        else:
            for s in getattr(rec,"spans",[]) or []:
                if isinstance(s, dict):
                    yield {"start": s.get("start"), "end": s.get("end"), "label": s.get("label")}
                else:
                    yield {"start": getattr(s,"start",None), "end": getattr(s,"end",None), "label": getattr(s,"label",None)}
    def _map_label(self, lab):
        key = (str(lab).lower().strip() if lab is not None else None)
        if key in self.lmap: return self.lmap[key]
        if self.lmap_default is not None: return self.lmap_default
        return lab
    def predict(self, sentences):
        for rec in self.inner.predict(sentences):
            rid = rec.get("id") if isinstance(rec,dict) else getattr(rec,"id",None)
            tlen = rec.get("text_len") if isinstance(rec,dict) else getattr(rec,"text_len",None)
            out = []
            for s in self._get_spans(rec):
                st,en,lab = s["start"], s["end"], self._map_label(s["label"])
                if st is not None and en is not None and st < en:
                    out.append({"start":st,"end":en,"label":lab})
            yield {"id":rid,"text_len":tlen,"spans":out}
