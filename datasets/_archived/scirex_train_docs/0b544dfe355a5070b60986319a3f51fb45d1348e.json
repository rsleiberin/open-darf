{"coref": {"BLEU_score": [[1739, 1741], [1807, 1809], [3217, 3219], [3737, 3739], [5051, 5053]], "CSLM": [[3544, 3545], [3556, 3557], [3754, 3755], [3801, 3802], [3835, 3836], [3840, 3841], [3883, 3884], [3902, 3903], [3596, 3597]], "CSLM___RNN___WP": [], "Machine_Translation": [[11, 14], [97, 101], [239, 242], [243, 245], [284, 285], [443, 444], [513, 514], [1623, 1626], [1630, 1634], [1635, 1637], [2258, 2260], [2284, 2285], [2900, 2903], [4522, 4524], [4970, 4973], [1691, 1692], [1751, 1752], [1954, 1955], [2893, 2894]], "RNN": [[34, 37], [38, 39], [42, 43], [332, 335], [336, 337], [615, 618], [619, 622], [658, 659], [699, 700], [909, 910], [967, 968], [985, 986], [1008, 1009], [1497, 1498], [2631, 2634], [2666, 2667], [2820, 2823], [3832, 3833], [3837, 3838], [3842, 3843], [4715, 4717], [6, 7], [26, 27], [117, 118], [324, 325], [427, 428], [507, 508], [521, 522], [545, 546], [581, 582], [607, 608], [623, 624], [807, 808], [931, 932], [1098, 1099], [1172, 1173], [1902, 1903], [1912, 1913], [1961, 1962], [2019, 2020], [2074, 2075], [2125, 2126], [2185, 2186], [2201, 2202], [2300, 2301], [2411, 2412], [2578, 2579], [2695, 2696], [2722, 2723], [2757, 2758], [3094, 3095], [3146, 3147], [3241, 3242], [3246, 3247], [3375, 3376], [3442, 3443], [3520, 3521], [3567, 3568], [3890, 3891], [3905, 3906], [4031, 4032], [4097, 4098], [4177, 4178], [4225, 4226], [4259, 4260], [4276, 4277], [4301, 4302], [4338, 4339], [4352, 4353], [4400, 4401], [4431, 4432], [4492, 4493], [4509, 4510], [4569, 4570], [4628, 4629], [4677, 4678], [4755, 4756], [4856, 4857], [4891, 4892], [4978, 4979], [5018, 5019], [5036, 5037], [5063, 5064], [5098, 5099], [5156, 5157], [5196, 5197], [5300, 5301], [5316, 5317]], "WMT2014_English-French": [[445, 448], [2982, 2984], [3168, 3171]], "WP": []}, "coref_non_salient": {"0": [[209, 212], [5146, 5150]], "1": [[3385, 3394], [3419, 3422]], "10": [[172, 174], [181, 183]], "11": [[22, 25], [197, 199], [281, 283], [627, 629], [1820, 1822], [1834, 1836], [1865, 1867], [2255, 2257], [2278, 2280], [2383, 2385], [2398, 2400], [2492, 2494], [3140, 3142], [3535, 3537], [3578, 3580], [3863, 3865], [3940, 3942], [4550, 4552], [5076, 5078]], "12": [[3564, 3566]], "13": [[2849, 2850], [3682, 3684], [3699, 3700]], "14": [[69, 70], [71, 72], [342, 343], [349, 350], [366, 367], [906, 907], [1146, 1147], [1644, 1645], [2673, 2674], [2787, 2790], [2810, 2811], [2825, 2826], [3264, 3265], [3268, 3269], [5419, 5420], [5496, 5497], [5520, 5521], [5548, 5549], [5560, 5561], [5569, 5570], [5583, 5584]], "15": [[3830, 3831], [3833, 3834], [3838, 3839], [2879, 2880], [3828, 3829]], "16": [[1994, 1996], [3749, 3751], [5614, 5616]], "17": [[1089, 1091], [1262, 1264]], "18": [[292, 295], [313, 316], [819, 822], [4850, 4853]], "19": [[4545, 4549]], "2": [[688, 697], [1290, 1292], [1492, 1494]], "20": [[1827, 1829], [2357, 2359], [2538, 2540], [2844, 2846], [3553, 3555], [3585, 3587], [5080, 5082]], "21": [[143, 144], [4556, 4557], [4652, 4653], [4813, 4814]], "22": [[587, 590], [4684, 4691]], "23": [[1812, 1816], [5104, 5108]], "24": [[3740, 3745]], "25": [[3362, 3364]], "26": [[3358, 3360]], "27": [[3436, 3439]], "28": [[569, 571], [5046, 5048]], "29": [[2555, 2561], [2609, 2615]], "3": [[502, 505], [2293, 2296], [2353, 2355]], "30": [[160, 163], [246, 249], [3352, 3355]], "31": [[2872, 2874]], "32": [[128, 132], [1696, 1700], [1786, 1790], [1939, 1943], [3969, 3973]], "33": [[417, 419]], "34": [[225, 227], [3078, 3080]], "35": [[3114, 3115]], "36": [[3652, 3654]], "37": [[5444, 5448]], "38": [[5238, 5240]], "39": [[3820, 3822]], "4": [[3, 5], [4502, 4506], [5640, 5644], [5652, 5656]], "40": [[3636, 3638]], "41": [[268, 273], [305, 310], [479, 484], [3200, 3205]], "42": [[2625, 2629], [2660, 2664]], "43": [[3108, 3110]], "44": [[677, 683], [1342, 1345], [5439, 5442]], "45": [[1600, 1602]], "46": [[3047, 3050]], "47": [[3844, 3846]], "48": [[3809, 3813]], "49": [[3434, 3435]], "5": [[50, 55], [369, 371], [833, 838], [843, 848]], "50": [[2801, 2805]], "51": [[231, 234]], "52": [[2835, 2840]], "53": [[2993, 2995]], "54": [[2865, 2870]], "55": [[2816, 2818]], "56": [[1073, 1074]], "57": [[228, 230]], "58": [[738, 745]], "59": [[3111, 3113]], "6": [[1676, 1678], [3540, 3543], [3695, 3697]], "60": [[3727, 3729]], "61": [[423, 424]], "62": [[784, 786]], "63": [[2225, 2227]], "64": [[1160, 1164]], "65": [[2157, 2159]], "66": [[3208, 3209]], "67": [[213, 215]], "68": [[145, 148]], "69": [[4622, 4625]], "7": [[434, 436], [1250, 1252], [1313, 1315], [1326, 1328], [1523, 1525], [1533, 1535], [4932, 4934], [4949, 4951]], "70": [[1516, 1520]], "71": [[2645, 2647]], "72": [[1512, 1514]], "73": [[3447, 3448]], "74": [[665, 670]], "75": [[2806, 2808]], "76": [[4009, 4011]], "77": [[1840, 1843]], "78": [[751, 754]], "79": [[2164, 2165]], "8": [[261, 264], [2309, 2312], [2434, 2437], [2544, 2547]], "80": [[2952, 2955]], "81": [[2515, 2516]], "82": [[2763, 2767]], "83": [[3504, 3507]], "84": [[536, 538], [1671, 1673], [1758, 1760], [2440, 2442], [4040, 4042], [4046, 4048], [4220, 4222], [4297, 4299]], "85": [[3769, 3772]], "9": [[4641, 4646], [4734, 4739]]}, "doc_id": "0b544dfe355a5070b60986319a3f51fb45d1348e", "method_subrelations": {"CSLM___RNN___WP": [[[0, 4], "CSLM"], [[7, 10], "RNN"], [[13, 15], "WP"]]}, "n_ary_relations": [{"Material": "WMT2014_English-French", "Method": "CSLM___RNN___WP", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "34.54"}], "ner": [[3, 5, "Method"], [11, 14, "Task"], [22, 25, "Method"], [34, 37, "Method"], [38, 39, "Method"], [42, 43, "Method"], [50, 55, "Method"], [69, 70, "Method"], [71, 72, "Method"], [97, 101, "Task"], [128, 132, "Method"], [143, 144, "Method"], [145, 148, "Method"], [160, 163, "Method"], [172, 174, "Task"], [181, 183, "Task"], [197, 199, "Method"], [209, 212, "Task"], [213, 215, "Task"], [225, 227, "Task"], [228, 230, "Task"], [231, 234, "Task"], [239, 242, "Task"], [243, 245, "Task"], [246, 249, "Method"], [261, 264, "Method"], [268, 273, "Method"], [281, 283, "Method"], [284, 285, "Task"], [292, 295, "Method"], [305, 310, "Method"], [313, 316, "Method"], [332, 335, "Method"], [336, 337, "Method"], [342, 343, "Method"], [349, 350, "Method"], [366, 367, "Method"], [369, 371, "Method"], [417, 419, "Metric"], [423, 424, "Task"], [434, 436, "Method"], [443, 444, "Task"], [445, 448, "Material"], [479, 484, "Method"], [502, 505, "Task"], [513, 514, "Task"], [536, 538, "Method"], [569, 571, "Metric"], [587, 590, "Method"], [615, 618, "Method"], [619, 622, "Method"], [627, 629, "Method"], [658, 659, "Method"], [665, 670, "Method"], [677, 683, "Method"], [688, 697, "Method"], [699, 700, "Method"], [738, 745, "Method"], [751, 754, "Method"], [784, 786, "Method"], [819, 822, "Method"], [833, 838, "Method"], [843, 848, "Method"], [906, 907, "Method"], [909, 910, "Method"], [967, 968, "Method"], [985, 986, "Method"], [1008, 1009, "Method"], [1073, 1074, "Method"], [1089, 1091, "Method"], [1146, 1147, "Method"], [1160, 1164, "Method"], [1250, 1252, "Method"], [1262, 1264, "Method"], [1290, 1292, "Method"], [1313, 1315, "Method"], [1326, 1328, "Method"], [1342, 1345, "Method"], [1492, 1494, "Method"], [1497, 1498, "Method"], [1512, 1514, "Method"], [1516, 1520, "Method"], [1523, 1525, "Method"], [1533, 1535, "Method"], [1600, 1602, "Method"], [1623, 1626, "Task"], [1630, 1634, "Task"], [1635, 1637, "Task"], [1644, 1645, "Method"], [1671, 1673, "Method"], [1676, 1678, "Method"], [1696, 1700, "Method"], [1739, 1741, "Metric"], [1758, 1760, "Method"], [1786, 1790, "Method"], [1807, 1809, "Metric"], [1812, 1816, "Method"], [1820, 1822, "Method"], [1827, 1829, "Method"], [1834, 1836, "Method"], [1840, 1843, "Task"], [1865, 1867, "Method"], [1939, 1943, "Method"], [1994, 1996, "Metric"], [2157, 2159, "Method"], [2164, 2165, "Metric"], [2225, 2227, "Method"], [2255, 2257, "Method"], [2258, 2260, "Task"], [2278, 2280, "Method"], [2284, 2285, "Task"], [2293, 2296, "Task"], [2309, 2312, "Method"], [2353, 2355, "Task"], [2357, 2359, "Method"], [2383, 2385, "Method"], [2398, 2400, "Method"], [2434, 2437, "Method"], [2440, 2442, "Method"], [2492, 2494, "Method"], [2515, 2516, "Method"], [2538, 2540, "Method"], [2544, 2547, "Method"], [2555, 2561, "Method"], [2609, 2615, "Method"], [2625, 2629, "Method"], [2631, 2634, "Method"], [2645, 2647, "Task"], [2660, 2664, "Method"], [2666, 2667, "Method"], [2673, 2674, "Method"], [2763, 2767, "Method"], [2787, 2790, "Method"], [2801, 2805, "Method"], [2806, 2808, "Method"], [2810, 2811, "Method"], [2816, 2818, "Method"], [2820, 2823, "Method"], [2825, 2826, "Method"], [2835, 2840, "Task"], [2844, 2846, "Method"], [2849, 2850, "Metric"], [2865, 2870, "Task"], [2872, 2874, "Material"], [2900, 2903, "Task"], [2952, 2955, "Method"], [2982, 2984, "Material"], [2993, 2995, "Method"], [3047, 3050, "Method"], [3078, 3080, "Task"], [3108, 3110, "Task"], [3111, 3113, "Task"], [3114, 3115, "Method"], [3140, 3142, "Method"], [3168, 3171, "Material"], [3200, 3205, "Method"], [3208, 3209, "Method"], [3217, 3219, "Metric"], [3264, 3265, "Method"], [3268, 3269, "Method"], [3352, 3355, "Method"], [3358, 3360, "Method"], [3362, 3364, "Method"], [3385, 3394, "Method"], [3419, 3422, "Method"], [3434, 3435, "Method"], [3436, 3439, "Method"], [3447, 3448, "Method"], [3504, 3507, "Method"], [3535, 3537, "Method"], [3540, 3543, "Method"], [3544, 3545, "Method"], [3553, 3555, "Method"], [3556, 3557, "Method"], [3564, 3566, "Method"], [3578, 3580, "Method"], [3585, 3587, "Method"], [3636, 3638, "Method"], [3652, 3654, "Method"], [3682, 3684, "Metric"], [3695, 3697, "Method"], [3699, 3700, "Metric"], [3727, 3729, "Task"], [3737, 3739, "Metric"], [3740, 3745, "Method"], [3749, 3751, "Metric"], [3754, 3755, "Method"], [3769, 3772, "Task"], [3801, 3802, "Method"], [3809, 3813, "Task"], [3820, 3822, "Task"], [3830, 3831, "Method"], [3832, 3833, "Method"], [3833, 3834, "Method"], [3835, 3836, "Method"], [3837, 3838, "Method"], [3838, 3839, "Method"], [3840, 3841, "Method"], [3842, 3843, "Method"], [3844, 3846, "Method"], [3863, 3865, "Method"], [3883, 3884, "Method"], [3902, 3903, "Method"], [3940, 3942, "Method"], [3969, 3973, "Method"], [4009, 4011, "Method"], [4040, 4042, "Method"], [4046, 4048, "Method"], [4220, 4222, "Method"], [4297, 4299, "Method"], [4502, 4506, "Method"], [4522, 4524, "Task"], [4545, 4549, "Method"], [4550, 4552, "Method"], [4622, 4625, "Method"], [4641, 4646, "Method"], [4684, 4691, "Method"], [4715, 4717, "Method"], [4850, 4853, "Method"], [4932, 4934, "Method"], [4949, 4951, "Method"], [4970, 4973, "Task"], [5046, 5048, "Metric"], [5051, 5053, "Metric"], [5076, 5078, "Method"], [5080, 5082, "Method"], [5104, 5108, "Method"], [5146, 5150, "Task"], [5238, 5240, "Task"], [5419, 5420, "Method"], [5439, 5442, "Method"], [5444, 5448, "Method"], [5496, 5497, "Method"], [5520, 5521, "Method"], [5548, 5549, "Method"], [5560, 5561, "Method"], [5569, 5570, "Method"], [5583, 5584, "Method"], [5614, 5616, "Metric"], [5640, 5644, "Method"], [5652, 5656, "Method"], [6, 7, "Method"], [26, 27, "Method"], [117, 118, "Method"], [324, 325, "Method"], [427, 428, "Method"], [507, 508, "Method"], [521, 522, "Method"], [545, 546, "Method"], [581, 582, "Method"], [607, 608, "Method"], [623, 624, "Method"], [807, 808, "Method"], [931, 932, "Method"], [1098, 1099, "Method"], [1172, 1173, "Method"], [1691, 1692, "Task"], [1751, 1752, "Task"], [1902, 1903, "Method"], [1912, 1913, "Method"], [1954, 1955, "Task"], [1961, 1962, "Method"], [2019, 2020, "Method"], [2074, 2075, "Method"], [2125, 2126, "Method"], [2185, 2186, "Method"], [2201, 2202, "Method"], [2300, 2301, "Method"], [2411, 2412, "Method"], [2578, 2579, "Method"], [2695, 2696, "Method"], [2722, 2723, "Method"], [2757, 2758, "Method"], [2879, 2880, "Method"], [2893, 2894, "Task"], [3094, 3095, "Method"], [3146, 3147, "Method"], [3241, 3242, "Method"], [3246, 3247, "Method"], [3375, 3376, "Method"], [3442, 3443, "Method"], [3520, 3521, "Method"], [3567, 3568, "Method"], [3596, 3597, "Method"], [3828, 3829, "Method"], [3890, 3891, "Method"], [3905, 3906, "Method"], [4031, 4032, "Method"], [4097, 4098, "Method"], [4177, 4178, "Method"], [4225, 4226, "Method"], [4259, 4260, "Method"], [4276, 4277, "Method"], [4301, 4302, "Method"], [4338, 4339, "Method"], [4352, 4353, "Method"], [4400, 4401, "Method"], [4431, 4432, "Method"], [4492, 4493, "Method"], [4509, 4510, "Method"], [4556, 4557, "Method"], [4569, 4570, "Method"], [4628, 4629, "Method"], [4652, 4653, "Method"], [4677, 4678, "Method"], [4734, 4739, "Method"], [4755, 4756, "Method"], [4813, 4814, "Method"], [4856, 4857, "Method"], [4891, 4892, "Method"], [4978, 4979, "Method"], [5018, 5019, "Method"], [5036, 5037, "Method"], [5063, 5064, "Method"], [5098, 5099, "Method"], [5156, 5157, "Method"], [5196, 5197, "Method"], [5300, 5301, "Method"], [5316, 5317, "Method"]], "sections": [[0, 157], [157, 605], [605, 611], [611, 805], [805, 1248], [1248, 1621], [1621, 1896], [1896, 2250], [2250, 2856], [2856, 2875], [2875, 3239], [3239, 3502], [3502, 3818], [3818, 4007], [4007, 4500], [4500, 4839], [4839, 5241], [5241, 5295], [5295, 5298], [5298, 5382], [5382, 5494], [5494, 5638], [5638, 5669]], "sentences": [[0, 14], [14, 41], [41, 68], [68, 93], [93, 133], [133, 152], [152, 157], [157, 160], [160, 190], [190, 216], [216, 235], [235, 256], [256, 274], [274, 311], [311, 348], [348, 380], [380, 400], [400, 425], [425, 449], [449, 468], [468, 494], [494, 516], [516, 539], [539, 572], [572, 605], [605, 611], [611, 618], [618, 648], [648, 671], [671, 698], [698, 720], [720, 734], [734, 768], [768, 805], [805, 811], [811, 856], [856, 905], [905, 920], [920, 937], [937, 943], [943, 977], [977, 1004], [1004, 1013], [1013, 1032], [1032, 1076], [1076, 1079], [1079, 1092], [1092, 1137], [1137, 1170], [1170, 1188], [1188, 1205], [1205, 1236], [1236, 1248], [1248, 1257], [1257, 1278], [1278, 1301], [1301, 1303], [1303, 1316], [1316, 1331], [1331, 1356], [1356, 1368], [1368, 1376], [1376, 1428], [1428, 1457], [1457, 1483], [1483, 1505], [1505, 1521], [1521, 1545], [1545, 1583], [1583, 1603], [1603, 1621], [1621, 1626], [1626, 1685], [1685, 1719], [1719, 1731], [1731, 1746], [1746, 1776], [1776, 1794], [1794, 1810], [1810, 1830], [1830, 1843], [1843, 1848], [1848, 1855], [1855, 1889], [1889, 1896], [1896, 1906], [1906, 1920], [1920, 1946], [1946, 1951], [1951, 1957], [1957, 1982], [1982, 2039], [2039, 2068], [2068, 2123], [2123, 2147], [2147, 2166], [2166, 2190], [2190, 2218], [2218, 2232], [2232, 2250], [2250, 2260], [2260, 2286], [2286, 2297], [2297, 2347], [2347, 2371], [2371, 2409], [2409, 2423], [2423, 2457], [2457, 2486], [2486, 2511], [2511, 2541], [2541, 2570], [2570, 2604], [2604, 2621], [2621, 2656], [2656, 2689], [2689, 2721], [2721, 2750], [2750, 2774], [2774, 2791], [2791, 2827], [2827, 2856], [2856, 2859], [2859, 2875], [2875, 2881], [2881, 2904], [2904, 2941], [2941, 2949], [2949, 2976], [2976, 2987], [2987, 3022], [3022, 3040], [3040, 3059], [3059, 3099], [3099, 3123], [3123, 3137], [3137, 3172], [3172, 3181], [3181, 3198], [3198, 3213], [3213, 3239], [3239, 3245], [3245, 3270], [3270, 3298], [3298, 3317], [3317, 3325], [3325, 3336], [3336, 3369], [3369, 3408], [3408, 3432], [3432, 3450], [3450, 3475], [3475, 3484], [3484, 3502], [3502, 3507], [3507, 3547], [3547, 3593], [3593, 3607], [3607, 3629], [3629, 3646], [3646, 3658], [3658, 3665], [3665, 3691], [3691, 3703], [3703, 3717], [3717, 3746], [3746, 3777], [3777, 3803], [3803, 3818], [3818, 3822], [3822, 3846], [3846, 3856], [3856, 3874], [3874, 3895], [3895, 3926], [3926, 3953], [3953, 3976], [3976, 3982], [3982, 4007], [4007, 4011], [4011, 4043], [4043, 4080], [4080, 4089], [4089, 4130], [4130, 4152], [4152, 4182], [4182, 4203], [4203, 4230], [4230, 4247], [4247, 4271], [4271, 4286], [4286, 4323], [4323, 4328], [4328, 4373], [4373, 4405], [4405, 4426], [4426, 4452], [4452, 4470], [4470, 4500], [4500, 4506], [4506, 4537], [4537, 4566], [4566, 4604], [4604, 4610], [4610, 4633], [4633, 4647], [4647, 4670], [4670, 4675], [4675, 4692], [4692, 4698], [4698, 4712], [4712, 4742], [4742, 4746], [4746, 4769], [4769, 4801], [4801, 4821], [4821, 4839], [4839, 4842], [4842, 4889], [4889, 4922], [4922, 4961], [4961, 4992], [4992, 5032], [5032, 5054], [5054, 5110], [5110, 5139], [5139, 5161], [5161, 5173], [5173, 5204], [5204, 5241], [5241, 5244], [5244, 5272], [5272, 5295], [5295, 5298], [5298, 5304], [5304, 5325], [5325, 5338], [5338, 5366], [5366, 5382], [5382, 5385], [5385, 5406], [5406, 5414], [5414, 5451], [5451, 5461], [5461, 5469], [5469, 5494], [5494, 5497], [5497, 5522], [5522, 5542], [5542, 5558], [5558, 5578], [5578, 5612], [5612, 5638], [5638, 5644], [5644, 5659], [5659, 5662], [5662, 5667], [5667, 5669]], "words": ["document", ":", "Learning", "Phrase", "Representations", "using", "RNN", "Encoder", "\u2013", "Decoder", "for", "Statistical", "Machine", "Translation", "In", "this", "paper", ",", "we", "propose", "a", "novel", "neural", "network", "model", "called", "RNN", "Encoder", "\u2013", "Decoder", "that", "consists", "of", "two", "recurrent", "neural", "networks", "(", "RNN", ")", ".", "One", "RNN", "encodes", "a", "sequence", "of", "symbols", "into", "a", "fixed", "-", "length", "vector", "representation", ",", "and", "the", "other", "decodes", "the", "representation", "into", "another", "sequence", "of", "symbols", ".", "The", "encoder", "and", "decoder", "of", "the", "proposed", "model", "are", "jointly", "trained", "to", "maximize", "the", "conditional", "probability", "of", "a", "target", "sequence", "given", "a", "source", "sequence", ".", "The", "performance", "of", "a", "statistical", "machine", "translation", "system", "is", "empirically", "found", "to", "improve", "by", "using", "the", "conditional", "probabilities", "of", "phrase", "pairs", "computed", "by", "the", "RNN", "Encoder", "\u2013", "Decoder", "as", "an", "additional", "feature", "in", "the", "existing", "log", "-", "linear", "model", ".", "Qualitatively", ",", "we", "show", "that", "the", "proposed", "model", "learns", "a", "semantically", "and", "syntactically", "meaningful", "representation", "of", "linguistic", "phrases", ".", "arxiv", "arxiv.", "/", "figures", "/", "section", ":", "Introduction", "Deep", "neural", "networks", "have", "shown", "great", "success", "in", "various", "applications", "such", "as", "objection", "recognition", "(", "see", ",", "e.g.", ",", ")", "and", "speech", "recognition", "(", "see", ",", "e.g.", ",", ")", ".", "Furthermore", ",", "many", "recent", "works", "showed", "that", "neural", "networks", "can", "be", "successfully", "used", "in", "a", "number", "of", "tasks", "in", "natural", "language", "processing", "(", "NLP", ")", ".", "These", "include", ",", "but", "are", "not", "limited", "to", ",", "language", "modeling", ",", "paraphrase", "detection", "and", "word", "embedding", "extraction", ".", "In", "the", "field", "of", "statistical", "machine", "translation", "(", "SMT", ")", ",", "deep", "neural", "networks", "have", "begun", "to", "show", "promising", "results", ".", "summarizes", "a", "successful", "usage", "of", "feedforward", "neural", "networks", "in", "the", "framework", "of", "phrase", "-", "based", "SMT", "system", ".", "Along", "this", "line", "of", "research", "on", "using", "neural", "networks", "for", "SMT", ",", "this", "paper", "focuses", "on", "a", "novel", "neural", "network", "architecture", "that", "can", "be", "used", "as", "a", "part", "of", "the", "conventional", "phrase", "-", "based", "SMT", "system", ".", "The", "proposed", "neural", "network", "architecture", ",", "which", "we", "will", "refer", "to", "as", "an", "RNN", "Encoder", "\u2013", "Decoder", ",", "consists", "of", "two", "recurrent", "neural", "networks", "(", "RNN", ")", "that", "act", "as", "an", "encoder", "and", "a", "decoder", "pair", ".", "The", "encoder", "maps", "a", "variable", "-", "length", "source", "sequence", "to", "a", "fixed", "-", "length", "vector", ",", "and", "the", "decoder", "maps", "the", "vector", "representation", "back", "to", "a", "variable", "-", "length", "target", "sequence", ".", "The", "two", "networks", "are", "trained", "jointly", "to", "maximize", "the", "conditional", "probability", "of", "the", "target", "sequence", "given", "a", "source", "sequence", ".", "Additionally", ",", "we", "propose", "to", "use", "a", "rather", "sophisticated", "hidden", "unit", "in", "order", "to", "improve", "both", "the", "memory", "capacity", "and", "the", "ease", "of", "training", ".", "The", "proposed", "RNN", "Encoder", "\u2013", "Decoder", "with", "a", "novel", "hidden", "unit", "is", "empirically", "evaluated", "on", "the", "task", "of", "translating", "from", "English", "to", "French", ".", "We", "train", "the", "model", "to", "learn", "the", "translation", "probability", "of", "an", "English", "phrase", "to", "a", "corresponding", "French", "phrase", ".", "The", "model", "is", "then", "used", "as", "a", "part", "of", "a", "standard", "phrase", "-", "based", "SMT", "system", "by", "scoring", "each", "phrase", "pair", "in", "the", "phrase", "table", ".", "The", "empirical", "evaluation", "reveals", "that", "this", "approach", "of", "scoring", "phrase", "pairs", "with", "an", "RNN", "Encoder", "\u2013", "Decoder", "improves", "the", "translation", "performance", ".", "We", "qualitatively", "analyze", "the", "trained", "RNN", "Encoder", "\u2013", "Decoder", "by", "comparing", "its", "phrase", "scores", "with", "those", "given", "by", "the", "existing", "translation", "model", ".", "The", "qualitative", "analysis", "shows", "that", "the", "RNN", "Encoder", "\u2013", "Decoder", "is", "better", "at", "capturing", "the", "linguistic", "regularities", "in", "the", "phrase", "table", ",", "indirectly", "explaining", "the", "quantitative", "improvements", "in", "the", "overall", "translation", "performance", ".", "The", "further", "analysis", "of", "the", "model", "reveals", "that", "the", "RNN", "Encoder", "\u2013", "Decoder", "learns", "a", "continuous", "space", "representation", "of", "a", "phrase", "that", "preserves", "both", "the", "semantic", "and", "syntactic", "structure", "of", "the", "phrase", ".", "section", ":", "RNN", "Encoder", "\u2013", "Decoder", "subsection", ":", "Preliminary", ":", "Recurrent", "Neural", "Networks", "A", "recurrent", "neural", "network", "(", "RNN", ")", "is", "a", "neural", "network", "that", "consists", "of", "a", "hidden", "state", "and", "an", "optional", "output", "which", "operates", "on", "a", "variable", "-", "length", "sequence", ".", "At", "each", "time", "step", ",", "the", "hidden", "state", "of", "the", "RNN", "is", "updated", "by", "where", "is", "a", "non", "-", "linear", "activation", "function", ".", "may", "be", "as", "simple", "as", "an", "element", "-", "wise", "logistic", "sigmoid", "function", "and", "as", "complex", "as", "a", "long", "short", "-", "term", "memory", "(", "LSTM", ")", "unit", ".", "An", "RNN", "can", "learn", "a", "probability", "distribution", "over", "a", "sequence", "by", "being", "trained", "to", "predict", "the", "next", "symbol", "in", "a", "sequence", ".", "In", "that", "case", ",", "the", "output", "at", "each", "timestep", "is", "the", "conditional", "distribution", ".", "For", "example", ",", "a", "multinomial", "distribution", "(", "-", "of", "-", "coding", ")", "can", "be", "output", "using", "a", "softmax", "activation", "function", "for", "all", "possible", "symbols", ",", "where", "are", "the", "rows", "of", "a", "weight", "matrix", ".", "By", "combining", "these", "probabilities", ",", "we", "can", "compute", "the", "probability", "of", "the", "sequence", "using", "From", "this", "learned", "distribution", ",", "it", "is", "straightforward", "to", "sample", "a", "new", "sequence", "by", "iteratively", "sampling", "a", "symbol", "at", "each", "time", "step", ".", "subsection", ":", "RNN", "Encoder", "\u2013", "Decoder", "In", "this", "paper", ",", "we", "propose", "a", "novel", "neural", "network", "architecture", "that", "learns", "to", "encode", "a", "variable", "-", "length", "sequence", "into", "a", "fixed", "-", "length", "vector", "representation", "and", "to", "decode", "a", "given", "fixed", "-", "length", "vector", "representation", "back", "into", "a", "variable", "-", "length", "sequence", ".", "From", "a", "probabilistic", "perspective", ",", "this", "new", "model", "is", "a", "general", "method", "to", "learn", "the", "conditional", "distribution", "over", "a", "variable", "-", "length", "sequence", "conditioned", "on", "yet", "another", "variable", "-", "length", "sequence", ",", "e.g.", ",", "where", "one", "should", "note", "that", "the", "input", "and", "output", "sequence", "lengths", "and", "may", "differ", ".", "The", "encoder", "is", "an", "RNN", "that", "reads", "each", "symbol", "of", "an", "input", "sequence", "sequentially", ".", "As", "it", "reads", "each", "symbol", ",", "the", "hidden", "state", "of", "the", "RNN", "changes", "according", "to", "Eq", ".", "(", "[", "reference", "]", ")", ".", "After", "reading", "the", "end", "of", "the", "sequence", "(", "marked", "by", "an", "end", "-", "of", "-", "sequence", "symbol", ")", ",", "the", "hidden", "state", "of", "the", "RNN", "is", "a", "summary", "of", "the", "whole", "input", "sequence", ".", "The", "decoder", "of", "the", "proposed", "model", "is", "another", "RNN", "which", "is", "trained", "to", "generate", "the", "output", "sequence", "by", "predicting", "the", "next", "symbol", "given", "the", "hidden", "state", ".", "However", ",", "unlike", "the", "RNN", "described", "in", "Sec", ".", "[", "reference", "]", ",", "both", "and", "are", "also", "conditioned", "on", "and", "on", "the", "summary", "of", "the", "input", "sequence", ".", "Hence", ",", "the", "hidden", "state", "of", "the", "decoder", "at", "time", "is", "computed", "by", ",", "and", "similarly", ",", "the", "conditional", "distribution", "of", "the", "next", "symbol", "is", "for", "given", "activation", "functions", "and", "(", "the", "latter", "must", "produce", "valid", "probabilities", ",", "e.g.", "with", "a", "softmax", ")", ".", "See", "Fig", ".", "[", "reference", "]", "for", "a", "graphical", "depiction", "of", "the", "proposed", "model", "architecture", ".", "The", "two", "components", "of", "the", "proposed", "RNN", "Encoder", "\u2013", "Decoder", "are", "jointly", "trained", "to", "maximize", "the", "conditional", "log", "-", "likelihood", "where", "is", "the", "set", "of", "the", "model", "parameters", "and", "each", "is", "an", "(", "input", "sequence", ",", "output", "sequence", ")", "pair", "from", "the", "training", "set", ".", "In", "our", "case", ",", "as", "the", "output", "of", "the", "decoder", ",", "starting", "from", "the", "input", ",", "is", "differentiable", ",", "we", "can", "use", "a", "gradient", "-", "based", "algorithm", "to", "estimate", "the", "model", "parameters", ".", "Once", "the", "RNN", "Encoder", "\u2013", "Decoder", "is", "trained", ",", "the", "model", "can", "be", "used", "in", "two", "ways", ".", "One", "way", "is", "to", "use", "the", "model", "to", "generate", "a", "target", "sequence", "given", "an", "input", "sequence", ".", "On", "the", "other", "hand", ",", "the", "model", "can", "be", "used", "to", "score", "a", "given", "pair", "of", "input", "and", "output", "sequences", ",", "where", "the", "score", "is", "simply", "a", "probability", "from", "Eqs", ".", "(", "[", "reference", "]", ")", "and", "(", "[", "reference", "]", ")", ".", "subsection", ":", "Hidden", "Unit", "that", "Adaptively", "Remembers", "and", "Forgets", "In", "addition", "to", "a", "novel", "model", "architecture", ",", "we", "also", "propose", "a", "new", "type", "of", "hidden", "unit", "(", "in", "Eq", ".", "(", "[", "reference", "]", ")", ")", "that", "has", "been", "motivated", "by", "the", "LSTM", "unit", "but", "is", "much", "simpler", "to", "compute", "and", "implement", ".", "Fig", ".", "[", "reference", "]", "shows", "the", "graphical", "depiction", "of", "the", "proposed", "hidden", "unit", ".", "Let", "us", "describe", "how", "the", "activation", "of", "the", "-", "th", "hidden", "unit", "is", "computed", ".", "First", ",", "the", "reset", "gate", "is", "computed", "by", "where", "is", "the", "logistic", "sigmoid", "function", ",", "and", "denotes", "the", "-", "th", "element", "of", "a", "vector", ".", "and", "are", "the", "input", "and", "the", "previous", "hidden", "state", ",", "respectively", ".", "and", "are", "weight", "matrices", "which", "are", "learned", ".", "Similarly", ",", "the", "update", "gate", "is", "computed", "by", "The", "actual", "activation", "of", "the", "proposed", "unit", "is", "then", "computed", "by", "where", "In", "this", "formulation", ",", "when", "the", "reset", "gate", "is", "close", "to", "0", ",", "the", "hidden", "state", "is", "forced", "to", "ignore", "the", "previous", "hidden", "state", "and", "reset", "with", "the", "current", "input", "only", ".", "This", "effectively", "allows", "the", "hidden", "state", "to", "drop", "any", "information", "that", "is", "found", "to", "be", "irrelevant", "later", "in", "the", "future", ",", "thus", ",", "allowing", "a", "more", "compact", "representation", ".", "On", "the", "other", "hand", ",", "the", "update", "gate", "controls", "how", "much", "information", "from", "the", "previous", "hidden", "state", "will", "carry", "over", "to", "the", "current", "hidden", "state", ".", "This", "acts", "similarly", "to", "the", "memory", "cell", "in", "the", "LSTM", "network", "and", "helps", "the", "RNN", "to", "remember", "long", "-", "term", "information", ".", "Furthermore", ",", "this", "may", "be", "considered", "an", "adaptive", "variant", "of", "a", "leaky", "-", "integration", "unit", ".", "As", "each", "hidden", "unit", "has", "separate", "reset", "and", "update", "gates", ",", "each", "hidden", "unit", "will", "learn", "to", "capture", "dependencies", "over", "different", "time", "scales", ".", "Those", "units", "that", "learn", "to", "capture", "short", "-", "term", "dependencies", "will", "tend", "to", "have", "reset", "gates", "that", "are", "frequently", "active", ",", "but", "those", "that", "capture", "longer", "-", "term", "dependencies", "will", "have", "update", "gates", "that", "are", "mostly", "active", ".", "In", "our", "preliminary", "experiments", ",", "we", "found", "that", "it", "is", "crucial", "to", "use", "this", "new", "unit", "with", "gating", "units", ".", "We", "were", "not", "able", "to", "get", "meaningful", "result", "with", "an", "oft", "-", "used", "unit", "without", "any", "gating", ".", "section", ":", "Statistical", "Machine", "Translation", "In", "a", "commonly", "used", "statistical", "machine", "translation", "system", "(", "SMT", ")", ",", "the", "goal", "of", "the", "system", "(", "decoder", ",", "specifically", ")", "is", "to", "find", "a", "translation", "given", "a", "source", "sentence", ",", "which", "maximizes", "where", "the", "first", "term", "at", "the", "right", "hand", "side", "is", "called", "translation", "model", "and", "the", "latter", "language", "model", "(", "see", ",", "e.g.", ",", ")", ".", "In", "practice", ",", "however", ",", "most", "SMT", "systems", "model", "as", "a", "log", "-", "linear", "model", "with", "additional", "features", "and", "corresponding", "weights", ":", "where", "and", "are", "the", "-", "th", "feature", "and", "weight", ",", "respectively", ".", "is", "a", "normalization", "constant", "that", "does", "not", "depend", "on", "the", "weights", ".", "The", "weights", "are", "often", "optimized", "to", "maximize", "the", "BLEU", "score", "on", "a", "development", "set", ".", "In", "the", "phrase", "-", "based", "SMT", "framework", "introduced", "in", "and", ",", "the", "translation", "model", "is", "factorized", "into", "the", "translation", "probabilities", "of", "matching", "phrases", "in", "the", "source", "and", "target", "sentences", ".", "These", "probabilities", "are", "once", "again", "considered", "additional", "features", "in", "the", "log", "-", "linear", "model", "(", "see", "Eq", ".", "(", "[", "reference", "]", ")", ")", "and", "are", "weighted", "accordingly", "to", "maximize", "the", "BLEU", "score", ".", "Since", "the", "neural", "net", "language", "model", "was", "proposed", "in", ",", "neural", "networks", "have", "been", "used", "widely", "in", "SMT", "systems", ".", "In", "many", "cases", ",", "neural", "networks", "have", "been", "used", "to", "rescore", "translation", "hypotheses", "(", "-", "best", "lists", ")", "(", "see", ",", "e.g.", ",", ")", ".", "Recently", ",", "however", ",", "there", "has", "been", "interest", "in", "training", "neural", "networks", "to", "score", "the", "translated", "sentence", "(", "or", "phrase", "pairs", ")", "using", "a", "representation", "of", "the", "source", "sentence", "as", "an", "additional", "input", ".", "See", ",", "e.g.", ",", ",", "and", ".", "subsection", ":", "Scoring", "Phrase", "Pairs", "with", "RNN", "Encoder", "\u2013", "Decoder", "Here", "we", "propose", "to", "train", "the", "RNN", "Encoder", "\u2013", "Decoder", "(", "see", "Sec", ".", "[", "reference", "]", ")", "on", "a", "table", "of", "phrase", "pairs", "and", "use", "its", "scores", "as", "additional", "features", "in", "the", "log", "-", "linear", "model", "in", "Eq", ".", "(", "[", "reference", "]", ")", "when", "tuning", "the", "SMT", "decoder", ".", "When", "we", "train", "the", "RNN", "Encoder", "\u2013", "Decoder", ",", "we", "ignore", "the", "(", "normalized", ")", "frequencies", "of", "each", "phrase", "pair", "in", "the", "original", "corpora", ".", "This", "measure", "was", "taken", "in", "order", "(", "1", ")", "to", "reduce", "the", "computational", "expense", "of", "randomly", "selecting", "phrase", "pairs", "from", "a", "large", "phrase", "table", "according", "to", "the", "normalized", "frequencies", "and", "(", "2", ")", "to", "ensure", "that", "the", "RNN", "Encoder", "\u2013", "Decoder", "does", "not", "simply", "learn", "to", "rank", "the", "phrase", "pairs", "according", "to", "their", "numbers", "of", "occurrences", ".", "One", "underlying", "reason", "for", "this", "choice", "was", "that", "the", "existing", "translation", "probability", "in", "the", "phrase", "table", "already", "reflects", "the", "frequencies", "of", "the", "phrase", "pairs", "in", "the", "original", "corpus", ".", "With", "a", "fixed", "capacity", "of", "the", "RNN", "Encoder", "\u2013", "Decoder", ",", "we", "try", "to", "ensure", "that", "most", "of", "the", "capacity", "of", "the", "model", "is", "focused", "toward", "learning", "linguistic", "regularities", ",", "i.e.", ",", "distinguishing", "between", "plausible", "and", "implausible", "translations", ",", "or", "learning", "the", "\u201c", "manifold", "\u201d", "(", "region", "of", "probability", "concentration", ")", "of", "plausible", "translations", ".", "Once", "the", "RNN", "Encoder", "\u2013", "Decoder", "is", "trained", ",", "we", "add", "a", "new", "score", "for", "each", "phrase", "pair", "to", "the", "existing", "phrase", "table", ".", "This", "allows", "the", "new", "scores", "to", "enter", "into", "the", "existing", "tuning", "algorithm", "with", "minimal", "additional", "overhead", "in", "computation", ".", "As", "Schwenk", "pointed", "out", "in", ",", "it", "is", "possible", "to", "completely", "replace", "the", "existing", "phrase", "table", "with", "the", "proposed", "RNN", "Encoder", "\u2013", "Decoder", ".", "In", "that", "case", ",", "for", "a", "given", "source", "phrase", ",", "the", "RNN", "Encoder", "\u2013", "Decoder", "will", "need", "to", "generate", "a", "list", "of", "(", "good", ")", "target", "phrases", ".", "This", "requires", ",", "however", ",", "an", "expensive", "sampling", "procedure", "to", "be", "performed", "repeatedly", ".", "In", "this", "paper", ",", "thus", ",", "we", "only", "consider", "rescoring", "the", "phrase", "pairs", "in", "the", "phrase", "table", ".", "subsection", ":", "Related", "Approaches", ":", "Neural", "Networks", "in", "Machine", "Translation", "Before", "presenting", "the", "empirical", "results", ",", "we", "discuss", "a", "number", "of", "recent", "works", "that", "have", "proposed", "to", "use", "neural", "networks", "in", "the", "context", "of", "SMT", ".", "Schwenk", "in", "proposed", "a", "similar", "approach", "of", "scoring", "phrase", "pairs", ".", "Instead", "of", "the", "RNN", "-", "based", "neural", "network", ",", "he", "used", "a", "feedforward", "neural", "network", "that", "has", "fixed", "-", "size", "inputs", "(", "7", "words", "in", "his", "case", ",", "with", "zero", "-", "padding", "for", "shorter", "phrases", ")", "and", "fixed", "-", "size", "outputs", "(", "7", "words", "in", "the", "target", "language", ")", ".", "When", "it", "is", "used", "specifically", "for", "scoring", "phrases", "for", "the", "SMT", "system", ",", "the", "maximum", "phrase", "length", "is", "often", "chosen", "to", "be", "small", ".", "However", ",", "as", "the", "length", "of", "phrases", "increases", "or", "as", "we", "apply", "neural", "networks", "to", "other", "variable", "-", "length", "sequence", "data", ",", "it", "is", "important", "that", "the", "neural", "network", "can", "handle", "variable", "-", "length", "input", "and", "output", ".", "The", "proposed", "RNN", "Encoder", "\u2013", "Decoder", "is", "well", "-", "suited", "for", "these", "applications", ".", "Similar", "to", ",", "Devlin", "et", "al", ".", "proposed", "to", "use", "a", "feedforward", "neural", "network", "to", "model", "a", "translation", "model", ",", "however", ",", "by", "predicting", "one", "word", "in", "a", "target", "phrase", "at", "a", "time", ".", "They", "reported", "an", "impressive", "improvement", ",", "but", "their", "approach", "still", "requires", "the", "maximum", "length", "of", "the", "input", "phrase", "(", "or", "context", "words", ")", "to", "be", "fixed", "a", "priori", ".", "Although", "it", "is", "not", "exactly", "a", "neural", "network", "they", "train", ",", "the", "authors", "of", "proposed", "to", "learn", "a", "bilingual", "embedding", "of", "words", "/", "phrases", ".", "They", "use", "the", "learned", "embedding", "to", "compute", "the", "distance", "between", "a", "pair", "of", "phrases", "which", "is", "used", "as", "an", "additional", "score", "of", "the", "phrase", "pair", "in", "an", "SMT", "system", ".", "In", ",", "a", "feedforward", "neural", "network", "was", "trained", "to", "learn", "a", "mapping", "from", "a", "bag", "-", "of", "-", "words", "representation", "of", "an", "input", "phrase", "to", "an", "output", "phrase", ".", "This", "is", "closely", "related", "to", "both", "the", "proposed", "RNN", "Encoder", "\u2013", "Decoder", "and", "the", "model", "proposed", "in", ",", "except", "that", "their", "input", "representation", "of", "a", "phrase", "is", "a", "bag", "-", "of", "-", "words", ".", "A", "similar", "approach", "of", "using", "bag", "-", "of", "-", "words", "representations", "was", "proposed", "in", "as", "well", ".", "Earlier", ",", "a", "similar", "encoder", "\u2013", "decoder", "model", "using", "two", "recursive", "neural", "networks", "was", "proposed", "in", ",", "but", "their", "model", "was", "restricted", "to", "a", "monolingual", "setting", ",", "i.e.", "the", "model", "reconstructs", "an", "input", "sentence", ".", "More", "recently", ",", "another", "encoder", "\u2013", "decoder", "model", "using", "an", "RNN", "was", "proposed", "in", ",", "where", "the", "decoder", "is", "conditioned", "on", "a", "representation", "of", "either", "a", "source", "sentence", "or", "a", "source", "context", ".", "One", "important", "difference", "between", "the", "proposed", "RNN", "Encoder", "\u2013", "Decoder", "and", "the", "approaches", "in", "and", "is", "that", "the", "order", "of", "the", "words", "in", "source", "and", "target", "phrases", "is", "taken", "into", "account", ".", "The", "RNN", "Encoder", "\u2013", "Decoder", "naturally", "distinguishes", "between", "sequences", "that", "have", "the", "same", "words", "but", "in", "a", "different", "order", ",", "whereas", "the", "aforementioned", "approaches", "effectively", "ignore", "order", "information", ".", "The", "closest", "approach", "related", "to", "the", "proposed", "RNN", "Encoder", "\u2013", "Decoder", "is", "the", "Recurrent", "Continuous", "Translation", "Model", "(", "Model", "2", ")", "proposed", "in", ".", "In", "their", "paper", ",", "they", "proposed", "a", "similar", "model", "that", "consists", "of", "an", "encoder", "and", "decoder", ".", "The", "difference", "with", "our", "model", "is", "that", "they", "used", "a", "convolutional", "-", "gram", "model", "(", "CGM", ")", "for", "the", "encoder", "and", "the", "hybrid", "of", "an", "inverse", "CGM", "and", "a", "recurrent", "neural", "network", "for", "the", "decoder", ".", "They", ",", "however", ",", "evaluated", "their", "model", "on", "rescoring", "the", "-", "best", "list", "proposed", "by", "the", "conventional", "SMT", "system", "and", "computing", "the", "perplexity", "of", "the", "gold", "standard", "translations", ".", "section", ":", "Experiments", "We", "evaluate", "our", "approach", "on", "the", "English", "/", "French", "translation", "task", "of", "the", "WMT\u201914", "workshop", ".", "subsection", ":", "Data", "and", "Baseline", "System", "Large", "amounts", "of", "resources", "are", "available", "to", "build", "an", "English", "/", "French", "SMT", "system", "in", "the", "framework", "of", "the", "WMT\u201914", "translation", "task", ".", "The", "bilingual", "corpora", "include", "Europarl", "(", "61", "M", "words", ")", ",", "news", "commentary", "(", "5.5", "M", ")", ",", "UN", "(", "421", "M", ")", ",", "and", "two", "crawled", "corpora", "of", "90", "M", "and", "780", "M", "words", "respectively", ".", "The", "last", "two", "corpora", "are", "quite", "noisy", ".", "To", "train", "the", "French", "language", "model", ",", "about", "712", "M", "words", "of", "crawled", "newspaper", "material", "is", "available", "in", "addition", "to", "the", "target", "side", "of", "the", "bitexts", ".", "All", "the", "word", "counts", "refer", "to", "French", "words", "after", "tokenization", ".", "It", "is", "commonly", "acknowledged", "that", "training", "statistical", "models", "on", "the", "concatenation", "of", "all", "this", "data", "does", "not", "necessarily", "lead", "to", "optimal", "performance", ",", "and", "results", "in", "extremely", "large", "models", "which", "are", "difficult", "to", "handle", ".", "Instead", ",", "one", "should", "focus", "on", "the", "most", "relevant", "subset", "of", "the", "data", "for", "a", "given", "task", ".", "We", "have", "done", "so", "by", "applying", "the", "data", "selection", "method", "proposed", "in", ",", "and", "its", "extension", "to", "bitexts", ".", "By", "these", "means", "we", "selected", "a", "subset", "of", "418", "M", "words", "out", "of", "more", "than", "2", "G", "words", "for", "language", "modeling", "and", "a", "subset", "of", "348", "M", "out", "of", "850", "M", "words", "for", "training", "the", "RNN", "Encoder", "\u2013", "Decoder", ".", "We", "used", "the", "test", "set", "newstest2012", "and", "2013", "for", "data", "selection", "and", "weight", "tuning", "with", "MERT", ",", "and", "newstest2014", "as", "our", "test", "set", ".", "Each", "set", "has", "more", "than", "70", "thousand", "words", "and", "a", "single", "reference", "translation", ".", "For", "training", "the", "neural", "networks", ",", "including", "the", "proposed", "RNN", "Encoder", "\u2013", "Decoder", ",", "we", "limited", "the", "source", "and", "target", "vocabulary", "to", "the", "most", "frequent", "15", ",", "000", "words", "for", "both", "English", "and", "French", ".", "This", "covers", "approximately", "93", "%", "of", "the", "dataset", ".", "All", "the", "out", "-", "of", "-", "vocabulary", "words", "were", "mapped", "to", "a", "special", "token", "(", ")", ".", "The", "baseline", "phrase", "-", "based", "SMT", "system", "was", "built", "using", "Moses", "with", "default", "settings", ".", "This", "system", "achieves", "a", "BLEU", "score", "of", "30.64", "and", "33.3", "on", "the", "development", "and", "test", "sets", ",", "respectively", "(", "see", "Table", "[", "reference", "]", ")", ".", "subsubsection", ":", "RNN", "Encoder", "\u2013", "Decoder", "The", "RNN", "Encoder", "\u2013", "Decoder", "used", "in", "the", "experiment", "had", "1000", "hidden", "units", "with", "the", "proposed", "gates", "at", "the", "encoder", "and", "at", "the", "decoder", ".", "The", "input", "matrix", "between", "each", "input", "symbol", "and", "the", "hidden", "unit", "is", "approximated", "with", "two", "lower", "-", "rank", "matrices", ",", "and", "the", "output", "matrix", "is", "approximated", "similarly", ".", "We", "used", "rank", "-", "100", "matrices", ",", "equivalent", "to", "learning", "an", "embedding", "of", "dimension", "100", "for", "each", "word", ".", "The", "activation", "function", "used", "for", "in", "Eq", ".", "(", "[", "reference", "]", ")", "is", "a", "hyperbolic", "tangent", "function", ".", "The", "computation", "from", "the", "hidden", "state", "in", "the", "decoder", "to", "the", "output", "is", "implemented", "as", "a", "deep", "neural", "network", "with", "a", "single", "intermediate", "layer", "having", "500", "maxout", "units", "each", "pooling", "2", "inputs", ".", "All", "the", "weight", "parameters", "in", "the", "RNN", "Encoder", "\u2013", "Decoder", "were", "initialized", "by", "sampling", "from", "an", "isotropic", "zero", "-", "mean", "(", "white", ")", "Gaussian", "distribution", "with", "its", "standard", "deviation", "fixed", "to", ",", "except", "for", "the", "recurrent", "weight", "parameters", ".", "For", "the", "recurrent", "weight", "matrices", ",", "we", "first", "sampled", "from", "a", "white", "Gaussian", "distribution", "and", "used", "its", "left", "singular", "vectors", "matrix", ",", "following", ".", "We", "used", "Adadelta", "and", "stochastic", "gradient", "descent", "to", "train", "the", "RNN", "Encoder", "\u2013", "Decoder", "with", "hyperparameters", "and", ".", "At", "each", "update", ",", "we", "used", "64", "randomly", "selected", "phrase", "pairs", "from", "a", "phrase", "table", "(", "which", "was", "created", "from", "348", "M", "words", ")", ".", "The", "model", "was", "trained", "for", "approximately", "three", "days", ".", "Details", "of", "the", "architecture", "used", "in", "the", "experiments", "are", "explained", "in", "more", "depth", "in", "the", "supplementary", "material", ".", "subsubsection", ":", "Neural", "Language", "Model", "In", "order", "to", "assess", "the", "effectiveness", "of", "scoring", "phrase", "pairs", "with", "the", "proposed", "RNN", "Encoder", "\u2013", "Decoder", ",", "we", "also", "tried", "a", "more", "traditional", "approach", "of", "using", "a", "neural", "network", "for", "learning", "a", "target", "language", "model", "(", "CSLM", ")", ".", "Especially", ",", "the", "comparison", "between", "the", "SMT", "system", "using", "CSLM", "and", "that", "using", "the", "proposed", "approach", "of", "phrase", "scoring", "by", "RNN", "Encoder", "\u2013", "Decoder", "will", "clarify", "whether", "the", "contributions", "from", "multiple", "neural", "networks", "in", "different", "parts", "of", "the", "SMT", "system", "add", "up", "or", "are", "redundant", ".", "We", "trained", "the", "CSLM", "model", "on", "7", "-", "grams", "from", "the", "target", "corpus", ".", "Each", "input", "word", "was", "projected", "into", "the", "embedding", "space", ",", "and", "they", "were", "concatenated", "to", "form", "a", "3072", "-", "dimensional", "vector", ".", "The", "concatenated", "vector", "was", "fed", "through", "two", "rectified", "layers", "(", "of", "size", "1536", "and", "1024", ")", ".", "The", "output", "layer", "was", "a", "simple", "softmax", "layer", "(", "see", "Eq", ".", "(", "[", "reference", "]", ")", ")", ".", "All", "the", "weight", "parameters", "were", "initialized", "uniformly", "between", "and", ",", "and", "the", "model", "was", "trained", "until", "the", "validation", "perplexity", "did", "not", "improve", "for", "10", "epochs", ".", "After", "training", ",", "the", "language", "model", "achieved", "a", "perplexity", "of", "45.80", ".", "The", "validation", "set", "was", "a", "random", "selection", "of", "0.1", "%", "of", "the", "corpus", ".", "The", "model", "was", "used", "to", "score", "partial", "translations", "during", "the", "decoding", "process", ",", "which", "generally", "leads", "to", "higher", "gains", "in", "BLEU", "score", "than", "n", "-", "best", "list", "rescoring", ".", "To", "address", "the", "computational", "complexity", "of", "using", "a", "CSLM", "in", "the", "decoder", "a", "buffer", "was", "used", "to", "aggregate", "n", "-", "grams", "during", "the", "stack", "-", "search", "performed", "by", "the", "decoder", ".", "Only", "when", "the", "buffer", "is", "full", ",", "or", "a", "stack", "is", "about", "to", "be", "pruned", ",", "the", "n", "-", "grams", "are", "scored", "by", "the", "CSLM", ".", "This", "allows", "us", "to", "perform", "fast", "matrix", "-", "matrix", "multiplication", "on", "GPU", "using", "Theano", ".", "subsection", ":", "Quantitative", "Analysis", "We", "tried", "the", "following", "combinations", ":", "Baseline", "configuration", "Baseline", "+", "RNN", "Baseline", "+", "CSLM", "+", "RNN", "Baseline", "+", "CSLM", "+", "RNN", "+", "Word", "penalty", "The", "results", "are", "presented", "in", "Table", "[", "reference", "]", ".", "As", "expected", ",", "adding", "features", "computed", "by", "neural", "networks", "consistently", "improves", "the", "performance", "over", "the", "baseline", "performance", ".", "The", "best", "performance", "was", "achieved", "when", "we", "used", "both", "CSLM", "and", "the", "phrase", "scores", "from", "the", "RNN", "Encoder", "\u2013", "Decoder", ".", "This", "suggests", "that", "the", "contributions", "of", "the", "CSLM", "and", "the", "RNN", "Encoder", "\u2013", "Decoder", "are", "not", "too", "correlated", "and", "that", "one", "can", "expect", "better", "results", "by", "improving", "each", "method", "independently", ".", "Furthermore", ",", "we", "tried", "penalizing", "the", "number", "of", "words", "that", "are", "unknown", "to", "the", "neural", "networks", "(", "i.e.", "words", "which", "are", "not", "in", "the", "shortlist", ")", ".", "We", "do", "so", "by", "simply", "adding", "the", "number", "of", "unknown", "words", "as", "an", "additional", "feature", "the", "log", "-", "linear", "model", "in", "Eq", ".", "(", "[", "reference", "]", ")", ".", "However", ",", "in", "this", "case", "we", "were", "not", "able", "to", "achieve", "better", "performance", "on", "the", "test", "set", ",", "but", "only", "on", "the", "development", "set", ".", "subsection", ":", "Qualitative", "Analysis", "In", "order", "to", "understand", "where", "the", "performance", "improvement", "comes", "from", ",", "we", "analyze", "the", "phrase", "pair", "scores", "computed", "by", "the", "RNN", "Encoder", "\u2013", "Decoder", "against", "the", "corresponding", "from", "the", "translation", "model", ".", "Since", "the", "existing", "translation", "model", "relies", "solely", "on", "the", "statistics", "of", "the", "phrase", "pairs", "in", "the", "corpus", ",", "we", "expect", "its", "scores", "to", "be", "better", "estimated", "for", "the", "frequent", "phrases", "but", "badly", "estimated", "for", "rare", "phrases", ".", "Also", ",", "as", "we", "mentioned", "earlier", "in", "Sec", ".", "[", "reference", "]", ",", "we", "further", "expect", "the", "RNN", "Encoder", "\u2013", "Decoder", "which", "was", "trained", "without", "any", "frequency", "information", "to", "score", "the", "phrase", "pairs", "based", "rather", "on", "the", "linguistic", "regularities", "than", "on", "the", "statistics", "of", "their", "occurrences", "in", "the", "corpus", ".", "We", "focus", "on", "those", "pairs", "whose", "source", "phrase", "is", "long", "(", "more", "than", "3", "words", "per", "source", "phrase", ")", "and", "frequent", ".", "For", "each", "such", "source", "phrase", ",", "we", "look", "at", "the", "target", "phrases", "that", "have", "been", "scored", "high", "either", "by", "the", "translation", "probability", "or", "by", "the", "RNN", "Encoder", "\u2013", "Decoder", ".", "Similarly", ",", "we", "perform", "the", "same", "procedure", "with", "those", "pairs", "whose", "source", "phrase", "is", "long", "but", "rare", "in", "the", "corpus", ".", "Table", "[", "reference", "]", "lists", "the", "top", "-", "target", "phrases", "per", "source", "phrase", "favored", "either", "by", "the", "translation", "model", "or", "by", "the", "RNN", "Encoder", "\u2013", "Decoder", ".", "The", "source", "phrases", "were", "randomly", "chosen", "among", "long", "ones", "having", "more", "than", "4", "or", "5", "words", ".", "In", "most", "cases", ",", "the", "choices", "of", "the", "target", "phrases", "by", "the", "RNN", "Encoder", "\u2013", "Decoder", "are", "closer", "to", "actual", "or", "literal", "translations", ".", "We", "can", "observe", "that", "the", "RNN", "Encoder", "\u2013", "Decoder", "prefers", "shorter", "phrases", "in", "general", ".", "Interestingly", ",", "many", "phrase", "pairs", "were", "scored", "similarly", "by", "both", "the", "translation", "model", "and", "the", "RNN", "Encoder", "\u2013", "Decoder", ",", "but", "there", "were", "as", "many", "other", "phrase", "pairs", "that", "were", "scored", "radically", "different", "(", "see", "Fig", ".", "[", "reference", "]", ")", ".", "This", "could", "arise", "from", "the", "proposed", "approach", "of", "training", "the", "RNN", "Encoder", "\u2013", "Decoder", "on", "a", "set", "of", "unique", "phrase", "pairs", ",", "discouraging", "the", "RNN", "Encoder", "\u2013", "Decoder", "from", "learning", "simply", "the", "frequencies", "of", "the", "phrase", "pairs", "from", "the", "corpus", ",", "as", "explained", "earlier", ".", "Furthermore", ",", "in", "Table", "[", "reference", "]", ",", "we", "show", "for", "each", "of", "the", "source", "phrases", "in", "Table", "[", "reference", "]", ",", "the", "generated", "samples", "from", "the", "RNN", "Encoder", "\u2013", "Decoder", ".", "For", "each", "source", "phrase", ",", "we", "generated", "50", "samples", "and", "show", "the", "top", "-", "five", "phrases", "accordingly", "to", "their", "scores", ".", "We", "can", "see", "that", "the", "RNN", "Encoder", "\u2013", "Decoder", "is", "able", "to", "propose", "well", "-", "formed", "target", "phrases", "without", "looking", "at", "the", "actual", "phrase", "table", ".", "Importantly", ",", "the", "generated", "phrases", "do", "not", "overlap", "completely", "with", "the", "target", "phrases", "from", "the", "phrase", "table", ".", "This", "encourages", "us", "to", "further", "investigate", "the", "possibility", "of", "replacing", "the", "whole", "or", "a", "part", "of", "the", "phrase", "table", "with", "the", "proposed", "RNN", "Encoder", "\u2013", "Decoder", "in", "the", "future", ".", "subsection", ":", "Word", "and", "Phrase", "Representations", "Since", "the", "proposed", "RNN", "Encoder", "\u2013", "Decoder", "is", "not", "specifically", "designed", "only", "for", "the", "task", "of", "machine", "translation", ",", "here", "we", "briefly", "look", "at", "the", "properties", "of", "the", "trained", "model", ".", "It", "has", "been", "known", "for", "some", "time", "that", "continuous", "space", "language", "models", "using", "neural", "networks", "are", "able", "to", "learn", "semantically", "meaningful", "embeddings", "(", "See", ",", "e.g.", ",", ")", ".", "Since", "the", "proposed", "RNN", "Encoder", "\u2013", "Decoder", "also", "projects", "to", "and", "maps", "back", "from", "a", "sequence", "of", "words", "into", "a", "continuous", "space", "vector", ",", "we", "expect", "to", "see", "a", "similar", "property", "with", "the", "proposed", "model", "as", "well", ".", "The", "left", "plot", "in", "Fig", ".", "[", "reference", "]", "shows", "the", "2\u2013D", "embedding", "of", "the", "words", "using", "the", "word", "embedding", "matrix", "learned", "by", "the", "RNN", "Encoder", "\u2013", "Decoder", ".", "The", "projection", "was", "done", "by", "the", "recently", "proposed", "Barnes", "-", "Hut", "-", "SNE", ".", "We", "can", "clearly", "see", "that", "semantically", "similar", "words", "are", "clustered", "with", "each", "other", "(", "see", "the", "zoomed", "-", "in", "plots", "in", "Fig", ".", "[", "reference", "]", ")", ".", "The", "proposed", "RNN", "Encoder", "\u2013", "Decoder", "naturally", "generates", "a", "continuous", "-", "space", "representation", "of", "a", "phrase", ".", "The", "representation", "(", "in", "Fig", ".", "[", "reference", "]", ")", "in", "this", "case", "is", "a", "1000", "-", "dimensional", "vector", ".", "Similarly", "to", "the", "word", "representations", ",", "we", "visualize", "the", "representations", "of", "the", "phrases", "that", "consists", "of", "four", "or", "more", "words", "using", "the", "Barnes", "-", "Hut", "-", "SNE", "in", "Fig", ".", "[", "reference", "]", ".", "From", "the", "visualization", ",", "it", "is", "clear", "that", "the", "RNN", "Encoder", "\u2013", "Decoder", "captures", "both", "semantic", "and", "syntactic", "structures", "of", "the", "phrases", ".", "For", "instance", ",", "in", "the", "bottom", "-", "left", "plot", ",", "most", "of", "the", "phrases", "are", "about", "the", "duration", "of", "time", ",", "while", "those", "phrases", "that", "are", "syntactically", "similar", "are", "clustered", "together", ".", "The", "bottom", "-", "right", "plot", "shows", "the", "cluster", "of", "phrases", "that", "are", "semantically", "similar", "(", "countries", "or", "regions", ")", ".", "On", "the", "other", "hand", ",", "the", "top", "-", "right", "plot", "shows", "the", "phrases", "that", "are", "syntactically", "similar", ".", "section", ":", "Conclusion", "In", "this", "paper", ",", "we", "proposed", "a", "new", "neural", "network", "architecture", ",", "called", "an", "RNN", "Encoder", "\u2013", "Decoder", "that", "is", "able", "to", "learn", "the", "mapping", "from", "a", "sequence", "of", "an", "arbitrary", "length", "to", "another", "sequence", ",", "possibly", "from", "a", "different", "set", ",", "of", "an", "arbitrary", "length", ".", "The", "proposed", "RNN", "Encoder", "\u2013", "Decoder", "is", "able", "to", "either", "score", "a", "pair", "of", "sequences", "(", "in", "terms", "of", "a", "conditional", "probability", ")", "or", "generate", "a", "target", "sequence", "given", "a", "source", "sequence", ".", "Along", "with", "the", "new", "architecture", ",", "we", "proposed", "a", "novel", "hidden", "unit", "that", "includes", "a", "reset", "gate", "and", "an", "update", "gate", "that", "adaptively", "control", "how", "much", "each", "hidden", "unit", "remembers", "or", "forgets", "while", "reading", "/", "generating", "a", "sequence", ".", "We", "evaluated", "the", "proposed", "model", "with", "the", "task", "of", "statistical", "machine", "translation", ",", "where", "we", "used", "the", "RNN", "Encoder", "\u2013", "Decoder", "to", "score", "each", "phrase", "pair", "in", "the", "phrase", "table", ".", "Qualitatively", ",", "we", "were", "able", "to", "show", "that", "the", "new", "model", "is", "able", "to", "capture", "linguistic", "regularities", "in", "the", "phrase", "pairs", "well", "and", "also", "that", "the", "RNN", "Encoder", "\u2013", "Decoder", "is", "able", "to", "propose", "well", "-", "formed", "target", "phrases", ".", "The", "scores", "by", "the", "RNN", "Encoder", "\u2013", "Decoder", "were", "found", "to", "improve", "the", "overall", "translation", "performance", "in", "terms", "of", "BLEU", "scores", ".", "Also", ",", "we", "found", "that", "the", "contribution", "by", "the", "RNN", "Encoder", "\u2013", "Decoder", "is", "rather", "orthogonal", "to", "the", "existing", "approach", "of", "using", "neural", "networks", "in", "the", "SMT", "system", ",", "so", "that", "we", "can", "improve", "further", "the", "performance", "by", "using", ",", "for", "instance", ",", "the", "RNN", "Encoder", "\u2013", "Decoder", "and", "the", "neural", "net", "language", "model", "together", ".", "Our", "qualitative", "analysis", "of", "the", "trained", "model", "shows", "that", "it", "indeed", "captures", "the", "linguistic", "regularities", "in", "multiple", "levels", "i.e.", "at", "the", "word", "level", "as", "well", "as", "phrase", "level", ".", "This", "suggests", "that", "there", "may", "be", "more", "natural", "language", "related", "applications", "that", "may", "benefit", "from", "the", "proposed", "RNN", "Encoder", "\u2013", "Decoder", ".", "The", "proposed", "architecture", "has", "large", "potential", "for", "further", "improvement", "and", "analysis", ".", "One", "approach", "that", "was", "not", "investigated", "here", "is", "to", "replace", "the", "whole", ",", "or", "a", "part", "of", "the", "phrase", "table", "by", "letting", "the", "RNN", "Encoder", "\u2013", "Decoder", "propose", "target", "phrases", ".", "Also", ",", "noting", "that", "the", "proposed", "model", "is", "not", "limited", "to", "being", "used", "with", "written", "language", ",", "it", "will", "be", "an", "important", "future", "research", "to", "apply", "the", "proposed", "architecture", "to", "other", "applications", "such", "as", "speech", "transcription", ".", "section", ":", "Acknowledgments", "KC", ",", "BM", ",", "CG", ",", "DB", "and", "YB", "would", "like", "to", "thank", "NSERC", ",", "Calcul", "Qu\u00e9bec", ",", "Compute", "Canada", ",", "the", "Canada", "Research", "Chairs", "and", "CIFAR", ".", "FB", "and", "HS", "were", "partially", "funded", "by", "the", "European", "Commission", "under", "the", "project", "MateCat", ",", "and", "by", "DARPA", "under", "the", "BOLT", "project", ".", "bibliography", ":", "References", "appendix", ":", "RNN", "Encoder", "\u2013", "Decoder", "In", "this", "document", ",", "we", "describe", "in", "detail", "the", "architecture", "of", "the", "RNN", "Encoder", "\u2013", "Decoder", "used", "in", "the", "experiments", ".", "Let", "us", "denote", "an", "source", "phrase", "by", "and", "a", "target", "phrase", "by", ".", "Each", "phrase", "is", "a", "sequence", "of", "-", "dimensional", "one", "-", "hot", "vectors", ",", "such", "that", "only", "one", "element", "of", "the", "vector", "is", "and", "all", "the", "others", "are", ".", "The", "index", "of", "the", "active", "(", ")", "element", "indicates", "the", "word", "represented", "by", "the", "vector", ".", "subsection", ":", "Encoder", "Each", "word", "of", "the", "source", "phrase", "is", "embedded", "in", "a", "-", "dimensional", "vector", "space", ":", ".", "is", "used", "in", "Sec", ".", "[", "reference", "]", "to", "visualize", "the", "words", ".", "The", "hidden", "state", "of", "an", "encoder", "consists", "of", "hidden", "units", ",", "and", "each", "one", "of", "them", "at", "time", "is", "computed", "by", "where", "and", "are", "a", "logistic", "sigmoid", "function", "and", "an", "element", "-", "wise", "multiplication", ",", "respectively", ".", "To", "make", "the", "equations", "uncluttered", ",", "we", "omit", "biases", ".", "The", "initial", "hidden", "state", "is", "fixed", "to", ".", "Once", "the", "hidden", "state", "at", "the", "step", "(", "the", "end", "of", "the", "source", "phrase", ")", "is", "computed", ",", "the", "representation", "of", "the", "source", "phrase", "is", "subsubsection", ":", "Decoder", "The", "decoder", "starts", "by", "initializing", "the", "hidden", "state", "with", "where", "we", "will", "use", "to", "distinguish", "parameters", "of", "the", "decoder", "from", "those", "of", "the", "encoder", ".", "The", "hidden", "state", "at", "time", "of", "the", "decoder", "is", "computed", "by", "where", "and", "is", "an", "all", "-", "zero", "vector", ".", "Similarly", "to", "the", "case", "of", "the", "encoder", ",", "is", "an", "embedding", "of", "a", "target", "word", ".", "Unlike", "the", "encoder", "which", "simply", "encodes", "the", "source", "phrase", ",", "the", "decoder", "is", "learned", "to", "generate", "a", "target", "phrase", ".", "At", "each", "time", ",", "the", "decoder", "computes", "the", "probability", "of", "generating", "-", "th", "word", "by", "where", "the", "-", "element", "of", "is", "and", "In", "short", ",", "the", "is", "a", "so", "-", "called", "maxout", "unit", ".", "For", "the", "computational", "efficiency", ",", "instead", "of", "a", "single", "-", "matrix", "output", "weight", ",", "we", "use", "a", "product", "of", "two", "matrices", "such", "that", "where", "and", ".", "appendix", ":", "Word", "and", "Phrase", "Representations", "Here", ",", "we", "show", "enlarged", "plots", "of", "the", "word", "and", "phrase", "representations", "in", "Figs", ".", "[", "reference", "]", "\u2013", "[", "reference", "]", ".", "arxiv", "arxiv"]}