{"coref": {"BLEU-1": [], "BLEU-4": [], "BiDAF": [[2, 7], [434, 435], [774, 775], [2051, 2052], [2565, 2566], [2644, 2645], [3766, 3767], [4764, 4765], [4850, 4851], [4893, 4894], [92, 97], [398, 403]], "BiDAF__ensemble_": [[3458, 3462]], "BiDAF__single_model_": [[738, 740], [2729, 2731]], "BiDaF_Baseline": [], "CNN": [], "CNN___Daily_Mail": [[163, 168], [787, 792], [2435, 2439], [4357, 4362], [4561, 4565], [4834, 4838], [4869, 4870], [2382, 2383], [2516, 2517], [4434, 4435], [4959, 4960]], "Daily_Mail": [], "EM": [[3135, 3140], [4262, 4263], [3464, 3465]], "EM__Quasar-T_": [], "F1": [[3145, 3147], [3470, 3472]], "F1__Quasar-T_": [], "METEOR": [], "MS_MARCO": [], "NarrativeQA": [], "Open-Domain_Question_Answering": [], "Quasar": [], "Question_Answering": [[181, 185], [2086, 2088], [2111, 2113], [2738, 2741], [2745, 2747], [2763, 2766], [2767, 2768], [2803, 2805], [2953, 2955], [3017, 3019], [3032, 3034]], "Rouge-L": [], "SQuAD1_1": [[155, 159], [160, 161], [749, 753], [754, 755], [2409, 2412], [2433, 2434], [2557, 2558], [3038, 3039], [3075, 3076], [4535, 4536], [4631, 4632], [4949, 4953], [4954, 4955], [5899, 5900], [807, 808], [2413, 2414], [3507, 3508], [3805, 3806], [5106, 5107]], "ensemble": [[3395, 3397], [4847, 4849], [4881, 4883]], "single_model": [[4873, 4877]]}, "coref_non_salient": {"0": [[1625, 1630], [4922, 4927]], "1": [[1361, 1362], [2701, 2705]], "10": [[1618, 1624], [1696, 1702], [1703, 1712], [2628, 2637]], "100": [[3237, 3244]], "101": [[958, 961]], "102": [[474, 476]], "103": [[128, 133], [458, 463], [657, 662], [1819, 1823]], "11": [[201, 204], [1322, 1325], [2756, 2759]], "12": [[2105, 2109], [3065, 3070], [4350, 4355], [4370, 4372], [4553, 4555]], "13": [[241, 244], [551, 556], [2568, 2573]], "14": [[1587, 1589], [1597, 1599], [1600, 1602]], "15": [[8, 10], [10, 12], [175, 180], [833, 835], [2336, 2338], [2443, 2450]], "16": [[1032, 1033], [1050, 1051], [1062, 1063], [1068, 1069], [2260, 2262], [2782, 2783], [3324, 3325]], "17": [[1445, 1450], [1924, 1931]], "18": [[3157, 3159], [3307, 3309]], "19": [[695, 699], [1633, 1634]], "2": [[1020, 1024], [3516, 3520], [3530, 3534], [3548, 3552]], "20": [[2605, 2606], [2919, 2921]], "21": [[2593, 2594], [5157, 5158], [5205, 5206], [5285, 5286], [5382, 5383], [5518, 5519], [5611, 5612]], "22": [[1192, 1202], [3607, 3609]], "23": [[38, 40], [287, 289], [465, 467], [711, 713], [1355, 1358], [2451, 2453], [2794, 2796], [3712, 3714]], "24": [[2678, 2681], [2709, 2711]], "25": [[2468, 2471], [2496, 2499], [3662, 3665]], "26": [[2599, 2605], [5933, 5935]], "27": [[2775, 2776], [4762, 4763]], "28": [[4514, 4516]], "29": [[5495, 5497], [5533, 5535]], "3": [[1223, 1224], [1235, 1236], [2263, 2265], [3327, 3329], [3677, 3678], [5879, 5880]], "30": [[5792, 5793], [5835, 5836], [5947, 5948]], "31": [[5428, 5431]], "32": [[5277, 5278]], "33": [[1147, 1151], [1156, 1158]], "34": [[5435, 5438], [5440, 5443]], "35": [[3257, 3259]], "36": [[5281, 5283]], "37": [[4250, 4252], [5084, 5086]], "38": [[3332, 3334], [5798, 5800], [5817, 5819]], "39": [[533, 535], [623, 625], [647, 649], [954, 956], [1409, 1411], [1910, 1912], [1917, 1919], [1936, 1938], [3012, 3014], [3674, 3676], [3757, 3759], [5882, 5884], [3705, 3707]], "4": [[898, 901], [1185, 1188], [1955, 1958], [3603, 3606], [3818, 3823], [3920, 3923], [4029, 4032]], "40": [[1028, 1031], [1317, 1320]], "41": [[2429, 2431]], "42": [[2396, 2399], [4200, 4202]], "43": [[5231, 5235]], "44": [[2905, 2909], [2910, 2914]], "45": [[1877, 1880]], "46": [[2537, 2538], [4713, 4714]], "47": [[119, 125], [4913, 4919]], "48": [[1890, 1891], [2915, 2916], [5837, 5838]], "49": [[4296, 4298]], "5": [[1883, 1887], [5801, 5805], [5820, 5822]], "50": [[4321, 4322]], "51": [[4825, 4829], [4853, 4857]], "52": [[3964, 3967], [3973, 3976]], "53": [[3260, 3263]], "54": [[2346, 2348]], "55": [[3316, 3320]], "56": [[5628, 5632]], "57": [[4136, 4142]], "58": [[1311, 1316]], "59": [[4781, 4783]], "6": [[103, 108], [409, 414], [846, 851], [4896, 4901]], "60": [[2367, 2374]], "61": [[2211, 2213]], "62": [[5552, 5555]], "63": [[2360, 2361]], "64": [[2878, 2880]], "65": [[2960, 2962]], "66": [[3245, 3247]], "67": [[13, 14], [45, 46], [261, 262], [4990, 4991]], "68": [[1428, 1431]], "69": [[894, 897]], "7": [[480, 482], [619, 621], [629, 631], [667, 669], [928, 931], [1330, 1333], [1334, 1337], [1366, 1369], [2653, 2655], [3637, 3639], [3736, 3738], [3846, 3848], [3938, 3940], [5020, 5022]], "70": [[134, 136], [543, 545], [1419, 1421], [4928, 4930]], "71": [[2712, 2714]], "72": [[2183, 2186]], "73": [[3792, 3793]], "74": [[2206, 2207]], "75": [[5698, 5700]], "76": [[4724, 4728]], "77": [[830, 832]], "78": [[3448, 3450]], "79": [[3151, 3156]], "8": [[3582, 3585], [3629, 3632]], "80": [[863, 866], [879, 882], [979, 982], [983, 986], [1092, 1095], [1096, 1099], [3890, 3893]], "81": [[4784, 4785]], "82": [[1849, 1852]], "83": [[197, 200]], "84": [[1119, 1121]], "85": [[874, 878]], "86": [[3294, 3297]], "87": [[4466, 4468]], "88": [[1976, 1980]], "89": [[2327, 2329]], "9": [[2706, 2707], [3717, 3719]], "90": [[2664, 2669]], "91": [[1363, 1364]], "92": [[269, 271]], "93": [[4613, 4615]], "94": [[966, 968], [2001, 2003], [2040, 2042], [2082, 2084], [2102, 2104], [2589, 2591]], "95": [[5432, 5434]], "96": [[2917, 2919]], "97": [[3569, 3573], [450, 454], [2974, 2978]], "98": [[1271, 1275]], "99": [[841, 844]]}, "doc_id": "007ab5528b3bd310a80d553cccad4b78dc496b02", "method_subrelations": {"BiDAF": [[[0, 5], "BiDAF"]], "BiDAF__ensemble_": [[[0, 5], "BiDAF"], [[7, 15], "ensemble"]], "BiDAF__single_model_": [[[0, 5], "BiDAF"], [[7, 19], "single_model"]], "BiDaF_Baseline": [[[0, 14], "BiDaF_Baseline"]]}, "n_ary_relations": [{"Material": "CNN___Daily_Mail", "Method": "BiDAF", "Metric": "CNN", "Task": "Question_Answering", "score": "76.9"}, {"Material": "CNN___Daily_Mail", "Method": "BiDAF", "Metric": "Daily_Mail", "Task": "Question_Answering", "score": "79.6"}, {"Material": "MS_MARCO", "Method": "BiDaF_Baseline", "Metric": "BLEU-1", "Task": "Question_Answering", "score": "10.64"}, {"Material": "MS_MARCO", "Method": "BiDaF_Baseline", "Metric": "Rouge-L", "Task": "Question_Answering", "score": "23.96"}, {"Material": "NarrativeQA", "Method": "BiDAF", "Metric": "BLEU-1", "Task": "Question_Answering", "score": "33.45"}, {"Material": "NarrativeQA", "Method": "BiDAF", "Metric": "BLEU-4", "Task": "Question_Answering", "score": "15.69"}, {"Material": "NarrativeQA", "Method": "BiDAF", "Metric": "METEOR", "Task": "Question_Answering", "score": "15.68"}, {"Material": "NarrativeQA", "Method": "BiDAF", "Metric": "Rouge-L", "Task": "Question_Answering", "score": "36.74"}, {"Material": "Quasar", "Method": "BiDAF", "Metric": "EM__Quasar-T_", "Task": "Open-Domain_Question_Answering", "score": "25.9"}, {"Material": "Quasar", "Method": "BiDAF", "Metric": "F1__Quasar-T_", "Task": "Open-Domain_Question_Answering", "score": "28.5"}, {"Material": "SQuAD1_1", "Method": "BiDAF__ensemble_", "Metric": "EM", "Task": "Question_Answering", "score": "73.744"}, {"Material": "SQuAD1_1", "Method": "BiDAF__single_model_", "Metric": "EM", "Task": "Question_Answering", "score": "67.974"}, {"Material": "SQuAD1_1", "Method": "BiDAF__ensemble_", "Metric": "F1", "Task": "Question_Answering", "score": "81.525"}, {"Material": "SQuAD1_1", "Method": "BiDAF__single_model_", "Metric": "F1", "Task": "Question_Answering", "score": "77.323"}], "ner": [[2, 7, "Method"], [8, 10, "Task"], [10, 12, "Task"], [13, 14, "Task"], [38, 40, "Method"], [45, 46, "Task"], [103, 108, "Method"], [119, 125, "Method"], [128, 133, "Method"], [134, 136, "Task"], [155, 159, "Material"], [160, 161, "Material"], [163, 168, "Material"], [175, 180, "Task"], [181, 185, "Task"], [197, 200, "Task"], [201, 204, "Task"], [241, 244, "Method"], [261, 262, "Task"], [269, 271, "Task"], [287, 289, "Method"], [409, 414, "Method"], [434, 435, "Method"], [458, 463, "Method"], [465, 467, "Method"], [474, 476, "Method"], [480, 482, "Method"], [533, 535, "Method"], [543, 545, "Task"], [551, 556, "Method"], [619, 621, "Method"], [623, 625, "Method"], [629, 631, "Method"], [647, 649, "Method"], [657, 662, "Method"], [667, 669, "Method"], [695, 699, "Task"], [711, 713, "Method"], [738, 740, "Method"], [749, 753, "Material"], [754, 755, "Material"], [774, 775, "Method"], [787, 792, "Material"], [830, 832, "Method"], [833, 835, "Task"], [841, 844, "Method"], [846, 851, "Method"], [863, 866, "Method"], [874, 878, "Method"], [879, 882, "Method"], [894, 897, "Method"], [898, 901, "Method"], [928, 931, "Method"], [954, 956, "Method"], [958, 961, "Method"], [966, 968, "Method"], [979, 982, "Method"], [983, 986, "Method"], [1020, 1024, "Method"], [1028, 1031, "Method"], [1032, 1033, "Method"], [1050, 1051, "Method"], [1062, 1063, "Method"], [1068, 1069, "Method"], [1092, 1095, "Method"], [1096, 1099, "Method"], [1119, 1121, "Method"], [1147, 1151, "Method"], [1156, 1158, "Method"], [1185, 1188, "Method"], [1192, 1202, "Method"], [1223, 1224, "Method"], [1235, 1236, "Method"], [1271, 1275, "Method"], [1311, 1316, "Method"], [1317, 1320, "Method"], [1322, 1325, "Task"], [1330, 1333, "Method"], [1334, 1337, "Method"], [1355, 1358, "Method"], [1361, 1362, "Method"], [1363, 1364, "Method"], [1366, 1369, "Method"], [1409, 1411, "Method"], [1419, 1421, "Task"], [1428, 1431, "Method"], [1445, 1450, "Method"], [1587, 1589, "Method"], [1597, 1599, "Method"], [1600, 1602, "Method"], [1618, 1624, "Task"], [1625, 1630, "Task"], [1633, 1634, "Task"], [1696, 1702, "Task"], [1703, 1712, "Task"], [1819, 1823, "Method"], [1849, 1852, "Method"], [1877, 1880, "Method"], [1883, 1887, "Method"], [1890, 1891, "Method"], [1910, 1912, "Method"], [1917, 1919, "Method"], [1924, 1931, "Method"], [1936, 1938, "Method"], [1955, 1958, "Method"], [1976, 1980, "Method"], [2001, 2003, "Method"], [2040, 2042, "Method"], [2051, 2052, "Method"], [2082, 2084, "Method"], [2086, 2088, "Task"], [2102, 2104, "Method"], [2105, 2109, "Task"], [2111, 2113, "Task"], [2183, 2186, "Method"], [2206, 2207, "Task"], [2211, 2213, "Metric"], [2260, 2262, "Method"], [2263, 2265, "Method"], [2327, 2329, "Method"], [2336, 2338, "Task"], [2346, 2348, "Method"], [2360, 2361, "Material"], [2367, 2374, "Method"], [2396, 2399, "Method"], [2409, 2412, "Material"], [2429, 2431, "Method"], [2433, 2434, "Material"], [2435, 2439, "Material"], [2443, 2450, "Task"], [2451, 2453, "Method"], [2468, 2471, "Method"], [2496, 2499, "Method"], [2537, 2538, "Metric"], [2557, 2558, "Material"], [2565, 2566, "Method"], [2568, 2573, "Method"], [2589, 2591, "Method"], [2593, 2594, "Task"], [2599, 2605, "Method"], [2605, 2606, "Method"], [2628, 2637, "Task"], [2644, 2645, "Method"], [2653, 2655, "Method"], [2664, 2669, "Method"], [2678, 2681, "Method"], [2701, 2705, "Method"], [2706, 2707, "Method"], [2709, 2711, "Method"], [2712, 2714, "Method"], [2729, 2731, "Method"], [2738, 2741, "Task"], [2745, 2747, "Task"], [2756, 2759, "Task"], [2763, 2766, "Task"], [2767, 2768, "Task"], [2775, 2776, "Method"], [2782, 2783, "Method"], [2794, 2796, "Method"], [2803, 2805, "Task"], [2878, 2880, "Method"], [2905, 2909, "Method"], [2910, 2914, "Method"], [2915, 2916, "Method"], [2917, 2919, "Method"], [2919, 2921, "Method"], [2953, 2955, "Task"], [2960, 2962, "Task"], [3012, 3014, "Method"], [3017, 3019, "Task"], [3032, 3034, "Task"], [3038, 3039, "Material"], [3065, 3070, "Task"], [3075, 3076, "Material"], [3135, 3140, "Metric"], [3145, 3147, "Metric"], [3151, 3156, "Metric"], [3157, 3159, "Metric"], [3237, 3244, "Method"], [3245, 3247, "Method"], [3257, 3259, "Method"], [3260, 3263, "Task"], [3294, 3297, "Method"], [3307, 3309, "Metric"], [3316, 3320, "Metric"], [3324, 3325, "Method"], [3327, 3329, "Method"], [3332, 3334, "Method"], [3395, 3397, "Method"], [3448, 3450, "Task"], [3458, 3462, "Method"], [3470, 3472, "Metric"], [3516, 3520, "Method"], [3530, 3534, "Method"], [3548, 3552, "Method"], [3569, 3573, "Method"], [3582, 3585, "Task"], [3603, 3606, "Method"], [3607, 3609, "Method"], [3629, 3632, "Task"], [3637, 3639, "Method"], [3662, 3665, "Method"], [3674, 3676, "Method"], [3677, 3678, "Method"], [3712, 3714, "Method"], [3717, 3719, "Method"], [3736, 3738, "Method"], [3757, 3759, "Method"], [3766, 3767, "Method"], [3792, 3793, "Task"], [3818, 3823, "Method"], [3846, 3848, "Method"], [3890, 3893, "Method"], [3920, 3923, "Method"], [3938, 3940, "Method"], [3964, 3967, "Method"], [3973, 3976, "Method"], [4029, 4032, "Method"], [4136, 4142, "Method"], [4200, 4202, "Method"], [4250, 4252, "Method"], [4262, 4263, "Metric"], [4296, 4298, "Task"], [4321, 4322, "Task"], [4350, 4355, "Task"], [4357, 4362, "Material"], [4370, 4372, "Task"], [4466, 4468, "Task"], [4514, 4516, "Task"], [4535, 4536, "Material"], [4553, 4555, "Task"], [4561, 4565, "Material"], [4613, 4615, "Method"], [4631, 4632, "Material"], [4713, 4714, "Metric"], [4724, 4728, "Method"], [4762, 4763, "Method"], [4764, 4765, "Method"], [4781, 4783, "Method"], [4784, 4785, "Task"], [4825, 4829, "Method"], [4834, 4838, "Material"], [4847, 4849, "Method"], [4850, 4851, "Method"], [4853, 4857, "Method"], [4869, 4870, "Material"], [4873, 4877, "Method"], [4881, 4883, "Method"], [4893, 4894, "Method"], [4896, 4901, "Method"], [4913, 4919, "Method"], [4922, 4927, "Task"], [4928, 4930, "Task"], [4949, 4953, "Material"], [4954, 4955, "Material"], [4990, 4991, "Task"], [5020, 5022, "Method"], [5084, 5086, "Method"], [5157, 5158, "Task"], [5205, 5206, "Task"], [5231, 5235, "Method"], [5277, 5278, "Task"], [5281, 5283, "Task"], [5285, 5286, "Task"], [5382, 5383, "Task"], [5428, 5431, "Task"], [5432, 5434, "Task"], [5435, 5438, "Task"], [5440, 5443, "Task"], [5495, 5497, "Task"], [5518, 5519, "Task"], [5533, 5535, "Task"], [5552, 5555, "Method"], [5611, 5612, "Task"], [5628, 5632, "Method"], [5698, 5700, "Method"], [5792, 5793, "Method"], [5798, 5800, "Method"], [5801, 5805, "Method"], [5817, 5819, "Method"], [5820, 5822, "Method"], [5835, 5836, "Method"], [5837, 5838, "Method"], [5879, 5880, "Method"], [5882, 5884, "Method"], [5899, 5900, "Material"], [5933, 5935, "Method"], [5947, 5948, "Method"], [92, 97, "Method"], [398, 403, "Method"], [450, 454, "Method"], [807, 808, "Material"], [2382, 2383, "Material"], [2413, 2414, "Material"], [2516, 2517, "Material"], [2974, 2978, "Method"], [3464, 3465, "Metric"], [3507, 3508, "Material"], [3705, 3707, "Method"], [3805, 3806, "Material"], [4434, 4435, "Material"], [4959, 4960, "Material"], [5106, 5107, "Material"]], "sections": [[0, 169], [169, 837], [837, 975], [975, 1088], [1088, 1181], [1181, 1326], [1326, 1906], [1906, 2032], [2032, 2330], [2330, 2334], [2334, 2736], [2736, 3015], [3015, 3071], [3071, 3209], [3209, 3434], [3434, 3488], [3488, 3790], [3790, 4121], [4121, 4248], [4248, 4336], [4336, 4364], [4364, 4517], [4517, 4817], [4817, 4884], [4884, 5023], [5023, 5079], [5079, 5082], [5082, 5624], [5624, 5677], [5677, 5713], [5713, 5754], [5754, 5782], [5782, 5827], [5827, 5949]], "sentences": [[0, 10], [10, 36], [36, 47], [47, 86], [86, 137], [137, 169], [169, 172], [172, 205], [205, 228], [228, 287], [287, 302], [302, 335], [335, 370], [370, 391], [391, 434], [434, 464], [464, 477], [477, 497], [497, 536], [536, 546], [546, 557], [557, 606], [606, 626], [626, 671], [671, 691], [691, 707], [707, 737], [737, 753], [753, 765], [765, 793], [793, 837], [837, 840], [840, 863], [863, 879], [879, 898], [898, 915], [915, 928], [928, 954], [954, 966], [966, 975], [975, 983], [983, 1000], [1000, 1015], [1015, 1035], [1035, 1064], [1064, 1088], [1088, 1096], [1096, 1111], [1111, 1132], [1132, 1152], [1152, 1181], [1181, 1189], [1189, 1220], [1220, 1237], [1237, 1252], [1252, 1282], [1282, 1326], [1326, 1334], [1334, 1352], [1352, 1383], [1383, 1412], [1412, 1422], [1422, 1438], [1438, 1466], [1466, 1489], [1489, 1539], [1539, 1603], [1603, 1618], [1618, 1625], [1625, 1646], [1646, 1664], [1664, 1679], [1679, 1696], [1696, 1703], [1703, 1735], [1735, 1758], [1758, 1765], [1765, 1785], [1785, 1795], [1795, 1828], [1828, 1870], [1870, 1906], [1906, 1913], [1913, 1932], [1932, 1950], [1950, 1971], [1971, 1990], [1990, 2008], [2008, 2032], [2032, 2039], [2039, 2047], [2047, 2077], [2077, 2089], [2089, 2110], [2110, 2130], [2130, 2149], [2149, 2170], [2170, 2189], [2189, 2208], [2208, 2305], [2305, 2307], [2307, 2330], [2330, 2334], [2334, 2339], [2339, 2356], [2356, 2375], [2375, 2403], [2403, 2423], [2423, 2440], [2440, 2458], [2458, 2493], [2493, 2519], [2519, 2539], [2539, 2559], [2559, 2574], [2574, 2599], [2599, 2605], [2605, 2638], [2638, 2670], [2670, 2708], [2708, 2724], [2724, 2736], [2736, 2742], [2742, 2760], [2760, 2794], [2794, 2826], [2826, 2846], [2846, 2872], [2872, 2894], [2894, 2919], [2919, 2923], [2923, 2956], [2956, 2987], [2987, 3015], [3015, 3020], [3020, 3052], [3052, 3071], [3071, 3075], [3075, 3097], [3097, 3110], [3110, 3127], [3127, 3163], [3163, 3184], [3184, 3209], [3209, 3214], [3214, 3229], [3229, 3254], [3254, 3271], [3271, 3283], [3283, 3291], [3291, 3315], [3315, 3341], [3341, 3362], [3362, 3377], [3377, 3391], [3391, 3411], [3411, 3434], [3434, 3438], [3438, 3458], [3458, 3480], [3480, 3488], [3488, 3492], [3492, 3511], [3511, 3524], [3524, 3527], [3527, 3567], [3567, 3581], [3581, 3602], [3602, 3610], [3610, 3628], [3628, 3653], [3653, 3686], [3686, 3708], [3708, 3730], [3730, 3760], [3760, 3790], [3790, 3794], [3794, 3809], [3809, 3824], [3824, 3849], [3849, 3888], [3888, 3941], [3941, 3956], [3956, 3973], [3973, 3999], [3999, 4028], [4028, 4050], [4050, 4072], [4072, 4093], [4093, 4121], [4121, 4125], [4125, 4144], [4144, 4148], [4148, 4164], [4164, 4183], [4183, 4197], [4197, 4216], [4216, 4237], [4237, 4248], [4248, 4253], [4253, 4271], [4271, 4323], [4323, 4336], [4336, 4341], [4341, 4364], [4364, 4368], [4368, 4398], [4398, 4440], [4440, 4461], [4461, 4498], [4498, 4517], [4517, 4522], [4522, 4556], [4556, 4600], [4600, 4627], [4627, 4647], [4647, 4658], [4658, 4684], [4684, 4695], [4695, 4721], [4721, 4761], [4761, 4786], [4786, 4800], [4800, 4817], [4817, 4821], [4821, 4850], [4850, 4867], [4867, 4884], [4884, 4887], [4887, 4931], [4931, 4963], [4963, 4976], [4976, 5008], [5008, 5023], [5023, 5026], [5026, 5069], [5069, 5079], [5079, 5082], [5082, 5086], [5086, 5108], [5108, 5110], [5110, 5111], [5111, 5132], [5132, 5133], [5133, 5136], [5136, 5156], [5156, 5157], [5157, 5159], [5159, 5165], [5165, 5167], [5167, 5175], [5175, 5176], [5176, 5192], [5192, 5196], [5196, 5204], [5204, 5205], [5205, 5207], [5207, 5208], [5208, 5216], [5216, 5217], [5217, 5223], [5223, 5224], [5224, 5267], [5267, 5268], [5268, 5270], [5270, 5271], [5271, 5284], [5284, 5285], [5285, 5287], [5287, 5293], [5293, 5295], [5295, 5301], [5301, 5302], [5302, 5353], [5353, 5360], [5360, 5381], [5381, 5382], [5382, 5384], [5384, 5385], [5385, 5392], [5392, 5393], [5393, 5397], [5397, 5398], [5398, 5483], [5483, 5504], [5504, 5508], [5508, 5517], [5517, 5520], [5520, 5521], [5521, 5545], [5545, 5567], [5567, 5599], [5599, 5600], [5600, 5602], [5602, 5610], [5610, 5611], [5611, 5621], [5621, 5624], [5624, 5632], [5632, 5670], [5670, 5677], [5677, 5688], [5688, 5698], [5698, 5713], [5713, 5723], [5723, 5734], [5734, 5754], [5754, 5764], [5764, 5775], [5775, 5782], [5782, 5794], [5794, 5817], [5817, 5827], [5827, 5839], [5839, 5852], [5852, 5866], [5866, 5889], [5889, 5908], [5908, 5932], [5932, 5949]], "words": ["document", ":", "Bi", "-", "Directional", "Attention", "Flow", "for", "Machine", "Comprehension", "Machine", "comprehension", "(", "MC", ")", ",", "answering", "a", "query", "about", "a", "given", "context", "paragraph", ",", "requires", "modeling", "complex", "interactions", "between", "the", "context", "and", "the", "query", ".", "Recently", ",", "attention", "mechanisms", "have", "been", "successfully", "extended", "to", "MC", ".", "Typically", "these", "methods", "use", "attention", "to", "focus", "on", "a", "small", "portion", "of", "the", "context", "and", "summarize", "it", "with", "a", "fixed", "-", "size", "vector", ",", "couple", "attentions", "temporally", ",", "and", "/", "or", "often", "form", "a", "uni", "-", "directional", "attention", ".", "In", "this", "paper", "we", "introduce", "the", "Bi", "-", "Directional", "Attention", "Flow", "(", "BiDAF", ")", "network", ",", "a", "multi", "-", "stage", "hierarchical", "process", "that", "represents", "the", "context", "at", "different", "levels", "of", "granularity", "and", "uses", "bi", "-", "directional", "attention", "flow", "mechanism", "to", "obtain", "a", "query", "-", "aware", "context", "representation", "without", "early", "summarization", ".", "Our", "experimental", "evaluations", "show", "that", "our", "model", "achieves", "the", "state", "-", "of", "-", "the", "-", "art", "results", "in", "Stanford", "Question", "Answering", "Dataset", "(", "SQuAD", ")", "and", "CNN", "/", "DailyMail", "cloze", "test", ".", "section", ":", "Introduction", "The", "tasks", "of", "machine", "comprehension", "(", "MC", ")", "and", "question", "answering", "(", "QA", ")", "have", "gained", "significant", "popularity", "over", "the", "past", "few", "years", "within", "the", "natural", "language", "processing", "and", "computer", "vision", "communities", ".", "Systems", "trained", "end", "-", "to", "-", "end", "now", "achieve", "promising", "results", "on", "a", "variety", "of", "tasks", "in", "the", "text", "and", "image", "domains", ".", "One", "of", "the", "key", "factors", "to", "the", "advancement", "has", "been", "the", "use", "of", "neural", "attention", "mechanism", ",", "which", "enables", "the", "system", "to", "focus", "on", "a", "targeted", "area", "within", "a", "context", "paragraph", "(", "for", "MC", ")", "or", "within", "an", "image", "(", "for", "Visual", "QA", ")", ",", "that", "is", "most", "relevant", "to", "answer", "the", "question", "memnn", ",", "antol2015vqa", ",", "xiong2016dynamic", ".", "Attention", "mechanisms", "in", "previous", "works", "typically", "have", "one", "or", "more", "of", "the", "following", "characteristics", ".", "First", ",", "the", "computed", "attention", "weights", "are", "often", "used", "to", "extract", "the", "most", "relevant", "information", "from", "the", "context", "for", "answering", "the", "question", "by", "summarizing", "the", "context", "into", "a", "fixed", "-", "size", "vector", ".", "Second", ",", "in", "the", "text", "domain", ",", "they", "are", "often", "temporally", "dynamic", ",", "whereby", "the", "attention", "weights", "at", "the", "current", "time", "step", "are", "a", "function", "of", "the", "attended", "vector", "at", "the", "previous", "time", "step", ".", "Third", ",", "they", "are", "usually", "uni", "-", "directional", ",", "wherein", "the", "query", "attends", "on", "the", "context", "paragraph", "or", "the", "image", ".", "In", "this", "paper", ",", "we", "introduce", "the", "Bi", "-", "Directional", "Attention", "Flow", "(", "BiDAF", ")", "network", ",", "a", "hierarchical", "multi", "-", "stage", "architecture", "for", "modeling", "the", "representations", "of", "the", "context", "paragraph", "at", "different", "levels", "of", "granularity", "(", "Figure", "[", "reference", "]", ")", ".", "BiDAF", "includes", "character", "-", "level", ",", "word", "-", "level", ",", "and", "contextual", "embeddings", ",", "and", "uses", "bi", "-", "directional", "attention", "flow", "to", "obtain", "a", "query", "-", "aware", "context", "representation", ".", "Our", "attention", "mechanism", "offers", "following", "improvements", "to", "the", "previously", "popular", "attention", "paradigms", ".", "First", ",", "our", "attention", "layer", "is", "not", "used", "to", "summarize", "the", "context", "paragraph", "into", "a", "fixed", "-", "size", "vector", ".", "Instead", ",", "the", "attention", "is", "computed", "for", "every", "time", "step", ",", "and", "the", "attended", "vector", "at", "each", "time", "step", ",", "along", "with", "the", "representations", "from", "previous", "layers", ",", "is", "allowed", "to", "flow", "through", "to", "the", "subsequent", "modeling", "layer", ".", "This", "reduces", "the", "information", "loss", "caused", "by", "early", "summarization", ".", "Second", ",", "we", "use", "a", "memory", "-", "less", "attention", "mechanism", ".", "That", "is", ",", "while", "we", "iteratively", "compute", "attention", "through", "time", "as", "in", ",", "the", "attention", "at", "each", "time", "step", "is", "a", "function", "of", "only", "the", "query", "and", "the", "context", "paragraph", "at", "the", "current", "time", "step", "and", "does", "not", "directly", "depend", "on", "the", "attention", "at", "the", "previous", "time", "step", ".", "We", "hypothesize", "that", "this", "simplification", "leads", "to", "the", "division", "of", "labor", "between", "the", "attention", "layer", "and", "the", "modeling", "layer", ".", "It", "forces", "the", "attention", "layer", "to", "focus", "on", "learning", "the", "attention", "between", "the", "query", "and", "the", "context", ",", "and", "enables", "the", "modeling", "layer", "to", "focus", "on", "learning", "the", "interaction", "within", "the", "query", "-", "aware", "context", "representation", "(", "the", "output", "of", "the", "attention", "layer", ")", ".", "It", "also", "allows", "the", "attention", "at", "each", "time", "step", "to", "be", "unaffected", "from", "incorrect", "attendances", "at", "previous", "time", "steps", ".", "Our", "experiments", "show", "that", "memory", "-", "less", "attention", "gives", "a", "clear", "advantage", "over", "dynamic", "attention", ".", "Third", ",", "we", "use", "attention", "mechanisms", "in", "both", "directions", ",", "query", "-", "to", "-", "context", "and", "context", "-", "to", "-", "query", ",", "which", "provide", "complimentary", "information", "to", "each", "other", ".", "Our", "BiDAF", "model", "outperforms", "all", "previous", "approaches", "on", "the", "highly", "-", "competitive", "Stanford", "Question", "Answering", "Dataset", "(", "SQuAD", ")", "test", "set", "leaderboard", "at", "the", "time", "of", "submission", ".", "With", "a", "modification", "to", "only", "the", "output", "layer", ",", "BiDAF", "achieves", "the", "state", "-", "of", "-", "the", "-", "art", "results", "on", "the", "CNN", "/", "DailyMail", "cloze", "test", ".", "We", "also", "provide", "an", "in", "-", "depth", "ablation", "study", "of", "our", "model", "on", "the", "SQuAD", "development", "set", ",", "visualize", "the", "intermediate", "feature", "spaces", "in", "our", "model", ",", "and", "analyse", "its", "performance", "as", "compared", "to", "a", "more", "traditional", "language", "model", "for", "machine", "comprehension", "rajpurkar2016squad", ".", "section", ":", "Model", "Our", "machine", "comprehension", "model", "is", "a", "hierarchical", "multi", "-", "stage", "process", "and", "consists", "of", "six", "layers", "(", "Figure", "[", "reference", "]", ")", ":", "Character", "Embedding", "Layer", "maps", "each", "word", "to", "a", "vector", "space", "using", "character", "-", "level", "CNNs", ".", "Word", "Embedding", "Layer", "maps", "each", "word", "to", "a", "vector", "space", "using", "a", "pre", "-", "trained", "word", "embedding", "model", ".", "Contextual", "Embedding", "Layer", "utilizes", "contextual", "cues", "from", "surrounding", "words", "to", "refine", "the", "embedding", "of", "the", "words", ".", "These", "first", "three", "layers", "are", "applied", "to", "both", "the", "query", "and", "context", ".", "Attention", "Flow", "Layer", "couples", "the", "query", "and", "context", "vectors", "and", "produces", "a", "set", "of", "query", "-", "aware", "feature", "vectors", "for", "each", "word", "in", "the", "context", ".", "Modeling", "Layer", "employs", "a", "Recurrent", "Neural", "Network", "to", "scan", "the", "context", ".", "Output", "Layer", "provides", "an", "answer", "to", "the", "query", ".", "paragraph", ":", "1", ".", "Character", "Embedding", "Layer", ".", "Character", "embedding", "layer", "is", "responsible", "for", "mapping", "each", "word", "to", "a", "high", "-", "dimensional", "vector", "space", ".", "Let", "and", "represent", "the", "words", "in", "the", "input", "context", "paragraph", "and", "query", ",", "respectively", ".", "Following", ",", "we", "obtain", "the", "character", "-", "level", "embedding", "of", "each", "word", "using", "Convolutional", "Neural", "Networks", "(", "CNN", ")", ".", "Characters", "are", "embedded", "into", "vectors", ",", "which", "can", "be", "considered", "as", "1D", "inputs", "to", "the", "CNN", ",", "and", "whose", "size", "is", "the", "input", "channel", "size", "of", "the", "CNN", ".", "The", "outputs", "of", "the", "CNN", "are", "max", "-", "pooled", "over", "the", "entire", "width", "to", "obtain", "a", "fixed", "-", "size", "vector", "for", "each", "word", ".", "paragraph", ":", "2", ".", "Word", "Embedding", "Layer", ".", "Word", "embedding", "layer", "also", "maps", "each", "word", "to", "a", "high", "-", "dimensional", "vector", "space", ".", "We", "use", "pre", "-", "trained", "word", "vectors", ",", "GloVe", "glove", ",", "to", "obtain", "the", "fixed", "word", "embedding", "of", "each", "word", ".", "The", "concatenation", "of", "the", "character", "and", "word", "embedding", "vectors", "is", "passed", "to", "a", "two", "-", "layer", "Highway", "Network", "highway", ".", "The", "outputs", "of", "the", "Highway", "Network", "are", "two", "sequences", "of", "-", "dimensional", "vectors", ",", "or", "more", "conveniently", ",", "two", "matrices", ":", "for", "the", "context", "and", "for", "the", "query", ".", "paragraph", ":", "3", ".", "Contextual", "Embedding", "Layer", ".", "We", "use", "a", "Long", "Short", "-", "Term", "Memory", "Network", "(", "LSTM", ")", "lstm", "on", "top", "of", "the", "embeddings", "provided", "by", "the", "previous", "layers", "to", "model", "the", "temporal", "interactions", "between", "words", ".", "We", "place", "an", "LSTM", "in", "both", "directions", ",", "and", "concatenate", "the", "outputs", "of", "the", "two", "LSTMs", ".", "Hence", "we", "obtain", "from", "the", "context", "word", "vectors", ",", "and", "from", "query", "word", "vectors", ".", "Note", "that", "each", "column", "vector", "of", "and", "is", "-", "dimensional", "because", "of", "the", "concatenation", "of", "the", "outputs", "of", "the", "forward", "and", "backward", "LSTMs", ",", "each", "with", "-", "dimensional", "output", ".", "It", "is", "worth", "noting", "that", "the", "first", "three", "layers", "of", "the", "model", "are", "computing", "features", "from", "the", "query", "and", "context", "at", "different", "levels", "of", "granularity", ",", "akin", "to", "the", "multi", "-", "stage", "feature", "computation", "of", "convolutional", "neural", "networks", "in", "the", "computer", "vision", "field", ".", "paragraph", ":", "4", ".", "Attention", "Flow", "Layer", ".", "Attention", "flow", "layer", "is", "responsible", "for", "linking", "and", "fusing", "information", "from", "the", "context", "and", "the", "query", "words", ".", "Unlike", "previously", "popular", "attention", "mechanisms", "memnn", ",", "hill2015goldilocks", ",", "iterative", ",", "reasonet", ",", "the", "attention", "flow", "layer", "is", "not", "used", "to", "summarize", "the", "query", "and", "context", "into", "single", "feature", "vectors", ".", "Instead", ",", "the", "attention", "vector", "at", "each", "time", "step", ",", "along", "with", "the", "embeddings", "from", "previous", "layers", ",", "are", "allowed", "to", "flow", "through", "to", "the", "subsequent", "modeling", "layer", ".", "This", "reduces", "the", "information", "loss", "caused", "by", "early", "summarization", ".", "The", "inputs", "to", "the", "layer", "are", "contextual", "vector", "representations", "of", "the", "context", "and", "the", "query", ".", "The", "outputs", "of", "the", "layer", "are", "the", "query", "-", "aware", "vector", "representations", "of", "the", "context", "words", ",", ",", "along", "with", "the", "contextual", "embeddings", "from", "the", "previous", "layer", ".", "In", "this", "layer", ",", "we", "compute", "attentions", "in", "two", "directions", ":", "from", "context", "to", "query", "as", "well", "as", "from", "query", "to", "context", ".", "Both", "of", "these", "attentions", ",", "which", "will", "be", "discussed", "below", ",", "are", "derived", "from", "a", "shared", "similarity", "matrix", ",", ",", "between", "the", "contextual", "embeddings", "of", "the", "context", "(", ")", "and", "the", "query", "(", ")", ",", "where", "indicates", "the", "similarity", "between", "-", "th", "context", "word", "and", "-", "th", "query", "word", ".", "The", "similarity", "matrix", "is", "computed", "by", "where", "is", "a", "trainable", "scalar", "function", "that", "encodes", "the", "similarity", "between", "its", "two", "input", "vectors", ",", "is", "-", "th", "column", "vector", "of", ",", "and", "is", "-", "th", "column", "vector", "of", ",", "We", "choose", ",", "where", "is", "a", "trainable", "weight", "vector", ",", "is", "elementwise", "multiplication", ",", "is", "vector", "concatenation", "across", "row", ",", "and", "implicit", "multiplication", "is", "matrix", "multiplication", ".", "Now", "we", "use", "to", "obtain", "the", "attentions", "and", "the", "attended", "vectors", "in", "both", "directions", ".", "Context", "-", "to", "-", "query", "Attention", ".", "Context", "-", "to", "-", "query", "(", "C2Q", ")", "attention", "signifies", "which", "query", "words", "are", "most", "relevant", "to", "each", "context", "word", ".", "Let", "represent", "the", "attention", "weights", "on", "the", "query", "words", "by", "-", "th", "context", "word", ",", "for", "all", ".", "The", "attention", "weight", "is", "computed", "by", ",", "and", "subsequently", "each", "attended", "query", "vector", "is", ".", "Hence", "is", "a", "-", "by", "-", "matrix", "containing", "the", "attended", "query", "vectors", "for", "the", "entire", "context", ".", "Query", "-", "to", "-", "context", "Attention", ".", "Query", "-", "to", "-", "context", "(", "Q2C", ")", "attention", "signifies", "which", "context", "words", "have", "the", "closest", "similarity", "to", "one", "of", "the", "query", "words", "and", "are", "hence", "critical", "for", "answering", "the", "query", ".", "We", "obtain", "the", "attention", "weights", "on", "the", "context", "words", "by", ",", "where", "the", "maximum", "function", "(", ")", "is", "performed", "across", "the", "column", ".", "Then", "the", "attended", "context", "vector", "is", ".", "This", "vector", "indicates", "the", "weighted", "sum", "of", "the", "most", "important", "words", "in", "the", "context", "with", "respect", "to", "the", "query", ".", "is", "tiled", "times", "across", "the", "column", ",", "thus", "giving", ".", "Finally", ",", "the", "contextual", "embeddings", "and", "the", "attention", "vectors", "are", "combined", "together", "to", "yield", ",", "where", "each", "column", "vector", "can", "be", "considered", "as", "the", "query", "-", "aware", "representation", "of", "each", "context", "word", ".", "We", "define", "by", "where", "is", "the", "-", "th", "column", "vector", "(", "corresponding", "to", "-", "th", "context", "word", ")", ",", "is", "a", "trainable", "vector", "function", "that", "fuses", "its", "(", "three", ")", "input", "vectors", ",", "and", "is", "the", "output", "dimension", "of", "the", "function", ".", "While", "the", "function", "can", "be", "an", "arbitrary", "trainable", "neural", "network", ",", "such", "as", "multi", "-", "layer", "perceptron", ",", "a", "simple", "concatenation", "as", "following", "still", "shows", "good", "performance", "in", "our", "experiments", ":", "(", "i.e.", ",", ")", ".", "paragraph", ":", "5", ".", "Modeling", "Layer", ".", "The", "input", "to", "the", "modeling", "layer", "is", ",", "which", "encodes", "the", "query", "-", "aware", "representations", "of", "context", "words", ".", "The", "output", "of", "the", "modeling", "layer", "captures", "the", "interaction", "among", "the", "context", "words", "conditioned", "on", "the", "query", ".", "This", "is", "different", "from", "the", "contextual", "embedding", "layer", ",", "which", "captures", "the", "interaction", "among", "context", "words", "independent", "of", "the", "query", ".", "We", "use", "two", "layers", "of", "bi", "-", "directional", "LSTM", ",", "with", "the", "output", "size", "of", "for", "each", "direction", ".", "Hence", "we", "obtain", "a", "matrix", ",", "which", "is", "passed", "onto", "the", "output", "layer", "to", "predict", "the", "answer", ".", "Each", "column", "vector", "of", "is", "expected", "to", "contain", "contextual", "information", "about", "the", "word", "with", "respect", "to", "the", "entire", "context", "paragraph", "and", "the", "query", ".", "paragraph", ":", "6", ".", "Output", "Layer", ".", "The", "output", "layer", "is", "application", "-", "specific", ".", "The", "modular", "nature", "of", "BiDAF", "allows", "us", "to", "easily", "swap", "out", "the", "output", "layer", "based", "on", "the", "task", ",", "with", "the", "rest", "of", "the", "architecture", "remaining", "exactly", "the", "same", ".", "Here", ",", "we", "describe", "the", "output", "layer", "for", "the", "QA", "task", ".", "In", "section", "[", "reference", "]", ",", "we", "use", "a", "slight", "modification", "of", "this", "output", "layer", "for", "cloze", "-", "style", "comprehension", ".", "The", "QA", "task", "requires", "the", "model", "to", "find", "a", "sub", "-", "phrase", "of", "the", "paragraph", "to", "answer", "the", "query", ".", "The", "phrase", "is", "derived", "by", "predicting", "the", "start", "and", "the", "end", "indices", "of", "the", "phrase", "in", "the", "paragraph", ".", "We", "obtain", "the", "probability", "distribution", "of", "the", "start", "index", "over", "the", "entire", "paragraph", "by", "where", "is", "a", "trainable", "weight", "vector", ".", "For", "the", "end", "index", "of", "the", "answer", "phrase", ",", "we", "pass", "to", "another", "bidirectional", "LSTM", "layer", "and", "obtain", ".", "Then", "we", "use", "to", "obtain", "the", "probability", "distribution", "of", "the", "end", "index", "in", "a", "similar", "manner", ":", "Training", ".", "We", "define", "the", "training", "loss", "(", "to", "be", "minimized", ")", "as", "the", "sum", "of", "the", "negative", "log", "probabilities", "of", "the", "true", "start", "and", "end", "indices", "by", "the", "predicted", "distributions", ",", "averaged", "over", "all", "examples", ":", "where", "is", "the", "set", "of", "all", "trainable", "weights", "in", "the", "model", "(", "the", "weights", "and", "biases", "of", "CNN", "filters", "and", "LSTM", "cells", ",", ",", "and", ")", ",", "is", "the", "number", "of", "examples", "in", "the", "dataset", ",", "and", "are", "the", "true", "start", "and", "end", "indices", "of", "the", "-", "th", "example", ",", "respectively", ",", "and", "indicates", "the", "-", "th", "value", "of", "the", "vector", ".", "Test", ".", "The", "answer", "span", "where", "with", "the", "maximum", "value", "of", "is", "chosen", ",", "which", "can", "be", "computed", "in", "linear", "time", "with", "dynamic", "programming", ".", "section", ":", "Related", "Work", "paragraph", ":", "Machine", "comprehension", ".", "A", "significant", "contributor", "to", "the", "advancement", "of", "MC", "models", "has", "been", "the", "availability", "of", "large", "datasets", ".", "Early", "datasets", "such", "as", "MCTest", "richardson2013mctest", "were", "too", "small", "to", "train", "end", "-", "to", "-", "end", "neural", "models", ".", "Massive", "cloze", "test", "datasets", "(", "CNN", "/", "DailyMail", "by", "Hermann2015TeachingMT", "and", "Childrens", "Book", "Test", "by", ")", ",", "enabled", "the", "application", "of", "deep", "neural", "architectures", "to", "this", "task", ".", "More", "recently", ",", "rajpurkar2016squad", "released", "the", "Stanford", "Question", "Answering", "(", "SQuAD", ")", "dataset", "with", "over", "100", ",", "000", "questions", ".", "We", "evaluate", "the", "performance", "of", "our", "comprehension", "system", "on", "both", "SQuAD", "and", "CNN", "/", "DailyMail", "datasets", ".", "Previous", "works", "in", "end", "-", "to", "-", "end", "machine", "comprehension", "use", "attention", "mechanisms", "in", "three", "distinct", "ways", ".", "The", "first", "group", "(", "largely", "inspired", "by", ")", "uses", "a", "dynamic", "attention", "mechanism", ",", "in", "which", "the", "attention", "weights", "are", "updated", "dynamically", "given", "the", "query", "and", "the", "context", "as", "well", "as", "the", "previous", "attention", ".", "argue", "that", "the", "dynamic", "attention", "model", "performs", "better", "than", "using", "a", "single", "fixed", "query", "vector", "to", "attend", "on", "context", "words", "on", "CNN", "&", "DailyMail", "datasets", ".", "show", "that", "simply", "using", "bilinear", "term", "for", "computing", "the", "attention", "weights", "in", "the", "same", "model", "drastically", "improves", "the", "accuracy", ".", "reverse", "the", "direction", "of", "the", "attention", "(", "attending", "on", "query", "words", "as", "the", "context", "RNN", "progresses", ")", "for", "SQuAD", ".", "In", "contrast", "to", "these", "models", ",", "BiDAF", "uses", "a", "memory", "-", "less", "attention", "mechanism", ".", "The", "second", "group", "computes", "the", "attention", "weights", "once", ",", "which", "are", "then", "fed", "into", "an", "output", "layer", "for", "final", "prediction", "(", "e.g.", ",", ")", ".", "Attention", "-", "over", "-", "attention", "model", "aoa", "uses", "a", "2D", "similarity", "matrix", "between", "the", "query", "and", "context", "words", "(", "similar", "to", "Equation", "[", "reference", "]", ")", "to", "compute", "the", "weighted", "average", "of", "query", "-", "to", "-", "context", "attention", ".", "In", "contrast", "to", "these", "models", ",", "BiDAF", "does", "not", "summarize", "the", "two", "modalities", "in", "the", "attention", "layer", "and", "instead", "lets", "the", "attention", "vectors", "flow", "into", "the", "modeling", "(", "RNN", ")", "layer", ".", "The", "third", "group", "(", "considered", "as", "variants", "of", "Memory", "Network", "memnn", ")", "repeats", "computing", "an", "attention", "vector", "between", "the", "query", "and", "the", "context", "through", "multiple", "layers", ",", "typically", "referred", "to", "as", "multi", "-", "hop", "iterative", ",", "ga", ".", "combine", "Memory", "Networks", "with", "Reinforcement", "Learning", "in", "order", "to", "dynamically", "control", "the", "number", "of", "hops", ".", "One", "can", "also", "extend", "our", "BiDAF", "model", "to", "incorporate", "multiple", "hops", ".", "paragraph", ":", "Visual", "question", "answering", ".", "The", "task", "of", "question", "answering", "has", "also", "gained", "a", "lot", "of", "interest", "in", "the", "computer", "vision", "community", ".", "Early", "works", "on", "visual", "question", "answering", "(", "VQA", ")", "involved", "encoding", "the", "question", "using", "an", "RNN", ",", "encoding", "the", "image", "using", "a", "CNN", "and", "combining", "them", "to", "answer", "the", "question", "antol2015vqa", ",", "Malinowski2015AskYN", ".", "Attention", "mechanisms", "have", "also", "been", "successfully", "employed", "for", "the", "VQA", "task", "and", "can", "be", "broadly", "clustered", "based", "on", "the", "granularity", "of", "their", "attention", "and", "the", "approach", "to", "construct", "the", "attention", "matrix", ".", "At", "the", "coarse", "level", "of", "granularity", ",", "the", "question", "attends", "to", "different", "patches", "in", "the", "image", "Zhu2015Visual7WGQ", ",", "xiong2016dynamic", ".", "At", "a", "finer", "level", ",", "each", "question", "word", "attends", "to", "each", "image", "patch", "and", "the", "highest", "attention", "value", "for", "each", "spatial", "location", "Xu2016AskAA", "is", "adopted", ".", "A", "hybrid", "approach", "is", "to", "combine", "questions", "representations", "at", "multiple", "levels", "of", "granularity", "(", "unigrams", ",", "bigrams", ",", "trigrams", ")", "yang2015stacked", ".", "Several", "approaches", "to", "constructing", "the", "attention", "matrix", "have", "been", "used", "including", "element", "-", "wise", "product", ",", "element", "-", "wise", "sum", ",", "concatenation", "and", "Multimodal", "Compact", "Bilinear", "Pooling", "fukui2016multimodal", ".", "lu2016hierarchical", "have", "recently", "shown", "that", "in", "addition", "to", "attending", "from", "the", "question", "to", "image", "patches", ",", "attending", "from", "the", "image", "back", "to", "the", "question", "words", "provides", "an", "improvement", "on", "the", "VQA", "task", ".", "This", "finding", "in", "the", "visual", "domain", "is", "consistent", "with", "our", "finding", "in", "the", "language", "domain", ",", "where", "our", "bi", "-", "directional", "attention", "between", "the", "query", "and", "context", "provides", "improved", "results", ".", "Their", "model", ",", "however", ",", "uses", "the", "attention", "weights", "directly", "in", "the", "output", "layer", "and", "does", "not", "take", "advantage", "of", "the", "attention", "flow", "to", "the", "modeling", "layer", ".", "section", ":", "Question", "Answering", "Experiments", "In", "this", "section", ",", "we", "evaluate", "our", "model", "on", "the", "task", "of", "question", "answering", "using", "the", "recently", "released", "SQuAD", "rajpurkar2016squad", ",", "which", "has", "gained", "a", "huge", "attention", "over", "a", "few", "months", ".", "In", "the", "next", "section", ",", "we", "evaluate", "our", "model", "on", "the", "task", "of", "cloze", "-", "style", "reading", "comprehension", ".", "paragraph", ":", "Dataset", ".", "SQuAD", "is", "a", "machine", "comprehension", "dataset", "on", "a", "large", "set", "of", "Wikipedia", "articles", ",", "with", "more", "than", "100", ",", "000", "questions", ".", "The", "answer", "to", "each", "question", "is", "always", "a", "span", "in", "the", "context", ".", "The", "model", "is", "given", "a", "credit", "if", "its", "answer", "matches", "one", "of", "the", "human", "written", "answers", ".", "Two", "metrics", "are", "used", "to", "evaluate", "models", ":", "Exact", "Match", "(", "EM", ")", "and", "a", "softer", "metric", ",", "F1", "score", ",", "which", "measures", "the", "weighted", "average", "of", "the", "precision", "and", "recall", "rate", "at", "character", "level", ".", "The", "dataset", "consists", "of", "90k", "/", "10k", "train", "/", "dev", "question", "-", "context", "tuples", "with", "a", "large", "hidden", "test", "set", ".", "It", "is", "one", "of", "the", "largest", "available", "MC", "datasets", "with", "human", "-", "written", "questions", "and", "serves", "as", "a", "great", "test", "bed", "for", "our", "model", ".", "paragraph", ":", "Model", "Details", ".", "The", "model", "architecture", "used", "for", "this", "task", "is", "depicted", "in", "Figure", "[", "reference", "]", ".", "Each", "paragraph", "and", "question", "are", "tokenized", "by", "a", "regular", "-", "expression", "-", "based", "word", "tokenizer", "(", "PTB", "Tokenizer", ")", "and", "fed", "into", "the", "model", ".", "We", "use", "100", "1D", "filters", "for", "CNN", "char", "embedding", ",", "each", "with", "a", "width", "of", "5", ".", "The", "hidden", "state", "size", "(", ")", "of", "the", "model", "is", "100", ".", "The", "model", "has", "about", "2.6", "million", "parameters", ".", "We", "use", "the", "AdaDelta", "adadelta", "optimizer", ",", "with", "a", "minibatch", "size", "of", "60", "and", "an", "initial", "learning", "rate", "of", ",", "for", "12", "epochs", ".", "A", "dropout", "dropout", "rate", "of", "is", "used", "for", "the", "CNN", ",", "all", "LSTM", "layers", ",", "and", "the", "linear", "transformation", "before", "the", "softmax", "for", "the", "answers", ".", "During", "training", ",", "the", "moving", "averages", "of", "all", "weights", "of", "the", "model", "are", "maintained", "with", "the", "exponential", "decay", "rate", "of", ".", "At", "test", "time", ",", "the", "moving", "averages", "instead", "of", "the", "raw", "weights", "are", "used", ".", "The", "training", "process", "takes", "roughly", "20", "hours", "on", "a", "single", "Titan", "X", "GPU", ".", "We", "also", "train", "an", "ensemble", "model", "consisting", "of", "12", "training", "runs", "with", "the", "identical", "architecture", "and", "hyper", "-", "parameters", ".", "At", "test", "time", ",", "we", "choose", "the", "answer", "with", "the", "highest", "sum", "of", "confidence", "scores", "amongst", "the", "12", "runs", "for", "each", "question", ".", "paragraph", ":", "Results", ".", "The", "results", "of", "our", "model", "and", "competing", "approaches", "on", "the", "hidden", "test", "are", "summarized", "in", "Table", "[", "reference", "]", ".", "BiDAF", "(", "ensemble", ")", "achieves", "an", "EM", "score", "of", "73.3", "and", "an", "F1", "score", "of", "81.1", ",", "outperforming", "all", "previous", "approaches", ".", "[", "htbp", "]", "0.6", "[", "htbp", "]", "0.4", "paragraph", ":", "Ablations", ".", "Table", "[", "reference", "]", "shows", "the", "performance", "of", "our", "model", "and", "its", "ablations", "on", "the", "SQuAD", "dev", "set", ".", "Both", "char", "-", "level", "and", "word", "-", "level", "embeddings", "contribute", "towards", "the", "model", "\u2019s", "performance", ".", "We", "conjecture", "that", "word", "-", "level", "embedding", "is", "better", "at", "representing", "the", "semantics", "of", "each", "word", "as", "a", "whole", ",", "while", "char", "-", "level", "embedding", "can", "better", "handle", "out", "-", "of", "-", "vocab", "(", "OOV", ")", "or", "rare", "words", ".", "To", "evaluate", "bi", "-", "directional", "attention", ",", "we", "remove", "C2Q", "and", "Q2C", "attentions", ".", "For", "ablating", "C2Q", "attention", ",", "we", "replace", "the", "attended", "question", "vector", "with", "the", "average", "of", "the", "output", "vectors", "of", "the", "question", "\u2019s", "contextual", "embedding", "layer", "(", "LSTM", ")", ".", "C2Q", "attention", "proves", "to", "be", "critical", "with", "a", "drop", "of", "more", "than", "10", "points", "on", "both", "metrics", ".", "For", "ablating", "Q2C", "attention", ",", "the", "output", "of", "the", "attention", "layer", ",", ",", "does", "not", "include", "terms", "that", "have", "the", "attended", "Q2C", "vectors", ",", ".", "To", "evaluate", "the", "attention", "flow", ",", "we", "study", "a", "dynamic", "attention", "model", ",", "where", "the", "attention", "is", "dynamically", "computed", "within", "the", "modeling", "layer", "\u2019s", "LSTM", ",", "following", "previous", "work", "Bahdanau2014NeuralMT", ",", "wang2016machine", ".", "This", "is", "in", "contrast", "with", "our", "approach", ",", "where", "the", "attention", "is", "pre", "-", "computed", "before", "flowing", "to", "the", "modeling", "layer", ".", "Despite", "being", "a", "simpler", "attention", "mechanism", ",", "our", "proposed", "static", "attention", "outperforms", "the", "dynamically", "computed", "attention", "by", "more", "than", "3", "points", ".", "We", "conjecture", "that", "separating", "out", "the", "attention", "layer", "results", "in", "a", "richer", "set", "of", "features", "computed", "in", "the", "first", "4", "layers", "which", "are", "then", "incorporated", "by", "the", "modeling", "layer", ".", "We", "also", "show", "the", "performance", "of", "BiDAF", "with", "several", "different", "definitions", "of", "and", "functions", "(", "Equation", "[", "reference", "]", "and", "[", "reference", "]", ")", "in", "Appendix", "[", "reference", "]", ".", "paragraph", ":", "Visualizations", ".", "We", "now", "provide", "a", "qualitative", "analysis", "of", "our", "model", "on", "the", "SQuAD", "dev", "set", ".", "First", ",", "we", "visualize", "the", "feature", "spaces", "after", "the", "word", "and", "contextual", "embedding", "layers", ".", "These", "two", "layers", "are", "responsible", "for", "aligning", "the", "embeddings", "between", "the", "query", "and", "context", "words", "which", "are", "the", "inputs", "to", "the", "subsequent", "attention", "layer", ".", "To", "visualize", "the", "embeddings", ",", "we", "choose", "a", "few", "frequent", "query", "words", "in", "the", "dev", "data", "and", "look", "at", "the", "context", "words", "that", "have", "the", "highest", "cosine", "similarity", "to", "the", "query", "words", "(", "Table", "[", "reference", "]", ")", ".", "At", "the", "word", "embedding", "layer", ",", "query", "words", "such", "as", "When", ",", "Where", "and", "Who", "are", "not", "well", "aligned", "to", "possible", "answers", "in", "the", "context", ",", "but", "this", "dramatically", "changes", "in", "the", "contextual", "embedding", "layer", "which", "has", "access", "to", "context", "from", "surrounding", "words", "and", "is", "just", "1", "layer", "below", "the", "attention", "layer", ".", "When", "begins", "to", "match", "years", ",", "Where", "matches", "locations", ",", "and", "Who", "matches", "names", ".", "We", "also", "visualize", "these", "two", "feature", "spaces", "using", "t", "-", "SNE", "in", "Figure", "[", "reference", "]", ".", "t", "-", "SNE", "is", "performed", "on", "a", "large", "fraction", "of", "dev", "data", "but", "we", "only", "plot", "data", "points", "corresponding", "to", "the", "months", "of", "the", "year", ".", "An", "interesting", "pattern", "emerges", "in", "the", "Word", "space", ",", "where", "May", "is", "separated", "from", "the", "rest", "of", "the", "months", "because", "May", "has", "multiple", "meanings", "in", "the", "English", "language", ".", "The", "contextual", "embedding", "layer", "uses", "contextual", "cues", "from", "surrounding", "words", "and", "is", "able", "to", "separate", "the", "usages", "of", "the", "word", "May", ".", "Finally", "we", "visualize", "the", "attention", "matrices", "for", "some", "question", "-", "context", "tuples", "in", "the", "dev", "data", "in", "Figure", "[", "reference", "]", ".", "In", "the", "first", "example", ",", "Where", "matches", "locations", "and", "in", "the", "second", "example", ",", "many", "matches", "quantities", "and", "numerical", "symbols", ".", "Also", ",", "entities", "in", "the", "question", "typically", "attend", "to", "the", "same", "entities", "in", "the", "context", ",", "thus", "providing", "a", "feature", "for", "the", "model", "to", "localize", "possible", "answers", ".", "paragraph", ":", "Discussions", ".", "We", "analyse", "the", "performance", "of", "our", "our", "model", "with", "a", "traditional", "language", "-", "feature", "-", "based", "baseline", "rajpurkar2016squad", ".", "Figure", "[", "reference", "]", "b", "shows", "a", "Venn", "diagram", "of", "the", "dev", "set", "questions", "correctly", "answered", "by", "the", "models", ".", "Our", "model", "is", "able", "to", "answer", "more", "than", "86", "%", "of", "the", "questions", "correctly", "answered", "by", "the", "baseline", ".", "The", "14", "%", "that", "are", "incorrectly", "answered", "does", "not", "have", "a", "clear", "pattern", ".", "This", "suggests", "that", "neural", "architectures", "are", "able", "to", "exploit", "much", "of", "the", "information", "captured", "by", "the", "language", "features", ".", "We", "also", "break", "this", "comparison", "down", "by", "the", "first", "words", "in", "the", "questions", "(", "Figure", "[", "reference", "]", "c", ")", ".", "Our", "model", "outperforms", "the", "traditional", "baseline", "comfortably", "in", "every", "category", ".", "paragraph", ":", "Error", "Analysis", ".", "We", "randomly", "select", "50", "incorrect", "questions", "(", "based", "on", "EM", ")", "and", "categorize", "them", "into", "6", "classes", ".", "50", "%", "of", "errors", "are", "due", "to", "the", "imprecise", "boundaries", "of", "the", "answers", ",", "28", "%", "involve", "syntactic", "complications", "and", "ambiguities", ",", "14", "%", "are", "paraphrase", "problems", ",", "4", "%", "require", "external", "knowledge", ",", "2", "%", "need", "multiple", "sentences", "to", "answer", ",", "and", "2", "%", "are", "due", "to", "mistakes", "during", "tokenization", ".", "See", "Appendix", "[", "reference", "]", "for", "the", "examples", "of", "the", "error", "modes", ".", "section", ":", "Cloze", "Test", "Experiments", "We", "also", "evaluate", "our", "model", "on", "the", "task", "of", "cloze", "-", "style", "reading", "comprehension", "using", "the", "CNN", "and", "Daily", "Mail", "datasets", "Hermann2015TeachingMT", ".", "paragraph", ":", "Dataset", ".", "In", "a", "cloze", "test", ",", "the", "reader", "is", "asked", "to", "fill", "in", "words", "that", "have", "been", "removed", "from", "a", "passage", ",", "for", "measuring", "one", "\u2019s", "ability", "to", "comprehend", "text", ".", "Hermann2015TeachingMT", "have", "recently", "compiled", "a", "massive", "Cloze", "-", "style", "comprehension", "dataset", ",", "consisting", "of", "300k", "/", "4k", "/", "3k", "and", "879k", "/", "65k", "/", "53k", "(", "train", "/", "dev", "/", "test", ")", "examples", "from", "CNN", "and", "DailyMail", "news", "articles", ",", "respectively", ".", "Each", "example", "has", "a", "news", "article", "and", "an", "incomplete", "sentence", "extracted", "from", "the", "human", "-", "written", "summary", "of", "the", "article", ".", "To", "distinguish", "this", "task", "from", "language", "modeling", "and", "force", "one", "to", "refer", "to", "the", "article", "to", "predict", "the", "correct", "missing", "word", ",", "the", "missing", "word", "is", "always", "a", "named", "entity", ",", "anonymized", "with", "a", "random", "ID", ".", "Also", ",", "the", "IDs", "must", "be", "shuffled", "constantly", "during", "test", ",", "which", "is", "also", "critical", "for", "full", "anonymization", ".", "paragraph", ":", "Model", "Details", ".", "The", "model", "architecture", "used", "for", "this", "task", "is", "very", "similar", "to", "that", "for", "SQuAD", "(", "Section", "[", "reference", "]", ")", "with", "only", "a", "few", "small", "changes", "to", "adapt", "it", "to", "the", "cloze", "test", ".", "Since", "each", "answer", "in", "the", "CNN", "/", "DailyMail", "datasets", "is", "always", "a", "single", "word", "(", "entity", ")", ",", "we", "only", "need", "to", "predict", "the", "start", "index", "(", ")", ";", "the", "prediction", "for", "the", "end", "index", "(", ")", "is", "omitted", "from", "the", "loss", "function", ".", "Also", ",", "we", "mask", "out", "all", "non", "-", "entity", "words", "in", "the", "final", "classification", "layer", "so", "that", "they", "are", "forced", "to", "be", "excluded", "from", "possible", "answers", ".", "Another", "important", "difference", "from", "SQuAD", "is", "that", "the", "answer", "entity", "might", "appear", "more", "than", "once", "in", "the", "context", "paragraph", ".", "To", "address", "this", ",", "we", "follow", "a", "similar", "strategy", "from", ".", "During", "training", ",", "after", "we", "obtain", ",", "we", "sum", "all", "probability", "values", "of", "the", "entity", "instances", "in", "the", "context", "that", "correspond", "to", "the", "correct", "answer", ".", "Then", "the", "loss", "function", "is", "computed", "from", "the", "summed", "probability", ".", "We", "use", "a", "minibatch", "size", "of", "48", "and", "train", "for", "8", "epochs", ",", "with", "early", "stop", "when", "the", "accuracy", "on", "validation", "data", "starts", "to", "drop", ".", "Inspired", "by", "the", "window", "-", "based", "method", "hill2015goldilocks", ",", "we", "split", "each", "article", "into", "short", "sentences", "where", "each", "sentence", "is", "a", "19", "-", "word", "window", "around", "each", "entity", "(", "hence", "the", "same", "word", "might", "appear", "in", "multiple", "sentences", ")", ".", "The", "RNNs", "in", "BiDAF", "are", "not", "feed", "-", "forwarded", "or", "back", "-", "propagated", "across", "sentences", ",", "which", "speed", "up", "the", "training", "process", "by", "parallelization", ".", "The", "entire", "training", "process", "takes", "roughly", "60", "hours", "on", "eight", "Titan", "X", "GPUs", ".", "The", "other", "hyper", "-", "parameters", "are", "identical", "to", "the", "model", "described", "in", "Section", "[", "reference", "]", ".", "paragraph", ":", "Results", ".", "The", "results", "of", "our", "single", "-", "run", "models", "and", "competing", "approaches", "on", "the", "CNN", "/", "DailyMail", "datasets", "are", "summarized", "in", "Table", "[", "reference", "]", ".", "indicates", "ensemble", "methods", ".", "BiDAF", "outperforms", "previous", "single", "-", "run", "models", "on", "both", "datasets", "for", "both", "val", "and", "test", "data", ".", "On", "the", "DailyMail", "test", ",", "our", "single", "-", "run", "model", "even", "outperforms", "the", "best", "ensemble", "method", ".", "section", ":", "Conclusion", "In", "this", "paper", ",", "we", "introduce", "BiDAF", ",", "a", "multi", "-", "stage", "hierarchical", "process", "that", "represents", "the", "context", "at", "different", "levels", "of", "granularity", "and", "uses", "a", "bi", "-", "directional", "attention", "flow", "mechanism", "to", "achieve", "a", "query", "-", "aware", "context", "representation", "without", "early", "summarization", ".", "The", "experimental", "evaluations", "show", "that", "our", "model", "achieves", "the", "state", "-", "of", "-", "the", "-", "art", "results", "in", "Stanford", "Question", "Answering", "Dataset", "(", "SQuAD", ")", "and", "CNN", "/", "DailyMail", "cloze", "test", ".", "The", "ablation", "analyses", "demonstrate", "the", "importance", "of", "each", "component", "in", "our", "model", ".", "The", "visualizations", "and", "discussions", "show", "that", "our", "model", "is", "learning", "a", "suitable", "representation", "for", "MC", "and", "is", "capable", "of", "answering", "complex", "questions", "by", "attending", "to", "correct", "locations", "in", "the", "given", "paragraph", ".", "Future", "work", "involves", "extending", "our", "approach", "to", "incorporate", "multiple", "hops", "of", "the", "attention", "layer", ".", "subsubsection", ":", "Acknowledgments", "This", "research", "was", "supported", "by", "the", "NSF", "(", "IIS", "1616112", ")", ",", "NSF", "(", "III", "1703166", ")", ",", "Allen", "Institute", "for", "AI", "(", "66", "-", "9175", ")", ",", "Allen", "Distinguished", "Investigator", "Award", ",", "Google", "Research", "Faculty", "Award", ",", "and", "Samsung", "GRO", "Award", ".", "We", "thank", "the", "anonymous", "reviewers", "for", "their", "helpful", "comments", ".", "bibliography", ":", "References", "appendix", ":", "Error", "Analysis", "Table", "[", "reference", "]", "summarizes", "the", "modes", "of", "errors", "by", "BiDAF", "and", "shows", "examples", "for", "each", "category", "of", "error", "in", "SQuAD", ".", "Context", ":", "\u201c", "The", "Free", "Movement", "of", "Workers", "Regulation", "articles", "1", "to", "7", "set", "out", "the", "main", "provisions", "on", "equal", "treatment", "of", "workers", ".", "\u201d", "Question", ":", "\u201c", "Which", "articles", "of", "the", "Free", "Movement", "of", "Workers", "Regulation", "set", "out", "the", "primary", "provisions", "on", "equal", "treatment", "of", "workers", "?", "\u201d", "Prediction", ":", "\u201c", "1", "to", "7", "\u201d", ",", "Answer", ":", "\u201c", "articles", "1", "to", "7", "\u201d", "Context", ":", "\u201c", "A", "piece", "of", "paper", "was", "later", "found", "on", "which", "Luther", "had", "written", "his", "last", "statement", ".", "\u201d", "Question", ":", "\u201c", "What", "was", "later", "discovered", "written", "by", "Luther", "?", "\u201d", "Prediction", ":", "\u201c", "A", "piece", "of", "paper", "\u201d", ",", "Answer", ":", "\u201c", "his", "last", "statement", "\u201d", "Context", ":", "\u201c", "Generally", ",", "education", "in", "Australia", "follows", "the", "three", "-", "tier", "model", "which", "includes", "primary", "education", "(", "primary", "schools", ")", ",", "followed", "by", "secondary", "education", "(", "secondary", "schools", "/", "high", "schools", ")", "and", "tertiary", "education", "(", "universities", "and", "/", "or", "TAFE", "colleges", ")", ".", "\u201d", "Question", ":", "\u201c", "What", "is", "the", "first", "model", "of", "education", ",", "in", "the", "Australian", "system", "?", "\u201d", "Prediction", ":", "\u201c", "three", "-", "tier", "\u201d", ",", "Answer", ":", "\u201c", "primary", "education", "\u201d", "Context", ":", "\u201c", "On", "June", "4", ",", "2014", ",", "the", "NFL", "announced", "that", "the", "practice", "of", "branding", "Super", "Bowl", "games", "with", "Roman", "numerals", ",", "a", "practice", "established", "at", "Super", "Bowl", "V", ",", "would", "be", "temporarily", "suspended", ",", "and", "that", "the", "game", "would", "be", "named", "using", "Arabic", "numerals", "as", "Super", "Bowl", "50", "as", "opposed", "to", "Super", "Bowl", "L.", "\u201d", "Question", ":", "\u201c", "If", "Roman", "numerals", "were", "used", "in", "the", "naming", "of", "the", "50th", "Super", "Bowl", ",", "which", "one", "would", "have", "been", "used", "?", "\u2019", "Prediction", ":", "\u201c", "Super", "Bowl", "50", "\u201d", ",", "Answer", ":", "\u201c", "L", "\u201d", "Context", ":", "\u201c", "Over", "the", "next", "several", "years", "in", "addition", "to", "host", "to", "host", "interactive", "connections", "the", "network", "was", "enhanced", "to", "support", "terminal", "to", "host", "connections", ",", "host", "to", "host", "batch", "connections", "(", "remote", "job", "submission", ",", "remote", "printing", ",", "batch", "file", "transfer", ")", ",", "interactive", "file", "transfer", ",", "gateways", "to", "the", "Tymnet", "and", "Telenet", "public", "data", "networks", ",", "X.25", "host", "attachments", ",", "gateways", "to", "X.25", "data", "networks", ",", "Ethernet", "attached", "hosts", ",", "and", "eventually", "TCP", "/", "IP", "and", "additional", "public", "universities", "in", "Michigan", "join", "the", "network", ".", "All", "of", "this", "set", "the", "stage", "for", "Merit", "\u2019s", "role", "in", "the", "NSFNET", "project", "starting", "in", "the", "mid", "-", "1980s", ".", "\u201d", "Question", ":", "\u201c", "What", "set", "the", "stage", "for", "Merits", "role", "in", "NSFNET", "\u201d", "Prediction", ":", "\u201c", "All", "of", "this", "set", "the", "stage", "for", "Merit", "\u2019s", "role", "in", "the", "NSFNET", "project", "starting", "in", "the", "mid", "-", "1980s", "\u201d", ",", "Answer", ":", "\u201c", "Ethernet", "attached", "hosts", ",", "and", "eventually", "TCP", "/", "IP", "and", "additional", "public", "universities", "in", "Michigan", "join", "the", "network", "\u201d", "Context", ":", "\u201c", "English", "chemist", "John", "Mayow", "(", "1641", "-", "1679", ")", "refined", "this", "work", "by", "showing", "that", "fire", "requires", "only", "a", "part", "of", "air", "that", "he", "called", "spiritus", "nitroaereus", "or", "just", "nitroaereus", ".", "\u201d", "Question", ":", "\u201c", "John", "Mayow", "died", "in", "what", "year", "?", "\u201d", "Prediction", ":", "\u201c", "1641", "-", "1679", "\u201d", ",", "Answer", ":", "\u201c", "1679", "\u201d", "appendix", ":", "Variations", "of", "Similarity", "and", "Fusion", "Functions", "In", "this", "appendix", "section", ",", "we", "experimentally", "demonstrate", "how", "different", "choices", "of", "the", "similarity", "function", "(", "Equation", "[", "reference", "]", ")", "and", "the", "fusion", "function", "(", "Equation", "[", "reference", "]", ")", "impact", "the", "performance", "of", "our", "model", ".", "Each", "variation", "is", "defined", "as", "following", ":", "paragraph", ":", "Eqn", ".", "[", "reference", "]", ":", "dot", "product", ".", "Dot", "product", "is", "defined", "as", "where", "indicates", "matrix", "transpose", ".", "Dot", "product", "has", "been", "used", "for", "the", "measurement", "of", "similarity", "between", "two", "vectors", "by", ".", "paragraph", ":", "Eqn", ".", "[", "reference", "]", ":", "linear", ".", "Linear", "is", "defined", "as", "where", "is", "a", "trainable", "weight", "matrix", ".", "This", "can", "be", "considered", "as", "the", "simplification", "of", "Equation", "[", "reference", "]", "by", "dropping", "the", "term", "in", "the", "concatenation", ".", "paragraph", ":", "Eqn", ".", "[", "reference", "]", ":", "bilinear", ".", "Bilinear", "is", "defined", "as", "where", "is", "a", "trainable", "weight", "matrix", ".", "Bilinear", "term", "has", "been", "used", "by", ".", "paragraph", ":", "Eqn", ".", "[", "reference", "]", ":", "linear", "after", "MLP", ".", "We", "can", "also", "perform", "linear", "mapping", "after", "single", "layer", "of", "perceptron", ":", "where", "and", "are", "trainable", "weight", "matrix", "and", "bias", ",", "respectively", ".", "Linear", "mapping", "after", "perceptron", "layer", "has", "been", "used", "by", ".", "paragraph", ":", "Eqn", ".", "[", "reference", "]", ":", "MLP", "after", "concatenation", ".", "We", "can", "define", "as", "where", "and", "are", "trainable", "weight", "matrix", "and", "bias", ".", "This", "is", "equivalent", "to", "adding", "ReLU", "after", "linearly", "transforming", "the", "original", "definition", "of", ".", "Since", "the", "output", "dimension", "of", "changes", ",", "the", "input", "dimension", "of", "the", "first", "LSTM", "of", "the", "modeling", "layer", "will", "change", "as", "well", ".", "The", "results", "of", "these", "variations", "on", "the", "dev", "data", "of", "SQuAD", "are", "shown", "in", "Table", "[", "reference", "]", ".", "It", "is", "important", "to", "note", "that", "there", "are", "non", "-", "trivial", "gaps", "between", "our", "definition", "of", "and", "other", "definitions", "employed", "by", "previous", "work", ".", "Adding", "MLP", "in", "does", "not", "seem", "to", "help", ",", "yielding", "slightly", "worse", "result", "than", "without", "MLP", "."]}