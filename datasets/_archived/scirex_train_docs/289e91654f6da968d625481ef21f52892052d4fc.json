{"coref": {"AG_News": [], "Accuracy": [[3107, 3108]], "Amazon_Review_Full": [[3187, 3189], [3243, 3245], [3311, 3313], [3439, 3441], [3450, 3452]], "Amazon_Review_Polarity": [[3187, 3189], [3243, 3245], [3311, 3313], [3439, 3441]], "DBpedia": [], "EXAM": [[2, 5], [108, 111], [114, 115], [328, 332], [844, 847], [850, 851], [994, 995], [1770, 1773], [1774, 1775], [1799, 1800], [2248, 2249], [2441, 2442], [2593, 2594], [2604, 2605], [2661, 2662], [2824, 2825], [2904, 2905], [3071, 3072], [3093, 3094], [3385, 3386], [3409, 3410], [3427, 3428], [3455, 3456], [3507, 3508], [3528, 3529], [3579, 3580], [3587, 3588], [3603, 3604], [3606, 3607], [3623, 3624], [3628, 3629], [3633, 3634], [3637, 3638], [3993, 3994], [4076, 4077], [4437, 4438], [4454, 4455], [4569, 4570], [4887, 4888], [5071, 5072], [5095, 5096], [5146, 5147], [936, 937], [1019, 1020], [2413, 2414]], "Error": [], "Sentiment_Analysis": [[311, 313], [2674, 2676]], "Text_Classification": [[6, 8], [8, 10], [32, 35], [95, 98], [134, 137], [138, 144], [176, 178], [211, 213], [294, 297], [298, 303], [318, 320], [444, 446], [695, 696], [732, 734], [824, 825], [1012, 1014], [1618, 1622], [1676, 1680], [1750, 1752], [1757, 1762], [1884, 1889], [2010, 2012], [2327, 2330], [2331, 2335], [2424, 2426], [2645, 2649], [2677, 2679], [2965, 2966], [3236, 3238], [3323, 3325], [3692, 3696], [4410, 4412], [4666, 4668], [4671, 4673], [4757, 4759], [4867, 4869], [5056, 5057], [5088, 5090], [5097, 5100], [5101, 5106], [222, 225], [230, 233], [288, 291], [941, 944], [945, 948], [1023, 1026], [1027, 1030], [2349, 2352], [2380, 2383], [2811, 2814], [3705, 3708], [3745, 3748]], "Yahoo__Answers": [[3754, 3759]]}, "coref_non_salient": {"0": [[71, 75], [453, 457], [486, 490], [492, 496], [594, 598], [620, 624], [757, 761], [887, 891], [1101, 1105], [1263, 1267], [1413, 1417], [1817, 1821], [2137, 2141], [2465, 2469], [2482, 2486]], "1": [[2861, 2863], [3665, 3670]], "10": [[2779, 2781], [4286, 4288]], "100": [[1514, 1516]], "101": [[2476, 2479], [3681, 3684]], "102": [[864, 868], [877, 881], [1079, 1083], [1253, 1257], [1806, 1810], [1855, 1859]], "103": [[250, 252]], "104": [[2190, 2191]], "105": [[4705, 4710]], "106": [[352, 355], [2975, 2978]], "107": [[2077, 2080]], "108": [[830, 834]], "109": [[2064, 2069]], "11": [[505, 506], [2596, 2598]], "110": [[4095, 4097]], "111": [[4769, 4772]], "112": [[2371, 2374]], "113": [[1593, 1597]], "114": [[375, 378]], "115": [[1461, 1470]], "116": [[4974, 4976]], "117": [[564, 569]], "118": [[3326, 3327]], "119": [[2271, 2273]], "12": [[4189, 4190], [4195, 4197], [4198, 4199], [4239, 4240], [4290, 4291], [4323, 4324]], "120": [[339, 345]], "121": [[4745, 4747]], "13": [[1916, 1922], [2001, 2004]], "14": [[2938, 2943], [3175, 3179], [3206, 3210], [3264, 3268], [3995, 3999], [4346, 4350]], "15": [[2054, 2055], [2148, 2149], [3512, 3514], [4105, 4106]], "16": [[3007, 3010], [3011, 3014], [4002, 4005], [4807, 4812]], "17": [[2255, 2256], [2277, 2278], [2609, 2613], [4120, 4121]], "18": [[1295, 1299], [1312, 1314], [1315, 1317], [1343, 1345], [1427, 1429], [3078, 3080], [3344, 3346]], "19": [[2947, 2952], [3022, 3027], [3201, 3205], [3334, 3338], [3422, 3426], [4019, 4023], [4026, 4030], [4339, 4343]], "2": [[806, 808], [4493, 4498]], "20": [[4040, 4041]], "21": [[84, 86], [120, 122], [717, 719], [740, 742], [838, 840], [869, 871], [895, 897], [999, 1001], [1779, 1781], [1823, 1825], [1894, 1896], [1906, 1908], [1908, 1910], [1938, 1940], [1979, 1981], [1995, 1997], [2019, 2021], [2037, 2039], [3593, 3595], [4898, 4900], [4900, 4902], [4918, 4920], [5075, 5077]], "22": [[17, 20], [185, 188], [1925, 1928], [4959, 4962]], "23": [[500, 502], [873, 875], [1837, 1839], [1897, 1899], [2194, 2196], [2225, 2227], [2600, 2602], [2616, 2618], [3499, 3501], [5151, 5153]], "24": [[4767, 4768], [4773, 4774], [4949, 4954]], "25": [[1088, 1090], [1424, 1426], [1455, 1457], [2818, 2820], [3366, 3368], [4863, 4865]], "26": [[2417, 2418], [2452, 2453], [2587, 2588], [2623, 2624], [3053, 3054], [4780, 4781], [4783, 4784]], "27": [[3722, 3724], [3842, 3844], [3907, 3909]], "28": [[497, 498], [552, 555]], "29": [[3713, 3717], [3727, 3731], [3853, 3856], [4351, 4355]], "3": [[3283, 3285], [4814, 4817]], "30": [[2340, 2342], [2362, 2364], [2376, 2378]], "31": [[4723, 4725]], "32": [[2846, 2848], [4146, 4148]], "33": [[23, 26], [434, 437], [447, 450], [4684, 4687], [4733, 4736]], "34": [[321, 323], [2933, 2935], [3129, 3131], [3152, 3154]], "35": [[4036, 4037], [4038, 4039], [4434, 4435]], "36": [[3015, 3016], [3259, 3260], [3269, 3270], [4839, 4840], [4981, 4984]], "37": [[4890, 4891], [4906, 4910], [4939, 4940], [4996, 4998], [5051, 5053]], "38": [[5154, 5155]], "39": [[2886, 2887], [4078, 4079]], "4": [[1247, 1248], [1261, 1262], [1363, 1364], [1391, 1392], [2056, 2057], [4102, 4103], [4109, 4111]], "40": [[4400, 4402]], "41": [[3478, 3482]], "42": [[2262, 2263]], "43": [[4911, 4912]], "44": [[1303, 1305], [1354, 1356], [1407, 1409]], "45": [[3051, 3052], [5003, 5008]], "46": [[4945, 4946]], "47": [[4555, 4559], [4563, 4565], [4566, 4568]], "48": [[1084, 1087], [1215, 1218], [1243, 1246], [5025, 5029]], "49": [[679, 681], [2026, 2028], [2120, 2122]], "5": [[3043, 3046], [3047, 3050], [4849, 4852]], "50": [[37, 39], [45, 47], [366, 370]], "51": [[4826, 4829]], "52": [[625, 627], [649, 651]], "53": [[4842, 4844]], "54": [[4627, 4629]], "55": [[1453, 1454], [3055, 3057], [3356, 3358], [4857, 4858]], "56": [[4721, 4722]], "57": [[4245, 4246], [4247, 4248], [4292, 4293], [4325, 4326]], "58": [[3295, 3299], [3431, 3435], [4062, 4066], [4381, 4386]], "59": [[3254, 3257]], "6": [[539, 543], [1745, 1749], [1982, 1986], [2387, 2392], [2400, 2404], [3549, 3553]], "60": [[1669, 1671], [1729, 1731], [4740, 4742]], "61": [[4086, 4087]], "62": [[2325, 2326]], "63": [[511, 514]], "64": [[4051, 4055]], "65": [[4718, 4720]], "66": [[4830, 4831]], "67": [[2890, 2893], [4134, 4137]], "68": [[4006, 4009]], "69": [[515, 516], [612, 613], [643, 644], [2258, 2259], [2491, 2492], [2546, 2547], [3520, 3521]], "7": [[608, 609], [811, 813], [4703, 4704], [4728, 4729]], "70": [[4560, 4562]], "71": [[5156, 5157]], "72": [[2703, 2705]], "73": [[3850, 3852]], "74": [[2979, 2983]], "75": [[3892, 3893], [4504, 4506]], "76": [[4511, 4513], [4957, 4958]], "77": [[4157, 4160]], "78": [[4698, 4701]], "79": [[2323, 2324]], "8": [[314, 316], [2680, 2683], [4372, 4375]], "80": [[4680, 4683]], "81": [[2842, 2843]], "82": [[3516, 3519]], "83": [[2626, 2630]], "84": [[2684, 2687]], "85": [[1236, 1241]], "86": [[372, 374]], "87": [[3084, 3085]], "88": [[4398, 4399]], "89": [[253, 255]], "9": [[2448, 2451], [4882, 4886]], "90": [[4406, 4409]], "91": [[1473, 1476], [2460, 2462], [4090, 4092]], "92": [[2973, 2974]], "93": [[3657, 3658]], "94": [[3894, 3896]], "95": [[2235, 2238]], "96": [[629, 633], [2111, 2113]], "97": [[3819, 3820]], "98": [[1929, 1933]], "99": [[2839, 2840], [4128, 4129]]}, "doc_id": "289e91654f6da968d625481ef21f52892052d4fc", "method_subrelations": {"EXAM": [[[0, 4], "EXAM"]]}, "n_ary_relations": [{"Material": "AG_News", "Method": "EXAM", "Metric": "Error", "Task": "Text_Classification", "score": "7"}, {"Material": "Amazon_Review_Full", "Method": "EXAM", "Metric": "Accuracy", "Task": "Sentiment_Analysis", "score": "61.9"}, {"Material": "Amazon_Review_Polarity", "Method": "EXAM", "Metric": "Accuracy", "Task": "Sentiment_Analysis", "score": "95.5"}, {"Material": "DBpedia", "Method": "EXAM", "Metric": "Error", "Task": "Text_Classification", "score": "1"}, {"Material": "Yahoo__Answers", "Method": "EXAM", "Metric": "Accuracy", "Task": "Text_Classification", "score": "74.8"}], "ner": [[2, 5, "Method"], [6, 8, "Task"], [8, 10, "Task"], [17, 20, "Task"], [23, 26, "Method"], [32, 35, "Task"], [37, 39, "Method"], [45, 47, "Method"], [71, 75, "Method"], [84, 86, "Method"], [95, 98, "Task"], [108, 111, "Method"], [114, 115, "Method"], [120, 122, "Method"], [134, 137, "Task"], [138, 144, "Task"], [176, 178, "Task"], [185, 188, "Task"], [211, 213, "Task"], [250, 252, "Task"], [253, 255, "Task"], [294, 297, "Task"], [298, 303, "Task"], [311, 313, "Task"], [314, 316, "Task"], [318, 320, "Task"], [321, 323, "Method"], [328, 332, "Method"], [339, 345, "Method"], [352, 355, "Method"], [366, 370, "Method"], [372, 374, "Method"], [375, 378, "Method"], [434, 437, "Method"], [444, 446, "Task"], [447, 450, "Method"], [453, 457, "Method"], [486, 490, "Method"], [492, 496, "Method"], [497, 498, "Method"], [500, 502, "Method"], [505, 506, "Method"], [511, 514, "Method"], [515, 516, "Method"], [539, 543, "Method"], [552, 555, "Method"], [564, 569, "Method"], [594, 598, "Method"], [608, 609, "Method"], [612, 613, "Method"], [620, 624, "Method"], [625, 627, "Method"], [629, 633, "Method"], [649, 651, "Method"], [679, 681, "Metric"], [695, 696, "Task"], [717, 719, "Method"], [732, 734, "Task"], [740, 742, "Method"], [757, 761, "Method"], [806, 808, "Method"], [811, 813, "Method"], [824, 825, "Task"], [830, 834, "Method"], [838, 840, "Method"], [844, 847, "Method"], [850, 851, "Method"], [864, 868, "Method"], [869, 871, "Method"], [873, 875, "Method"], [877, 881, "Method"], [887, 891, "Method"], [895, 897, "Method"], [994, 995, "Method"], [999, 1001, "Method"], [1012, 1014, "Task"], [1079, 1083, "Method"], [1084, 1087, "Method"], [1088, 1090, "Method"], [1101, 1105, "Method"], [1215, 1218, "Method"], [1236, 1241, "Task"], [1243, 1246, "Method"], [1247, 1248, "Method"], [1253, 1257, "Method"], [1261, 1262, "Method"], [1263, 1267, "Method"], [1295, 1299, "Method"], [1303, 1305, "Method"], [1312, 1314, "Method"], [1315, 1317, "Method"], [1343, 1345, "Method"], [1354, 1356, "Method"], [1363, 1364, "Method"], [1391, 1392, "Method"], [1407, 1409, "Method"], [1413, 1417, "Method"], [1424, 1426, "Method"], [1427, 1429, "Method"], [1453, 1454, "Method"], [1455, 1457, "Method"], [1461, 1470, "Method"], [1473, 1476, "Method"], [1514, 1516, "Method"], [1593, 1597, "Method"], [1618, 1622, "Task"], [1669, 1671, "Method"], [1676, 1680, "Task"], [1729, 1731, "Method"], [1745, 1749, "Method"], [1750, 1752, "Task"], [1757, 1762, "Task"], [1770, 1773, "Method"], [1774, 1775, "Method"], [1779, 1781, "Method"], [1799, 1800, "Method"], [1806, 1810, "Method"], [1817, 1821, "Method"], [1823, 1825, "Method"], [1837, 1839, "Method"], [1855, 1859, "Method"], [1884, 1889, "Task"], [1894, 1896, "Method"], [1897, 1899, "Method"], [1906, 1908, "Method"], [1908, 1910, "Method"], [1916, 1922, "Task"], [1925, 1928, "Task"], [1929, 1933, "Task"], [1938, 1940, "Method"], [1979, 1981, "Method"], [1982, 1986, "Method"], [1995, 1997, "Method"], [2001, 2004, "Task"], [2010, 2012, "Task"], [2019, 2021, "Method"], [2026, 2028, "Metric"], [2037, 2039, "Method"], [2054, 2055, "Method"], [2056, 2057, "Method"], [2064, 2069, "Method"], [2077, 2080, "Method"], [2111, 2113, "Method"], [2120, 2122, "Metric"], [2137, 2141, "Method"], [2148, 2149, "Method"], [2190, 2191, "Metric"], [2194, 2196, "Method"], [2225, 2227, "Method"], [2235, 2238, "Method"], [2248, 2249, "Method"], [2255, 2256, "Method"], [2262, 2263, "Method"], [2271, 2273, "Method"], [2277, 2278, "Method"], [2323, 2324, "Method"], [2325, 2326, "Method"], [2327, 2330, "Task"], [2331, 2335, "Task"], [2340, 2342, "Method"], [2362, 2364, "Method"], [2371, 2374, "Method"], [2376, 2378, "Method"], [2387, 2392, "Method"], [2400, 2404, "Method"], [2417, 2418, "Method"], [2424, 2426, "Task"], [2441, 2442, "Method"], [2448, 2451, "Method"], [2452, 2453, "Method"], [2460, 2462, "Method"], [2465, 2469, "Method"], [2476, 2479, "Method"], [2482, 2486, "Method"], [2587, 2588, "Method"], [2593, 2594, "Method"], [2596, 2598, "Method"], [2600, 2602, "Method"], [2604, 2605, "Method"], [2609, 2613, "Method"], [2616, 2618, "Method"], [2623, 2624, "Method"], [2626, 2630, "Task"], [2645, 2649, "Task"], [2661, 2662, "Method"], [2674, 2676, "Task"], [2677, 2679, "Task"], [2680, 2683, "Task"], [2684, 2687, "Task"], [2703, 2705, "Task"], [2779, 2781, "Metric"], [2818, 2820, "Method"], [2824, 2825, "Method"], [2839, 2840, "Method"], [2842, 2843, "Method"], [2846, 2848, "Metric"], [2861, 2863, "Method"], [2886, 2887, "Method"], [2890, 2893, "Method"], [2904, 2905, "Method"], [2933, 2935, "Method"], [2938, 2943, "Method"], [2947, 2952, "Method"], [2965, 2966, "Task"], [2973, 2974, "Method"], [2975, 2978, "Method"], [2979, 2983, "Method"], [3007, 3010, "Method"], [3011, 3014, "Method"], [3015, 3016, "Method"], [3022, 3027, "Method"], [3043, 3046, "Method"], [3047, 3050, "Method"], [3051, 3052, "Method"], [3053, 3054, "Method"], [3055, 3057, "Method"], [3071, 3072, "Method"], [3078, 3080, "Method"], [3084, 3085, "Method"], [3093, 3094, "Method"], [3107, 3108, "Metric"], [3129, 3131, "Method"], [3152, 3154, "Method"], [3175, 3179, "Method"], [3187, 3189, "Material"], [3201, 3205, "Method"], [3206, 3210, "Method"], [3236, 3238, "Task"], [3243, 3245, "Material"], [3254, 3257, "Method"], [3259, 3260, "Method"], [3264, 3268, "Method"], [3269, 3270, "Method"], [3283, 3285, "Method"], [3295, 3299, "Method"], [3311, 3313, "Material"], [3323, 3325, "Task"], [3326, 3327, "Task"], [3334, 3338, "Method"], [3344, 3346, "Method"], [3356, 3358, "Method"], [3366, 3368, "Method"], [3385, 3386, "Method"], [3409, 3410, "Method"], [3422, 3426, "Method"], [3427, 3428, "Method"], [3431, 3435, "Method"], [3439, 3441, "Material"], [3450, 3452, "Material"], [3455, 3456, "Method"], [3478, 3482, "Method"], [3499, 3501, "Method"], [3507, 3508, "Method"], [3512, 3514, "Method"], [3516, 3519, "Method"], [3528, 3529, "Method"], [3549, 3553, "Method"], [3579, 3580, "Method"], [3587, 3588, "Method"], [3593, 3595, "Method"], [3603, 3604, "Method"], [3606, 3607, "Method"], [3623, 3624, "Method"], [3628, 3629, "Method"], [3633, 3634, "Method"], [3637, 3638, "Method"], [3657, 3658, "Metric"], [3665, 3670, "Method"], [3681, 3684, "Method"], [3692, 3696, "Task"], [3713, 3717, "Material"], [3722, 3724, "Material"], [3727, 3731, "Material"], [3754, 3759, "Material"], [3819, 3820, "Task"], [3842, 3844, "Material"], [3850, 3852, "Task"], [3853, 3856, "Material"], [3892, 3893, "Task"], [3894, 3896, "Task"], [3907, 3909, "Material"], [3993, 3994, "Method"], [3995, 3999, "Method"], [4002, 4005, "Method"], [4006, 4009, "Method"], [4019, 4023, "Method"], [4026, 4030, "Method"], [4036, 4037, "Material"], [4038, 4039, "Material"], [4040, 4041, "Material"], [4051, 4055, "Task"], [4062, 4066, "Method"], [4076, 4077, "Method"], [4078, 4079, "Method"], [4086, 4087, "Method"], [4090, 4092, "Method"], [4095, 4097, "Metric"], [4102, 4103, "Method"], [4105, 4106, "Method"], [4109, 4111, "Method"], [4120, 4121, "Method"], [4128, 4129, "Method"], [4134, 4137, "Method"], [4146, 4148, "Metric"], [4157, 4160, "Task"], [4189, 4190, "Metric"], [4195, 4197, "Metric"], [4198, 4199, "Metric"], [4239, 4240, "Metric"], [4245, 4246, "Metric"], [4247, 4248, "Metric"], [4286, 4288, "Metric"], [4290, 4291, "Metric"], [4292, 4293, "Metric"], [4323, 4324, "Metric"], [4325, 4326, "Metric"], [4339, 4343, "Method"], [4346, 4350, "Method"], [4351, 4355, "Material"], [4372, 4375, "Task"], [4381, 4386, "Method"], [4398, 4399, "Task"], [4400, 4402, "Method"], [4406, 4409, "Method"], [4410, 4412, "Task"], [4434, 4435, "Material"], [4437, 4438, "Method"], [4454, 4455, "Method"], [4493, 4498, "Method"], [4504, 4506, "Task"], [4511, 4513, "Task"], [4555, 4559, "Task"], [4560, 4562, "Task"], [4563, 4565, "Task"], [4566, 4568, "Task"], [4569, 4570, "Method"], [4627, 4629, "Material"], [4666, 4668, "Task"], [4671, 4673, "Task"], [4680, 4683, "Method"], [4684, 4687, "Method"], [4698, 4701, "Method"], [4703, 4704, "Method"], [4705, 4710, "Method"], [4718, 4720, "Task"], [4721, 4722, "Method"], [4723, 4725, "Method"], [4728, 4729, "Method"], [4733, 4736, "Method"], [4740, 4742, "Method"], [4745, 4747, "Method"], [4757, 4759, "Task"], [4767, 4768, "Method"], [4769, 4772, "Method"], [4773, 4774, "Method"], [4780, 4781, "Method"], [4783, 4784, "Method"], [4807, 4812, "Method"], [4814, 4817, "Method"], [4826, 4829, "Method"], [4830, 4831, "Method"], [4839, 4840, "Method"], [4842, 4844, "Method"], [4849, 4852, "Method"], [4857, 4858, "Method"], [4863, 4865, "Method"], [4867, 4869, "Task"], [4882, 4886, "Method"], [4887, 4888, "Method"], [4890, 4891, "Task"], [4898, 4900, "Method"], [4900, 4902, "Method"], [4906, 4910, "Task"], [4911, 4912, "Task"], [4918, 4920, "Method"], [4939, 4940, "Task"], [4945, 4946, "Method"], [4949, 4954, "Method"], [4957, 4958, "Task"], [4959, 4962, "Task"], [4974, 4976, "Method"], [4981, 4984, "Method"], [4996, 4998, "Task"], [5003, 5008, "Method"], [5025, 5029, "Method"], [5051, 5053, "Task"], [5056, 5057, "Task"], [5071, 5072, "Method"], [5075, 5077, "Method"], [5088, 5090, "Task"], [5095, 5096, "Method"], [5097, 5100, "Task"], [5101, 5106, "Task"], [5146, 5147, "Method"], [5151, 5153, "Method"], [5154, 5155, "Method"], [5156, 5157, "Method"], [222, 225, "Task"], [230, 233, "Task"], [288, 291, "Task"], [643, 644, "Method"], [936, 937, "Method"], [941, 944, "Task"], [945, 948, "Task"], [1019, 1020, "Method"], [1023, 1026, "Task"], [1027, 1030, "Task"], [2258, 2259, "Method"], [2349, 2352, "Task"], [2380, 2383, "Task"], [2413, 2414, "Method"], [2491, 2492, "Method"], [2546, 2547, "Method"], [2811, 2814, "Task"], [3520, 3521, "Method"], [3705, 3708, "Task"], [3745, 3748, "Task"]], "sections": [[0, 173], [173, 1066], [1066, 1213], [1213, 1422], [1422, 1611], [1611, 1614], [1614, 1736], [1736, 1904], [1904, 2192], [2192, 2338], [2338, 2385], [2385, 2640], [2640, 2643], [2643, 2649], [2649, 2806], [2806, 2894], [2894, 3086], [3086, 3476], [3476, 3690], [3690, 3696], [3696, 3978], [3978, 4067], [4067, 4170], [4170, 4300], [4300, 4502], [4502, 4660], [4660, 4664], [4664, 4896], [4896, 5058], [5058, 5158], [5158, 5237], [5237, 5240]], "sentences": [[0, 8], [8, 21], [21, 40], [40, 76], [76, 99], [99, 123], [123, 145], [145, 156], [156, 173], [173, 176], [176, 203], [203, 238], [238, 271], [271, 293], [293, 321], [321, 338], [338, 383], [383, 422], [422, 447], [447, 482], [482, 508], [508, 532], [532, 556], [556, 599], [599, 634], [634, 661], [661, 708], [708, 735], [735, 755], [755, 799], [799, 835], [835, 853], [853, 876], [876, 892], [892, 915], [915, 932], [932, 951], [951, 977], [977, 1015], [1015, 1033], [1033, 1044], [1044, 1066], [1066, 1069], [1069, 1091], [1091, 1116], [1116, 1150], [1150, 1213], [1213, 1218], [1218, 1258], [1258, 1312], [1312, 1315], [1315, 1339], [1339, 1354], [1354, 1357], [1357, 1404], [1404, 1422], [1422, 1426], [1426, 1449], [1449, 1471], [1471, 1503], [1503, 1549], [1549, 1582], [1582, 1598], [1598, 1611], [1611, 1614], [1614, 1618], [1618, 1623], [1623, 1639], [1639, 1676], [1676, 1681], [1681, 1696], [1696, 1723], [1723, 1736], [1736, 1740], [1740, 1789], [1789, 1822], [1822, 1836], [1836, 1853], [1853, 1904], [1904, 1908], [1908, 1934], [1934, 1971], [1971, 2014], [2014, 2034], [2034, 2070], [2070, 2108], [2108, 2157], [2157, 2170], [2170, 2192], [2192, 2196], [2196, 2224], [2224, 2239], [2239, 2274], [2274, 2307], [2307, 2315], [2315, 2338], [2338, 2342], [2342, 2385], [2385, 2392], [2392, 2416], [2416, 2452], [2452, 2490], [2490, 2511], [2511, 2524], [2524, 2557], [2557, 2584], [2584, 2603], [2603, 2640], [2640, 2643], [2643, 2649], [2649, 2652], [2652, 2663], [2663, 2690], [2690, 2703], [2703, 2720], [2720, 2744], [2744, 2771], [2771, 2785], [2785, 2806], [2806, 2809], [2809, 2826], [2826, 2837], [2837, 2858], [2858, 2879], [2879, 2894], [2894, 2897], [2897, 2920], [2920, 2938], [2938, 2947], [2947, 2953], [2953, 2986], [2986, 3019], [3019, 3061], [3061, 3086], [3086, 3090], [3090, 3109], [3109, 3119], [3119, 3146], [3146, 3175], [3175, 3190], [3190, 3239], [3239, 3241], [3241, 3261], [3261, 3295], [3295, 3314], [3314, 3351], [3351, 3379], [3379, 3395], [3395, 3403], [3403, 3418], [3418, 3476], [3476, 3482], [3482, 3502], [3502, 3528], [3528, 3554], [3554, 3596], [3596, 3611], [3611, 3645], [3645, 3659], [3659, 3690], [3690, 3696], [3696, 3699], [3699, 3727], [3727, 3732], [3732, 3762], [3762, 3791], [3791, 3812], [3812, 3842], [3842, 3845], [3845, 3881], [3881, 3897], [3897, 3910], [3910, 3931], [3931, 3951], [3951, 3978], [3978, 3981], [3981, 3995], [3995, 4000], [4000, 4019], [4019, 4024], [4024, 4042], [4042, 4067], [4067, 4070], [4070, 4080], [4080, 4100], [4100, 4118], [4118, 4126], [4126, 4151], [4151, 4164], [4164, 4170], [4170, 4173], [4173, 4189], [4189, 4191], [4191, 4236], [4236, 4247], [4247, 4283], [4283, 4300], [4300, 4304], [4304, 4328], [4328, 4356], [4356, 4380], [4380, 4413], [4413, 4439], [4439, 4479], [4479, 4502], [4502, 4506], [4506, 4519], [4519, 4523], [4523, 4547], [4547, 4569], [4569, 4576], [4576, 4596], [4596, 4639], [4639, 4660], [4660, 4664], [4664, 4668], [4668, 4688], [4688, 4705], [4705, 4721], [4721, 4730], [4730, 4760], [4760, 4767], [4767, 4780], [4780, 4792], [4792, 4833], [4833, 4870], [4870, 4896], [4896, 4900], [4900, 4914], [4914, 4941], [4941, 4963], [4963, 4985], [4985, 4990], [4990, 4999], [4999, 5003], [5003, 5018], [5018, 5022], [5022, 5038], [5038, 5058], [5058, 5061], [5061, 5091], [5091, 5107], [5107, 5120], [5120, 5139], [5139, 5158], [5158, 5161], [5161, 5180], [5180, 5190], [5190, 5193], [5193, 5219], [5219, 5237], [5237, 5240]], "words": ["document", ":", "Explicit", "Interaction", "Model", "towards", "Text", "Classification", "Text", "classification", "is", "one", "of", "the", "fundamental", "tasks", "in", "natural", "language", "processing", ".", "Recently", ",", "deep", "neural", "networks", "have", "achieved", "promising", "performance", "in", "the", "text", "classification", "task", "compared", "to", "shallow", "models", ".", "Despite", "of", "the", "significance", "of", "deep", "models", ",", "they", "ignore", "the", "fine", "-", "grained", "(", "matching", "signals", "between", "words", "and", "classes", ")", "classification", "clues", "since", "their", "classifications", "mainly", "rely", "on", "the", "text", "-", "level", "representations", ".", "To", "address", "this", "problem", ",", "we", "introduce", "the", "interaction", "mechanism", "to", "incorporate", "word", "-", "level", "matching", "signals", "into", "the", "text", "classification", "task", ".", "In", "particular", ",", "we", "design", "a", "novel", "framework", ",", "EXplicit", "interAction", "Model", "(", "dubbed", "as", "EXAM", ")", ",", "equipped", "with", "the", "interaction", "mechanism", ".", "We", "justified", "the", "proposed", "approach", "on", "several", "benchmark", "datasets", "including", "both", "multi", "-", "label", "and", "multi", "-", "class", "text", "classification", "tasks", ".", "Extensive", "experimental", "results", "demonstrate", "the", "superiority", "of", "the", "proposed", "method", ".", "As", "a", "byproduct", ",", "we", "have", "released", "the", "codes", "and", "parameter", "settings", "to", "facilitate", "other", "researches", ".", "section", ":", "Introduction", "Text", "classification", "is", "one", "of", "the", "fundamental", "tasks", "in", "natural", "language", "processing", ",", "targeting", "at", "classifying", "a", "piece", "of", "text", "content", "into", "one", "or", "multiple", "categories", ".", "According", "to", "the", "number", "of", "desired", "categories", ",", "text", "classification", "can", "be", "divided", "into", "two", "groups", ",", "namely", ",", "multi", "-", "label", "(", "multiple", "categories", ")", "and", "multi", "-", "class", "(", "unique", "category", ")", ".", "For", "instance", ",", "classifying", "an", "article", "into", "different", "topics", "(", "e.g.", ",", "machine", "learning", "or", "data", "mining", ")", "falls", "into", "the", "former", "one", "since", "an", "article", "could", "be", "under", "several", "topics", "simultaneously", ".", "By", "contrast", ",", "classifying", "a", "comment", "of", "a", "movie", "into", "its", "corresponding", "rating", "level", "lies", "into", "the", "multi", "-", "class", "group", ".", "Both", "multi", "-", "label", "and", "multi", "-", "class", "text", "classifications", "have", "been", "widely", "applied", "in", "many", "fields", "like", "sentimental", "analysis", ",", "topic", "tagging", ",", "and", "document", "classification", ".", "Feature", "engineering", "dominates", "the", "performance", "of", "traditional", "shallow", "text", "classification", "methods", "for", "a", "very", "long", "time", ".", "Various", "rule", "-", "based", "and", "statistical", "features", "like", "bag", "-", "of", "-", "words", "and", "N", "-", "grams", "are", "designed", "to", "describe", "the", "text", ",", "and", "fed", "into", "the", "shallow", "machine", "learning", "models", "such", "as", "Linear", "Regression", "and", "Support", "Vector", "Machine", "to", "make", "the", "judgment", ".", "Traditional", "solutions", "suffer", "from", "two", "defects", ":", "1", ")", "High", "labor", "intensity", "for", "the", "manually", "crafted", "features", ",", "and", "2", ")", "data", "sparsity", "(", "a", "N", "-", "grams", "could", "occur", "only", "several", "times", "in", "a", "given", "dataset", ")", ".", "Recently", ",", "owing", "to", "the", "ability", "of", "tackling", "the", "aforementioned", "problems", ",", "deep", "neural", "networks", "have", "become", "the", "promising", "solutions", "for", "the", "text", "classification", ".", "Deep", "neural", "networks", "typically", "learn", "a", "word", "-", "level", "representation", "for", "the", "input", "text", ",", "which", "is", "usually", "a", "matrix", "with", "each", "row", "/", "column", "as", "an", "embedding", "of", "a", "word", "in", "the", "text", ".", "They", "then", "compress", "the", "word", "-", "level", "representation", "into", "a", "text", "-", "level", "representation", "(", "vector", ")", "with", "aggregation", "operations", "(", "e.g.", ",", "pooling", ")", ".", "Thereafter", ",", "a", "fully", "-", "connected", "(", "FC", ")", "layer", "at", "the", "topmost", "of", "the", "network", "is", "appended", "to", "make", "the", "final", "decision", ".", "Note", "that", "these", "solutions", "are", "also", "called", "encoding", "-", "based", "methods", ",", "since", "they", "encode", "the", "textual", "content", "into", "a", "latent", "vector", "representation", ".", "Although", "great", "success", "has", "been", "achieved", ",", "these", "deep", "neural", "network", "based", "solutions", "naturally", "ignore", "the", "fine", "-", "grained", "classification", "clues", "(", "i.e.", ",", "matching", "signals", "between", "words", "and", "classes", ")", ",", "since", "their", "classifications", "are", "based", "on", "text", "-", "level", "representations", ".", "As", "shown", "in", "Figure", "[", "reference", "]", ",", "the", "classification", "(", "i.e.", ",", "FC", ")", "layer", "of", "these", "solutions", "matches", "the", "text", "-", "level", "representation", "with", "class", "representations", "via", "a", "dot", "-", "product", "operation", ".", "Mathematically", ",", "it", "interprets", "the", "parameter", "matrix", "of", "the", "FC", "layer", "as", "a", "set", "of", "class", "representations", "(", "each", "column", "is", "associated", "with", "a", "class", ")", ".", "As", "such", ",", "the", "probability", "of", "the", "text", "belonging", "to", "a", "class", "is", "largely", "determined", "by", "their", "overall", "matching", "score", "regardless", "of", "word", "-", "level", "matching", "signals", ",", "which", "would", "provide", "explicit", "signals", "for", "classification", "(", "e.g.", ",", "missile", "strongly", "indicates", "the", "topic", "of", "military", ")", ".", "To", "address", "the", "aforementioned", "problems", ",", "we", "introduce", "the", "interaction", "mechanism", ",", "which", "is", "capable", "of", "incorporating", "the", "word", "-", "level", "matching", "signals", "for", "text", "classification", ".", "The", "key", "idea", "behind", "the", "interaction", "mechanism", "is", "to", "explicitly", "calculate", "the", "matching", "scores", "between", "the", "words", "and", "classes", ".", "From", "the", "word", "-", "level", "representation", ",", "it", "computes", "an", "interaction", "matrix", ",", "in", "which", "each", "entry", "is", "the", "matching", "score", "between", "a", "word", "and", "a", "class", "(", "dot", "-", "product", "between", "their", "representations", ")", ",", "illustrating", "the", "word", "-", "level", "matching", "signals", ".", "By", "taking", "the", "interaction", "matrix", "as", "a", "text", "representation", ",", "the", "later", "classification", "layer", "could", "incorporate", "fine", "-", "grained", "word", "level", "signals", "for", "the", "finer", "classification", "rather", "than", "simply", "making", "the", "text", "-", "level", "matching", ".", "Based", "upon", "the", "interaction", "mechanism", ",", "we", "devise", "an", "EXplicit", "interAction", "Model", "(", "dubbed", "as", "EXAM", ")", ".", "Specifically", ",", "the", "proposed", "framework", "consists", "of", "three", "main", "components", ":", "word", "-", "level", "encoder", ",", "interaction", "layer", ",", "and", "aggregation", "layer", ".", "The", "word", "-", "level", "encoder", "projects", "the", "textual", "contents", "into", "the", "word", "-", "level", "representations", ".", "Hereafter", ",", "the", "interaction", "layer", "calculates", "the", "matching", "scores", "between", "the", "words", "and", "classes", "(", "i.e.", ",", "constructs", "the", "interaction", "matrix", ")", ".", "Then", ",", "the", "last", "layer", "aggregates", "those", "matching", "scores", "into", "predictions", "over", "each", "class", ",", "respectively", ".", "We", "justify", "our", "proposed", "EXAM", "model", "over", "both", "the", "multi", "-", "label", "and", "multi", "-", "class", "text", "classifications", ".", "Extensive", "experiments", "on", "several", "benchmarks", "demonstrate", "the", "effectiveness", "of", "the", "proposed", "method", ",", "surpassing", "the", "corresponding", "state", "-", "of", "-", "the", "-", "art", "methods", "remarkably", ".", "In", "summary", ",", "the", "contributions", "of", "this", "work", "are", "threefold", ":", "We", "present", "a", "novel", "framework", ",", "EXAM", ",", "which", "leverages", "the", "interaction", "mechanism", "to", "explicitly", "compute", "the", "word", "-", "level", "interaction", "signals", "for", "the", "text", "classification", ".", "We", "justify", "the", "proposed", "EXAM", "model", "over", "both", "multi", "-", "label", "and", "multi", "-", "class", "text", "classifications", ".", "Extensive", "experimental", "results", "demonstrate", "the", "effectiveness", "of", "the", "proposed", "method", ".", "We", "release", "the", "implementation", "of", "our", "method", "(", "including", "some", "baselines", ")", "and", "the", "involved", "parameter", "settings", "to", "facilitate", "later", "researchers", ".", "section", ":", "Preliminaries", "In", "this", "section", ",", "we", "introduce", "two", "widely", "-", "used", "word", "-", "level", "encoders", ":", "Gated", "Recurrent", "Units", "and", "Region", "Embedding", ".", "These", "encoders", "project", "a", "piece", "of", "input", "text", "into", "a", "word", "-", "level", "representation", ",", "serving", "as", "the", "building", "blocks", "of", "the", "proposed", "method", ".", "For", "the", "notations", "in", "this", "paper", ",", "we", "use", "bold", "capital", "letters", "(", "e.g.", ",", "X", ")", "and", "bold", "lowercase", "letters", "(", "e.g.", ",", "x", ")", "to", "denote", "matrices", "and", "vectors", ",", "respectively", ".", "We", "employ", "non", "-", "bold", "letters", "(", "e.g.", ",", "x", ")", "to", "represent", "scalars", ",", "and", "Greek", "letters", "(", "e.g.", ",", ")", "as", "parameters", ".", "is", "used", "to", "refer", "the", "i", "-", "th", "row", "of", "the", "matrix", ",", "to", "represent", "the", "j", "-", "th", "column", "vector", "and", "to", "denote", "the", "element", "in", "the", "i", "-", "th", "row", "and", "j", "-", "th", "column", ".", "subsection", ":", "Gated", "Recurrent", "Units", "Owing", "to", "the", "ability", "of", "capturing", "the", "sequential", "dependencies", "and", "being", "easily", "optimized", "(", "i.e.", ",", "avoid", "the", "gradient", "vanishing", "and", "explosion", "problems", ")", ",", "Gated", "Recurrent", "Units", "(", "GRU", ")", "becomes", "a", "widely", "used", "word", "-", "level", "encoder", ".", "Typically", ",", "a", "GRU", "generates", "word", "-", "level", "representations", "in", "two", "phases", ":", "1", ")", "mapping", "each", "word", "in", "the", "text", "into", "an", "embedding", "(", "a", "real", "-", "valued", "vector", ")", ",", "and", "2", ")", "projecting", "the", "sequence", "of", "word", "embeddings", "into", "a", "sequence", "of", "hidden", "representations", ",", "which", "encodes", "the", "sequential", "dependencies", ".", "Word", "embedding", ".", "Word", "embedding", "is", "a", "general", "method", "to", "map", "a", "word", "from", "one", "hot", "vector", "to", "a", "low", "dimensional", "and", "real", "-", "valued", "vector", ".", "With", "enough", "data", ",", "word", "embedding", "can", "capture", "high", "-", "level", "representations", "of", "words", ".", "Hidden", "representation", ".", "Given", "an", "embedding", "feature", "sequence", ",", "GRU", "will", "compute", "a", "vector", "at", "the", "i", "-", "th", "time", "-", "step", "for", "each", ",", "and", "is", "defined", "as", ":", "where", "and", "are", "trainable", "parameters", "in", "the", "GRU", ",", "and", "and", "are", "sigmoid", "and", "tanh", "activation", "functions", ",", "respectively", ".", "The", "sequence", "of", "hidden", "representations", "is", "denoted", "as", "the", "word", "-", "level", "representation", "of", "the", "input", "text", ".", "subsection", ":", "Region", "Embedding", "Although", "word", "embedding", "is", "a", "good", "representation", "for", "the", "word", ",", "it", "can", "only", "compute", "the", "feature", "vector", "for", "the", "single", "word", ".", "Qiao", "et", "al", ".", "regionemb", "proposed", "region", "embedding", "to", "learn", "and", "utilize", "task", "-", "specific", "distributed", "representations", "of", "N", "-", "grams", ".", "In", "the", "region", "embedding", "layer", ",", "the", "representation", "of", "a", "word", "has", "two", "parts", ",", "the", "embedding", "of", "the", "word", "itself", "and", "a", "weighting", "matrix", "to", "interact", "with", "the", "local", "context", ".", "For", "the", "word", ",", "the", "first", "part", "is", "learned", "by", "an", "embedding", "matrix", "and", "the", "second", "part", "is", "looked", "up", "in", "the", "tensor", "by", "\u2019s", "index", "in", "the", "vocabulary", ",", "where", "is", "the", "size", "of", "the", "vocabulary", ",", "the", "region", "size", "and", "the", "embedding", "size", ".", "And", "then", ",", "each", "column", "in", "is", "used", "to", "interact", "with", "the", "context", "word", "in", "the", "corresponding", "relative", "position", "of", "to", "get", "the", "context", "-", "aware", "for", "each", "word", "in", "the", "region", ".", "Formally", "it", "is", "computed", "by", "the", "following", "function", ":", "where", "denotes", "element", "-", "wise", "multiply", ".", "And", "the", "final", "representation", "of", "the", "middle", "word", "is", "computed", "as", "follows", ":", "section", ":", "Model", "subsection", ":", "Problem", "Formulation", "Multi", "-", "Class", "Classification", ".", "In", "this", "task", ",", "we", "should", "categorize", "each", "text", "instance", "to", "precisely", "one", "of", "classes", ".", "Suppose", "that", "we", "have", "a", "data", "set", "=", ",", "where", "denotes", "the", "text", "and", "the", "one", "-", "hot", "vector", "represents", "the", "label", "for", ",", "our", "goal", "is", "to", "learn", "a", "neural", "network", "to", "classify", "the", "text", ".", "Multi", "-", "Label", "Classification", ".", "In", "this", "task", ",", "each", "text", "instance", "belongs", "to", "a", "set", "of", "target", "labels", ".", "Formally", ",", "suppose", "that", "we", "have", "a", "dataset", "=", ",", "where", "denotes", "the", "text", "and", "the", "multi", "-", "hot", "vector", "represents", "the", "label", "for", "the", "text", ".", "Our", "goal", "is", "to", "learn", "a", "neural", "network", "to", "classify", "the", "text", ".", "subsection", ":", "Model", "Overview", "Motivated", "by", "the", "limitation", "of", "encoding", "-", "based", "models", "for", "text", "classification", ",", "which", "is", "lacking", "the", "fine", "-", "grained", "classification", "clue", ",", "we", "propose", "a", "novel", "framework", ",", "named", "EXplicit", "interAction", "Model", "(", "EXAM", ")", ",", "leveraging", "the", "interaction", "mechanism", "to", "incorporate", "word", "-", "level", "matching", "signals", ".", "As", "can", "be", "seen", "from", "Figure", "[", "reference", "]", ",", "EXAM", "mainly", "contains", "three", "components", ":", "A", "word", "-", "level", "encoder", "to", "project", "the", "input", "text", "into", "a", "word", "-", "level", "representation", ".", "An", "interaction", "layer", "to", "compute", "the", "interaction", "signals", "between", "the", "words", "and", "classes", ".", "An", "aggregation", "layer", "to", "aggregate", "the", "interaction", "signals", "for", "each", "class", "and", "make", "the", "final", "predictions", ".", "Considering", "that", "word", "-", "level", "encoders", "are", "well", "investigated", "in", "previous", "studies", "(", "as", "mentioned", "in", "the", "Section", "2", ")", ",", "and", "the", "target", "of", "this", "work", "is", "to", "learn", "the", "fine", "-", "grained", "classification", "signals", ",", "we", "only", "elaborate", "the", "interaction", "layer", "and", "aggregation", "layer", "in", "the", "following", "subsections", ".", "subsection", ":", "Interaction", "Layer", "Interaction", "mechanism", "is", "widely", "used", "in", "tasks", "of", "matching", "source", "and", "target", "textual", "contents", ",", "such", "as", "natural", "language", "inference", "and", "retrieve", "-", "based", "chatbot", ".", "The", "key", "idea", "of", "interaction", "mechanism", "is", "to", "use", "the", "interaction", "features", "between", "the", "small", "units", "(", "e.g.", ",", "words", "in", "the", "textual", "contents", ")", "to", "infer", "fine", "-", "grained", "clues", "whether", "two", "contents", "are", "matching", ".", "Inspired", "by", "the", "success", "of", "methods", "equipped", "with", "interaction", "mechanism", "over", "encode", "-", "based", "methods", "in", "matching", "the", "textual", "contents", ",", "we", "introduce", "the", "interaction", "mechanism", "into", "the", "task", "of", "matching", "textual", "contents", "with", "their", "classes", "(", "i.e.", ",", "text", "classification", ")", ".", "Specifically", ",", "we", "devise", "an", "interaction", "layer", "which", "aims", "to", "compute", "the", "matching", "score", "between", "the", "word", "and", "class", ".", "Different", "from", "conventional", "interaction", "layer", ",", "where", "the", "word", "-", "level", "representations", "of", "both", "source", "and", "target", "are", "extracted", "with", "encoders", "like", "GRU", ",", "here", "we", "first", "project", "classes", "into", "real", "-", "valued", "latent", "representations", ".", "In", "other", "words", ",", "we", "employ", "a", "trainable", "representation", "matrix", "to", "encode", "classes", "(", "each", "row", "represents", "a", "class", ")", ",", "where", "denotes", "the", "amount", "of", "classes", "and", "is", "the", "embedding", "size", "equals", "to", "that", "of", "words", ".", "We", "then", "adopt", "dot", "product", "as", "the", "interaction", "function", "to", "estimate", "the", "matching", "score", "between", "the", "target", "word", "and", "class", ",", "of", "which", "the", "formulation", "is", ",", "where", "denotes", "word", "-", "level", "representation", "of", "the", "text", ",", "extracted", "by", "the", "encoder", "with", "denoting", "the", "length", "of", "the", "text", ".", "In", "this", "way", ",", "we", "can", "compute", "the", "interaction", "matrix", "by", "following", ":", "Note", "that", "we", "reject", "more", "complex", "interaction", "functions", "like", "element", "-", "wise", "multiply", "and", "cosine", "similarity", "for", "the", "consideration", "of", "efficiency", ".", "subsection", ":", "Aggregation", "Layer", "This", "layer", "is", "devised", "to", "aggregate", "the", "interaction", "features", "for", "each", "class", "into", "a", "logits", ",", "which", "denotes", "the", "matching", "score", "between", "class", "and", "the", "input", "text", ".", "The", "aggregation", "layer", "can", "be", "implemented", "in", "different", "ways", "such", "as", "CNN", "and", "LSTM", ".", "However", ",", "to", "keep", "the", "simplicity", "and", "efficiency", "of", "EXAM", ",", "here", "we", "only", "use", "a", "MLP", "with", "two", "FC", "layers", ",", "where", "ReLU", "is", "employed", "as", "the", "activation", "function", "of", "the", "first", "layer", ".", "Formally", ",", "the", "MLP", "aggregates", "the", "interaction", "features", "for", "class", ",", "and", "compute", "its", "associated", "logits", "as", "following", ":", "where", "and", "are", "trainable", "parameters", "and", "is", "the", "bias", "in", "the", "first", "layer", ".", "We", "then", "normalize", "the", "logits", "into", "probabilities", ".", "Note", "that", "we", "follow", "previous", "work", "and", "employ", "softmax", "and", "sigmoid", "for", "multi", "-", "class", "and", "multi", "-", "label", "classifications", ",", "respectively", ".", "subsection", ":", "Loss", "Function", "Similar", "to", "previous", "studies", ",", "in", "the", "multi", "-", "class", "text", "classification", ",", "we", "use", "cross", "entorpy", "loss", "as", "our", "loss", "function", ":", "Following", "previous", "researchers", ",", "we", "choose", "binary", "classification", "loss", "as", "our", "loss", "function", "for", "the", "multi", "-", "label", "one", ":", "section", ":", "Generalized", "Encoding", "-", "Based", "Model", "In", "this", "section", ",", "we", "elaborate", "how", "the", "encoding", "-", "based", "model", "can", "be", "interpreted", "as", "a", "special", "case", "of", "our", "EXAM", "framework", ".", "As", "FastText", "is", "the", "most", "popular", "model", "for", "text", "classification", "and", "has", "been", "investigated", "extensively", "in", "the", "literature", ",", "being", "able", "to", "recover", "it", "allows", "EXAM", "to", "mimic", "a", "large", "family", "of", "text", "classification", "models", ".", "FastText", "contains", "three", "layers", ":", "1", ")", "an", "embedding", "layer", "to", "get", "the", "word", "-", "level", "representation", "for", "the", "word", ",", "2", ")", "an", "average", "pooling", "layer", "to", "get", "the", "text", "-", "level", "representation", ",", "and", "3", ")", "a", "FC", "layer", "to", "get", "the", "final", "logits", ",", "where", "denotes", "the", "embedding", "size", "and", "means", "the", "number", "of", "classes", ".", "Note", "that", "we", "omit", "the", "subscript", "of", "the", "document", "ID", "for", "conciseness", ".", "Formally", ",", "it", "computes", "the", "logits", "of", "-", "th", "class", "as", "follows", ":", "where", "and", "are", "the", "trainable", "parameters", "in", "the", "last", "FC", "layer", ",", "and", "denotes", "the", "length", "of", "the", "text", ".", "The", "Eqn.", "(", "9", ")", "has", "an", "equivalent", "form", "as", "following", ":", "It", "is", "worth", "noting", "that", "is", "exactly", "the", "interaction", "feature", "between", "word", "and", "class", ".", "Therefore", ",", "the", "FastText", "is", "a", "special", "case", "of", "EXAM", "with", "an", "average", "pooling", "as", "the", "aggregation", "layer", ".", "In", "EXAM", ",", "we", "use", "a", "non", "-", "linear", "MLP", "to", "be", "the", "aggregation", "layer", ",", "and", "it", "will", "generalize", "FastText", "to", "a", "non", "-", "linear", "setting", "which", "might", "be", "more", "expressive", "than", "the", "original", "one", ".", "section", ":", "Experiments", "subsection", ":", "Multi", "-", "Class", "Classification", "subsubsection", ":", "Datasets", "We", "used", "publicly", "available", "benchmark", "datasets", "from", "to", "evaluate", "EXAM", ".", "There", "are", "in", "total", "6", "text", "classification", "datasets", ",", "corresponding", "to", "sentiment", "analysis", ",", "news", "classification", ",", "question", "-", "answer", "and", "ontology", "extraction", "tasks", ",", "respectively", ".", "Table", "1", "shows", "the", "descriptive", "statistics", "of", "datasets", "used", "in", "our", "experiments", ".", "Stanford", "tokenizer", "is", "used", "to", "tokenize", "the", "text", "and", "all", "words", "are", "converted", "to", "lower", "case", ".", "We", "used", "padding", "to", "handle", "the", "various", "lengths", "of", "the", "text", ",", "and", "different", "maximum", "lengths", "are", "set", "for", "each", "dataset", ",", "respectively", ".", "If", "the", "length", "of", "the", "text", "is", "less", "than", "the", "corresponding", "predefined", "value", ",", "we", "padded", "it", "with", "zero", ";", "otherwise", "we", "truncated", "the", "original", "text", ".", "To", "guarantee", "a", "fair", "comparison", ",", "the", "same", "evaluation", "protocol", "of", "is", "employed", ".", "We", "split", "10", "%", "samples", "from", "the", "training", "set", "as", "the", "validation", "set", "to", "perform", "early", "stop", "for", "our", "models", ".", "subsubsection", ":", "Hyperparameters", "For", "the", "multi", "-", "class", "task", ",", "we", "chose", "region", "embedding", "as", "the", "Encoder", "in", "EXAM", ".", "The", "region", "size", "is", "7", "and", "embedding", "size", "is", "128", ".", "We", "used", "adam", "as", "the", "optimizer", "with", "the", "initial", "learning", "rate", "0.0001", "and", "the", "batch", "size", "is", "set", "to", "16", ".", "As", "for", "the", "aggregation", "MLP", ",", "we", "set", "the", "size", "of", "the", "hidden", "layer", "as", "2", "times", "interaction", "feature", "length", ".", "Our", "models", "are", "implemented", "and", "trained", "by", "MXNet", "with", "a", "single", "NVIDIA", "TITAN", "Xp", ".", "subsubsection", ":", "Baselines", "To", "demonstrate", "the", "effectiveness", "of", "our", "proposed", "EXAM", ",", "we", "compared", "it", "with", "several", "state", "-", "of", "-", "the", "-", "art", "baselines", ".", "The", "baselines", "are", "mainly", "in", "three", "variants", ":", "1", ")", "models", "based", "on", "feature", "engineering", ";", "2", ")", "Char", "-", "based", "deep", "models", ",", "and", "3", ")", "Word", "-", "based", "deep", "models", ".", "The", "first", "category", "uses", "the", "feature", "from", "the", "text", "to", "conduct", "the", "classification", ",", "and", "we", "reported", "the", "results", "from", "BoW", ",", "N", "-", "grams", "and", "N", "-", "grams", "TFIDF", "as", "baselines", ".", "The", "second", "one", "means", "the", "input", "of", "the", "model", "is", "the", "character", "in", "the", "original", "text", ",", "and", "we", "chose", "the", "Char", "-", "CNN", ",", "Char", "-", "CRNN", "and", "VDCNN", "as", "baselines", ".", "As", "for", "the", "word", "-", "based", "deep", "models", ",", "the", "text", "is", "pre", "-", "segmented", "into", "words", "as", "the", "input", ",", "and", "we", "applied", "Small", "word", "CNN", ",", "Large", "word", "CNN", ",", "LSTM", ",", "FastText", "and", "W.C", "RegionEmb", "as", "the", "baselines", ".", "It", "is", "worth", "emphasizing", "that", "all", "the", "baselines", "and", "our", "EXAM", "do", "not", "use", "pre", "-", "trained", "word", "embedding", "over", "other", "corpus", "like", "glove", ".", "subsubsection", ":", "Overall", "Performance", "We", "compared", "our", "EXAM", "to", "several", "state", "-", "of", "-", "the", "-", "art", "baselines", "with", "respect", "to", "accuracy", ".", "All", "results", "are", "summarized", "in", "Table", "[", "reference", "]", ".", "Four", "points", "are", "observed", "as", "following", ":", "Models", "based", "on", "feature", "engineering", "get", "the", "worst", "results", "on", "all", "the", "five", "datasets", "compared", "to", "the", "other", "methods", ".", "The", "main", "reason", "is", "that", "the", "feature", "engineering", "can", "not", "take", "full", "advantage", "of", "the", "supervision", "from", "the", "training", "set", "and", "it", "also", "suffers", "from", "the", "data", "sparsity", ".", "Char", "-", "based", "models", "get", "the", "highest", "overall", "scores", "on", "the", "two", "Amazon", "datasets", ".", "There", "are", "possibly", "two", "reasons", ",", "1", ")", "compared", "to", "the", "word", "-", "based", "models", ",", "char", "-", "based", "models", "enrich", "the", "supervision", "from", "characters", "and", "the", "characters", "are", "combined", "to", "form", "N", "-", "grams", ",", "stems", ",", "words", "and", "phrase", "which", "are", "helpful", "in", "the", "sentimental", "classification", ".", "2", ")", "The", "two", "Amazon", "datasets", "contain", "millions", "of", "training", "samples", ",", "perfectly", "fitting", "the", "deep", "residual", "architecture", "for", "the", "VDCNN", ".", "For", "the", "three", "char", "-", "based", "baselines", ",", "VDCNN", "gets", "the", "best", "performance", "on", "almost", "all", "the", "datasets", "because", "it", "has", "29", "convolutional", "layers", "allowing", "the", "model", "to", "learn", "more", "combinations", "of", "characters", ".", "Word", "-", "based", "baselines", "exceed", "the", "other", "variants", "on", "three", "datasets", "and", "lose", "on", "the", "two", "Amazon", "datasets", ".", "The", "main", "reason", "is", "that", "the", "three", "tasks", "like", "news", "classification", "conduct", "categorization", "mainly", "via", "key", "words", ",", "and", "the", "word", "-", "based", "models", "are", "able", "to", "directly", "use", "the", "word", "embedding", "without", "combining", "the", "characters", ".", "For", "the", "five", "baselines", ",", "W.C", "RegionEmb", "performs", "the", "best", ",", "because", "it", "learns", "the", "region", "embedding", "to", "utilize", "the", "N", "-", "grams", "feature", "from", "the", "text", ".", "It", "is", "clear", "to", "see", "that", "EXAM", "achieves", "the", "best", "performance", "over", "the", "three", "datasets", ":", "AG", ",", "Yah", ".", "A.", "and", "DBP", ".", "For", "the", "Yah", ".", "A.", ",", "EXAM", "improves", "the", "best", "performance", "by", "1.1", "%", ".", "Additionally", ",", "as", "a", "word", "-", "based", "model", ",", "EXAM", "beats", "all", "the", "word", "-", "based", "baselines", "on", "the", "other", "two", "Amazon", "datasets", "with", "a", "performance", "gain", "of", "1.0", "%", "on", "the", "Amazon", "Full", ",", "because", "our", "EXAM", "considers", "more", "fine", "-", "grained", "interaction", "features", "between", "classes", "and", "words", ",", "which", "is", "quite", "helpful", "in", "this", "task", ".", "subsubsection", ":", "Component", "-", "wise", "Evaluation", "We", "studied", "the", "variant", "of", "our", "model", "to", "further", "investigate", "the", "effectiveness", "of", "the", "interaction", "layer", "and", "aggregation", "layer", ".", "We", "built", "a", "model", "called", "EXAM", "to", "preserve", "only", "the", "Encoder", "component", "with", "a", "max", "pooling", "layer", "and", "FC", "layer", "to", "derive", "the", "final", "probabilities", ".", "EXAM", "does", "not", "consider", "the", "interaction", "features", "between", "the", "classes", "and", "words", ",", "so", "it", "will", "automatically", "be", "degenerated", "into", "the", "Encoding", "-", "Based", "model", ".", "We", "reported", "the", "results", "of", "the", "two", "models", "on", "all", "the", "datasets", "at", "Table", "[", "reference", "]", ",", "and", "it", "is", "clear", "to", "see", "that", "EXAM", "is", "not", "a", "patch", "on", "the", "original", "EXAM", ",", "verifying", "the", "effectiveness", "of", "interaction", "mechanism", ".", "We", "also", "drew", "the", "convergence", "lines", "for", "EXAM", "and", "the", "EXAM", "for", "the", "datasets", ".", "From", "the", "Figure", "[", "reference", "]", ",", "where", "the", "red", "lines", "represent", "EXAM", "and", "the", "blue", "is", "EXAM", ",", "we", "observed", "that", "EXAM", "converges", "faster", "than", "EXAM", "with", "respect", "to", "all", "the", "datasets", ".", "Therefore", ",", "the", "interaction", "brings", "not", "only", "performance", "improvement", "but", "also", "faster", "convergence", ".", "The", "possible", "reason", "is", "that", "a", "non", "-", "linear", "aggregation", "layer", "introduces", "more", "parameters", "to", "fit", "the", "interaction", "features", "compared", "to", "the", "average", "pooling", "layer", "as", "mentioned", "in", "Section", "4", ".", "subsection", ":", "Multi", "-", "Label", "Classification", "subsubsection", ":", "Datasets", "We", "conducted", "experiments", "on", "two", "different", "multi", "-", "label", "text", "classification", "datasets", ",", "named", "KanShan", "-", "Cup", "dataset", "(", "a", "benchmark", ")", "and", "Zhihu", "dataset", ",", "respectively", ".", "KanShan", "-", "Cup", "dataset", ".", "This", "dataset", "is", "released", "by", "a", "competition", "of", "tagging", "topics", "for", "questions", "(", "multi", "-", "label", "classification", ")", "posted", "in", "the", "largest", "Chinese", "community", "question", "answering", "platform", ",", "Zhihu", ".", "The", "dataset", "contains", "3", ",", "000", ",", "000", "questions", "and", "1", ",", "999", "topics", "(", "classes", ")", ",", "where", "one", "question", "may", "belong", "to", "one", "to", "five", "topics", ".", "For", "questions", "with", "more", "than", "30", "words", ",", "we", "kept", "the", "last", "30", "words", ",", "otherwise", ",", "we", "padded", "zeros", ".", "We", "separated", "the", "dataset", "into", "training", ",", "validation", ",", "and", "testing", "with", "2", ",", "800", ",", "000", ",", "20", ",", "000", ",", "and", "180", ",", "000", "questions", ",", "respectively", ".", "Zhihu", "dataset", ".", "Considering", "the", "user", "privacy", "and", "data", "security", ",", "KanShan", "-", "Cup", "does", "not", "provide", "the", "original", "texts", "of", "the", "questions", "and", "topics", ",", "but", "uses", "numbered", "codes", "and", "numbered", "segmented", "words", "to", "represent", "text", "messages", ".", "Therefore", ",", "it", "is", "inconvenient", "for", "researchers", "to", "perform", "analyses", "like", "visualization", "and", "case", "study", ".", "To", "solve", "this", "problem", ",", "we", "constructed", "a", "dataset", "named", "Zhihu", "dataset", ".", "We", "chose", "the", "top", "1", ",", "999", "frequent", "topics", "from", "Zhihu", "and", "crawled", "all", "the", "questions", "relevant", "to", "these", "topics", ".", "Finally", ",", "we", "acquired", "3", ",", "300", ",", "000", "questions", ",", "with", "less", "than", "5", "topics", "for", "each", "question", ".", "We", "adopted", "3", ",", "000", ",", "000", "samples", "as", "the", "training", "set", ",", "30", ",", "000", "samples", "as", "validation", "and", "300", ",", "000", "samples", "as", "testing", ".", "subsubsection", ":", "Baselines", "We", "applied", "the", "following", "models", "as", "baselines", "to", "evaluate", "the", "effectiveness", "of", "EXAM", ".", "Char", "-", "based", "Model", ".", "We", "chose", "Char", "-", "CNN", "and", "Char", "-", "RNN", "as", "the", "baselines", "to", "represent", "this", "kind", "of", "methods", ".", "Word", "-", "based", "Model", ".", "For", "the", "word", "-", "based", "models", ",", "we", "reported", "the", "results", "from", "TextCNN", ",", "TextRNN", "and", "FastText", ".", "The", "three", "models", "got", "the", "best", "performance", "in", "the", "KanShan", "-", "Cup", "competition", ",", "so", "we", "applied", "them", "as", "the", "word", "-", "based", "baselines", ".", "subsubsection", ":", "Hyperparameters", "We", "implemented", "the", "baseline", "models", "and", "EXAM", "by", "MXNet", ".", "We", "used", "the", "matrix", "trained", "by", "word2vec", "to", "initialize", "the", "embedding", "layer", ",", "and", "the", "embedding", "size", "is", "256", ".", "We", "adopted", "GRU", "as", "the", "Encoder", ",", "and", "each", "GRU", "Cell", "has", "1", ",", "024", "hidden", "states", ".", "The", "accumulated", "MLP", "has", "60", "hidden", "units", ".", "We", "applied", "Adam", "to", "optimize", "models", "on", "one", "NVIDIA", "TITAN", "Xp", "with", "the", "batch", "size", "of", "1000", "and", "the", "initial", "learning", "rate", "is", "0.001", ".", "The", "validation", "set", "is", "applied", "for", "early", "-", "stopping", "to", "avoid", "overfitting", ".", "All", "hyperparameters", "are", "chosen", "empirically", ".", "subsubsection", ":", "Metrics", "We", "used", "the", "following", "metrics", "to", "evaluate", "the", "performance", "of", "our", "model", "and", "baseline", "models", ".", "Precision", ":", "Different", "from", "the", "traditional", "precision", "metric", "(", "Precision@5", ")", "which", "is", "set", "as", "the", "fraction", "of", "the", "relevant", "topic", "tags", "among", "the", "five", "returned", "tags", ",", "we", "utilized", "weighted", "precision", "to", "encourage", "the", "relevant", "topic", "tags", "to", "be", "ranked", "higher", "in", "the", "returned", "list", ".", "Formally", ",", "the", "Precision", "is", "computed", "as", "following", ",", "Recall@5", ":", "Recall", "is", "the", "fraction", "of", "relevant", "topic", "tags", "that", "have", "been", "retrieved", "over", "the", "total", "amount", "of", "five", "relevant", "topic", "tags", ",", "high", "recall", "means", "that", "the", "model", "returns", "most", "of", "the", "relevant", "topic", "tags", ".", ":", "is", "the", "harmonic", "average", "of", "the", "precision", "and", "recall", ",", "we", "computed", "it", "as", "following", ",", "subsubsection", ":", "Performance", "Comparison", "Table", "[", "reference", "]", "gives", "the", "performance", "of", "our", "model", "and", "baselines", "over", "two", "different", "datasets", "with", "respect", "to", "Precision", ",", "Recall@5", "and", ".", "We", "observed", "the", "following", "from", "the", "Table", "[", "reference", "]", ":", "Word", "-", "based", "models", "are", "better", "than", "char", "-", "based", "models", "in", "Kanshan", "-", "Cup", "dataset", ".", "That", "may", "be", "because", "in", "Chinese", "the", "words", "can", "offer", "more", "supervisions", "than", "characters", "and", "the", "question", "tagging", "task", "needs", "more", "word", "supervision", ".", "For", "word", "-", "based", "baseline", "models", ",", "all", "the", "baselines", "have", "similar", "performance", "which", "corroborates", "the", "conclusion", "in", "FastText", "that", "simple", "network", "is", "on", "par", "with", "deep", "learning", "classifiers", "in", "text", "classification", ".", "Our", "models", "achieve", "the", "state", "-", "of", "-", "the", "-", "art", "performance", "over", "two", "different", "datasets", "though", "we", "only", "slightly", "modified", "TextRNN", "to", "build", "EXAM", ".", "Different", "from", "the", "traditional", "models", "which", "encode", "the", "whole", "text", "into", "a", "vector", ",", "in", "EXAM", ",", "the", "representations", "of", "classes", "firstly", "interact", "with", "words", "to", "get", "more", "fine", "-", "grained", "features", "as", "shown", "in", "Figure", "[", "reference", "]", ".", "The", "results", "suggest", "that", "word", "-", "level", "interaction", "features", "are", "relatively", "more", "important", "than", "global", "text", "-", "level", "representations", "in", "this", "task", ".", "subsubsection", ":", "Interaction", "Visualization", "To", "illustrate", "the", "effectiveness", "of", "explicit", "interaction", ",", "we", "visualized", "an", "interaction", "feature", "I", "of", "the", "question", "\u201c", "Second", "-", "hand", "TIDDA", "1.6", "T", "Mannual", "gear", "has", "gotten", "some", "problems", ",", "please", "everybody", "help", "me", "to", "solve", "it", "?", "\u201d", ".", "This", "question", "has", "5", "topics", ":", "Car", ",", "Second", "-", "hand", "Car", ",", "Motor", "Dom", ",", "Autocar", "Conversation", "and", "Autocar", "Service", ".", "EXAM", "only", "misclassified", "the", "last", "topic", ".", "In", "Figure", "[", "reference", "]", ",", "we", "observed", "that", "when", "classifying", "different", "topics", ",", "the", "interaction", "features", "are", "different", ".", "The", "topics", "\u201c", "Car", "\u201d", "and", "\u201c", "Second", "-", "hand", "Car", "\u201d", "pay", "much", "attention", "to", "the", "words", "like", "\u201c", "Second", "-", "hand", "TIIDA", "\u201d", "and", "the", "other", "topic", "like", "\u201c", "Autocar", "Conversation", "\u201d", "focuses", "more", "on", "\u201c", "got", "some", "problems", "\u201d", ".", "The", "results", "clearly", "signify", "that", "the", "interaction", "feature", "between", "the", "word", "and", "class", "is", "well", "-", "learned", "and", "highly", "meaningful", ".", "section", ":", "Related", "Work", "subsubsection", ":", "Text", "Classification", "Existing", "researches", "on", "text", "classification", "can", "be", "categorized", "into", "two", "groups", ":", "feature", "-", "based", "and", "deep", "neural", "models", ".", "The", "former", "focuses", "on", "hand", "-", "craft", "features", "and", "uses", "machine", "learning", "algorithms", "as", "the", "classifier", ".", "Bag", "-", "of", "-", "words", "is", "a", "very", "efficient", "way", "to", "conduct", "the", "feature", "engineering", ".", "SVM", "and", "Naive", "Bayes", "are", "constantly", "the", "classifier", ".", "The", "latter", ",", "deep", "neural", "models", ",", "taking", "advantage", "of", "neural", "networks", "to", "accomplish", "the", "model", "learning", "from", "data", ",", "have", "become", "the", "promising", "solution", "for", "the", "text", "classification", ".", "For", "instance", ",", "Iyyer", "et", "al", ".", "dan", "proposed", "Deep", "Averaging", "Networks", "(", "DAN", ")", "and", "Grave", "et", "al", ".", "fasttext", "proposed", "the", "FastText", ",", "and", "both", "are", "simple", "but", "efficient", ".", "To", "get", "the", "temporal", "features", "between", "the", "words", "in", "the", "text", ",", "some", "models", "like", "TextCNN", "and", "Char", "-", "CNN", "exploit", "the", "convolutional", "neural", "network", ",", "and", "there", "are", "also", "some", "models", "based", "on", "Recurrent", "Neural", "Network", "(", "RNN", ")", ".", "Recently", ",", "Johnson", "et", "al", ".", "vdcnn", "investigated", "the", "residual", "architecture", "and", "built", "a", "model", "called", "VD", "-", "CNN", "and", "Qiao", "et", "al", ".", "regionemb", "proposed", "a", "new", "method", "of", "region", "embedding", "for", "the", "text", "classification", ".", "However", ",", "as", "mentioned", "in", "the", "Introduction", ",", "all", "these", "methods", "are", "text", "-", "level", "models", "while", "EXAM", "conducts", "the", "matching", "at", "the", "word", "level", ".", "subsubsection", ":", "Interaction", "Mechanism", "Interaction", "Mechanism", "is", "widely", "used", "in", "Natural", "Language", "Sentence", "Matching", "(", "NLSM", ")", ".", "The", "key", "idea", "of", "interaction", "mechanism", "is", "to", "use", "the", "interaction", "features", "between", "the", "small", "units", "(", "like", "words", "in", "sentence", ")", "to", "make", "the", "matching", ".", "Wang", "et", "al", ".", "llstm", "proposed", "a", "\u201c", "matching", "-", "aggregation", "\u201d", "framework", "to", "perform", "the", "interaction", "in", "Natural", "Language", "Inference", ".", "Following", "this", "work", ",", "Parikh", "et", "al", ".", "DATTENTION", "integrated", "the", "attention", "mechanism", "into", "this", "framework", ",", "called", "Decomposable", "Attention", "Model", ".", "Then", "Wang", "et", "al", ".", "Wang2016ACM", "discussed", "different", "interaction", "functions", "in", "Text", "Matching", ".", "Yu", "et", "al", ".", "TREE", "adopted", "tree", "-", "LSTM", "to", "get", "different", "level", "units", "to", "perform", "the", "interaction", ".", "Gong", "et", "al", ".", "diin", "proposed", "a", "densely", "interactive", "inference", "network", "to", "use", "DenseNet", "to", "aggregate", "dense", "interaction", "features", ".", "Our", "work", "is", "different", "from", "them", "since", "they", "mainly", "apply", "this", "mechanism", "in", "text", "matching", "instead", "of", "the", "classification", ".", "section", ":", "Conclusion", "In", "this", "work", ",", "we", "present", "a", "novel", "framework", "named", "EXAM", "which", "employs", "the", "interaction", "mechanism", "to", "explicitly", "compute", "the", "word", "-", "level", "interaction", "signals", "for", "the", "text", "classification", ".", "We", "apply", "the", "proposed", "EXAM", "on", "multi", "-", "class", "and", "multi", "-", "label", "text", "classifications", ".", "Experiments", "over", "several", "benchmark", "datasets", "verify", "the", "effectiveness", "of", "our", "proposed", "mechanism", ".", "In", "the", "future", ",", "we", "plan", "to", "investigate", "the", "effect", "of", "different", "interaction", "functions", "in", "the", "interaction", "mechanism", ".", "Besides", ",", "we", "are", "interested", "in", "extend", "EXAM", "by", "introducing", "more", "complex", "aggregation", "layers", "like", "ResNet", "or", "DenseNet", ".", "section", ":", "Acknowledgments", "This", "work", "is", "supported", "by", "the", "National", "Basic", "Research", "Program", "of", "China", "(", "973", "Program", ")", ",", "No", ".", ":", "2015CB352502", ";", "National", "Natural", "Science", "Foundation", "of", "China", ",", "No", ".", ":", "61772310", ",", "No.:61702300", ",", "and", "No.:61702302", ";", "the", "Project", "of", "Thousand", "Youth", "Talents", "2016", ";", "and", "the", "Tencent", "AI", "Lab", "Rhino", "-", "Bird", "Joint", "Research", "Program", "(", "No", ".", "JR201805", ")", ";", "Fundamental", "Research", "Funds", "of", "Shandong", "University", "(", "No", ".", "2017HW001", ")", ".", "bibliography", ":", "References"]}