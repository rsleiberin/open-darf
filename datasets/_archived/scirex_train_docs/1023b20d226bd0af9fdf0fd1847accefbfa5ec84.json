{"coref": {"ASR": [[2494, 2496]], "AS_Reader": [], "AS_Reader__ensemble_model_": [], "AS_Reader__single_model_": [], "AS_reader": [[6, 10], [1817, 1819], [1888, 1890], [1896, 1898], [2222, 2224]], "AS_reader__avg_": [], "AS_reader__greedy_": [], "Accuracy-CN": [], "Accuracy-NE": [[2369, 2370], [3107, 3110], [3395, 3396], [3506, 3508], [3510, 3512], [3527, 3529], [3576, 3577], [3596, 3597], [3676, 3677], [3728, 3729], [3812, 3813], [3890, 3891], [3914, 3915], [3963, 3964], [3983, 3984], [4066, 4067], [4118, 4119], [4265, 4267], [4286, 4288], [4310, 4311], [4327, 4329]], "CNN": [], "CNN___Daily_Mail": [[28, 34], [792, 796], [951, 953], [1110, 1114], [2662, 2666], [3182, 3183], [3184, 3186], [3419, 3420], [3425, 3427], [3499, 3501], [811, 812], [1877, 1878], [2869, 2870], [3330, 3331], [3579, 3580], [3721, 3722], [4078, 4079]], "Children_s_Book_Test": [[36, 40], [975, 979], [1115, 1116], [2667, 2669], [3187, 3188], [3351, 3353], [3585, 3586], [3823, 3825], [4351, 4355], [966, 970], [980, 981]], "Daily_Mail": [], "N-gram_F1": [], "Open-Domain_Question_Answering": [], "Question_Answering": [[118, 122]], "SearchQA": [], "Unigram_Acc": [], "avg": [[3056, 3058], [3212, 3214], [3613, 3615]], "ensemble_model": [[3001, 3003], [3166, 3168], [3194, 3196]], "greedy": [[3285, 3287], [3414, 3416]], "single_model": [[2993, 2995], [3142, 3144], [3093, 3095], [3124, 3126], [3631, 3633]]}, "coref_non_salient": {"0": [[1662, 1664], [1927, 1932], [2188, 2190]], "1": [[1249, 1251], [1399, 1401], [1942, 1944]], "10": [[1527, 1528], [1536, 1537], [1767, 1769], [2072, 2074], [2394, 2396], [2475, 2477]], "11": [[2375, 2377], [3609, 3611]], "12": [[2711, 2714]], "13": [[1557, 1558], [2471, 2472], [2499, 2500], [2599, 2600]], "14": [[1281, 1284], [1290, 1293], [1669, 1672], [2755, 2758]], "15": [[3543, 3545], [3563, 3565]], "16": [[51, 54], [475, 477], [1743, 1745], [2245, 2247]], "17": [[2252, 2259]], "18": [[1286, 1288], [1301, 1303], [2749, 2751]], "19": [[3020, 3021]], "2": [[1733, 1737], [4036, 4039]], "20": [[2963, 2967]], "21": [[1624, 1626], [2335, 2337], [2575, 2577]], "22": [[3231, 3233]], "23": [[2626, 2629]], "24": [[2990, 2992]], "25": [[2444, 2447]], "26": [[2353, 2355]], "27": [[1356, 1359], [1903, 1906]], "28": [[2, 4], [216, 218]], "29": [[2715, 2719]], "3": [[1628, 1630], [1832, 1834]], "30": [[4040, 4044]], "31": [[3567, 3569]], "32": [[3434, 3439]], "33": [[1305, 1307], [1583, 1585]], "34": [[2503, 2504], [2508, 2509]], "35": [[1657, 1659]], "36": [[2126, 2127]], "37": [[2834, 2835], [3022, 3024]], "38": [[2238, 2239], [2403, 2404], [2613, 2614], [3607, 3608], [3639, 3640], [3656, 3657]], "39": [[2194, 2196]], "4": [[2981, 2982], [3469, 3471]], "40": [[1970, 1971]], "41": [[2706, 2709]], "42": [[649, 653]], "43": [[2088, 2090]], "44": [[2463, 2465], [2535, 2537]], "45": [[191, 193]], "46": [[3170, 3171]], "47": [[2448, 2451]], "48": [[1068, 1071]], "49": [[97, 99]], "5": [[3588, 3591], [3627, 3630]], "50": [[514, 516]], "51": [[1946, 1948]], "52": [[263, 265]], "53": [[206, 208]], "54": [[1296, 1298]], "55": [[2412, 2415]], "56": [[1829, 1831]], "57": [[3133, 3136]], "58": [[1529, 1535]], "59": [[2236, 2238]], "6": [[2428, 2431], [2432, 2436]], "60": [[1433, 1435]], "61": [[508, 512]], "62": [[1646, 1648]], "63": [[2791, 2793]], "64": [[386, 388]], "65": [[2372, 2374]], "66": [[58, 62]], "67": [[3494, 3496]], "68": [[1216, 1221], [1225, 1227]], "69": [[4233, 4235]], "7": [[343, 345], [1041, 1043]], "70": [[528, 529]], "8": [[1589, 1597], [1634, 1637]], "9": [[1239, 1241], [1253, 1255], [1326, 1328], [1395, 1397]]}, "doc_id": "1023b20d226bd0af9fdf0fd1847accefbfa5ec84", "method_subrelations": {"ASR": [[[0, 3], "ASR"]], "AS_Reader__ensemble_model_": [[[0, 9], "AS_Reader"], [[11, 25], "ensemble_model"]], "AS_Reader__single_model_": [[[0, 9], "AS_Reader"], [[11, 23], "single_model"]], "AS_reader__avg_": [[[0, 9], "AS_reader"], [[11, 14], "avg"]], "AS_reader__greedy_": [[[0, 9], "AS_reader"], [[11, 17], "greedy"]]}, "n_ary_relations": [{"Material": "CNN___Daily_Mail", "Method": "AS_Reader__ensemble_model_", "Metric": "CNN", "Task": "Question_Answering", "score": "75.4"}, {"Material": "CNN___Daily_Mail", "Method": "AS_Reader__single_model_", "Metric": "CNN", "Task": "Question_Answering", "score": " 69.5"}, {"Material": "CNN___Daily_Mail", "Method": "AS_Reader__ensemble_model_", "Metric": "Daily_Mail", "Task": "Question_Answering", "score": "77.7"}, {"Material": "CNN___Daily_Mail", "Method": "AS_Reader__single_model_", "Metric": "Daily_Mail", "Task": "Question_Answering", "score": "73.9"}, {"Material": "Children_s_Book_Test", "Method": "AS_reader__avg_", "Metric": "Accuracy-CN", "Task": "Question_Answering", "score": "68.9%"}, {"Material": "Children_s_Book_Test", "Method": "AS_reader__greedy_", "Metric": "Accuracy-CN", "Task": "Question_Answering", "score": "67.5%"}, {"Material": "Children_s_Book_Test", "Method": "AS_reader__avg_", "Metric": "Accuracy-NE", "Task": "Question_Answering", "score": "70.6%"}, {"Material": "Children_s_Book_Test", "Method": "AS_reader__greedy_", "Metric": "Accuracy-NE", "Task": "Question_Answering", "score": "71%"}, {"Material": "SearchQA", "Method": "ASR", "Metric": "N-gram_F1", "Task": "Open-Domain_Question_Answering", "score": "22.8"}, {"Material": "SearchQA", "Method": "ASR", "Metric": "Unigram_Acc", "Task": "Open-Domain_Question_Answering", "score": "41.3"}], "ner": [[2, 4, "Task"], [6, 10, "Method"], [28, 34, "Material"], [36, 40, "Material"], [51, 54, "Task"], [58, 62, "Method"], [97, 99, "Method"], [118, 122, "Task"], [191, 193, "Task"], [206, 208, "Task"], [216, 218, "Task"], [263, 265, "Method"], [343, 345, "Metric"], [386, 388, "Task"], [475, 477, "Task"], [508, 512, "Method"], [514, 516, "Method"], [528, 529, "Method"], [649, 653, "Task"], [792, 796, "Material"], [951, 953, "Material"], [975, 979, "Material"], [1041, 1043, "Metric"], [1068, 1071, "Method"], [1110, 1114, "Material"], [1115, 1116, "Material"], [1216, 1221, "Method"], [1225, 1227, "Method"], [1239, 1241, "Method"], [1249, 1251, "Method"], [1253, 1255, "Method"], [1281, 1284, "Method"], [1286, 1288, "Method"], [1290, 1293, "Method"], [1296, 1298, "Method"], [1301, 1303, "Method"], [1305, 1307, "Method"], [1326, 1328, "Method"], [1356, 1359, "Method"], [1395, 1397, "Method"], [1399, 1401, "Method"], [1433, 1435, "Method"], [1527, 1528, "Method"], [1529, 1535, "Method"], [1536, 1537, "Method"], [1557, 1558, "Method"], [1583, 1585, "Method"], [1589, 1597, "Method"], [1624, 1626, "Method"], [1628, 1630, "Method"], [1634, 1637, "Method"], [1646, 1648, "Method"], [1657, 1659, "Method"], [1662, 1664, "Task"], [1669, 1672, "Method"], [1733, 1737, "Method"], [1743, 1745, "Task"], [1767, 1769, "Method"], [1817, 1819, "Method"], [1829, 1831, "Method"], [1832, 1834, "Method"], [1888, 1890, "Method"], [1896, 1898, "Method"], [1903, 1906, "Method"], [1927, 1932, "Task"], [1942, 1944, "Method"], [1946, 1948, "Method"], [1970, 1971, "Method"], [2072, 2074, "Method"], [2088, 2090, "Method"], [2126, 2127, "Method"], [2188, 2190, "Task"], [2194, 2196, "Method"], [2222, 2224, "Method"], [2236, 2238, "Method"], [2238, 2239, "Method"], [2245, 2247, "Task"], [2252, 2259, "Method"], [2335, 2337, "Method"], [2353, 2355, "Task"], [2369, 2370, "Metric"], [2372, 2374, "Method"], [2375, 2377, "Method"], [2394, 2396, "Method"], [2403, 2404, "Method"], [2412, 2415, "Task"], [2428, 2431, "Method"], [2432, 2436, "Method"], [2444, 2447, "Method"], [2448, 2451, "Method"], [2463, 2465, "Method"], [2471, 2472, "Method"], [2475, 2477, "Method"], [2494, 2496, "Method"], [2499, 2500, "Method"], [2503, 2504, "Method"], [2508, 2509, "Method"], [2535, 2537, "Method"], [2575, 2577, "Method"], [2599, 2600, "Method"], [2613, 2614, "Method"], [2626, 2629, "Method"], [2662, 2666, "Material"], [2667, 2669, "Material"], [2706, 2709, "Method"], [2711, 2714, "Method"], [2715, 2719, "Method"], [2749, 2751, "Method"], [2755, 2758, "Method"], [2791, 2793, "Method"], [2834, 2835, "Task"], [2963, 2967, "Task"], [2981, 2982, "Method"], [2990, 2992, "Metric"], [2993, 2995, "Method"], [3001, 3003, "Method"], [3020, 3021, "Method"], [3022, 3024, "Task"], [3056, 3058, "Method"], [3107, 3110, "Metric"], [3133, 3136, "Method"], [3142, 3144, "Method"], [3166, 3168, "Method"], [3170, 3171, "Task"], [3182, 3183, "Material"], [3184, 3186, "Material"], [3187, 3188, "Material"], [3194, 3196, "Method"], [3212, 3214, "Method"], [3231, 3233, "Metric"], [3285, 3287, "Method"], [3351, 3353, "Material"], [3395, 3396, "Metric"], [3419, 3420, "Material"], [3425, 3427, "Material"], [3434, 3439, "Task"], [3469, 3471, "Method"], [3494, 3496, "Method"], [3499, 3501, "Material"], [3506, 3508, "Metric"], [3510, 3512, "Metric"], [3527, 3529, "Metric"], [3543, 3545, "Method"], [3563, 3565, "Method"], [3567, 3569, "Method"], [3576, 3577, "Metric"], [3585, 3586, "Material"], [3588, 3591, "Task"], [3596, 3597, "Metric"], [3607, 3608, "Method"], [3609, 3611, "Method"], [3613, 3615, "Method"], [3627, 3630, "Task"], [3639, 3640, "Method"], [3656, 3657, "Method"], [3676, 3677, "Metric"], [3728, 3729, "Metric"], [3812, 3813, "Metric"], [3823, 3825, "Material"], [3890, 3891, "Metric"], [3914, 3915, "Metric"], [3963, 3964, "Metric"], [3983, 3984, "Metric"], [4036, 4039, "Method"], [4040, 4044, "Task"], [4066, 4067, "Metric"], [4118, 4119, "Metric"], [4233, 4235, "Method"], [4265, 4267, "Metric"], [4286, 4288, "Metric"], [4310, 4311, "Metric"], [4327, 4329, "Metric"], [4351, 4355, "Material"], [811, 812, "Material"], [966, 970, "Material"], [980, 981, "Material"], [1877, 1878, "Material"], [2869, 2870, "Material"], [3093, 3095, "Method"], [3124, 3126, "Method"], [3330, 3331, "Material"], [3414, 3416, "Method"], [3579, 3580, "Material"], [3631, 3633, "Method"], [3721, 3722, "Material"], [4078, 4079, "Material"]], "sections": [[0, 164], [164, 605], [605, 638], [638, 773], [773, 787], [787, 964], [964, 1125], [1125, 1273], [1273, 1574], [1574, 1726], [1726, 1801], [1801, 2146], [2146, 2234], [2234, 2426], [2426, 2461], [2461, 2558], [2558, 2650], [2650, 2695], [2695, 3040], [3040, 3320], [3320, 3659], [3659, 4026], [4026, 4124], [4124, 4148], [4148, 4151], [4151, 4306], [4306, 4376]], "sentences": [[0, 10], [10, 41], [41, 71], [71, 111], [111, 133], [133, 148], [148, 153], [153, 164], [164, 167], [167, 187], [187, 209], [209, 236], [236, 271], [271, 304], [304, 338], [338, 357], [357, 385], [385, 413], [413, 453], [453, 478], [478, 503], [503, 517], [517, 550], [550, 572], [572, 583], [583, 605], [605, 610], [610, 638], [638, 643], [643, 671], [671, 692], [692, 699], [699, 734], [734, 743], [743, 773], [773, 776], [776, 787], [787, 796], [796, 817], [817, 851], [851, 886], [886, 939], [939, 964], [964, 970], [970, 996], [996, 1012], [1012, 1035], [1035, 1063], [1063, 1091], [1091, 1106], [1106, 1125], [1125, 1133], [1133, 1134], [1134, 1157], [1157, 1165], [1165, 1204], [1204, 1222], [1222, 1243], [1243, 1273], [1273, 1277], [1277, 1289], [1289, 1299], [1299, 1322], [1322, 1329], [1329, 1345], [1345, 1367], [1367, 1378], [1378, 1402], [1402, 1414], [1414, 1436], [1436, 1453], [1453, 1485], [1485, 1520], [1520, 1550], [1550, 1559], [1559, 1574], [1574, 1579], [1579, 1627], [1627, 1638], [1638, 1668], [1668, 1685], [1685, 1702], [1702, 1716], [1716, 1726], [1726, 1730], [1730, 1746], [1746, 1761], [1761, 1787], [1787, 1801], [1801, 1807], [1807, 1815], [1815, 1826], [1826, 1845], [1845, 1863], [1863, 1883], [1883, 1926], [1926, 1945], [1945, 1972], [1972, 1976], [1976, 1977], [1977, 2013], [2013, 2018], [2018, 2027], [2027, 2030], [2030, 2031], [2031, 2048], [2048, 2049], [2049, 2061], [2061, 2087], [2087, 2133], [2133, 2145], [2145, 2146], [2146, 2153], [2153, 2164], [2164, 2187], [2187, 2203], [2203, 2214], [2214, 2233], [2233, 2234], [2234, 2238], [2238, 2249], [2249, 2277], [2277, 2298], [2298, 2319], [2319, 2364], [2364, 2402], [2402, 2416], [2416, 2425], [2425, 2426], [2426, 2431], [2431, 2461], [2461, 2465], [2465, 2497], [2497, 2532], [2532, 2558], [2558, 2561], [2561, 2573], [2573, 2601], [2601, 2615], [2615, 2638], [2638, 2650], [2650, 2653], [2653, 2670], [2670, 2695], [2695, 2699], [2699, 2720], [2720, 2759], [2759, 2768], [2768, 2772], [2772, 2788], [2788, 2806], [2806, 2821], [2821, 2832], [2832, 2853], [2853, 2864], [2864, 2895], [2895, 2920], [2920, 2939], [2939, 2940], [2940, 2958], [2958, 2975], [2975, 2976], [2976, 2998], [2998, 3008], [3008, 3025], [3025, 3033], [3033, 3039], [3039, 3040], [3040, 3044], [3044, 3059], [3059, 3092], [3092, 3142], [3142, 3152], [3152, 3169], [3169, 3193], [3193, 3215], [3215, 3234], [3234, 3252], [3252, 3270], [3270, 3279], [3279, 3288], [3288, 3292], [3292, 3296], [3296, 3300], [3300, 3304], [3304, 3308], [3308, 3312], [3312, 3316], [3316, 3320], [3320, 3323], [3323, 3354], [3354, 3370], [3370, 3389], [3389, 3419], [3419, 3424], [3424, 3443], [3443, 3460], [3460, 3478], [3478, 3497], [3497, 3516], [3516, 3546], [3546, 3566], [3566, 3587], [3587, 3626], [3626, 3658], [3658, 3659], [3659, 3662], [3662, 3719], [3719, 3741], [3741, 3751], [3751, 3761], [3761, 3787], [3787, 3821], [3821, 3834], [3834, 3839], [3839, 3878], [3878, 3900], [3900, 3917], [3917, 3942], [3942, 3976], [3976, 4004], [4004, 4017], [4017, 4020], [4020, 4025], [4025, 4026], [4026, 4029], [4029, 4045], [4045, 4072], [4072, 4124], [4124, 4127], [4127, 4148], [4148, 4151], [4151, 4155], [4155, 4179], [4179, 4189], [4189, 4214], [4214, 4215], [4215, 4236], [4236, 4268], [4268, 4296], [4296, 4306], [4306, 4318], [4318, 4347], [4347, 4368], [4368, 4376]], "words": ["document", ":", "Text", "Understanding", "with", "the", "Attention", "Sum", "Reader", "Network", "black", "Several", "large", "cloze", "-", "style", "context", "-", "question", "-", "answer", "datasets", "have", "been", "introduced", "recently", ":", "the", "CNN", "and", "Daily", "Mail", "news", "data", "and", "the", "Children", "\u2019s", "Book", "Test", ".", "Thanks", "to", "the", "size", "of", "these", "datasets", ",", "the", "associated", "text", "comprehension", "task", "is", "well", "suited", "for", "deep", "-", "learning", "techniques", "that", "currently", "seem", "to", "outperform", "all", "alternative", "approaches", ".", "We", "present", "a", "new", ",", "simple", "model", "that", "uses", "attention", "to", "directly", "pick", "the", "answer", "from", "the", "context", "as", "opposed", "to", "computing", "the", "answer", "using", "a", "blended", "representation", "of", "words", "in", "the", "document", "as", "is", "usual", "in", "similar", "models", ".", "This", "makes", "the", "model", "particularly", "suitable", "for", "question", "-", "answering", "problems", "where", "the", "answer", "is", "a", "single", "word", "from", "the", "document", ".", "blackEnsemble", "of", "our", "models", "sets", "new", "state", "of", "the", "art", "on", "all", "evaluated", "datasets", ".", "MemNNMemNNMemoryNetwork", "ptrnetPtr", "-", "NetPointerNetwork", "psrASReaderAttentionSumReader", "MenNNname", "=", "MemNN", ",", "description", "=", "isaprogrammablemachinethatreceivesinput", ",", "storesandmanipulatesdata", ",", "andprovidesoutputinausefulformat", "section", ":", "Introduction", "Most", "of", "the", "information", "humanity", "has", "gathered", "up", "to", "this", "point", "is", "stored", "in", "the", "form", "of", "plain", "text", ".", "Hence", "the", "task", "of", "teaching", "machines", "how", "to", "understand", "this", "data", "is", "of", "utmost", "importance", "in", "the", "field", "of", "Artificial", "Intelligence", ".", "One", "way", "of", "testing", "the", "level", "of", "text", "understanding", "is", "simply", "to", "ask", "the", "system", "questions", "for", "which", "the", "answer", "can", "be", "inferred", "from", "the", "text", ".", "A", "well", "-", "known", "example", "of", "a", "system", "that", "could", "make", "use", "of", "a", "huge", "collection", "of", "unstructured", "documents", "to", "answer", "questions", "is", "for", "instance", "IBM", "\u2019s", "Watson", "system", "used", "for", "the", "Jeopardy", "challenge", ".", "Cloze", "-", "style", "questions", ",", "i.e.", "questions", "formed", "by", "removing", "a", "phrase", "from", "a", "sentence", ",", "are", "an", "appealing", "form", "of", "such", "questions", "(", "for", "example", "see", "Figure", "[", "reference", "]", ")", ".", "While", "the", "task", "is", "easy", "to", "evaluate", ",", "one", "can", "vary", "the", "context", ",", "the", "question", "sentence", "or", "the", "specific", "phrase", "missing", "in", "the", "question", "to", "dramatically", "change", "the", "task", "structure", "and", "difficulty", ".", "One", "way", "of", "altering", "the", "task", "difficulty", "is", "to", "vary", "the", "word", "type", "being", "replaced", ",", "as", "in", ".", "The", "complexity", "of", "such", "variation", "comes", "from", "the", "fact", "that", "the", "level", "of", "context", "understanding", "needed", "in", "order", "to", "correctly", "predict", "different", "types", "of", "words", "varies", "greatly", ".", "While", "predicting", "prepositions", "can", "easily", "be", "done", "using", "relatively", "simple", "models", "with", "very", "little", "context", "knowledge", ",", "predicting", "named", "entities", "requires", "a", "deeper", "understanding", "of", "the", "context", ".", "Also", ",", "as", "opposed", "to", "selecting", "a", "random", "sentence", "from", "a", "text", "as", "in", ")", ",", "the", "question", "can", "be", "formed", "from", "a", "specific", "part", "of", "the", "document", ",", "such", "as", "a", "short", "summary", "or", "a", "list", "of", "tags", ".", "Since", "such", "sentences", "often", "paraphrase", "in", "a", "condensed", "form", "what", "was", "said", "in", "the", "text", ",", "they", "are", "particularly", "suitable", "for", "testing", "text", "comprehension", ".", "An", "important", "property", "of", "cloze", "-", "style", "questions", "is", "that", "a", "large", "amount", "of", "such", "questions", "can", "be", "automatically", "generated", "from", "real", "world", "documents", ".", "This", "opens", "the", "task", "to", "data", "-", "hungry", "techniques", "such", "as", "deep", "learning", ".", "This", "is", "an", "advantage", "compared", "to", "smaller", "machine", "understanding", "datasets", "like", "MCTest", "that", "have", "only", "hundreds", "of", "training", "examples", "and", "therefore", "the", "best", "performing", "systems", "usually", "rely", "on", "hand", "-", "crafted", "features", ".", "In", "the", "first", "part", "of", "this", "article", "we", "introduce", "the", "task", "at", "hand", "and", "the", "main", "aspects", "of", "the", "relevant", "datasets", ".", "Then", "we", "present", "our", "own", "model", "to", "tackle", "the", "problem", ".", "Subsequently", "we", "compare", "the", "model", "to", "previously", "proposed", "architectures", "and", "finally", "describe", "the", "experimental", "results", "on", "the", "performance", "of", "our", "model", ".", "section", ":", "Task", "and", "datasets", "In", "this", "section", "we", "introduce", "the", "task", "that", "we", "are", "seeking", "to", "solve", "and", "relevant", "large", "-", "scale", "datasets", "that", "have", "recently", "been", "introduced", "for", "this", "task", ".", "subsection", ":", "Formal", "Task", "Description", "The", "task", "consists", "of", "answering", "a", "cloze", "-", "style", "question", ",", "the", "answer", "to", "which", "depends", "on", "the", "understanding", "of", "a", "context", "document", "provided", "with", "the", "question", ".", "The", "model", "is", "also", "provided", "with", "a", "set", "of", "possible", "answers", "from", "which", "the", "correct", "one", "is", "to", "be", "selected", ".", "This", "can", "be", "formalized", "as", "follows", ":", "The", "training", "data", "consist", "of", "tuples", ",", "where", "is", "a", "question", ",", "is", "a", "document", "that", "contains", "the", "answer", "to", "question", ",", "is", "a", "set", "of", "possible", "answers", "and", "is", "the", "ground", "truth", "answer", ".", "Both", "and", "are", "sequences", "of", "words", "from", "vocabulary", ".", "We", "also", "assume", "that", "all", "possible", "answers", "are", "words", "from", "the", "vocabulary", ",", "that", "is", ",", "and", "that", "the", "ground", "truth", "answer", "appears", "in", "the", "document", ",", "that", "is", ".", "subsection", ":", "Datasets", "We", "will", "now", "briefly", "summarize", "important", "features", "of", "the", "datasets", ".", "subsubsection", ":", "News", "Articles", "\u2014", "CNN", "and", "Daily", "Mail", "The", "first", "two", "datasets", "were", "constructed", "from", "a", "large", "number", "of", "news", "articles", "from", "the", "CNN", "and", "Daily", "Mail", "websites", ".", "The", "main", "body", "of", "each", "article", "forms", "a", "context", ",", "while", "the", "cloze", "-", "style", "question", "is", "formed", "from", "one", "of", "short", "highlight", "sentences", ",", "appearing", "at", "the", "top", "of", "each", "article", "page", ".", "Specifically", ",", "the", "question", "is", "created", "by", "replacing", "a", "named", "entity", "from", "the", "summary", "sentence", "(", "e.g.", "\u201c", "Producer", "X", "will", "not", "press", "charges", "against", "Jeremy", "Clarkson", ",", "his", "lawyer", "says", ".", "\u201d", ")", ".", "Furthermore", "the", "named", "entities", "in", "the", "whole", "dataset", "were", "replaced", "by", "anonymous", "tokens", "which", "were", "further", "shuffled", "for", "each", "example", "so", "that", "the", "model", "can", "not", "build", "up", "any", "world", "knowledge", "about", "the", "entities", "and", "hence", "has", "to", "genuinely", "rely", "on", "the", "context", "document", "to", "search", "for", "an", "answer", "to", "the", "question", ".", "black", "Qualitative", "analysis", "of", "reasoning", "patterns", "needed", "to", "answer", "questions", "in", "the", "CNN", "dataset", "together", "with", "human", "performance", "on", "this", "task", "are", "provided", "in", ".", "subsubsection", ":", "Children", "\u2019s", "Book", "Test", "The", "third", "dataset", ",", "the", "Children", "\u2019s", "Book", "Test", "(", "CBT", ")", ",", "is", "built", "from", "books", "that", "are", "freely", "available", "thanks", "to", "Project", "Gutenberg", ".", "Each", "context", "document", "is", "formed", "by", "consecutive", "sentences", "taken", "from", "a", "children", "\u2019s", "book", "story", ".", "Due", "to", "the", "lack", "of", "summary", ",", "the", "cloze", "-", "style", "question", "is", "then", "constructed", "from", "the", "subsequent", "(", "st", ")", "sentence", ".", "One", "can", "also", "see", "how", "the", "task", "complexity", "varies", "with", "the", "type", "of", "the", "omitted", "word", "(", "named", "entity", ",", "common", "noun", ",", "verb", ",", "preposition", ")", ".", "have", "shown", "that", "while", "standard", "LSTM", "language", "models", "have", "human", "level", "performance", "on", "predicting", "verbs", "and", "prepositions", ",", "they", "lack", "behind", "on", "named", "entities", "and", "common", "nouns", ".", "In", "this", "article", "we", "therefore", "focus", "only", "on", "predicting", "the", "first", "two", "word", "types", ".", "Basic", "statistics", "about", "the", "CNN", ",", "Daily", "Mail", "and", "CBT", "datasets", "are", "summarized", "in", "Table", "[", "reference", "]", ".", "section", ":", "Our", "Model", "\u2014", "Attention", "Sum", "Reader", "black", "Our", "model", "called", "the", "is", "tailor", "-", "made", "to", "leverage", "the", "fact", "that", "the", "answer", "is", "a", "word", "from", "the", "context", "document", ".", "This", "is", "a", "double", "-", "edged", "sword", ".", "While", "it", "achieves", "state", "-", "of", "-", "the", "-", "art", "results", "on", "all", "of", "the", "mentioned", "datasets", "(", "where", "this", "assumption", "holds", "true", ")", ",", "it", "can", "not", "produce", "an", "answer", "which", "is", "not", "contained", "in", "the", "document", ".", "Intuitively", ",", "our", "model", "is", "structured", "as", "follows", ":", "We", "compute", "a", "vector", "embedding", "of", "the", "query", ".", "We", "compute", "a", "vector", "embedding", "of", "each", "individual", "word", "in", "the", "context", "of", "the", "whole", "document", "(", "contextual", "embedding", ")", ".", "Using", "a", "dot", "product", "between", "the", "question", "embedding", "and", "the", "contextual", "embedding", "of", "each", "occurrence", "of", "a", "candidate", "answer", "in", "the", "document", ",", "we", "select", "the", "most", "likely", "answer", ".", "subsection", ":", "Formal", "Description", "Our", "model", "uses", "one", "word", "embedding", "function", "and", "two", "encoder", "functions", ".", "The", "word", "embedding", "function", "translates", "words", "into", "vector", "representations", ".", "The", "first", "encoder", "function", "is", "a", "document", "encoder", "that", "encodes", "every", "word", "from", "the", "document", "in", "the", "context", "of", "the", "whole", "document", ".", "We", "call", "this", "the", "contextual", "embedding", ".", "For", "convenience", "we", "will", "denote", "the", "contextual", "embedding", "of", "the", "-", "th", "word", "in", "as", ".", "The", "second", "encoder", "is", "used", "to", "translate", "the", "query", "into", "a", "fixed", "length", "representation", "of", "the", "same", "dimensionality", "as", "each", "black", ".", "Both", "encoders", "use", "word", "embeddings", "computed", "by", "as", "their", "input", ".", "Then", "we", "compute", "a", "weight", "for", "every", "word", "in", "the", "document", "as", "the", "dot", "product", "of", "its", "contextual", "embedding", "and", "the", "query", "embedding", ".", "This", "weight", "might", "be", "viewed", "as", "an", "attention", "over", "the", "document", ".", "To", "form", "a", "proper", "probability", "distribution", "over", "the", "words", "in", "the", "document", ",", "we", "normalize", "the", "weights", "using", "the", "softmax", "function", ".", "This", "way", "we", "model", "probability", "that", "the", "answer", "to", "query", "appears", "at", "position", "in", "the", "document", ".", "In", "a", "functional", "form", "this", "is", ":", "Finally", "we", "compute", "the", "probability", "that", "word", "is", "a", "correct", "answer", "as", ":", "where", "is", "a", "set", "of", "positions", "where", "appears", "in", "the", "document", ".", "We", "call", "this", "mechanism", "pointer", "sum", "attention", "since", "we", "use", "attention", "as", "a", "pointer", "over", "discrete", "tokens", "in", "the", "context", "document", "and", "then", "we", "directly", "sum", "the", "word", "\u2019s", "attention", "across", "all", "the", "occurrences", ".", "This", "differs", "from", "the", "usual", "use", "of", "attention", "in", "sequence", "-", "to", "-", "sequence", "models", "where", "attention", "is", "used", "to", "blend", "representations", "of", "words", "into", "a", "new", "embedding", "vector", ".", "Our", "use", "of", "attention", "was", "inspired", "by", "ptrnet", ".", "A", "high", "level", "structure", "of", "our", "model", "is", "shown", "in", "Figure", "[", "reference", "]", ".", "subsection", ":", "Model", "instance", "details", "In", "our", "model", "the", "document", "encoder", "is", "implemented", "as", "a", "bidirectional", "Gated", "Recurrent", "Unit", "(", "GRU", ")", "network", "whose", "hidden", "states", "form", "the", "contextual", "word", "embeddings", ",", "that", "is", ",", "where", "denotes", "vector", "concatenation", "and", "and", "denote", "forward", "and", "backward", "contextual", "embeddings", "from", "the", "respective", "recurrent", "networks", ".", "The", "query", "encoder", "is", "implemented", "by", "another", "bidirectional", "GRU", "network", ".", "This", "time", "the", "last", "hidden", "state", "of", "the", "forward", "network", "is", "concatenated", "with", "the", "last", "hidden", "state", "of", "the", "backward", "network", "to", "form", "the", "query", "embedding", ",", "that", "is", ".", "The", "word", "embedding", "function", "is", "implemented", "in", "a", "usual", "way", "as", "a", "look", "-", "up", "table", ".", "is", "a", "matrix", "whose", "rows", "can", "be", "indexed", "by", "words", "from", "the", "vocabulary", ",", "that", "is", ".", "Therefore", ",", "each", "row", "of", "contains", "embedding", "of", "one", "word", "from", "the", "vocabulary", ".", "During", "training", "we", "jointly", "optimize", "parameters", "of", ",", "and", ".", "section", ":", "Related", "Work", "black", "Several", "recent", "deep", "neural", "network", "architectures", "were", "applied", "to", "the", "task", "of", "text", "comprehension", ".", "The", "last", "two", "architectures", "were", "developed", "independently", "at", "the", "same", "time", "as", "our", "work", ".", "All", "of", "these", "architectures", "use", "an", "attention", "mechanism", "that", "allows", "them", "to", "highlight", "places", "in", "the", "document", "that", "might", "be", "relevant", "to", "answering", "the", "question", ".", "We", "will", "now", "briefly", "describe", "these", "architectures", "and", "compare", "them", "to", "our", "approach", ".", "subsection", ":", "Attentive", "and", "Impatient", "Readers", "Attentive", "and", "Impatient", "Readers", "were", "proposed", "in", ".", "The", "simpler", "Attentive", "Reader", "is", "very", "similar", "to", "our", "architecture", ".", "It", "also", "uses", "bidirectional", "document", "and", "query", "encoders", "to", "compute", "an", "attention", "in", "a", "similar", "way", "we", "do", ".", "The", "more", "complex", "Impatient", "Reader", "computes", "attention", "over", "the", "document", "after", "reading", "every", "word", "of", "the", "query", ".", "However", ",", "empirical", "evaluation", "has", "shown", "that", "both", "models", "perform", "almost", "identically", "on", "the", "CNN", "and", "Daily", "Mail", "datasets", ".", "The", "key", "difference", "between", "the", "Attentive", "Reader", "and", "our", "model", "is", "that", "the", "Attentive", "Reader", "uses", "attention", "to", "compute", "a", "fixed", "length", "representation", "of", "the", "document", "that", "is", "equal", "to", "a", "weighted", "sum", "of", "contextual", "embeddings", "of", "words", "in", ",", "that", "is", ".", "A", "joint", "query", "and", "document", "embedding", "is", "then", "a", "non", "-", "linear", "function", "of", "and", "the", "query", "embedding", ".", "This", "joint", "embedding", "is", "in", "the", "end", "compared", "against", "all", "candidate", "answers", "using", "the", "dot", "product", ",", "in", "the", "end", "the", "scores", "are", "normalized", "by", "softmax", ".", "That", "is", ":", ".", "black", "In", "contrast", "to", "the", "Attentive", "Reader", ",", "we", "select", "the", "answer", "from", "the", "context", "directly", "using", "the", "computed", "attention", "rather", "than", "using", "such", "attention", "for", "a", "weighted", "sum", "of", "the", "individual", "representations", "(", "see", "Eq", ".", "[", "reference", "]", ")", ".", "The", "motivation", "for", "such", "simplification", "is", "the", "following", ".", "Consider", "a", "context", "\u201c", "A", "UFO", "was", "observed", "above", "our", "city", "in", "January", "and", "again", "in", "March", ".", "\u201d", "and", "question", "\u201c", "An", "observer", "has", "spotted", "a", "UFO", "in", "_", "_", "_", ".", "\u201d", "Since", "both", "January", "and", "March", "are", "equally", "good", "candidates", ",", "the", "attention", "mechanism", "might", "put", "the", "same", "attention", "on", "both", "these", "candidates", "in", "the", "context", ".", "The", "blending", "mechanism", "described", "above", "would", "compute", "a", "vector", "between", "the", "representations", "of", "these", "two", "words", "and", "propose", "the", "closest", "word", "as", "the", "answer", "-", "this", "may", "well", "happen", "to", "be", "February", "(", "it", "is", "indeed", "the", "case", "for", "Word2Vec", "trained", "on", "Google", "News", ")", ".", "By", "contrast", ",", "our", "model", "would", "correctly", "propose", "January", "or", "March", ".", "black", "subsection", ":", "Chen", "et", "al", ".", "2016", "A", "model", "presented", "in", "is", "inspired", "by", "the", "Attentive", "Reader", ".", "One", "difference", "is", "that", "the", "attention", "weights", "are", "computed", "with", "a", "bilinear", "term", "instead", "of", "simple", "dot", "-", "product", ",", "that", "is", ".", "The", "document", "embedding", "is", "computed", "using", "a", "weighted", "sum", "as", "in", "the", "Attentive", "Reader", ",", ".", "In", "the", "end", ",", "where", "is", "a", "new", "embedding", "function", ".", "Even", "though", "it", "is", "a", "simplification", "of", "the", "Attentive", "Reader", "this", "model", "performs", "significantly", "better", "than", "the", "original", ".", "black", "subsection", ":", "Memory", "Networks", "MenNN", "were", "applied", "to", "the", "task", "of", "text", "comprehension", "in", ".", "The", "best", "performing", "memory", "networks", "model", "setup", "-", "window", "memory", "-", "uses", "windows", "of", "fixed", "length", "(", "8", ")", "centered", "around", "the", "candidate", "words", "as", "memory", "cells", ".", "Due", "to", "this", "limited", "context", "window", ",", "the", "model", "is", "unable", "to", "capture", "dependencies", "out", "of", "scope", "of", "this", "window", ".", "Furthermore", ",", "the", "representation", "within", "such", "window", "is", "computed", "simply", "as", "the", "sum", "of", "embeddings", "of", "words", "in", "that", "window", ".", "By", "contrast", ",", "in", "our", "model", "the", "representation", "of", "each", "individual", "word", "is", "computed", "using", "a", "recurrent", "network", ",", "which", "not", "only", "allows", "it", "to", "capture", "context", "from", "the", "entire", "document", "but", "also", "the", "embedding", "computation", "is", "much", "more", "flexible", "than", "a", "simple", "sum", ".", "To", "improve", "on", "the", "initial", "accuracy", ",", "a", "heuristic", "approach", "called", "self", "supervision", "is", "used", "in", "to", "help", "the", "network", "to", "select", "the", "right", "supporting", "\u201c", "memories", "\u201d", "using", "an", "attention", "mechanism", "showing", "similarities", "to", "the", "ours", ".", "Plain", "MenNN", "without", "this", "heuristic", "are", "not", "competitive", "on", "these", "machine", "reading", "tasks", ".", "Our", "model", "does", "not", "need", "any", "similar", "heuristics", ".", "black", "subsection", ":", "Dynamic", "Entity", "Representation", "The", "Dynamic", "Entity", "Representation", "model", "has", "a", "complex", "architecture", "also", "based", "on", "the", "weighted", "attention", "mechanism", "and", "max", "-", "pooling", "over", "contextual", "embeddings", "of", "vectors", "for", "each", "named", "entity", ".", "subsection", ":", "Pointer", "Networks", "Our", "model", "architecture", "was", "inspired", "by", "ptrnet", "in", "using", "an", "attention", "mechanism", "to", "select", "the", "answer", "in", "the", "context", "rather", "than", "to", "blend", "words", "from", "the", "context", "into", "an", "answer", "representation", ".", "While", "a", "ptrnet", "consists", "of", "an", "encoder", "as", "well", "as", "a", "decoder", ",", "which", "uses", "the", "attention", "to", "select", "the", "output", "at", "each", "step", ",", "our", "model", "outputs", "the", "answer", "in", "a", "single", "step", ".", "Furthermore", ",", "the", "pointer", "networks", "assume", "that", "no", "input", "in", "the", "sequence", "appears", "more", "than", "once", ",", "which", "is", "not", "the", "case", "in", "our", "settings", ".", "subsection", ":", "Summary", "Our", "model", "combines", "the", "best", "features", "of", "the", "architectures", "mentioned", "above", ".", "We", "use", "recurrent", "networks", "to", "\u201c", "read", "\u201d", "the", "document", "and", "the", "query", "as", "black", "done", "in", "and", "we", "use", "attention", "in", "a", "way", "similar", "to", "ptrnet", ".", "We", "also", "use", "summation", "of", "attention", "weights", "in", "a", "way", "similar", "to", "MenNN", ".", "black", "From", "a", "high", "level", "perspective", "we", "simplify", "all", "the", "discussed", "text", "comprehension", "models", "by", "removing", "all", "transformations", "past", "the", "attention", "step", ".", "Instead", "we", "use", "the", "attention", "directly", "to", "compute", "the", "answer", "probability", ".", "section", ":", "Evaluation", "In", "this", "section", "we", "evaluate", "our", "model", "on", "the", "CNN", ",", "Daily", "Mail", "and", "CBT", "datasets", ".", "We", "show", "that", "despite", "the", "model", "\u2019s", "simplicity", "its", "ensembles", "achieve", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "each", "of", "these", "datasets", ".", "subsection", ":", "Training", "Details", "black", "To", "train", "the", "model", "we", "used", "stochastic", "gradient", "descent", "with", "the", "ADAM", "update", "rule", "and", "learning", "rate", "of", "or", ".", "During", "training", "we", "minimized", "the", "following", "negative", "log", "-", "likelihood", "with", "respect", "to", ":", "where", "is", "the", "correct", "answer", "for", "query", "and", "document", ",", "and", "represents", "parameters", "of", "the", "encoder", "functions", "and", "and", "of", "the", "word", "embedding", "function", ".", "The", "optimized", "probability", "distribution", "is", "defined", "in", "Eq", ".", "[", "reference", "]", ".", "The", "initial", "weights", "in", "the", "word", "embedding", "matrix", "were", "drawn", "randomly", "uniformly", "from", "the", "interval", ".", "Weights", "in", "the", "GRU", "networks", "were", "initialized", "by", "random", "orthogonal", "matrices", "and", "biases", "were", "initialized", "to", "zero", ".", "We", "also", "used", "a", "gradient", "clipping", "threshold", "of", "10", "and", "batches", "of", "size", "32", ".", "During", "training", "we", "randomly", "shuffled", "all", "examples", "in", "each", "epoch", ".", "To", "speedup", "training", ",", "we", "always", "pre", "-", "fetched", "batches", "worth", "of", "examples", "and", "sorted", "them", "according", "to", "document", "length", ".", "Hence", "each", "batch", "contained", "documents", "of", "roughly", "the", "same", "length", ".", "For", "each", "batch", "of", "the", "CNN", "and", "Daily", "Mail", "datasets", "we", "randomly", "reshuffled", "the", "assignment", "of", "named", "entities", "to", "the", "corresponding", "word", "embedding", "vectors", "to", "match", "the", "procedure", "proposed", "in", ".", "This", "guaranteed", "that", "word", "embeddings", "of", "named", "entities", "were", "used", "only", "as", "semantically", "meaningless", "labels", "not", "encoding", "any", "intrinsic", "features", "of", "the", "represented", "entities", ".", "This", "forced", "the", "model", "to", "truly", "deduce", "the", "answer", "from", "the", "single", "context", "document", "associated", "with", "the", "question", ".", "black", "We", "also", "do", "not", "use", "pre", "-", "trained", "word", "embeddings", "to", "make", "our", "training", "procedure", "comparable", "to", ".", "We", "did", "not", "perform", "any", "text", "pre", "-", "processing", "since", "the", "original", "datasets", "were", "already", "tokenized", ".", "black", "We", "do", "not", "use", "any", "regularization", "since", "in", "our", "experience", "it", "leads", "to", "longer", "training", "times", "of", "single", "models", ",", "however", ",", "performance", "of", "a", "model", "ensemble", "is", "usually", "the", "same", ".", "This", "way", "we", "can", "train", "the", "whole", "ensemble", "faster", "when", "using", "multiple", "GPUs", "for", "parallel", "training", ".", "black", "For", "Additional", "details", "about", "the", "training", "procedure", "see", "Appendix", "[", "reference", "]", ".", "black", "subsection", ":", "Evaluation", "Method", "We", "evaluated", "the", "proposed", "model", "both", "as", "a", "single", "model", "and", "using", "ensemble", "averaging", ".", "blackAlthough", "the", "model", "computes", "attention", "for", "every", "word", "in", "the", "document", "we", "restrict", "the", "model", "to", "select", "an", "answer", "from", "a", "list", "of", "candidate", "answers", "associated", "with", "each", "question", "-", "document", "pair", ".", "For", "single", "models", "we", "are", "reporting", "results", "for", "the", "best", "model", "as", "well", "as", "the", "average", "of", "accuracies", "for", "the", "best", "20", "%", "of", "models", "with", "best", "performance", "on", "validation", "data", "since", "single", "models", "display", "considerable", "variation", "of", "results", "due", "to", "random", "weight", "initialization", "even", "for", "identical", "hyperparameter", "values", ".", "Single", "model", "performance", "may", "consequently", "prove", "difficult", "to", "reproduce", ".", "What", "concerns", "ensembles", ",", "we", "used", "simple", "averaging", "of", "the", "answer", "probabilities", "predicted", "by", "ensemble", "members", ".", "For", "ensembling", "we", "used", "14", ",", "16", ",", "84", "and", "53", "models", "for", "CNN", ",", "Daily", "Mail", "and", "CBT", "CN", "and", "NE", "respectively", ".", "The", "ensemble", "models", "were", "chosen", "either", "as", "the", "top", "70", "%", "of", "all", "trained", "models", ",", "we", "call", "this", "avg", "ensemble", ".", "Alternatively", "we", "use", "the", "following", "algorithm", ":", "We", "started", "with", "the", "best", "performing", "model", "according", "to", "validation", "performance", ".", "Then", "in", "each", "step", "we", "tried", "adding", "the", "best", "performing", "model", "that", "had", "not", "been", "previously", "tried", ".", "We", "kept", "it", "in", "the", "ensemble", "if", "it", "did", "improve", "its", "validation", "performance", "and", "discarded", "it", "otherwise", ".", "This", "way", "we", "gradually", "tried", "each", "model", "once", ".", "We", "call", "the", "resulting", "model", "a", "greedy", "ensemble", ".", "[", "b", "]", "0.475", "[", "b", "]", "0.475", "[", "b", "]", "0.475", "[", "b", "]", "0.475", "[", "b", "]", "0.475", "[", "b", "]", "0.475", "[", "b", "]", "0.475", "[", "b", "]", "0.475", "subsection", ":", "Results", "black", "Performance", "of", "our", "models", "on", "the", "CNN", "and", "Daily", "Mail", "datasets", "is", "summarized", "in", "Table", "[", "reference", "]", ",", "Table", "[", "reference", "]", "shows", "results", "on", "the", "CBT", "dataset", ".", "The", "tables", "also", "list", "performance", "of", "other", "published", "models", "that", "were", "evaluated", "on", "these", "datasets", ".", "Ensembles", "of", "our", "models", "set", "new", "state", "-", "of", "-", "the", "-", "art", "results", "on", "all", "evaluated", "datasets", ".", "Table", "[", "reference", "]", "then", "measures", "accuracy", "as", "the", "proportion", "of", "test", "cases", "where", "the", "ground", "truth", "was", "among", "the", "top", "answers", "proposed", "by", "the", "greedy", "ensemble", "model", "for", ".", "CNN", "and", "Daily", "Mail", ".", "blackThe", "CNN", "dataset", "is", "the", "most", "widely", "used", "dataset", "for", "evaluation", "of", "text", "comprehension", "systems", "published", "so", "far", ".", "Performance", "of", "our", "single", "model", "is", "a", "little", "bit", "worse", "than", "performance", "of", "simultaneously", "published", "models", ".", "Compared", "to", "our", "work", "these", "models", "were", "trained", "with", "Dropout", "regularization", "which", "might", "improve", "single", "model", "performance", ".", "However", ",", "ensemble", "of", "our", "models", "outperforms", "these", "models", "even", "though", "they", "use", "pre", "-", "trained", "word", "embeddings", ".", "On", "the", "CNN", "dataset", "our", "single", "model", "with", "best", "validation", "accuracy", "achieves", "a", "test", "accuracy", "of", "69.5", "%", ".", "The", "average", "performance", "of", "the", "top", "20", "%", "models", "according", "to", "validation", "accuracy", "is", "69.9", "%", "which", "is", "even", "0.5", "%", "better", "than", "the", "single", "best", "-", "validation", "model", ".", "This", "shows", "that", "there", "were", "many", "models", "that", "performed", "better", "on", "test", "set", "than", "the", "best", "-", "validation", "model", ".", "Fusing", "multiple", "models", "then", "gives", "a", "significant", "further", "increase", "in", "accuracy", "on", "both", "CNN", "and", "Daily", "Mail", "datasets", "..", "CBT", ".", "In", "named", "entity", "prediction", "our", "best", "single", "model", "with", "accuracy", "of", "68.6", "%", "performs", "2", "%", "absolute", "better", "than", "the", "MenNN", "with", "self", "supervision", ",", "the", "averaging", "ensemble", "performs", "4", "%", "absolute", "better", "than", "the", "best", "previous", "result", ".", "In", "common", "noun", "prediction", "our", "single", "models", "is", "0.4", "%", "absolute", "better", "than", "MenNN", "however", "the", "ensemble", "improves", "the", "performance", "to", "69", "%", "which", "is", "6", "%", "absolute", "better", "than", "MenNN", ".", "black", "section", ":", "Analysis", "To", "further", "analyze", "the", "properties", "of", "our", "model", ",", "we", "examined", "the", "dependence", "of", "accuracy", "on", "the", "length", "of", "the", "context", "document", "(", "Figure", "[", "reference", "]", ")", ",", "the", "number", "of", "candidate", "answers", "(", "Figure", "[", "reference", "]", ")", "and", "the", "frequency", "of", "the", "correct", "answer", "in", "the", "context", "(", "Figure", "[", "reference", "]", ")", ".", "On", "the", "CNN", "and", "Daily", "Mail", "datasets", ",", "the", "accuracy", "decreases", "with", "increasing", "document", "length", "(", "Figure", "[", "reference", "]", ")", ".", "We", "hypothesize", "this", "may", "be", "due", "to", "multiple", "factors", ".", "Firstly", "long", "documents", "may", "make", "the", "task", "more", "complex", ".", "Secondly", "such", "cases", "are", "quite", "rare", "in", "the", "training", "data", "(", "Figure", "[", "reference", "]", ")", "which", "motivates", "the", "model", "to", "specialize", "on", "shorter", "contexts", ".", "Finally", "the", "context", "length", "is", "correlated", "with", "the", "number", "of", "named", "entities", ",", "i.e.", "the", "number", "of", "possible", "answers", "which", "is", "itself", "negatively", "correlated", "with", "accuracy", "(", "see", "Figure", "[", "reference", "]", ")", ".", "On", "the", "CBT", "dataset", "this", "negative", "trend", "seems", "to", "disappear", "(", "Fig", ".", "[", "reference", "]", ")", ".", "This", "supports", "the", "later", "two", "explanations", "since", "the", "distribution", "of", "document", "lengths", "is", "somewhat", "more", "uniform", "(", "Figure", "[", "reference", "]", ")", "and", "the", "number", "of", "candidate", "answers", "is", "constant", "(", ")", "for", "all", "examples", "in", "this", "dataset", ".", "The", "effect", "of", "increasing", "number", "of", "candidate", "answers", "on", "the", "model", "\u2019s", "accuracy", "can", "be", "seen", "in", "Figure", "[", "reference", "]", ".", "We", "can", "clearly", "see", "that", "as", "the", "number", "of", "candidate", "answers", "increases", ",", "the", "accuracy", "drops", ".", "On", "the", "other", "hand", ",", "the", "amount", "of", "examples", "with", "large", "number", "of", "candidate", "answers", "is", "quite", "small", "(", "Figure", "[", "reference", "]", ")", ".", "Finally", ",", "since", "the", "summation", "of", "attention", "in", "our", "model", "inherently", "favours", "frequently", "occurring", "tokens", ",", "we", "also", "visualize", "how", "the", "accuracy", "depends", "on", "the", "frequency", "of", "the", "correct", "answer", "in", "the", "document", ".", "Figure", "[", "reference", "]", "shows", "that", "the", "accuracy", "significantly", "drops", "as", "the", "correct", "answer", "gets", "less", "and", "less", "frequent", "in", "the", "document", "compared", "to", "other", "candidate", "answers", ".", "On", "the", "other", "hand", ",", "the", "correct", "answer", "is", "likely", "to", "occur", "frequently", "(", "Fig", ".", "[", "reference", "]", ")", ".", "black", "section", ":", "Conclusion", "In", "this", "article", "we", "presented", "a", "new", "neural", "network", "architecture", "for", "natural", "language", "text", "comprehension", ".", "While", "our", "model", "is", "simpler", "than", "previously", "published", "models", ",", "it", "gives", "a", "new", "state", "-", "of", "-", "the", "-", "art", "accuracy", "on", "all", "evaluated", "datasets", ".", "An", "analysis", "by", "suggests", "that", "on", "CNN", "and", "Daily", "Mail", "datasets", "a", "significant", "proportion", "of", "questions", "is", "ambiguous", "or", "too", "difficult", "to", "answer", "even", "for", "humans", "(", "partly", "due", "to", "entity", "anonymization", ")", "so", "the", "ensemble", "of", "our", "models", "may", "be", "very", "near", "to", "the", "maximal", "accuracy", "achievable", "on", "these", "datasets", ".", "section", ":", "Acknowledgments", "We", "would", "like", "to", "thank", "Tim", "Klinger", "for", "providing", "us", "with", "masked", "softmax", "code", "that", "we", "used", "in", "our", "implementation", ".", "bibliography", ":", "References", "section", ":", "Training", "Details", "During", "training", "we", "evaluated", "the", "model", "performance", "after", "each", "epoch", "and", "stopped", "the", "training", "when", "the", "error", "on", "the", "validation", "set", "started", "increasing", ".", "The", "models", "usually", "converged", "after", "two", "epochs", "of", "training", ".", "Time", "needed", "to", "complete", "a", "single", "epoch", "of", "training", "on", "each", "dataset", "on", "an", "Nvidia", "K40", "GPU", "is", "shown", "in", "Table", "[", "reference", "]", ".", "black", "The", "hyperparameters", ",", "namely", "the", "recurrent", "hidden", "layer", "dimension", "and", "the", "source", "embedding", "dimension", ",", "were", "chosen", "by", "grid", "search", ".", "We", "started", "with", "a", "range", "of", "128", "to", "384", "for", "both", "parameters", "and", "subsequently", "kept", "increasing", "the", "upper", "bound", "by", "128", "until", "we", "started", "observing", "a", "consistent", "decrease", "in", "validation", "accuracy", ".", "The", "region", "of", "the", "parameter", "space", "that", "we", "explored", "together", "with", "the", "parameters", "of", "the", "model", "with", "best", "validation", "accuracy", "are", "summarized", "in", "Table", "[", "reference", "]", ".", "black", "Our", "model", "was", "implemented", "using", "Theano", "and", "Blocks", ".", "section", ":", "Dependence", "of", "accuracy", "on", "the", "frequency", "of", "the", "correct", "answer", "In", "Section", "[", "reference", "]", "we", "analysed", "how", "the", "test", "accuracy", "depends", "on", "how", "frequent", "the", "correct", "answer", "is", "compared", "to", "other", "answer", "candidates", "for", "the", "news", "datasets", ".", "The", "plots", "for", "the", "Children", "\u2019s", "Book", "Test", "looks", "very", "similar", ",", "however", "we", "are", "adding", "it", "here", "for", "completeness", ".", "[", "b", "]", "0.475", "[", "b", "]", "0.475"]}