{"coref": {"BLEU_score": [[82, 84], [155, 156], [3907, 3909], [3943, 3945], [3989, 3991], [4133, 4135], [4154, 4156], [4202, 4204], [4442, 4444]], "FT": [[65, 70], [3280, 3284], [4168, 4171], [4190, 4194]], "IWSLT2015_English-German": [[117, 118], [119, 122], [124, 127], [3460, 3463], [3472, 3473], [3554, 3555], [3860, 3861], [3455, 3458], [4085, 4086], [4236, 4237]], "Machine_Translation": [[2, 8], [11, 14], [175, 177], [178, 179], [399, 403]], "NAT": [[704, 708], [1184, 1188], [1189, 1190], [1199, 1203], [1204, 1205], [1276, 1280], [2642, 2645], [2998, 3003], [3924, 3925], [3937, 3938], [4323, 4324], [1323, 1324], [1369, 1370], [2114, 2115], [2626, 2627], [2842, 2843], [3287, 3288], [3444, 3445], [3750, 3751], [4082, 4083]], "NAT__FT___NPD": [], "NPD": [[2686, 2689], [2690, 2691], [2783, 2784], [3610, 3613], [3963, 3966], [3976, 3977], [4035, 4036], [4300, 4303], [4325, 4326], [4306, 4307], [4353, 4356]], "WMT2014_English-German": [[124, 127], [3076, 3078], [3098, 3100], [3504, 3506], [3536, 3538], [3837, 3839]], "WMT2014_German-English": [[124, 127], [3504, 3506], [3536, 3538], [3837, 3839]], "WMT2016_English-Romanian": [[124, 127], [157, 162], [3465, 3466], [3466, 3469], [3504, 3506], [3536, 3538], [3837, 3839], [3971, 3972]], "WMT2016_Romanian-English": [[124, 127], [3466, 3469], [3504, 3506], [3536, 3538], [3837, 3839]]}, "coref_non_salient": {"0": [[1109, 1112], [1141, 1144]], "1": [[739, 742], [1905, 1908]], "10": [[499, 502], [513, 516], [3233, 3235]], "100": [[535, 538]], "101": [[1258, 1260], [2521, 2523]], "102": [[296, 299]], "103": [[2213, 2215]], "104": [[823, 827]], "105": [[2616, 2619]], "106": [[1836, 1838]], "107": [[87, 90]], "108": [[3314, 3319]], "109": [[3385, 3389]], "11": [[518, 522], [3337, 3341]], "110": [[1698, 1701]], "111": [[467, 469]], "112": [[1861, 1863]], "12": [[362, 365], [2986, 2988], [325, 327], [411, 413], [3121, 3123]], "13": [[3204, 3207], [3606, 3609], [3891, 3894]], "14": [[50, 52], [3683, 3685]], "15": [[109, 111], [1174, 1176]], "16": [[634, 636], [1310, 1312]], "17": [[473, 477], [878, 882]], "18": [[4070, 4072], [4077, 4079]], "19": [[286, 289], [1691, 1695], [646, 649], [1650, 1653], [1726, 1729]], "2": [[1739, 1742], [3523, 3524]], "20": [[1419, 1421], [1427, 1429], [1744, 1746], [1813, 1815], [2228, 2230]], "21": [[1236, 1238], [1240, 1242], [1266, 1268], [1337, 1339], [1355, 1357]], "22": [[300, 301], [1300, 1301]], "23": [[330, 332], [341, 343], [668, 670], [1332, 1334], [1767, 1769], [3642, 3644]], "24": [[2587, 2589], [2568, 2570]], "25": [[2261, 2262], [2440, 2441]], "26": [[45, 46], [2824, 2825], [4424, 4426]], "27": [[944, 946], [1163, 1165], [1841, 1843], [1844, 1846], [2318, 2320]], "28": [[2859, 2861], [2877, 2879]], "29": [[2786, 2789]], "3": [[1758, 1761], [1803, 1805]], "30": [[1284, 1288]], "31": [[337, 338], [376, 377], [609, 610], [802, 803], [1326, 1327], [2437, 2438], [4108, 4109], [4398, 4399]], "32": [[4146, 4150]], "33": [[3625, 3627]], "34": [[2042, 2045], [3005, 3008], [4386, 4389]], "35": [[3518, 3522]], "36": [[1246, 1248], [3269, 3271], [3675, 3678]], "37": [[3920, 3922]], "38": [[722, 724], [1195, 1197]], "39": [[3417, 3418]], "4": [[3148, 3152], [3766, 3770]], "40": [[4175, 4177]], "41": [[47, 48], [317, 318], [589, 590], [829, 830], [1411, 1412], [2937, 2939]], "42": [[3738, 3740]], "43": [[3105, 3110], [3569, 3574]], "44": [[166, 170], [193, 195]], "45": [[774, 776], [833, 835], [4028, 4030], [4215, 4217]], "46": [[4158, 4162]], "47": [[3597, 3598]], "48": [[3803, 3806]], "49": [[3689, 3691], [3706, 3709]], "5": [[583, 584], [1349, 1351], [1365, 1366], [1721, 1722], [2525, 2527], [4033, 4034]], "50": [[2751, 2753], [3603, 3605]], "51": [[625, 627], [717, 719], [1658, 1660]], "52": [[3670, 3674]], "53": [[1448, 1450], [1518, 1520], [1619, 1621], [2502, 2504]], "54": [[3899, 3901]], "55": [[4166, 4167]], "56": [[208, 210]], "57": [[2870, 2873]], "58": [[3547, 3552]], "59": [[2303, 2305]], "6": [[2284, 2286], [2895, 2897], [3252, 3255]], "60": [[1781, 1783]], "61": [[605, 607]], "62": [[199, 202]], "63": [[2018, 2021]], "64": [[3692, 3694]], "65": [[2206, 2211]], "66": [[2185, 2187]], "67": [[3244, 3249]], "68": [[541, 545]], "69": [[480, 485]], "7": [[751, 753], [1878, 1879], [3764, 3765], [30, 31], [140, 141], [211, 212], [305, 306], [324, 325], [714, 715], [812, 813], [863, 864], [872, 873], [1271, 1272], [1316, 1317], [2279, 2280], [2732, 2733], [2747, 2748], [3016, 3017], [3119, 3120], [3585, 3586], [3631, 3632], [3948, 3949], [3984, 3985], [4019, 4020], [4264, 4265], [4337, 4338], [4392, 4393], [4436, 4437]], "70": [[779, 782]], "71": [[279, 280]], "72": [[2795, 2797]], "73": [[2975, 2977]], "74": [[1292, 1297], [1750, 1755]], "75": [[256, 260]], "76": [[1170, 1172]], "77": [[3799, 3801]], "78": [[3208, 3211]], "79": [[172, 174]], "8": [[2100, 2102], [3819, 3822]], "80": [[1289, 1290]], "81": [[3427, 3429]], "82": [[3780, 3782]], "83": [[2667, 2669]], "84": [[1092, 1095]], "85": [[2929, 2933]], "86": [[2096, 2099]], "87": [[611, 614]], "88": [[1831, 1833]], "89": [[698, 700]], "9": [[3127, 3128], [3593, 3595], [4207, 4209], [4310, 4312]], "90": [[2991, 2995]], "91": [[1261, 1263]], "92": [[2291, 2294]], "93": [[616, 617]], "94": [[3847, 3850]], "95": [[2298, 2301]], "96": [[2631, 2633]], "97": [[2884, 2887]], "98": [[246, 249]], "99": [[3856, 3858]]}, "doc_id": "15e81c8d1c21f9e928c72721ac46d458f3341454", "method_subrelations": {"NAT__FT___NPD": [[[0, 3], "NAT"], [[5, 7], "FT"], [[10, 13], "NPD"]]}, "n_ary_relations": [{"Material": "IWSLT2015_English-German", "Method": "NAT__FT___NPD", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "28.16"}, {"Material": "WMT2014_English-German", "Method": "NAT__FT___NPD", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "19.17"}, {"Material": "WMT2014_German-English", "Method": "NAT__FT___NPD", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "23.20"}, {"Material": "WMT2016_English-Romanian", "Method": "NAT__FT___NPD", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "29.79"}, {"Material": "WMT2016_Romanian-English", "Method": "NAT__FT___NPD", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "31.44"}], "ner": [[2, 8, "Task"], [11, 14, "Task"], [45, 46, "Metric"], [47, 48, "Task"], [50, 52, "Method"], [65, 70, "Method"], [82, 84, "Metric"], [87, 90, "Method"], [109, 111, "Method"], [117, 118, "Material"], [119, 122, "Material"], [124, 127, "Material"], [155, 156, "Metric"], [157, 162, "Material"], [166, 170, "Method"], [172, 174, "Method"], [175, 177, "Task"], [178, 179, "Task"], [193, 195, "Method"], [199, 202, "Method"], [208, 210, "Method"], [246, 249, "Method"], [256, 260, "Method"], [279, 280, "Method"], [286, 289, "Method"], [296, 299, "Method"], [300, 301, "Method"], [317, 318, "Task"], [330, 332, "Method"], [337, 338, "Method"], [341, 343, "Method"], [362, 365, "Method"], [376, 377, "Method"], [399, 403, "Task"], [467, 469, "Method"], [473, 477, "Method"], [480, 485, "Method"], [499, 502, "Method"], [513, 516, "Method"], [518, 522, "Metric"], [535, 538, "Method"], [541, 545, "Method"], [583, 584, "Task"], [589, 590, "Task"], [605, 607, "Method"], [609, 610, "Method"], [611, 614, "Method"], [616, 617, "Method"], [625, 627, "Method"], [634, 636, "Task"], [668, 670, "Method"], [698, 700, "Method"], [704, 708, "Method"], [717, 719, "Method"], [722, 724, "Method"], [739, 742, "Task"], [751, 753, "Method"], [774, 776, "Method"], [779, 782, "Method"], [802, 803, "Method"], [823, 827, "Metric"], [829, 830, "Task"], [833, 835, "Method"], [878, 882, "Method"], [944, 946, "Task"], [1092, 1095, "Method"], [1109, 1112, "Method"], [1141, 1144, "Method"], [1163, 1165, "Task"], [1170, 1172, "Method"], [1174, 1176, "Method"], [1184, 1188, "Method"], [1189, 1190, "Method"], [1195, 1197, "Method"], [1199, 1203, "Method"], [1204, 1205, "Method"], [1236, 1238, "Method"], [1240, 1242, "Method"], [1246, 1248, "Method"], [1258, 1260, "Method"], [1261, 1263, "Task"], [1266, 1268, "Method"], [1276, 1280, "Method"], [1284, 1288, "Method"], [1289, 1290, "Method"], [1292, 1297, "Method"], [1300, 1301, "Method"], [1310, 1312, "Task"], [1326, 1327, "Method"], [1332, 1334, "Method"], [1337, 1339, "Method"], [1349, 1351, "Task"], [1355, 1357, "Method"], [1365, 1366, "Task"], [1411, 1412, "Task"], [1419, 1421, "Method"], [1427, 1429, "Method"], [1448, 1450, "Method"], [1518, 1520, "Method"], [1619, 1621, "Method"], [1658, 1660, "Method"], [1691, 1695, "Method"], [1698, 1701, "Method"], [1721, 1722, "Task"], [1739, 1742, "Method"], [1744, 1746, "Method"], [1750, 1755, "Method"], [1758, 1761, "Method"], [1767, 1769, "Method"], [1781, 1783, "Method"], [1803, 1805, "Method"], [1813, 1815, "Method"], [1831, 1833, "Task"], [1836, 1838, "Task"], [1841, 1843, "Task"], [1844, 1846, "Task"], [1861, 1863, "Task"], [1878, 1879, "Method"], [1905, 1908, "Task"], [2018, 2021, "Method"], [2042, 2045, "Method"], [2096, 2099, "Method"], [2100, 2102, "Method"], [2185, 2187, "Task"], [2206, 2211, "Method"], [2213, 2215, "Method"], [2228, 2230, "Method"], [2261, 2262, "Method"], [2284, 2286, "Method"], [2291, 2294, "Method"], [2298, 2301, "Task"], [2303, 2305, "Task"], [2318, 2320, "Task"], [2437, 2438, "Method"], [2440, 2441, "Method"], [2502, 2504, "Method"], [2521, 2523, "Method"], [2525, 2527, "Task"], [2587, 2589, "Task"], [2616, 2619, "Method"], [2631, 2633, "Method"], [2642, 2645, "Method"], [2667, 2669, "Method"], [2686, 2689, "Method"], [2690, 2691, "Method"], [2751, 2753, "Method"], [2783, 2784, "Method"], [2786, 2789, "Method"], [2795, 2797, "Metric"], [2824, 2825, "Metric"], [2859, 2861, "Method"], [2870, 2873, "Metric"], [2877, 2879, "Method"], [2884, 2887, "Method"], [2895, 2897, "Method"], [2929, 2933, "Method"], [2937, 2939, "Task"], [2975, 2977, "Method"], [2986, 2988, "Method"], [2991, 2995, "Method"], [2998, 3003, "Method"], [3005, 3008, "Method"], [3076, 3078, "Material"], [3098, 3100, "Material"], [3105, 3110, "Method"], [3127, 3128, "Method"], [3148, 3152, "Method"], [3204, 3207, "Task"], [3208, 3211, "Method"], [3233, 3235, "Method"], [3244, 3249, "Method"], [3252, 3255, "Method"], [3269, 3271, "Method"], [3280, 3284, "Method"], [3314, 3319, "Method"], [3337, 3341, "Metric"], [3385, 3389, "Method"], [3417, 3418, "Method"], [3427, 3429, "Method"], [3460, 3463, "Material"], [3465, 3466, "Material"], [3466, 3469, "Material"], [3472, 3473, "Material"], [3504, 3506, "Material"], [3518, 3522, "Method"], [3523, 3524, "Method"], [3536, 3538, "Material"], [3547, 3552, "Method"], [3554, 3555, "Material"], [3569, 3574, "Method"], [3593, 3595, "Method"], [3597, 3598, "Task"], [3603, 3605, "Method"], [3606, 3609, "Task"], [3610, 3613, "Method"], [3625, 3627, "Metric"], [3642, 3644, "Method"], [3670, 3674, "Method"], [3675, 3678, "Method"], [3683, 3685, "Method"], [3689, 3691, "Method"], [3692, 3694, "Method"], [3706, 3709, "Method"], [3738, 3740, "Method"], [3764, 3765, "Method"], [3766, 3770, "Method"], [3780, 3782, "Task"], [3799, 3801, "Method"], [3803, 3806, "Method"], [3819, 3822, "Method"], [3837, 3839, "Material"], [3847, 3850, "Method"], [3856, 3858, "Method"], [3860, 3861, "Material"], [3891, 3894, "Task"], [3899, 3901, "Metric"], [3907, 3909, "Metric"], [3920, 3922, "Method"], [3924, 3925, "Method"], [3937, 3938, "Method"], [3943, 3945, "Metric"], [3963, 3966, "Method"], [3976, 3977, "Method"], [3989, 3991, "Metric"], [4028, 4030, "Method"], [4033, 4034, "Task"], [4035, 4036, "Method"], [4070, 4072, "Task"], [4077, 4079, "Task"], [4108, 4109, "Method"], [4133, 4135, "Metric"], [4146, 4150, "Method"], [4154, 4156, "Metric"], [4158, 4162, "Metric"], [4166, 4167, "Method"], [4168, 4171, "Method"], [4175, 4177, "Method"], [4190, 4194, "Method"], [4202, 4204, "Metric"], [4207, 4209, "Method"], [4215, 4217, "Method"], [4300, 4303, "Method"], [4310, 4312, "Method"], [4323, 4324, "Method"], [4325, 4326, "Method"], [4386, 4389, "Method"], [4398, 4399, "Method"], [4424, 4426, "Metric"], [30, 31, "Method"], [140, 141, "Method"], [211, 212, "Method"], [305, 306, "Method"], [324, 325, "Method"], [325, 327, "Method"], [411, 413, "Method"], [646, 649, "Method"], [714, 715, "Method"], [812, 813, "Method"], [863, 864, "Method"], [872, 873, "Method"], [1271, 1272, "Method"], [1316, 1317, "Method"], [1323, 1324, "Method"], [1369, 1370, "Method"], [1650, 1653, "Method"], [1726, 1729, "Method"], [2114, 2115, "Method"], [2279, 2280, "Method"], [2568, 2570, "Task"], [2626, 2627, "Method"], [2732, 2733, "Method"], [2747, 2748, "Method"], [2842, 2843, "Method"], [3016, 3017, "Method"], [3119, 3120, "Method"], [3121, 3123, "Method"], [3287, 3288, "Method"], [3444, 3445, "Method"], [3455, 3458, "Material"], [3585, 3586, "Method"], [3631, 3632, "Method"], [3750, 3751, "Method"], [3948, 3949, "Method"], [3971, 3972, "Material"], [3984, 3985, "Method"], [4019, 4020, "Method"], [4082, 4083, "Method"], [4085, 4086, "Material"], [4236, 4237, "Material"], [4264, 4265, "Method"], [4306, 4307, "Method"], [4337, 4338, "Method"], [4353, 4356, "Method"], [4392, 4393, "Method"], [4436, 4437, "Method"], [4442, 4444, "Metric"]], "sections": [[0, 163], [163, 394], [394, 397], [397, 497], [497, 539], [539, 702], [702, 708], [708, 858], [858, 941], [941, 1181], [1181, 1264], [1264, 1335], [1335, 1360], [1360, 1645], [1645, 1730], [1730, 1834], [1834, 2183], [2183, 2256], [2256, 2519], [2519, 2629], [2629, 2665], [2665, 2684], [2684, 2837], [2837, 2996], [2996, 3202], [3202, 3430], [3430, 3433], [3433, 3437], [3437, 3566], [3566, 3679], [3679, 3736], [3736, 3778], [3778, 3831], [3831, 3897], [3897, 3911], [3911, 3926], [3926, 4068], [4068, 4380], [4380, 4445], [4445, 4448], [4448, 4453]], "sentences": [[0, 8], [8, 23], [23, 49], [49, 95], [95, 118], [118, 128], [128, 163], [163, 166], [166, 177], [177, 184], [184, 207], [207, 234], [234, 267], [267, 319], [319, 334], [334, 367], [367, 394], [394, 397], [397, 403], [403, 460], [460, 470], [470, 497], [497, 502], [502, 539], [539, 545], [545, 581], [581, 601], [601, 628], [628, 660], [660, 702], [702, 708], [708, 716], [716, 728], [728, 751], [751, 790], [790, 796], [796, 831], [831, 858], [858, 865], [865, 883], [883, 902], [902, 926], [926, 941], [941, 946], [946, 966], [966, 977], [977, 996], [996, 1027], [1027, 1040], [1040, 1041], [1041, 1057], [1057, 1081], [1081, 1139], [1139, 1140], [1140, 1158], [1158, 1181], [1181, 1191], [1191, 1216], [1216, 1221], [1221, 1264], [1264, 1268], [1268, 1298], [1298, 1320], [1320, 1335], [1335, 1339], [1339, 1360], [1360, 1364], [1364, 1389], [1389, 1422], [1422, 1443], [1443, 1459], [1459, 1494], [1494, 1531], [1531, 1546], [1546, 1590], [1590, 1591], [1591, 1645], [1645, 1653], [1653, 1681], [1681, 1702], [1702, 1730], [1730, 1734], [1734, 1796], [1796, 1817], [1817, 1827], [1827, 1834], [1834, 1843], [1843, 1876], [1876, 1883], [1883, 1910], [1910, 1954], [1954, 1994], [1994, 2024], [2024, 2032], [2032, 2057], [2057, 2065], [2065, 2105], [2105, 2137], [2137, 2169], [2169, 2183], [2183, 2187], [2187, 2192], [2192, 2231], [2231, 2256], [2256, 2261], [2261, 2306], [2306, 2330], [2330, 2355], [2355, 2381], [2381, 2399], [2399, 2414], [2414, 2439], [2439, 2456], [2456, 2493], [2493, 2519], [2519, 2527], [2527, 2546], [2546, 2559], [2559, 2582], [2582, 2600], [2600, 2613], [2613, 2629], [2629, 2633], [2633, 2665], [2665, 2669], [2669, 2684], [2684, 2692], [2692, 2727], [2727, 2741], [2741, 2783], [2783, 2804], [2804, 2837], [2837, 2840], [2840, 2862], [2862, 2888], [2888, 2934], [2934, 2948], [2948, 2962], [2962, 2996], [2996, 3003], [3003, 3040], [3040, 3060], [3060, 3079], [3079, 3101], [3101, 3153], [3153, 3174], [3174, 3177], [3177, 3185], [3185, 3202], [3202, 3207], [3207, 3236], [3236, 3276], [3276, 3291], [3291, 3322], [3322, 3344], [3344, 3399], [3399, 3403], [3403, 3430], [3430, 3433], [3433, 3437], [3437, 3440], [3440, 3454], [3454, 3460], [3460, 3466], [3466, 3470], [3470, 3507], [3507, 3534], [3534, 3566], [3566, 3569], [3569, 3591], [3591, 3614], [3614, 3645], [3645, 3679], [3679, 3685], [3685, 3700], [3700, 3736], [3736, 3740], [3740, 3778], [3778, 3784], [3784, 3807], [3807, 3831], [3831, 3834], [3834, 3859], [3859, 3890], [3890, 3897], [3897, 3901], [3901, 3911], [3911, 3914], [3914, 3926], [3926, 3929], [3929, 3967], [3967, 4001], [4001, 4031], [4031, 4068], [4068, 4072], [4072, 4088], [4088, 4110], [4110, 4136], [4136, 4168], [4168, 4205], [4205, 4228], [4228, 4242], [4242, 4246], [4246, 4274], [4274, 4318], [4318, 4346], [4346, 4360], [4360, 4380], [4380, 4383], [4383, 4418], [4418, 4445], [4445, 4448], [4448, 4453]], "words": ["document", ":", "Non", "-", "Autoregressive", "Neural", "Machine", "Translation", "Existing", "approaches", "to", "neural", "machine", "translation", "condition", "each", "output", "word", "on", "previously", "generated", "outputs", ".", "We", "introduce", "a", "model", "that", "avoids", "this", "autoregressive", "property", "and", "produces", "its", "outputs", "in", "parallel", ",", "allowing", "an", "order", "of", "magnitude", "lower", "latency", "during", "inference", ".", "Through", "knowledge", "distillation", ",", "the", "use", "of", "input", "token", "fertilities", "as", "a", "latent", "variable", ",", "and", "policy", "gradient", "fine", "-", "tuning", ",", "we", "achieve", "this", "at", "a", "cost", "of", "as", "little", "as", "2.0", "BLEU", "points", "relative", "to", "the", "autoregressive", "Transformer", "network", "used", "as", "a", "teacher", ".", "We", "demonstrate", "substantial", "cumulative", "improvements", "associated", "with", "each", "of", "the", "three", "aspects", "of", "our", "training", "strategy", ",", "and", "validate", "our", "approach", "on", "IWSLT", "2016", "English", "\u2013", "German", "and", "two", "WMT", "language", "pairs", ".", "By", "sampling", "fertilities", "in", "parallel", "at", "inference", "time", ",", "our", "non", "-", "autoregressive", "model", "achieves", "near", "-", "state", "-", "of", "-", "the", "-", "art", "performance", "of", "29.8", "BLEU", "on", "WMT", "2016", "English", "\u2013", "Romanian", ".", "section", ":", "Introduction", "Neural", "network", "based", "models", "outperform", "traditional", "statistical", "models", "for", "machine", "translation", "(", "MT", ")", "bahdanau2014neural", ",", "luong2015effective", ".", "However", ",", "state", "-", "of", "-", "the", "-", "art", "neural", "models", "are", "much", "slower", "than", "statistical", "MT", "approaches", "at", "inference", "time", "wu2016google", ".", "Both", "model", "families", "use", "autoregressive", "decoders", "that", "operate", "one", "step", "at", "a", "time", ":", "they", "generate", "each", "token", "conditioned", "on", "the", "sequence", "of", "tokens", "previously", "generated", ".", "This", "process", "is", "not", "parallelizable", ",", "and", ",", "in", "the", "case", "of", "neural", "MT", "models", ",", "it", "is", "particularly", "slow", "because", "a", "computationally", "intensive", "neural", "network", "is", "used", "to", "generate", "each", "token", ".", "While", "several", "recently", "proposed", "models", "avoid", "recurrence", "at", "train", "time", "by", "leveraging", "convolutions", "kalchbrenner2016neural", ",", "gehring2017convolutional", ",", "kaiser2017depthwise", "or", "self", "-", "attention", "vaswani2017attention", "as", "more", "-", "parallelizable", "alternatives", "to", "recurrent", "neural", "networks", "(", "RNNs", ")", ",", "use", "of", "autoregressive", "decoding", "makes", "it", "impossible", "to", "take", "full", "advantage", "of", "parallelism", "during", "inference", ".", "We", "introduce", "a", "non", "-", "autoregressive", "translation", "model", "based", "on", "the", "Transformer", "network", "vaswani2017attention", ".", "We", "modify", "the", "encoder", "of", "the", "original", "Transformer", "network", "by", "adding", "a", "module", "that", "predicts", "fertilities", ",", "sequences", "of", "numbers", "that", "form", "an", "important", "component", "of", "many", "traditional", "machine", "translation", "models", "brown1993mathematics", ".", "These", "fertilities", "are", "supervised", "during", "training", "and", "provide", "the", "decoder", "at", "inference", "time", "with", "a", "globally", "consistent", "plan", "on", "which", "to", "condition", "its", "simultaneously", "computed", "outputs", ".", "section", ":", "Background", "subsection", ":", "Autoregressive", "Neural", "Machine", "Translation", "Given", "a", "source", "sentence", ",", "a", "neural", "machine", "translation", "model", "factors", "the", "distribution", "over", "possible", "output", "sentences", "into", "a", "chain", "of", "conditional", "probabilities", "with", "a", "left", "-", "to", "-", "right", "causal", "structure", ":", "where", "the", "special", "tokens", "(", "e.g.", ")", "and", "(", "e.g.", ")", "are", "used", "to", "represent", "the", "beginning", "and", "end", "of", "all", "target", "sentences", ".", "These", "conditional", "probabilities", "are", "parameterized", "using", "a", "neural", "network", ".", "Typically", ",", "an", "encoder", "-", "decoder", "architecture", "sutskever2014sequence", "with", "a", "unidirectional", "RNN", "-", "based", "decoder", "is", "used", "to", "capture", "the", "causal", "structure", "of", "the", "output", "distribution", ".", "paragraph", ":", "Maximum", "Likelihood", "training", "Choosing", "to", "factorize", "the", "machine", "translation", "output", "distribution", "autoregressively", "enables", "straightforward", "maximum", "likelihood", "training", "with", "a", "cross", "-", "entropy", "loss", "applied", "at", "each", "decoding", "step", ":", "This", "loss", "provides", "direct", "supervision", "for", "each", "conditional", "probability", "prediction", ".", "paragraph", ":", "Autoregressive", "NMT", "without", "RNNs", "Since", "the", "entire", "target", "translation", "is", "known", "at", "training", "time", ",", "the", "calculation", "of", "later", "conditional", "probabilities", "(", "and", "their", "corresponding", "losses", ")", "does", "not", "depend", "on", "the", "output", "words", "chosen", "during", "earlier", "decoding", "steps", ".", "Even", "though", "decoding", "must", "remain", "entirely", "sequential", "during", "inference", ",", "models", "can", "take", "advantage", "of", "this", "parallelism", "during", "training", ".", "One", "such", "approach", "replaces", "recurrent", "layers", "in", "the", "decoder", "with", "masked", "convolution", "layers", "kalchbrenner2016neural", ",", "gehring2017convolutional", "that", "provide", "the", "causal", "structure", "required", "by", "the", "autoregressive", "factorization", ".", "A", "recently", "introduced", "option", "which", "reduces", "sequential", "computation", "still", "further", "is", "to", "construct", "the", "decoder", "layers", "out", "of", "self", "-", "attention", "computations", "that", "have", "been", "causally", "masked", "in", "an", "analogous", "way", ".", "The", "state", "-", "of", "-", "the", "-", "art", "Transformer", "network", "takes", "this", "approach", ",", "which", "allows", "information", "to", "flow", "in", "the", "decoder", "across", "arbitrarily", "long", "distances", "in", "a", "constant", "number", "of", "operations", ",", "asymptotically", "fewer", "than", "required", "by", "convolutional", "architectures", "vaswani2017attention", ".", "subsection", ":", "Non", "-", "Autoregressive", "Decoding", "paragraph", ":", "Pros", "and", "cons", "of", "autoregressive", "decoding", "The", "autoregressive", "factorization", "used", "by", "conventional", "NMT", "models", "has", "several", "benefits", ".", "It", "corresponds", "to", "the", "word", "-", "by", "-", "word", "nature", "of", "human", "language", "production", "and", "effectively", "captures", "the", "distribution", "of", "real", "translations", ".", "Autoregressive", "models", "achieve", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "large", "-", "scale", "corpora", "and", "are", "easy", "to", "train", ",", "while", "beam", "search", "provides", "an", "effective", "local", "search", "method", "for", "finding", "approximately", "-", "optimal", "output", "translations", ".", "But", "there", "are", "also", "drawbacks", ".", "As", "the", "individual", "steps", "of", "the", "decoder", "must", "be", "run", "sequentially", "rather", "than", "in", "parallel", ",", "autoregressive", "decoding", "prevents", "architectures", "like", "the", "Transformer", "from", "fully", "realizing", "their", "train", "-", "time", "performance", "advantage", "during", "inference", ".", "Meanwhile", ",", "beam", "search", "suffers", "from", "diminishing", "returns", "with", "respect", "to", "beam", "size", "koehn2017six", "and", "exhibits", "limited", "search", "parallelism", "because", "it", "introduces", "computational", "dependence", "between", "beams", ".", "paragraph", ":", "Towards", "non", "-", "autoregressive", "decoding", "A", "na\u00efve", "solution", "is", "to", "remove", "the", "autoregressive", "connection", "directly", "from", "an", "existing", "encoder", "-", "decoder", "model", ".", "Assuming", "that", "the", "target", "sequence", "length", "can", "be", "modeled", "with", "a", "separate", "conditional", "distribution", ",", "this", "becomes", "This", "model", "still", "has", "an", "explicit", "likelihood", "function", ",", "and", "it", "can", "still", "be", "trained", "using", "independent", "cross", "-", "entropy", "losses", "on", "each", "output", "distribution", ".", "Now", ",", "however", ",", "these", "distributions", "can", "be", "computed", "in", "parallel", "at", "inference", "time", ".", "subsection", ":", "The", "Multimodality", "Problem", "However", ",", "this", "na\u00efve", "approach", "does", "not", "yield", "good", "results", ",", "because", "such", "a", "model", "exhibits", "complete", "conditional", "independence", ".", "Each", "token", "\u2019s", "distribution", "depends", "only", "on", "the", "source", "sentence", ".", "This", "makes", "it", "a", "poor", "approximation", "to", "the", "true", "target", "distribution", ",", "which", "exhibits", "strong", "correlation", "across", "time", ".", "Intuitively", ",", "such", "a", "decoder", "is", "akin", "to", "a", "panel", "of", "human", "translators", "each", "asked", "to", "provide", "a", "single", "word", "of", "a", "translation", "independently", "of", "the", "words", "their", "colleagues", "choose", ".", "In", "particular", ",", "consider", "an", "English", "source", "sentence", "like", "\u201c", "Thank", "you", ".", "\u201d", "This", "can", "be", "accurately", "translated", "into", "German", "as", "any", "one", "of", "\u201c", "Danke", ".", "\u201d", ",", "\u201c", "Danke", "sch\u00f6n", ".", "\u201d", ",", "or", "\u201c", "Vielen", "Dank", ".", "\u201d", ",", "all", "of", "which", "may", "occur", "in", "a", "given", "training", "corpus", ".", "This", "target", "distribution", "can", "not", "be", "represented", "as", "a", "product", "of", "independent", "probability", "distributions", "for", "each", "of", "the", "first", ",", "second", ",", "and", "third", "words", ",", "because", "a", "conditionally", "independent", "distribution", "can", "not", "allow", "\u201c", "Danke", "sch\u00f6n", ".", "\u201d", "and", "\u201c", "Vielen", "Dank", ".", "\u201d", "without", "also", "licensing", "\u201c", "Danke", "Dank", ".", "\u201d", "and", "\u201c", "Vielen", "sch\u00f6n", ".", "\u201d", "The", "conditional", "independence", "assumption", "prevents", "a", "model", "from", "properly", "capturing", "the", "highly", "multimodal", "distribution", "of", "target", "translations", ".", "We", "call", "this", "the", "\u201c", "multimodality", "problem", "\u201d", "and", "introduce", "both", "a", "modified", "model", "and", "new", "training", "techniques", "to", "tackle", "this", "issue", ".", "section", ":", "The", "Non", "-", "Autoregressive", "Transformer", "(", "NAT", ")", "We", "introduce", "a", "novel", "NMT", "model", "\u2014", "the", "Non", "-", "Autoregressive", "Transformer", "(", "NAT", ")", "\u2014that", "can", "produce", "an", "entire", "output", "translation", "in", "parallel", ".", "As", "shown", "in", "Fig", ".", "[", "reference", "]", ",", "the", "model", "is", "composed", "of", "the", "following", "four", "modules", ":", "an", "encoder", "stack", ",", "a", "decoder", "stack", ",", "a", "newly", "added", "fertility", "predictor", "(", "details", "in", "[", "reference", "]", ")", ",", "and", "a", "translation", "predictor", "for", "token", "decoding", ".", "subsection", ":", "Encoder", "Stack", "Similar", "to", "the", "autoregressive", "Transformer", ",", "both", "the", "encoder", "and", "decoder", "stacks", "are", "composed", "entirely", "of", "feed", "-", "forward", "networks", "(", "MLPs", ")", "and", "multi", "-", "head", "attention", "modules", ".", "Since", "no", "RNNs", "are", "used", ",", "there", "is", "no", "inherent", "requirement", "for", "sequential", "execution", ",", "making", "non", "-", "autoregressive", "decoding", "possible", ".", "For", "our", "proposed", "NAT", ",", "the", "encoder", "stays", "unchanged", "from", "the", "original", "Transformer", "network", ".", "subsection", ":", "Decoder", "Stack", "In", "order", "to", "translate", "non", "-", "autoregressively", "and", "parallelize", "the", "decoding", "process", ",", "we", "modify", "the", "decoder", "stack", "as", "follows", ".", "paragraph", ":", "Decoder", "Inputs", "Before", "decoding", "starts", ",", "the", "NAT", "needs", "to", "know", "how", "long", "the", "target", "sentence", "will", "be", "in", "order", "to", "generate", "all", "words", "in", "parallel", ".", "More", "crucially", ",", "we", "can", "not", "use", "time", "-", "shifted", "target", "outputs", "(", "during", "training", ")", "or", "previously", "predicted", "outputs", "(", "during", "inference", ")", "as", "the", "inputs", "to", "the", "first", "decoder", "layer", ".", "Omitting", "inputs", "to", "the", "first", "decoder", "layer", "entirely", ",", "or", "using", "only", "positional", "embeddings", ",", "resulted", "in", "very", "poor", "performance", ".", "Instead", ",", "we", "initialize", "the", "decoding", "process", "using", "copied", "source", "inputs", "from", "the", "encoder", "side", ".", "As", "the", "source", "and", "target", "sentences", "are", "often", "of", "different", "lengths", ",", "we", "propose", "two", "methods", ":", "Copy", "source", "inputs", "uniformly", ":", "Each", "decoder", "input", "is", "a", "copy", "of", "the", "-", "th", "encoder", "input", ".", "This", "is", "equivalent", "to", "\u201c", "scanning", "\u201d", "source", "inputs", "from", "left", "to", "right", "with", "a", "constant", "\u201c", "speed", ",", "\u201d", "and", "results", "in", "a", "decoding", "process", "that", "is", "deterministic", "given", "a", "(", "predicted", ")", "target", "length", ".", "Copy", "source", "inputs", "using", "fertilities", ":", "A", "more", "powerful", "way", ",", "depicted", "in", "Fig", ".", "[", "reference", "]", "and", "discussed", "in", "more", "detail", "below", ",", "is", "to", "copy", "each", "encoder", "input", "as", "a", "decoder", "input", "zero", "or", "more", "times", ",", "with", "the", "number", "of", "times", "each", "input", "is", "copied", "referred", "to", "as", "that", "input", "word", "\u2019s", "\u201c", "fertility", ".", "\u201d", "In", "this", "case", "the", "source", "inputs", "are", "scanned", "from", "left", "to", "right", "at", "a", "\u201c", "speed", "\u201d", "that", "varies", "inversely", "with", "the", "fertility", "of", "each", "input", ";", "the", "decoding", "process", "is", "now", "conditioned", "on", "the", "sequence", "of", "fertilities", ",", "while", "the", "resulting", "output", "length", "is", "determined", "by", "the", "sum", "of", "all", "fertility", "values", ".", "paragraph", ":", "Non", "-", "causal", "self", "-", "attention", "Without", "the", "constraint", "of", "an", "autoregressive", "factorization", "of", "the", "output", "distribution", ",", "we", "no", "longer", "need", "to", "prevent", "earlier", "decoding", "steps", "from", "accessing", "information", "from", "later", "steps", ".", "Thus", "we", "can", "avoid", "the", "causal", "mask", "used", "in", "the", "self", "-", "attention", "module", "of", "the", "conventional", "Transformer", "\u2019s", "decoder", ".", "Instead", ",", "we", "mask", "out", "each", "query", "position", "only", "from", "attending", "to", "itself", ",", "which", "we", "found", "to", "improve", "decoder", "performance", "relative", "to", "unmasked", "self", "-", "attention", ".", "paragraph", ":", "Positional", "attention", "We", "also", "include", "an", "additional", "positional", "attention", "module", "in", "each", "decoder", "layer", ",", "which", "is", "a", "multi", "-", "head", "attention", "module", "with", "the", "same", "general", "attention", "mechanism", "used", "in", "other", "parts", "of", "the", "Transformer", "network", ",", "i.e.", "where", "is", "the", "model", "hidden", "size", ",", "but", "with", "the", "positional", "encoding", "as", "both", "query", "and", "key", "and", "the", "decoder", "states", "as", "the", "value", ".", "This", "incorporates", "positional", "information", "directly", "into", "the", "attention", "process", "and", "provides", "a", "stronger", "positional", "signal", "than", "the", "embedding", "layer", "alone", ".", "We", "also", "hypothesize", "that", "this", "additional", "information", "improves", "the", "decoder", "\u2019s", "ability", "to", "perform", "local", "reordering", ".", "subsection", ":", "Modeling", "Fertility", "to", "Tackle", "the", "Multimodality", "Problem", "The", "multimodality", "problem", "can", "be", "attacked", "by", "introducing", "a", "latent", "variable", "to", "directly", "model", "the", "nondeterminism", "in", "the", "translation", "process", ":", "we", "first", "sample", "from", "a", "prior", "distribution", "and", "then", "condition", "on", "to", "non", "-", "autoregressively", "generate", "a", "translation", ".", "One", "way", "to", "interpret", "this", "latent", "variable", "is", "as", "a", "sentence", "-", "level", "\u201c", "plan", "\u201d", "akin", "to", "those", "discussed", "in", "the", "language", "production", "literature", "martin2010planning", ".", "There", "are", "several", "desirable", "properties", "for", "this", "latent", "variable", ":", "It", "should", "be", "simple", "to", "infer", "a", "value", "for", "the", "latent", "variable", "given", "a", "particular", "input", "-", "output", "pair", ",", "as", "this", "is", "needed", "to", "train", "the", "model", "end", "-", "to", "-", "end", ".", "Adding", "to", "the", "conditioning", "context", "should", "account", "as", "much", "as", "possible", "for", "the", "correlations", "across", "time", "between", "different", "outputs", ",", "so", "that", "the", "remaining", "marginal", "probabilities", "at", "each", "output", "location", "are", "as", "close", "as", "possible", "to", "satisfying", "conditional", "independence", ".", "It", "should", "not", "account", "for", "the", "variation", "in", "output", "translations", "so", "directly", "that", "becomes", "trivial", "to", "learn", ",", "since", "that", "is", "the", "function", "our", "decoder", "neural", "network", "will", "approximate", ".", "The", "factorization", "by", "length", "introduced", "in", "Eq", ".", "[", "reference", "]", "provides", "a", "very", "weak", "example", "of", "a", "latent", "variable", "model", ",", "satisfying", "the", "first", "and", "third", "property", "but", "not", "the", "first", ".", "We", "propose", "the", "use", "of", "fertilities", "instead", ".", "These", "are", "integers", "for", "each", "word", "in", "the", "source", "sentence", "that", "correspond", "to", "the", "number", "of", "words", "in", "the", "target", "sentence", "that", "can", "be", "aligned", "to", "that", "source", "word", "using", "a", "hard", "alignment", "algorithm", "like", "IBM", "Model", "2", "brown1993mathematics", ".", "One", "of", "the", "most", "important", "properties", "of", "the", "proposed", "NAT", "is", "that", "it", "naturally", "introduces", "an", "informative", "latent", "variable", "when", "we", "choose", "to", "copy", "the", "encoder", "inputs", "based", "on", "predicted", "fertilities", ".", "More", "precisely", ",", "given", "a", "source", "sentence", ",", "the", "conditional", "probability", "of", "a", "target", "translation", "is", ":", "where", "is", "the", "set", "of", "all", "fertility", "sequences", "\u2014", "one", "fertility", "value", "per", "source", "word", "\u2014", "that", "sum", "to", "the", "length", "of", "and", "denotes", "the", "token", "repeated", "times", ".", "paragraph", ":", "Fertility", "prediction", "As", "shown", "in", "Fig", ".", "[", "reference", "]", ",", "we", "model", "the", "fertility", "at", "each", "position", "independently", "using", "a", "one", "-", "layer", "neural", "network", "with", "a", "softmax", "classifier", "(", "in", "our", "experiments", ")", "on", "top", "of", "the", "output", "of", "the", "last", "encoder", "layer", ".", "This", "models", "the", "way", "that", "fertility", "values", "are", "a", "property", "of", "each", "input", "word", "but", "depend", "on", "information", "and", "context", "from", "the", "entire", "sentence", ".", "paragraph", ":", "Benefits", "of", "fertility", "Fertilities", "possess", "all", "three", "of", "the", "properties", "listed", "earlier", "as", "desired", "of", "a", "latent", "variable", "for", "non", "-", "autoregressive", "machine", "translation", ":", "An", "external", "aligner", "provides", "a", "simple", "and", "fast", "approximate", "inference", "model", "that", "effectively", "reduces", "the", "unsupervised", "training", "problem", "to", "two", "supervised", "ones", ".", "Using", "fertilities", "as", "a", "latent", "variable", "makes", "significant", "progress", "towards", "solving", "the", "multimodality", "problem", "by", "providing", "a", "natural", "factorization", "of", "the", "output", "space", ".", "Given", "a", "source", "sentence", ",", "restricting", "the", "output", "distribution", "to", "those", "target", "sentences", "consistent", "with", "a", "particular", "fertility", "sequence", "dramatically", "reduces", "the", "mode", "space", ".", "Furthermore", ",", "the", "global", "choice", "of", "mode", "is", "factored", "into", "a", "set", "of", "local", "mode", "choices", ":", "namely", ",", "how", "to", "translate", "each", "input", "word", ".", "These", "local", "mode", "choices", "can", "be", "effectively", "supervised", "because", "the", "fertilities", "provide", "a", "fixed", "\u201c", "scaffold", ".", "\u201d", "Including", "both", "fertilities", "and", "reordering", "in", "the", "latent", "variable", "would", "provide", "complete", "alignment", "statistics", ".", "This", "would", "make", "the", "decoding", "function", "trivially", "easy", "to", "approximate", "given", "the", "latent", "variable", "and", "force", "all", "of", "the", "modeling", "complexity", "into", "the", "encoder", ".", "Using", "fertilities", "alone", "allows", "the", "decoder", "to", "take", "some", "of", "this", "burden", "off", "of", "the", "encoder", ".", "Our", "use", "of", "fertilities", "as", "a", "latent", "variable", "also", "means", "that", "there", "is", "no", "need", "to", "have", "a", "separate", "means", "of", "explicitly", "modeling", "the", "length", "of", "the", "translation", ",", "which", "is", "simply", "the", "sum", "of", "fertilities", ".", "And", "fertilities", "provide", "a", "powerful", "way", "to", "condition", "the", "decoding", "process", ",", "allowing", "the", "model", "to", "generate", "diverse", "translations", "by", "sampling", "over", "the", "fertility", "space", ".", "subsection", ":", "Translation", "Predictor", "and", "the", "Decoding", "Process", "At", "inference", "time", ",", "the", "model", "can", "identify", "the", "translation", "with", "the", "highest", "conditional", "probability", "(", "see", "Eq", ".", "[", "reference", "]", ")", "by", "marginalizing", "over", "all", "possible", "latent", "fertility", "sequences", ".", "Given", "a", "fertility", "sequence", ",", "however", ",", "identifying", "the", "optimal", "translation", "only", "requires", "independently", "maximizing", "the", "local", "probability", "for", "each", "output", "position", ".", "We", "define", "to", "represent", "the", "optimal", "translation", "given", "a", "source", "sentence", "and", "a", "sequence", "of", "fertility", "values", ".", "But", "searching", "and", "marginalizing", "over", "the", "whole", "fertility", "space", "is", "still", "intractable", ".", "We", "propose", "three", "heuristic", "decoding", "algorithms", "to", "reduce", "the", "search", "space", "of", "the", "NAT", "model", ":", "paragraph", ":", "Argmax", "decoding", "Since", "the", "fertility", "sequence", "is", "also", "modeled", "with", "a", "conditionally", "independent", "factorization", ",", "we", "can", "simply", "estimate", "the", "best", "translation", "by", "choosing", "the", "highest", "-", "probability", "fertility", "for", "each", "input", "word", ":", "paragraph", ":", "Average", "decoding", "We", "can", "also", "estimate", "each", "fertility", "as", "the", "expectation", "of", "its", "corresponding", "softmax", "distribution", ":", "paragraph", ":", "Noisy", "parallel", "decoding", "(", "NPD", ")", "A", "more", "accurate", "approximation", "of", "the", "true", "optimum", "of", "the", "target", "distribution", ",", "inspired", "by", "cho2016noisy", ",", "is", "to", "draw", "samples", "from", "the", "fertility", "space", "and", "compute", "the", "best", "translation", "for", "each", "fertility", "sequence", ".", "We", "can", "then", "use", "the", "autoregressive", "teacher", "to", "identify", "the", "best", "overall", "translation", ":", "Note", "that", ",", "when", "using", "an", "autoregressive", "model", "as", "a", "scoring", "function", "for", "a", "set", "of", "decoded", "translations", ",", "it", "can", "run", "as", "fast", "as", "it", "does", "at", "train", "time", "because", "it", "can", "be", "provided", "with", "all", "decoder", "inputs", "in", "parallel", ".", "NPD", "is", "a", "stochastic", "search", "method", ",", "and", "it", "also", "increases", "the", "computational", "resources", "required", "linearly", "by", "the", "sample", "size", ".", "However", ",", "because", "all", "the", "search", "samples", "can", "be", "computed", "and", "scored", "entirely", "independently", ",", "the", "process", "only", "doubles", "the", "latency", "compared", "to", "computing", "a", "single", "translation", "if", "sufficient", "parallelism", "is", "available", ".", "section", ":", "Training", "The", "proposed", "NAT", "contains", "a", "discrete", "sequential", "latent", "variable", ",", "whose", "conditional", "posterior", "distribution", "we", "can", "approximate", "using", "a", "proposal", "distribution", ".", "This", "provides", "a", "variational", "bound", "for", "the", "overall", "maximum", "likelihood", "loss", ":", "We", "choose", "a", "proposal", "distribution", "defined", "by", "a", "separate", ",", "fixed", "fertility", "model", ".", "Possible", "options", "include", "the", "output", "of", "an", "external", "aligner", ",", "which", "produces", "a", "deterministic", "sequence", "of", "integer", "fertilities", "for", "each", "(", "source", ",", "target", ")", "pair", "in", "a", "training", "corpus", ",", "or", "fertilities", "computed", "from", "the", "attention", "weights", "used", "in", "our", "fixed", "autoregressive", "teacher", "model", ".", "This", "simplifies", "the", "inference", "process", "considerably", ",", "as", "the", "expectation", "over", "is", "deterministic", ".", "The", "resulting", "loss", "function", ",", "consisting", "of", "the", "two", "bracketed", "terms", "in", "Eq", ".", "[", "reference", "]", ",", "allows", "us", "to", "train", "the", "entire", "model", "in", "a", "supervised", "fashion", ",", "using", "the", "inferred", "fertilities", "to", "simultaneously", "train", "the", "translation", "model", "and", "supervise", "the", "fertility", "neural", "network", "model", ".", "subsection", ":", "Sequence", "-", "Level", "Knowledge", "Distillation", "While", "the", "latent", "fertility", "model", "substantially", "improves", "the", "ability", "of", "the", "non", "-", "autoregressive", "output", "distribution", "to", "approximate", "the", "multimodal", "target", "distribution", ",", "it", "does", "not", "completely", "solve", "the", "problem", "of", "nondeterminism", "in", "the", "training", "data", ".", "In", "many", "cases", ",", "there", "are", "multiple", "correct", "translations", "consistent", "with", "a", "single", "sequence", "of", "fertilities", "\u2014", "for", "instance", ",", "both", "\u201c", "Danke", "sch\u00f6n", ".", "\u201d", "and", "\u201c", "Vielen", "dank", ".", "\u201d", "are", "consistent", "with", "the", "English", "input", "\u201c", "Thank", "you", ".", "\u201d", "and", "the", "fertility", "sequence", ",", "because", "\u201c", "you", "\u201d", "is", "not", "directly", "translated", "in", "either", "German", "sentence", ".", "Thus", "we", "additionally", "apply", "sequence", "-", "level", "knowledge", "distillation", "kim2016sequence", "to", "construct", "a", "new", "corpus", "by", "training", "an", "autoregressive", "machine", "translation", "model", ",", "known", "as", "the", "teacher", ",", "on", "an", "existing", "training", "corpus", ",", "then", "using", "that", "model", "\u2019s", "greedy", "outputs", "as", "the", "targets", "for", "training", "the", "non", "-", "autoregressive", "student", ".", "The", "resulting", "targets", "are", "less", "noisy", "and", "more", "deterministic", ",", "as", "the", "trained", "model", "will", "consistently", "translate", "a", "sentence", "like", "\u201c", "Thank", "you", ".", "\u201d", "into", "the", "same", "German", "translation", "every", "time", ";", "on", "the", "other", "hand", ",", "they", "are", "also", "lower", "in", "quality", "than", "the", "original", "dataset", ".", "subsection", ":", "Fine", "-", "Tuning", "Our", "supervised", "fertility", "model", "enables", "a", "decomposition", "of", "the", "overall", "maximum", "likelihood", "loss", "into", "translation", "and", "fertility", "terms", ",", "but", "it", "has", "some", "drawbacks", "compared", "to", "variational", "training", ".", "In", "particular", ",", "it", "heavily", "relies", "on", "the", "deterministic", ",", "approximate", "inference", "model", "provided", "by", "the", "external", "alignment", "system", ",", "while", "it", "would", "be", "desirable", "to", "train", "the", "entire", "model", ",", "including", "the", "fertility", "predictor", ",", "end", "to", "end", ".", "Thus", "we", "propose", "a", "fine", "-", "tuning", "step", "after", "training", "the", "NAT", "to", "convergence", ".", "We", "introduce", "an", "additional", "loss", "term", "consisting", "of", "the", "reverse", "K", "-", "L", "divergence", "with", "the", "teacher", "output", "distribution", ",", "a", "form", "of", "word", "-", "level", "knowledge", "distillation", ":", "where", ".", "Such", "a", "loss", "is", "more", "favorable", "towards", "highly", "peaked", "student", "output", "distributions", "than", "a", "standard", "cross", "-", "entropy", "error", "would", "be", ".", "Then", "we", "train", "the", "whole", "model", "jointly", "with", "a", "weighted", "sum", "of", "the", "original", "distillation", "loss", "and", "two", "such", "terms", ",", "one", "an", "expectation", "over", "the", "predicted", "fertility", "distribution", ",", "normalized", "with", "a", "baseline", ",", "and", "the", "other", "based", "on", "the", "external", "fertility", "inference", "model", ":", "where", "is", "the", "average", "fertility", "computed", "by", "Eq", ".", "[", "reference", "]", ".", "The", "gradient", "with", "respect", "to", "the", "non", "-", "differentiable", "term", "can", "be", "estimated", "with", "REINFORCE", "williams1992simple", ",", "while", "the", "term", "can", "be", "trained", "using", "ordinary", "backpropagation", ".", "section", ":", "Experiments", "subsection", ":", "Experimental", "Settings", "paragraph", ":", "Dataset", "We", "evaluate", "the", "proposed", "NAT", "on", "three", "widely", "used", "public", "machine", "translation", "corpora", ":", "IWSLT16", "En", "\u2013", "De", ",", "WMT14", "En", "\u2013", "De", ",", "and", "WMT16", "En", "\u2013", "Ro", ".", "We", "use", "IWSLT", "\u2014", "which", "is", "smaller", "than", "the", "other", "two", "datasets", "\u2014", "as", "the", "development", "dataset", "for", "ablation", "experiments", ",", "and", "additionally", "train", "and", "test", "our", "primary", "models", "on", "both", "directions", "of", "both", "WMT", "datasets", ".", "All", "the", "data", "are", "tokenized", "and", "segmented", "into", "subword", "symbols", "using", "byte", "-", "pair", "encoding", "(", "BPE", ")", "sennrich2015neural", "to", "restrict", "the", "size", "of", "the", "vocabulary", ".", "For", "both", "WMT", "datasets", ",", "we", "use", "shared", "BPE", "vocabulary", "and", "additionally", "share", "encoder", "and", "decoder", "word", "embeddings", ";", "for", "IWSLT", ",", "we", "use", "separate", "English", "and", "German", "vocabulary", "and", "embeddings", ".", "paragraph", ":", "Teacher", "Sequence", "-", "level", "knowledge", "distillation", "is", "applied", "to", "alleviate", "multimodality", "in", "the", "training", "dataset", ",", "using", "autoregressive", "models", "as", "the", "teachers", ".", "The", "same", "teacher", "model", "used", "for", "distillation", "is", "also", "used", "as", "a", "scoring", "function", "for", "fine", "-", "tuning", "and", "noisy", "parallel", "decoding", ".", "To", "enable", "a", "fair", "comparison", ",", "and", "benefit", "from", "its", "high", "translation", "quality", ",", "we", "implemented", "the", "autoregressive", "teachers", "using", "the", "state", "-", "of", "-", "the", "-", "art", "Transformer", "architecture", ".", "In", "addition", ",", "we", "use", "the", "same", "sizes", "and", "hyperparameters", "for", "each", "student", "and", "its", "respective", "teacher", ",", "with", "the", "exception", "of", "the", "newly", "added", "positional", "self", "-", "attention", "and", "fertility", "prediction", "modules", ".", "paragraph", ":", "Preparation", "for", "knowledge", "distillation", "We", "first", "train", "all", "teacher", "models", "using", "maximum", "likelihood", ",", "then", "freeze", "their", "parameters", ".", "To", "avoid", "the", "redundancy", "of", "running", "fixed", "teacher", "models", "repeatedly", "on", "the", "same", "data", ",", "we", "decode", "the", "entire", "training", "set", "once", "using", "each", "teacher", "to", "create", "a", "new", "training", "dataset", "for", "its", "respective", "student", ".", "paragraph", ":", "Encoder", "initialization", "We", "find", "it", "helpful", "to", "initialize", "the", "weights", "in", "the", "NAT", "student", "\u2019s", "encoder", "with", "the", "encoder", "weights", "from", "its", "teacher", ",", "as", "the", "autoregressive", "and", "non", "-", "autoregressive", "models", "share", "the", "same", "encoder", "input", "and", "architecture", ".", "paragraph", ":", "Fertility", "supervision", "during", "training", "As", "described", "above", ",", "we", "supervise", "the", "fertility", "predictions", "at", "train", "time", "by", "using", "a", "fixed", "aligner", "as", "a", "fertility", "inference", "function", ".", "We", "use", "the", "fast_alignhttps:", "//", "github.com", "/", "clab", "/", "fast_align", "implementation", "of", "IBM", "Model", "2", "for", "this", "purpose", ",", "with", "default", "parameters", "dyer2013simple", ".", "paragraph", ":", "Hyperparameters", "For", "experiments", "on", "WMT", "datasets", ",", "we", "use", "the", "hyperparameter", "settings", "of", "the", "base", "Transformer", "model", "described", "in", "vaswani2017attention", ",", "though", "without", "label", "smoothing", ".", "As", "IWSLT", "is", "a", "smaller", "corpus", ",", "and", "to", "reduce", "training", "time", ",", "we", "use", "a", "set", "of", "smaller", "hyperparameters", "(", ",", "and", ")", "for", "all", "experiments", "on", "that", "dataset", ".", "For", "fine", "-", "tuning", "we", "use", ".", "paragraph", ":", "Evaluation", "metrics", "We", "evaluate", "using", "tokenized", "and", "cased", "BLEU", "scores", "papineni2002bleu", ".", "paragraph", ":", "Implementation", "We", "have", "open", "-", "sourced", "our", "PyTorch", "implementation", "of", "the", "NAT", ".", "subsection", ":", "Results", "Across", "the", "three", "datasets", "we", "used", ",", "the", "NAT", "performs", "between", "2", "-", "5", "BLEU", "points", "worse", "than", "its", "autoregressive", "teacher", ",", "with", "part", "or", "all", "of", "this", "gap", "addressed", "by", "the", "use", "of", "noisy", "parallel", "decoding", ".", "In", "the", "case", "of", "WMT16", "English", "\u2013", "Romanian", ",", "NPD", "improves", "the", "performance", "of", "our", "non", "-", "autoregressive", "model", "to", "within", "0.2", "BLEU", "points", "of", "the", "previous", "overall", "state", "of", "the", "art", "gehring2017convolutional", ".", "Comparing", "latencies", "on", "the", "development", "model", "shows", "a", "speedup", "of", "more", "than", "a", "factor", "of", "10", "over", "greedy", "autoregressive", "decoding", ",", "or", "a", "factor", "of", "15", "over", "beam", "search", ".", "Latencies", "for", "decoding", "with", "NPD", ",", "regardless", "of", "sample", "size", ",", "could", "be", "reduced", "to", "about", "80ms", "by", "parallelizing", "across", "multiple", "GPUs", "because", "each", "sample", "can", "be", "generated", ",", "then", "scored", ",", "independently", "from", "the", "others", ".", "subsection", ":", "Ablation", "Study", "We", "also", "conduct", "an", "extensive", "ablation", "study", "with", "the", "proposed", "NAT", "on", "the", "IWSLT", "dataset", ".", "First", ",", "we", "note", "that", "the", "model", "fails", "to", "train", "when", "provided", "with", "only", "positional", "embeddings", "as", "input", "to", "the", "decoder", ".", "Second", ",", "we", "see", "that", "training", "on", "the", "distillation", "corpus", "rather", "than", "the", "ground", "truth", "provides", "a", "fairly", "consistent", "improvement", "of", "around", "5", "BLEU", "points", ".", "Third", ",", "switching", "from", "uniform", "copying", "of", "source", "inputs", "to", "fertility", "-", "based", "copying", "improves", "performance", "by", "four", "BLEU", "points", "when", "using", "ground", "-", "truth", "training", "or", "two", "when", "using", "distillation", ".", "Fine", "-", "tuning", "does", "not", "converge", "with", "reinforcement", "learning", "alone", ",", "or", "with", "the", "term", "alone", ",", "but", "use", "of", "all", "three", "fine", "-", "tuning", "terms", "together", "leads", "to", "an", "improvement", "of", "around", "1.5", "BLEU", "points", ".", "Training", "the", "student", "model", "from", "a", "distillation", "corpus", "produced", "using", "beam", "search", "is", "similar", "to", "training", "from", "the", "greedily", "-", "distilled", "corpus", ".", "We", "include", "two", "examples", "of", "translations", "from", "the", "IWSLT", "development", "set", "in", "Fig", ".", "[", "reference", "]", ".", "Instances", "of", "repeated", "words", "or", "phrases", ",", "highlighted", "in", "gray", ",", "are", "most", "prevalent", "in", "the", "non", "-", "autoregressive", "output", "for", "the", "relatively", "complex", "first", "example", "sentence", ".", "Two", "pairs", "of", "repeated", "words", "in", "the", "first", "example", ",", "as", "well", "as", "a", "pair", "in", "the", "second", ",", "are", "not", "present", "in", "the", "versions", "with", "noisy", "parallel", "decoding", ",", "suggesting", "that", "NPD", "scoring", "using", "the", "teacher", "model", "can", "filter", "out", "such", "mistakes", ".", "The", "translations", "produced", "by", "the", "NAT", "with", "NPD", ",", "while", "of", "a", "similar", "quality", "to", "those", "produced", "by", "the", "autoregressive", "model", ",", "are", "also", "noticeably", "more", "literal", ".", "We", "also", "show", "an", "example", "of", "the", "noisy", "parallel", "decoding", "process", "in", "Fig", ".", "[", "reference", "]", ",", "demonstrating", "the", "diversity", "of", "translations", "that", "can", "be", "found", "by", "sampling", "from", "the", "fertility", "space", ".", "section", ":", "Conclusion", "We", "introduce", "a", "latent", "variable", "model", "for", "non", "-", "autoregressive", "machine", "translation", "that", "enables", "a", "decoder", "based", "on", "vaswani2017attention", "to", "take", "full", "advantage", "of", "its", "exceptional", "degree", "of", "internal", "parallelism", "even", "at", "inference", "time", ".", "As", "a", "result", ",", "we", "measure", "translation", "latencies", "of", "one", "-", "tenth", "that", "of", "an", "equal", "-", "sized", "autoregressive", "model", ",", "while", "maintaining", "competitive", "BLEU", "scores", ".", "bibliography", ":", "References", "appendix", ":", "Schematic", "and", "Analysis"]}