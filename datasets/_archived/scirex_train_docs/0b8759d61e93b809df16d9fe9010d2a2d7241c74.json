{"coref": {"CIFAR-10": [[270, 273], [2647, 2650], [3513, 3516], [3708, 3711], [3730, 3733], [4250, 4253]], "CIFAR-100": [[281, 284], [2667, 2670], [3093, 3096], [3509, 3512], [3739, 3742], [3757, 3760], [4262, 4265], [3133, 3136]], "Exponential_Linear_Units": [[9, 12], [13, 14], [19, 23], [24, 25], [61, 62], [75, 76], [94, 95], [165, 166], [185, 186], [213, 214], [241, 246], [259, 261], [262, 264], [299, 301], [2251, 2254], [2255, 2256], [2258, 2261], [2262, 2263], [2267, 2268], [2275, 2276], [2290, 2291], [2354, 2355], [2400, 2401], [2445, 2446], [2537, 2538], [2547, 2550], [2551, 2552], [2568, 2569], [2719, 2720], [2737, 2740], [2837, 2838], [2851, 2853], [2879, 2881], [2916, 2918], [2925, 2927], [3008, 3009], [3053, 3054], [3077, 3079], [3245, 3246], [3372, 3373], [3413, 3414], [3433, 3435], [3470, 3471], [3483, 3485], [3525, 3527], [3654, 3656], [3700, 3703], [3734, 3736], [3782, 3785], [3952, 3953], [3963, 3964], [3971, 3974], [4030, 4032], [4067, 4068], [4081, 4083], [4090, 4092], [4100, 4103], [4104, 4105], [4117, 4118], [4136, 4137], [4187, 4188], [4213, 4214], [4225, 4227], [4238, 4240], [4280, 4282], [4305, 4307], [4563, 4564], [4577, 4579], [4609, 4612], [4688, 4690]], "Image_Classification": [], "Percentage_correct": []}, "coref_non_salient": {"0": [[1033, 1034], [2937, 2939]], "1": [[29, 30], [124, 125], [219, 220], [304, 305], [524, 525], [581, 582], [906, 907], [962, 964], [1743, 1744], [2164, 2165], [2378, 2379], [2711, 2713], [2976, 2977], [4111, 4112], [4154, 4155]], "10": [[1111, 1112], [1207, 1211]], "11": [[341, 343], [570, 572], [1004, 1006], [3677, 3679], [4583, 4585]], "12": [[1162, 1164], [3176, 3180], [3553, 3557], [3623, 3627], [3640, 3644]], "13": [[2786, 2788], [3224, 3227]], "14": [[1127, 1130], [4468, 4471]], "15": [[226, 228], [3506, 3508]], "16": [[3140, 3142], [3543, 3545], [4314, 4316]], "17": [[3105, 3106], [3130, 3131], [3529, 3530], [3662, 3663], [3675, 3676], [3826, 3827]], "18": [[485, 488], [944, 947], [3669, 3670]], "19": [[338, 340], [633, 635], [761, 763], [809, 811], [839, 841], [1258, 1260], [2231, 2233], [2341, 2344], [3012, 3014], [3045, 3047], [3063, 3065], [3444, 3446], [4217, 4219]], "2": [[673, 677], [3463, 3465], [3665, 3666], [4037, 4038]], "20": [[2556, 2557], [2928, 2929]], "21": [[2848, 2850], [3017, 3023], [3417, 3419]], "22": [[705, 710], [3667, 3668]], "23": [[288, 292], [3765, 3769], [4269, 4274]], "24": [[4057, 4059], [4063, 4066]], "25": [[58, 59], [147, 148], [678, 679], [4174, 4175], [4185, 4186]], "26": [[3346, 3349], [3377, 3379], [3421, 3423], [3686, 3688], [3713, 3715], [3744, 3746], [3967, 3968], [3979, 3983], [3998, 4000], [4020, 4025]], "27": [[110, 112], [251, 253], [254, 256], [584, 586], [2616, 2618], [3085, 3087], [3458, 3460], [3490, 3492], [4177, 4179], [4235, 4237]], "28": [[2950, 2954], [3841, 3844]], "29": [[49, 51], [646, 649], [2304, 2306], [2588, 2590], [2602, 2604]], "3": [[1079, 1083], [4367, 4371]], "30": [[78, 80], [3058, 3060]], "31": [[1783, 1786], [2028, 2031]], "32": [[42, 45], [345, 348], [2576, 2579]], "33": [[3170, 3172], [3880, 3882]], "34": [[3845, 3846], [3876, 3877], [3901, 3902]], "35": [[2921, 2923]], "36": [[3493, 3498]], "37": [[365, 367], [4113, 4116]], "38": [[52, 53], [145, 146], [231, 232], [650, 651], [681, 682], [711, 712], [747, 748], [2307, 2308], [2591, 2592], [3426, 3427], [4172, 4173], [4183, 4184], [742, 743], [2744, 2745], [3391, 3392]], "39": [[2605, 2606], [3429, 3430], [3472, 3474]], "4": [[5, 8], [31, 34], [731, 733], [2564, 2567], [2731, 2736], [3101, 3104]], "40": [[4488, 4492]], "41": [[1100, 1105]], "42": [[959, 961]], "43": [[3155, 3158], [3558, 3561], [3680, 3684], [3850, 3853]], "44": [[384, 386]], "45": [[968, 973]], "46": [[1183, 1185], [2995, 2997], [3025, 3027], [3034, 3036], [3202, 3205], [3587, 3589]], "47": [[608, 609]], "48": [[115, 117], [3111, 3113]], "49": [[3522, 3524]], "5": [[602, 607], [1027, 1032], [1046, 1049]], "50": [[901, 904], [1814, 1817], [1889, 1892], [2044, 2047]], "51": [[3278, 3280]], "52": [[293, 295], [3770, 3772], [4275, 4277]], "53": [[2501, 2505]], "54": [[4628, 4630]], "55": [[3868, 3869]], "56": [[641, 643]], "57": [[64, 67], [397, 400], [2312, 2315]], "58": [[3671, 3672]], "59": [[3572, 3574]], "6": [[46, 47], [55, 57], [92, 93], [229, 230], [349, 350], [391, 392], [659, 660], [671, 672], [2301, 2302], [2484, 2485], [2580, 2581], [2741, 2742], [2877, 2878], [3424, 3425], [3461, 3462], [4071, 4072], [4575, 4576], [4605, 4606], [248, 249], [308, 309], [369, 370], [2888, 2889], [2894, 2895], [3082, 3083], [3240, 3241], [3487, 3488], [3954, 3955], [3989, 3990], [4039, 4040], [4231, 4232], [4295, 4296], [4565, 4566], [4660, 4661], [4666, 4667]], "60": [[1926, 1928], [1942, 1944]], "61": [[357, 360]], "62": [[1058, 1064]], "63": [[2514, 2515]], "64": [[3274, 3277]], "65": [[3864, 3867]], "66": [[4011, 4013]], "67": [[2520, 2521]], "68": [[1652, 1654], [1731, 1733]], "69": [[981, 986]], "7": [[975, 979], [1037, 1045]], "70": [[1066, 1069]], "71": [[1301, 1302]], "72": [[1050, 1051]], "73": [[3257, 3261]], "74": [[3327, 3329]], "75": [[325, 330]], "76": [[2945, 2947]], "77": [[2558, 2563]], "8": [[998, 1001], [1173, 1175], [2782, 2785], [2979, 2982]], "9": [[38, 40], [320, 322], [3689, 3691]]}, "doc_id": "0b8759d61e93b809df16d9fe9010d2a2d7241c74", "method_subrelations": {"Exponential_Linear_Units": [[[0, 24], "Exponential_Linear_Units"]]}, "n_ary_relations": [{"Material": "CIFAR-10", "Method": "Exponential_Linear_Units", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "93.5"}, {"Material": "CIFAR-100", "Method": "Exponential_Linear_Units", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "75.7"}], "ner": [[5, 8, "Method"], [9, 12, "Method"], [13, 14, "Method"], [19, 23, "Method"], [24, 25, "Method"], [29, 30, "Task"], [31, 34, "Method"], [38, 40, "Metric"], [42, 45, "Method"], [46, 47, "Method"], [49, 51, "Method"], [52, 53, "Method"], [55, 57, "Method"], [58, 59, "Method"], [61, 62, "Method"], [64, 67, "Task"], [75, 76, "Method"], [78, 80, "Metric"], [92, 93, "Method"], [94, 95, "Method"], [110, 112, "Method"], [115, 117, "Metric"], [124, 125, "Task"], [145, 146, "Method"], [147, 148, "Method"], [165, 166, "Method"], [185, 186, "Method"], [213, 214, "Method"], [219, 220, "Task"], [226, 228, "Metric"], [229, 230, "Method"], [231, 232, "Method"], [241, 246, "Method"], [251, 253, "Method"], [254, 256, "Method"], [259, 261, "Method"], [262, 264, "Method"], [270, 273, "Material"], [281, 284, "Material"], [288, 292, "Method"], [293, 295, "Method"], [299, 301, "Method"], [304, 305, "Task"], [320, 322, "Metric"], [325, 330, "Method"], [338, 340, "Method"], [341, 343, "Method"], [345, 348, "Method"], [349, 350, "Method"], [357, 360, "Method"], [365, 367, "Task"], [384, 386, "Method"], [391, 392, "Method"], [397, 400, "Task"], [485, 488, "Method"], [524, 525, "Task"], [570, 572, "Method"], [581, 582, "Task"], [584, 586, "Method"], [602, 607, "Method"], [608, 609, "Method"], [633, 635, "Method"], [641, 643, "Method"], [646, 649, "Method"], [650, 651, "Method"], [659, 660, "Method"], [671, 672, "Method"], [673, 677, "Method"], [678, 679, "Method"], [681, 682, "Method"], [705, 710, "Method"], [711, 712, "Method"], [731, 733, "Method"], [747, 748, "Method"], [761, 763, "Method"], [809, 811, "Method"], [839, 841, "Method"], [901, 904, "Method"], [906, 907, "Task"], [944, 947, "Method"], [959, 961, "Metric"], [962, 964, "Task"], [968, 973, "Method"], [975, 979, "Method"], [981, 986, "Method"], [998, 1001, "Method"], [1004, 1006, "Method"], [1027, 1032, "Method"], [1033, 1034, "Method"], [1037, 1045, "Method"], [1046, 1049, "Method"], [1050, 1051, "Method"], [1058, 1064, "Method"], [1066, 1069, "Method"], [1079, 1083, "Method"], [1100, 1105, "Method"], [1111, 1112, "Method"], [1127, 1130, "Method"], [1162, 1164, "Metric"], [1173, 1175, "Method"], [1183, 1185, "Metric"], [1207, 1211, "Method"], [1258, 1260, "Method"], [1301, 1302, "Method"], [1652, 1654, "Method"], [1731, 1733, "Method"], [1743, 1744, "Task"], [1783, 1786, "Task"], [1814, 1817, "Method"], [1889, 1892, "Method"], [1926, 1928, "Method"], [1942, 1944, "Method"], [2028, 2031, "Task"], [2044, 2047, "Method"], [2164, 2165, "Task"], [2231, 2233, "Method"], [2251, 2254, "Method"], [2255, 2256, "Method"], [2258, 2261, "Method"], [2262, 2263, "Method"], [2267, 2268, "Method"], [2275, 2276, "Method"], [2290, 2291, "Method"], [2301, 2302, "Method"], [2304, 2306, "Method"], [2307, 2308, "Method"], [2312, 2315, "Task"], [2341, 2344, "Method"], [2354, 2355, "Method"], [2378, 2379, "Task"], [2400, 2401, "Method"], [2445, 2446, "Method"], [2484, 2485, "Method"], [2501, 2505, "Task"], [2514, 2515, "Task"], [2520, 2521, "Method"], [2537, 2538, "Method"], [2547, 2550, "Method"], [2551, 2552, "Method"], [2556, 2557, "Task"], [2558, 2563, "Task"], [2564, 2567, "Method"], [2568, 2569, "Method"], [2576, 2579, "Method"], [2580, 2581, "Method"], [2588, 2590, "Method"], [2591, 2592, "Method"], [2602, 2604, "Method"], [2605, 2606, "Method"], [2616, 2618, "Method"], [2647, 2650, "Material"], [2667, 2670, "Material"], [2711, 2713, "Task"], [2719, 2720, "Method"], [2731, 2736, "Method"], [2737, 2740, "Method"], [2741, 2742, "Method"], [2782, 2785, "Method"], [2786, 2788, "Method"], [2837, 2838, "Method"], [2848, 2850, "Metric"], [2851, 2853, "Method"], [2877, 2878, "Method"], [2879, 2881, "Method"], [2916, 2918, "Method"], [2921, 2923, "Method"], [2925, 2927, "Method"], [2937, 2939, "Method"], [2945, 2947, "Method"], [2950, 2954, "Method"], [2976, 2977, "Task"], [2979, 2982, "Method"], [2995, 2997, "Metric"], [3008, 3009, "Method"], [3012, 3014, "Method"], [3017, 3023, "Metric"], [3025, 3027, "Metric"], [3034, 3036, "Metric"], [3045, 3047, "Method"], [3053, 3054, "Method"], [3058, 3060, "Metric"], [3063, 3065, "Method"], [3077, 3079, "Method"], [3085, 3087, "Method"], [3093, 3096, "Material"], [3101, 3104, "Method"], [3105, 3106, "Method"], [3111, 3113, "Metric"], [3130, 3131, "Method"], [3140, 3142, "Method"], [3155, 3158, "Method"], [3170, 3172, "Task"], [3176, 3180, "Metric"], [3202, 3205, "Metric"], [3224, 3227, "Method"], [3245, 3246, "Method"], [3257, 3261, "Metric"], [3274, 3277, "Method"], [3278, 3280, "Method"], [3327, 3329, "Method"], [3346, 3349, "Metric"], [3372, 3373, "Method"], [3377, 3379, "Metric"], [3413, 3414, "Method"], [3417, 3419, "Metric"], [3421, 3423, "Metric"], [3424, 3425, "Method"], [3426, 3427, "Method"], [3429, 3430, "Method"], [3433, 3435, "Method"], [3444, 3446, "Method"], [3458, 3460, "Method"], [3461, 3462, "Method"], [3463, 3465, "Method"], [3470, 3471, "Method"], [3472, 3474, "Method"], [3483, 3485, "Method"], [3490, 3492, "Method"], [3493, 3498, "Metric"], [3506, 3508, "Metric"], [3509, 3512, "Material"], [3513, 3516, "Material"], [3522, 3524, "Method"], [3525, 3527, "Method"], [3543, 3545, "Method"], [3553, 3557, "Metric"], [3558, 3561, "Method"], [3572, 3574, "Method"], [3587, 3589, "Metric"], [3623, 3627, "Metric"], [3640, 3644, "Metric"], [3654, 3656, "Method"], [3665, 3666, "Method"], [3667, 3668, "Method"], [3669, 3670, "Method"], [3671, 3672, "Method"], [3677, 3679, "Method"], [3680, 3684, "Method"], [3686, 3688, "Metric"], [3689, 3691, "Metric"], [3700, 3703, "Method"], [3708, 3711, "Material"], [3713, 3715, "Metric"], [3730, 3733, "Material"], [3734, 3736, "Method"], [3739, 3742, "Material"], [3744, 3746, "Metric"], [3757, 3760, "Material"], [3765, 3769, "Method"], [3770, 3772, "Method"], [3782, 3785, "Method"], [3841, 3844, "Method"], [3845, 3846, "Method"], [3850, 3853, "Method"], [3864, 3867, "Method"], [3868, 3869, "Method"], [3880, 3882, "Task"], [3952, 3953, "Method"], [3963, 3964, "Method"], [3967, 3968, "Metric"], [3971, 3974, "Method"], [3979, 3983, "Metric"], [3998, 4000, "Metric"], [4011, 4013, "Task"], [4020, 4025, "Metric"], [4030, 4032, "Method"], [4037, 4038, "Method"], [4057, 4059, "Metric"], [4063, 4066, "Metric"], [4067, 4068, "Method"], [4071, 4072, "Method"], [4081, 4083, "Method"], [4090, 4092, "Method"], [4100, 4103, "Method"], [4104, 4105, "Method"], [4111, 4112, "Task"], [4113, 4116, "Task"], [4117, 4118, "Method"], [4136, 4137, "Method"], [4154, 4155, "Task"], [4172, 4173, "Method"], [4174, 4175, "Method"], [4177, 4179, "Method"], [4183, 4184, "Method"], [4185, 4186, "Method"], [4187, 4188, "Method"], [4213, 4214, "Method"], [4217, 4219, "Method"], [4225, 4227, "Method"], [4235, 4237, "Method"], [4238, 4240, "Method"], [4250, 4253, "Material"], [4262, 4265, "Material"], [4269, 4274, "Method"], [4275, 4277, "Method"], [4280, 4282, "Method"], [4305, 4307, "Method"], [4314, 4316, "Method"], [4367, 4371, "Method"], [4468, 4471, "Method"], [4488, 4492, "Method"], [4563, 4564, "Method"], [4575, 4576, "Method"], [4577, 4579, "Method"], [4583, 4585, "Method"], [4605, 4606, "Method"], [4609, 4612, "Method"], [4628, 4630, "Method"], [4688, 4690, "Method"], [248, 249, "Method"], [308, 309, "Method"], [369, 370, "Method"], [742, 743, "Method"], [2744, 2745, "Method"], [2888, 2889, "Method"], [2894, 2895, "Method"], [2928, 2929, "Task"], [3082, 3083, "Method"], [3133, 3136, "Material"], [3240, 3241, "Method"], [3391, 3392, "Method"], [3487, 3488, "Method"], [3529, 3530, "Method"], [3662, 3663, "Method"], [3675, 3676, "Method"], [3826, 3827, "Method"], [3876, 3877, "Method"], [3901, 3902, "Method"], [3954, 3955, "Method"], [3989, 3990, "Method"], [4039, 4040, "Method"], [4231, 4232, "Method"], [4295, 4296, "Method"], [4565, 4566, "Method"], [4660, 4661, "Method"], [4666, 4667, "Method"]], "sections": [[0, 331], [331, 899], [899, 1490], [1490, 1637], [1637, 1910], [1910, 1952], [1952, 2249], [2249, 2533], [2533, 2706], [2706, 2709], [2709, 2919], [2919, 3041], [3041, 3504], [3504, 3773], [3773, 4093], [4093, 4329], [4329, 4362], [4362, 4365], [4365, 4371], [4371, 4399], [4399, 4461], [4461, 4471], [4471, 4483], [4483, 4556], [4556, 4691]], "sentences": [[0, 15], [15, 41], [41, 74], [74, 89], [89, 118], [118, 144], [144, 165], [165, 184], [184, 210], [210, 240], [240, 262], [262, 296], [296, 331], [331, 334], [334, 368], [368, 382], [382, 412], [412, 430], [430, 447], [447, 468], [468, 481], [481, 507], [507, 526], [526, 545], [545, 569], [569, 583], [583, 584], [584, 600], [600, 618], [618, 636], [636, 644], [644, 673], [673, 702], [702, 734], [734, 747], [747, 758], [758, 787], [787, 807], [807, 835], [835, 847], [847, 872], [872, 899], [899, 907], [907, 926], [926, 965], [965, 1002], [1002, 1027], [1027, 1046], [1046, 1070], [1070, 1095], [1095, 1100], [1100, 1113], [1113, 1124], [1124, 1136], [1136, 1153], [1153, 1161], [1161, 1173], [1173, 1186], [1186, 1205], [1205, 1223], [1223, 1257], [1257, 1270], [1270, 1288], [1288, 1317], [1317, 1321], [1321, 1340], [1340, 1349], [1349, 1375], [1375, 1395], [1395, 1404], [1404, 1447], [1447, 1460], [1460, 1490], [1490, 1493], [1493, 1519], [1519, 1564], [1564, 1572], [1572, 1599], [1599, 1615], [1615, 1637], [1637, 1641], [1641, 1670], [1670, 1690], [1690, 1710], [1710, 1711], [1711, 1734], [1734, 1745], [1745, 1768], [1768, 1782], [1782, 1813], [1813, 1828], [1828, 1856], [1856, 1863], [1863, 1880], [1880, 1910], [1910, 1913], [1913, 1952], [1952, 1956], [1956, 1981], [1981, 1997], [1997, 2004], [2004, 2014], [2014, 2026], [2026, 2043], [2043, 2059], [2059, 2062], [2062, 2106], [2106, 2138], [2138, 2166], [2166, 2188], [2188, 2227], [2227, 2249], [2249, 2257], [2257, 2285], [2285, 2290], [2290, 2311], [2311, 2337], [2337, 2349], [2349, 2369], [2369, 2375], [2375, 2400], [2400, 2412], [2412, 2432], [2432, 2445], [2445, 2472], [2472, 2506], [2506, 2533], [2533, 2538], [2538, 2568], [2568, 2610], [2610, 2619], [2619, 2688], [2688, 2706], [2706, 2709], [2709, 2713], [2713, 2731], [2731, 2764], [2764, 2796], [2796, 2804], [2804, 2823], [2823, 2825], [2825, 2837], [2837, 2847], [2847, 2863], [2863, 2882], [2882, 2891], [2891, 2919], [2919, 2923], [2923, 2944], [2944, 2966], [2966, 2975], [2975, 3000], [3000, 3002], [3002, 3028], [3028, 3041], [3041, 3047], [3047, 3073], [3073, 3088], [3088, 3117], [3117, 3121], [3121, 3125], [3125, 3153], [3153, 3169], [3169, 3190], [3190, 3200], [3200, 3217], [3217, 3231], [3231, 3256], [3256, 3266], [3266, 3281], [3281, 3295], [3295, 3307], [3307, 3319], [3319, 3330], [3330, 3346], [3346, 3361], [3361, 3372], [3372, 3413], [3413, 3431], [3431, 3458], [3458, 3472], [3472, 3478], [3478, 3483], [3483, 3504], [3504, 3516], [3516, 3528], [3528, 3552], [3552, 3585], [3585, 3604], [3604, 3612], [3612, 3654], [3654, 3685], [3685, 3696], [3696, 3700], [3700, 3734], [3734, 3750], [3750, 3773], [3773, 3778], [3778, 3793], [3793, 3817], [3817, 3848], [3848, 3879], [3879, 3904], [3904, 3920], [3920, 3930], [3930, 3942], [3942, 3944], [3944, 3957], [3957, 3970], [3970, 4001], [4001, 4029], [4029, 4042], [4042, 4060], [4060, 4078], [4078, 4093], [4093, 4096], [4096, 4117], [4117, 4135], [4135, 4156], [4156, 4180], [4180, 4209], [4209, 4224], [4224, 4238], [4238, 4278], [4278, 4298], [4298, 4329], [4329, 4333], [4333, 4362], [4362, 4365], [4365, 4371], [4371, 4374], [4374, 4393], [4393, 4399], [4399, 4403], [4403, 4436], [4436, 4452], [4452, 4461], [4461, 4471], [4471, 4474], [4474, 4483], [4483, 4487], [4487, 4493], [4493, 4504], [4504, 4506], [4506, 4511], [4511, 4526], [4526, 4543], [4543, 4548], [4548, 4556], [4556, 4567], [4567, 4617], [4617, 4636], [4636, 4654], [4654, 4663], [4663, 4691]], "words": ["document", ":", "Fast", "and", "Accurate", "Deep", "Network", "Learning", "by", "Exponential", "Linear", "Units", "(", "ELUs", ")", "We", "introduce", "the", "\u201c", "exponential", "linear", "unit", "\u201d", "(", "ELU", ")", "which", "speeds", "up", "learning", "in", "deep", "neural", "networks", "and", "leads", "to", "higher", "classification", "accuracies", ".", "Like", "rectified", "linear", "units", "(", "ReLUs", ")", ",", "leaky", "ReLUs", "(", "LReLUs", ")", "and", "parametrized", "ReLUs", "(", "PReLUs", ")", ",", "ELUs", "alleviate", "the", "vanishing", "gradient", "problem", "via", "the", "identity", "for", "positive", "values", ".", "However", "ELUs", "have", "improved", "learning", "characteristics", "compared", "to", "the", "units", "with", "other", "activation", "functions", ".", "In", "contrast", "to", "ReLUs", ",", "ELUs", "have", "negative", "values", "which", "allows", "them", "to", "push", "mean", "unit", "activations", "closer", "to", "zero", "like", "batch", "normalization", "but", "with", "lower", "computational", "complexity", ".", "Mean", "shifts", "toward", "zero", "speed", "up", "learning", "by", "bringing", "the", "normal", "gradient", "closer", "to", "the", "unit", "natural", "gradient", "because", "of", "a", "reduced", "bias", "shift", "effect", ".", "While", "LReLUs", "and", "PReLUs", "have", "negative", "values", ",", "too", ",", "they", "do", "not", "ensure", "a", "noise", "-", "robust", "deactivation", "state", ".", "ELUs", "saturate", "to", "a", "negative", "value", "with", "smaller", "inputs", "and", "thereby", "decrease", "the", "forward", "propagated", "variation", "and", "information", ".", "Therefore", "ELUs", "code", "the", "degree", "of", "presence", "of", "particular", "phenomena", "in", "the", "input", ",", "while", "they", "do", "not", "quantitatively", "model", "the", "degree", "of", "their", "absence", ".", "In", "experiments", ",", "ELUs", "lead", "not", "only", "to", "faster", "learning", ",", "but", "also", "to", "significantly", "better", "generalization", "performance", "than", "ReLUs", "and", "LReLUs", "on", "networks", "with", "more", "than", "5", "layers", ".", "On", "CIFAR", "-", "100", "ELUs", "networks", "significantly", "outperform", "ReLU", "networks", "with", "batch", "normalization", "while", "batch", "normalization", "does", "not", "improve", "ELU", "networks", ".", "ELU", "networks", "are", "among", "the", "top", "10", "reported", "CIFAR", "-", "10", "results", "and", "yield", "the", "best", "published", "result", "on", "CIFAR", "-", "100", ",", "without", "resorting", "to", "multi", "-", "view", "evaluation", "or", "model", "averaging", ".", "On", "ImageNet", ",", "ELU", "networks", "considerably", "speed", "up", "learning", "compared", "to", "a", "ReLU", "network", "with", "the", "same", "architecture", ",", "obtaining", "less", "than", "10", "%", "classification", "error", "for", "a", "single", "crop", ",", "single", "model", "network", ".", "section", ":", "Introduction", "Currently", "the", "most", "popular", "activation", "function", "for", "neural", "networks", "is", "the", "rectified", "linear", "unit", "(", "ReLU", ")", ",", "which", "was", "first", "proposed", "for", "restricted", "Boltzmann", "machines", "and", "then", "successfully", "used", "for", "neural", "networks", ".", "The", "ReLU", "activation", "function", "is", "the", "identity", "for", "positive", "arguments", "and", "zero", "otherwise", ".", "Besides", "producing", "sparse", "codes", ",", "the", "main", "advantage", "of", "ReLUs", "is", "that", "they", "alleviate", "the", "vanishing", "gradient", "problem", "since", "the", "derivative", "of", "1", "for", "positive", "values", "is", "not", "contractive", ".", "However", "ReLUs", "are", "non", "-", "negative", "and", ",", "therefore", ",", "have", "a", "mean", "activation", "larger", "than", "zero", ".", "Units", "that", "have", "a", "non", "-", "zero", "mean", "activation", "act", "as", "bias", "for", "the", "next", "layer", ".", "If", "such", "units", "do", "not", "cancel", "each", "other", "out", ",", "learning", "causes", "a", "bias", "shift", "for", "units", "in", "next", "layer", ".", "The", "more", "the", "units", "are", "correlated", ",", "the", "higher", "their", "bias", "shift", ".", "We", "will", "see", "that", "Fisher", "optimal", "learning", ",", "i.e.", ",", "the", "natural", "gradient", ",", "would", "correct", "for", "the", "bias", "shift", "by", "adjusting", "the", "weight", "updates", ".", "Thus", ",", "less", "bias", "shift", "brings", "the", "standard", "gradient", "closer", "to", "the", "natural", "gradient", "and", "speeds", "up", "learning", ".", "We", "aim", "at", "activation", "functions", "that", "push", "activation", "means", "closer", "to", "zero", "to", "decrease", "the", "bias", "shift", "effect", ".", "Centering", "the", "activations", "at", "zero", "has", "been", "proposed", "in", "order", "to", "keep", "the", "off", "-", "diagonal", "entries", "of", "the", "Fisher", "information", "matrix", "small", ".", "For", "neural", "network", "it", "is", "known", "that", "centering", "the", "activations", "speeds", "up", "learning", ".", "\u201c", "Batch", "normalization", "\u201d", "also", "centers", "activations", "with", "the", "goal", "to", "counter", "the", "internal", "covariate", "shift", ".", "Also", "the", "Projected", "Natural", "Gradient", "Descent", "algorithm", "(", "PRONG", ")", "centers", "the", "activations", "by", "implicitly", "whitening", "them", ".", "An", "alternative", "to", "centering", "is", "to", "push", "the", "mean", "activation", "toward", "zero", "by", "an", "appropriate", "activation", "function", ".", "Therefore", "has", "been", "preferred", "over", "logistic", "functions", ".", "Recently", "\u201c", "Leaky", "ReLUs", "\u201d", "(", "LReLUs", ")", "that", "replace", "the", "negative", "part", "of", "the", "ReLU", "with", "a", "linear", "function", "have", "been", "shown", "to", "be", "superior", "to", "ReLUs", ".", "Parametric", "Rectified", "Linear", "Units", "(", "PReLUs", ")", "generalize", "LReLUs", "by", "learning", "the", "slope", "of", "the", "negative", "part", "which", "yielded", "improved", "learning", "behavior", "on", "large", "image", "benchmark", "data", "sets", ".", "Another", "variant", "are", "Randomized", "Leaky", "Rectified", "Linear", "Units", "(", "RReLUs", ")", "which", "randomly", "sample", "the", "slope", "of", "the", "negative", "part", "which", "raised", "the", "performance", "on", "image", "benchmark", "datasets", "and", "convolutional", "networks", ".", "In", "contrast", "to", "ReLUs", ",", "activation", "functions", "like", "LReLUs", ",", "PReLUs", ",", "and", "RReLUs", "do", "not", "ensure", "a", "noise", "-", "robust", "deactivation", "state", ".", "We", "propose", "an", "activation", "function", "that", "has", "negative", "values", "to", "allow", "for", "mean", "activations", "close", "to", "zero", ",", "but", "which", "saturates", "to", "a", "negative", "value", "with", "smaller", "arguments", ".", "The", "saturation", "decreases", "the", "variation", "of", "the", "units", "if", "deactivated", ",", "so", "the", "precise", "deactivation", "argument", "is", "less", "relevant", ".", "Such", "an", "activation", "function", "can", "code", "the", "degree", "of", "presence", "of", "particular", "phenomena", "in", "the", "input", ",", "but", "does", "not", "quantitatively", "model", "the", "degree", "of", "their", "absence", ".", "Therefore", ",", "such", "an", "activation", "function", "is", "more", "robust", "to", "noise", ".", "Consequently", ",", "dependencies", "between", "coding", "units", "are", "much", "easier", "to", "model", "and", "much", "easier", "to", "interpret", "since", "only", "activated", "code", "units", "carry", "much", "information", ".", "Furthermore", ",", "distinct", "concepts", "are", "much", "less", "likely", "to", "interfere", "with", "such", "activation", "functions", "since", "the", "deactivation", "state", "is", "non", "-", "informative", ",", "i.e.", "variance", "decreasing", ".", "section", ":", "Bias", "Shift", "Correction", "Speeds", "Up", "Learning", "To", "derive", "and", "analyze", "the", "bias", "shift", "effect", "mentioned", "in", "the", "introduction", ",", "we", "utilize", "the", "natural", "gradient", ".", "The", "natural", "gradient", "corrects", "the", "gradient", "direction", "with", "the", "inverse", "Fisher", "information", "matrix", "and", ",", "thereby", ",", "enables", "Fisher", "optimal", "learning", ",", "which", "ensures", "the", "steepest", "descent", "in", "the", "Riemannian", "parameter", "manifold", "and", "Fisher", "efficiency", "for", "online", "learning", ".", "The", "recently", "introduced", "Hessian", "-", "Free", "Optimization", "technique", "and", "the", "Krylov", "Subspace", "Descent", "methods", "use", "an", "extended", "Gauss", "-", "Newton", "approximation", "of", "the", "Hessian", ",", "therefore", "they", "can", "be", "interpreted", "as", "versions", "of", "natural", "gradient", "descent", ".", "Since", "for", "neural", "networks", "the", "Fisher", "information", "matrix", "is", "typically", "too", "expensive", "to", "compute", ",", "different", "approximations", "of", "the", "natural", "gradient", "have", "been", "proposed", ".", "Topmoumoute", "Online", "natural", "Gradient", "Algorithm", "(", "TONGA", ")", "uses", "a", "low", "-", "rank", "approximation", "of", "natural", "gradient", "descent", ".", "FActorized", "Natural", "Gradient", "(", "FANG", ")", "estimates", "the", "natural", "gradient", "via", "an", "approximation", "of", "the", "Fisher", "information", "matrix", "by", "a", "Gaussian", "graphical", "model", ".", "The", "Fisher", "information", "matrix", "can", "be", "approximated", "by", "a", "block", "-", "diagonal", "matrix", ",", "where", "unit", "or", "quasi", "-", "diagonal", "natural", "gradients", "are", "used", ".", "Unit", "natural", "gradients", "or", "\u201c", "Unitwise", "Fisher", "\u2019s", "scoring", "\u201d", "are", "based", "on", "natural", "gradients", "for", "perceptrons", ".", "We", "will", "base", "our", "analysis", "on", "the", "unit", "natural", "gradient", ".", "We", "assume", "a", "parameterized", "probabilistic", "model", "with", "parameter", "vector", "and", "data", ".", "The", "training", "data", "are", "with", ",", "where", "is", "the", "input", "for", "example", "and", "is", "its", "label", ".", "is", "the", "loss", "of", "example", "using", "model", ".", "The", "average", "loss", "on", "the", "training", "data", "is", "the", "empirical", "risk", ".", "Gradient", "descent", "updates", "the", "weight", "vector", "by", "where", "is", "the", "learning", "rate", ".", "The", "natural", "gradient", "is", "the", "inverse", "Fisher", "information", "matrix", "multiplied", "by", "the", "gradient", "of", "the", "empirical", "risk", ":", ".", "For", "a", "multi", "-", "layer", "perceptron", "is", "the", "unit", "activation", "vector", "and", "is", "the", "bias", "unit", "activation", ".", "We", "consider", "the", "ingoing", "weights", "to", "unit", ",", "therefore", "we", "drop", "the", "index", ":", "for", "the", "weight", "from", "unit", "to", "unit", ",", "for", "the", "activation", ",", "and", "for", "the", "bias", "weight", "of", "unit", ".", "The", "activation", "function", "maps", "the", "net", "input", "of", "unit", "to", "its", "activation", ".", "For", "computing", "the", "Fisher", "information", "matrix", ",", "the", "derivative", "of", "the", "log", "-", "output", "probability", "is", "required", ".", "Therefore", "we", "define", "the", "at", "unit", "as", ",", "which", "can", "be", "computed", "via", "backpropagation", ",", "but", "using", "the", "log", "-", "output", "probability", "instead", "of", "the", "conventional", "loss", "function", ".", "The", "derivative", "is", ".", "We", "restrict", "the", "Fisher", "information", "matrix", "to", "weights", "leading", "to", "unit", "which", "is", "the", "unit", "Fisher", "information", "matrix", ".", "captures", "only", "the", "interactions", "of", "weights", "to", "unit", ".", "Consequently", ",", "the", "unit", "natural", "gradient", "only", "corrects", "the", "interactions", "of", "weights", "to", "unit", ",", "i.e.", "considers", "the", "Riemannian", "parameter", "manifold", "only", "in", "a", "subspace", ".", "The", "unit", "Fisher", "information", "matrix", "is", "Weighting", "the", "activations", "by", "is", "equivalent", "to", "adjusting", "the", "probability", "of", "drawing", "inputs", ".", "Inputs", "with", "large", "are", "drawn", "with", "higher", "probability", ".", "Since", ",", "we", "can", "define", "a", "distribution", ":", "Using", ",", "the", "entries", "of", "can", "be", "expressed", "as", "second", "moments", ":", "If", "the", "bias", "unit", "is", "with", "weight", "then", "the", "weight", "vector", "can", "be", "divided", "into", "a", "bias", "part", "and", "the", "rest", ":", ".", "For", "the", "row", "that", "corresponds", "to", "the", "bias", "weight", ",", "we", "have", ":", "The", "next", "Theorem", "[", "reference", "]", "gives", "the", "correction", "of", "the", "standard", "gradient", "by", "the", "unit", "natural", "gradient", "where", "the", "bias", "weight", "is", "treated", "separately", "(", "see", "also", ")", ".", "theorem", ":", ".", "The", "unit", "natural", "gradient", "corrects", "the", "weight", "update", "(", "\u2062\u0394wT", ",", "\u2062\u0394w0", ")", "T", "to", "a", "unit", "i", "by", "following", "affine", "transformation", "of", "the", "gradient", "=", "\u2207", "(", "wT", ",", "w0", ")", "TRemp", "(", "gT", ",", "g0", ")", "T", ":", "where", "A=", "[", "\u2062F", "(", "w", ")]", "\u2062\u00ac0", ",", "\u2062\u00ac0=\u2062E\u2062p", "(", "z", ")(", "\u03b42", ")", "E\u2062q", "(", "z", ")(", "\u2062aaT", ")", "is", "the", "unit", "Fisher", "information", "matrix", "without", "row", "0", "and", "column", "0", "corresponding", "to", "the", "bias", "weight", ".", "The", "vector", "=", "b", "[", "\u2062F", "(", "w", ")]", "0", "is", "the", "zeroth", "column", "of", "F", "corresponding", "to", "the", "bias", "weight", ",", "and", "the", "positive", "scalar", "s", "is", "where", "a", "is", "the", "vector", "of", "activations", "of", "units", "with", "weights", "to", "unit", "i", "and", "=", "\u2062q", "(", "z", ")", "\u2062\u03b42", "(", "z", ")", "p", "(", "z", ")", "E\u2062p", "(", "z", ")-", "1", "(", "\u03b42", ")", ".", "proof", ":", "Proof", ".", "Multiplying", "the", "inverse", "Fisher", "matrix", "with", "the", "separated", "gradient", "gives", "the", "weight", "update", ":", "where", "The", "previous", "formula", "is", "derived", "in", "Lemma", "[", "reference", "]", "in", "the", "appendix", ".", "Using", "in", "the", "update", "gives", "The", "right", "hand", "side", "is", "obtained", "by", "inserting", "in", "the", "left", "hand", "side", "update", ".", "Since", ",", ",", "and", ",", "we", "obtain", "Applying", "Lemma", "[", "reference", "]", "in", "the", "appendix", "gives", "the", "formula", "for", ".", "\u220e", "The", "bias", "shift", "(", "mean", "shift", ")", "of", "unit", "is", "the", "change", "of", "unit", "\u2019s", "mean", "value", "due", "to", "the", "weight", "update", ".", "Bias", "shifts", "of", "unit", "lead", "to", "oscillations", "and", "impede", "learning", ".", "See", "Section", "4.4", "in", "for", "demonstrating", "this", "effect", "at", "the", "inputs", "and", "in", "for", "explaining", "this", "effect", "using", "the", "input", "covariance", "matrix", ".", "Such", "bias", "shifts", "are", "mitigated", "or", "even", "prevented", "by", "the", "unit", "natural", "gradient", ".", "The", "bias", "shift", "correction", "of", "the", "unit", "natural", "gradient", "is", "the", "effect", "on", "the", "bias", "shift", "due", "to", "which", "captures", "the", "interaction", "between", "the", "bias", "unit", "and", "the", "incoming", "units", ".", "Without", "bias", "shift", "correction", ",", "i.e.", ",", "and", ",", "the", "weight", "updates", "are", "and", ".", "As", "only", "the", "activations", "depend", "on", "the", "input", ",", "the", "bias", "shift", "can", "be", "computed", "by", "multiplying", "the", "weight", "update", "by", "the", "mean", "of", "the", "activation", "vector", ".", "Thus", "we", "obtain", "the", "bias", "shift", ".", "The", "bias", "shift", "strongly", "depends", "on", "the", "correlation", "of", "the", "incoming", "units", "which", "is", "captured", "by", ".", "Next", ",", "Theorem", "[", "reference", "]", "states", "that", "the", "bias", "shift", "correction", "by", "the", "unit", "natural", "gradient", "can", "be", "considered", "to", "correct", "the", "incoming", "mean", "proportional", "to", "toward", "zero", ".", "theorem", ":", ".", "The", "bias", "shift", "correction", "by", "the", "unit", "natural", "gradient", "is", "equivalent", "to", "an", "additive", "correction", "of", "the", "incoming", "mean", "by", "-", "\u2062kE\u2062q", "(", "z", ")(", "a", ")", "and", "a", "multiplicative", "correction", "of", "the", "bias", "unit", "by", "k", ",", "where", "proof", ":", "Proof", ".", "Using", ",", "the", "bias", "shift", "is", ":", "The", "mean", "correction", "term", ",", "indicated", "by", "an", "underbrace", "in", "previous", "formula", ",", "is", "The", "expression", "Eq", ".", "(", "[", "reference", "]", ")", "for", "follows", "from", "Lemma", "[", "reference", "]", "in", "the", "appendix", ".", "The", "bias", "unit", "correction", "term", "is", ".", "\u220e", "In", "Theorem", "[", "reference", "]", "we", "can", "reformulate", ".", "Therefore", "increases", "with", "the", "length", "of", "for", "given", "variances", "and", "covariances", ".", "Consequently", "the", "bias", "shift", "correction", "through", "the", "unit", "natural", "gradient", "is", "governed", "by", "the", "length", "of", ".", "The", "bias", "shift", "correction", "is", "zero", "for", "since", "does", "not", "correct", "the", "bias", "unit", "multiplicatively", ".", "Using", "Eq", ".", "(", "[", "reference", "]", ")", ",", "is", "split", "into", "an", "offset", "and", "an", "information", "containing", "term", ":", "In", "general", ",", "smaller", "positive", "\u2062E\u2062p", "(", "z", ")(", "a", ")", "lead", "to", "smaller", "positive", "\u2062E\u2062q", "(", "z", ")(", "a", ")", ",", "therefore", "to", "smaller", "corrections", ".", "The", "reason", "is", "that", "in", "general", "the", "largest", "absolute", "components", "of", "are", "positive", ",", "since", "activated", "inputs", "will", "activate", "the", "unit", "which", "in", "turn", "will", "have", "large", "impact", "on", "the", "output", ".", "To", "summarize", ",", "the", "unit", "natural", "gradient", "corrects", "the", "bias", "shift", "of", "unit", "via", "the", "interactions", "of", "incoming", "units", "with", "the", "bias", "unit", "to", "ensure", "efficient", "learning", ".", "This", "correction", "is", "equivalent", "to", "shifting", "the", "mean", "activations", "of", "the", "incoming", "units", "toward", "zero", "and", "scaling", "up", "the", "bias", "unit", ".", "To", "reduce", "the", "undesired", "bias", "shift", "effect", "without", "the", "natural", "gradient", ",", "either", "the", "(", "i", ")", "activation", "of", "incoming", "units", "can", "be", "centered", "at", "zero", "or", "(", "ii", ")", "activation", "functions", "with", "negative", "values", "can", "be", "used", ".", "We", "introduce", "a", "new", "activation", "function", "with", "negative", "values", "while", "keeping", "the", "identity", "for", "positive", "arguments", "where", "it", "is", "not", "contradicting", ".", "section", ":", "Exponential", "Linear", "Units", "(", "ELUs", ")", "The", "exponential", "linear", "unit", "(", "ELU", ")", "with", "is", "The", "ELU", "hyperparameter", "controls", "the", "value", "to", "which", "an", "ELU", "saturates", "for", "negative", "net", "inputs", "(", "see", "Fig", ".", "[", "reference", "]", ")", ".", "ELUs", "diminish", "the", "vanishing", "gradient", "effect", "as", "rectified", "linear", "units", "(", "ReLUs", ")", "and", "leaky", "ReLUs", "(", "LReLUs", ")", "do", ".", "The", "vanishing", "gradient", "problem", "is", "alleviated", "because", "the", "positive", "part", "of", "these", "functions", "is", "the", "identity", ",", "therefore", "their", "derivative", "is", "one", "and", "not", "contractive", ".", "In", "contrast", ",", "and", "sigmoid", "activation", "functions", "are", "contractive", "almost", "everywhere", ".", "In", "contrast", "to", "ReLUs", ",", "ELUs", "have", "negative", "values", "which", "pushes", "the", "mean", "of", "the", "activations", "closer", "to", "zero", ".", "Mean", "activations", "that", "are", "closer", "to", "zero", "enable", "faster", "learning", "as", "they", "bring", "the", "gradient", "closer", "to", "the", "natural", "gradient", "(", "see", "Theorem", "[", "reference", "]", "and", "text", "thereafter", ")", ".", "ELUs", "saturate", "to", "a", "negative", "value", "when", "the", "argument", "gets", "smaller", ".", "Saturation", "means", "a", "small", "derivative", "which", "decreases", "the", "variation", "and", "the", "information", "that", "is", "propagated", "to", "the", "next", "layer", ".", "Therefore", "the", "representation", "is", "both", "noise", "-", "robust", "and", "low", "-", "complex", ".", "ELUs", "code", "the", "degree", "of", "presence", "of", "input", "concepts", ",", "while", "they", "neither", "quantify", "the", "degree", "of", "their", "absence", "nor", "distinguish", "the", "causes", "of", "their", "absence", ".", "This", "property", "of", "non", "-", "informative", "deactivation", "states", "is", "also", "present", "at", "ReLUs", "and", "allowed", "to", "detect", "biclusters", "corresponding", "to", "biological", "modules", "in", "gene", "expression", "datasets", "and", "to", "identify", "toxicophores", "in", "toxicity", "prediction", ".", "The", "enabling", "features", "for", "these", "interpretations", "is", "that", "activation", "can", "be", "clearly", "distinguished", "from", "deactivation", "and", "that", "only", "active", "units", "carry", "relevant", "information", "and", "can", "crosstalk", ".", "section", ":", "Experiments", "Using", "ELUs", "In", "this", "section", ",", "we", "assess", "the", "performance", "of", "exponential", "linear", "units", "(", "ELUs", ")", "if", "used", "for", "unsupervised", "and", "supervised", "learning", "of", "deep", "autoencoders", "and", "deep", "convolutional", "networks", ".", "ELUs", "with", "are", "compared", "to", "(", "i", ")", "Rectified", "Linear", "Units", "(", "ReLUs", ")", "with", "activation", ",", "(", "ii", ")", "Leaky", "ReLUs", "(", "LReLUs", ")", "with", "activation", "(", ")", ",", "and", "(", "iii", ")", "Shifted", "ReLUs", "(", "SReLUs", ")", "with", "activation", ".", "Comparisons", "are", "done", "with", "and", "without", "batch", "normalization", ".", "The", "following", "benchmark", "datasets", "are", "used", ":", "(", "i", ")", "MNIST", "(", "gray", "images", "in", "10", "classes", ",", "60k", "train", "and", "10k", "test", ")", ",", "(", "ii", ")", "CIFAR", "-", "10", "(", "color", "images", "in", "10", "classes", ",", "50k", "train", "and", "10k", "test", ")", ",", "(", "iii", ")", "CIFAR", "-", "100", "(", "color", "images", "in", "100", "classes", ",", "50k", "train", "and", "10k", "test", ")", ",", "and", "(", "iv", ")", "ImageNet", "(", "color", "images", "in", "1", ",", "000", "classes", ",", "1.3", "M", "train", "and", "100k", "tests", ")", ".", "subsection", ":", "MNIST", "subsubsection", ":", "Learning", "Behavior", "We", "first", "want", "to", "verify", "that", "ELUs", "keep", "the", "mean", "activations", "closer", "to", "zero", "than", "other", "units", ".", "Fully", "connected", "deep", "neural", "networks", "with", "ELUs", "(", ")", ",", "ReLUs", ",", "and", "LReLUs", "(", ")", "were", "trained", "on", "the", "MNIST", "digit", "classification", "dataset", "while", "each", "hidden", "unit", "\u2019s", "activation", "was", "tracked", ".", "Each", "network", "had", "eight", "hidden", "layers", "of", "128", "units", "each", ",", "and", "was", "trained", "for", "300", "epochs", "by", "stochastic", "gradient", "descent", "with", "learning", "rate", "and", "mini", "-", "batches", "of", "size", "64", ".", "The", "weights", "have", "been", "initialized", "according", "to", ".", "After", "each", "epoch", "we", "calculated", "the", "units", "\u2019", "average", "activations", "on", "a", "fixed", "subset", "of", "the", "training", "data", ".", "Fig", ".", "[", "reference", "]", "shows", "the", "median", "over", "all", "units", "along", "learning", ".", "ELUs", "stay", "have", "smaller", "median", "throughout", "the", "training", "process", ".", "The", "training", "error", "of", "ELU", "networks", "decreases", "much", "more", "rapidly", "than", "for", "the", "other", "networks", ".", "Section", "[", "reference", "]", "in", "the", "appendix", "compares", "the", "variance", "of", "median", "activation", "in", "ReLU", "and", "ELU", "networks", ".", "The", "median", "varies", "much", "more", "in", "ReLU", "networks", ".", "This", "indicates", "that", "ReLU", "networks", "continuously", "try", "to", "correct", "the", "bias", "shift", "introduced", "by", "previous", "weight", "updates", "while", "this", "effect", "is", "much", "less", "prominent", "in", "ELU", "networks", ".", "subsubsection", ":", "Autoencoder", "Learning", "To", "evaluate", "ELU", "networks", "at", "unsupervised", "settings", ",", "we", "followed", "and", "and", "trained", "a", "deep", "autoencoder", "on", "the", "MNIST", "dataset", ".", "The", "encoder", "part", "consisted", "of", "four", "fully", "connected", "hidden", "layers", "with", "sizes", "1000", ",", "500", ",", "250", "and", "30", ",", "respectively", ".", "The", "decoder", "part", "was", "symmetrical", "to", "the", "encoder", ".", "For", "learning", "we", "applied", "stochastic", "gradient", "descent", "with", "mini", "-", "batches", "of", "64", "samples", "for", "500", "epochs", "using", "the", "fixed", "learning", "rates", "(", ")", ".", "Fig", ".", "[", "reference", "]", "shows", ",", "that", "ELUs", "outperform", "the", "competing", "activation", "functions", "in", "terms", "of", "training", "/", "test", "set", "reconstruction", "error", "for", "all", "learning", "rates", ".", "As", "already", "noted", "by", ",", "higher", "learning", "rates", "seem", "to", "perform", "better", ".", "subsection", ":", "Comparison", "of", "Activation", "Functions", "In", "this", "subsection", "we", "show", "that", "ELUs", "indeed", "possess", "a", "superior", "learning", "behavior", "compared", "to", "other", "activation", "functions", "as", "postulated", "in", "Section", "[", "reference", "]", ".", "Furthermore", "we", "show", "that", "ELU", "networks", "perform", "better", "than", "ReLU", "networks", "with", "batch", "normalization", ".", "We", "use", "as", "benchmark", "dataset", "CIFAR", "-", "100", "and", "use", "a", "relatively", "simple", "convolutional", "neural", "network", "(", "CNN", ")", "architecture", "to", "keep", "the", "computational", "complexity", "reasonable", "for", "comparisons", ".", "[", "-", "2.0ex", "]", "[", "-", "2.0ex", "]", "[", "-", "2.0ex", "]", "The", "CNN", "for", "these", "CIFAR", "-", "100", "experiments", "consists", "of", "11", "convolutional", "layers", "arranged", "in", "stacks", "of", "(", ")", "layers", "units", "receptive", "fields", ".", "2", "2", "max", "-", "pooling", "with", "a", "stride", "of", "2", "was", "applied", "after", "each", "stack", ".", "For", "network", "regularization", "we", "used", "the", "following", "drop", "-", "out", "rate", "for", "the", "last", "layer", "of", "each", "stack", "(", ")", ".", "The", "-", "weight", "decay", "regularization", "term", "was", "set", "to", ".", "The", "following", "learning", "rate", "schedule", "was", "applied", "(", ")", "(", "iterations", "[", "learning", "rate", "]", ")", ".", "For", "fair", "comparisons", ",", "we", "used", "this", "learning", "rate", "schedule", "for", "all", "networks", ".", "During", "previous", "experiments", ",", "this", "schedule", "was", "optimized", "for", "ReLU", "networks", ",", "however", "as", "ELUs", "converge", "faster", "they", "would", "benefit", "from", "an", "adjusted", "schedule", ".", "The", "momentum", "term", "learning", "rate", "was", "fixed", "to", "0.9", ".", "The", "dataset", "was", "preprocessed", "as", "described", "in", "with", "global", "contrast", "normalization", "and", "ZCA", "whitening", ".", "Additionally", ",", "the", "images", "were", "padded", "with", "four", "zero", "pixels", "at", "all", "borders", ".", "The", "model", "was", "trained", "on", "random", "crops", "with", "random", "horizontal", "flipping", ".", "Besides", "that", ",", "we", "no", "further", "augmented", "the", "dataset", "during", "training", ".", "Each", "network", "was", "run", "10", "times", "with", "different", "weight", "initialization", ".", "Across", "networks", "with", "different", "activation", "functions", "the", "same", "run", "number", "had", "the", "same", "initial", "weights", ".", "Mean", "test", "error", "results", "of", "networks", "with", "different", "activation", "functions", "are", "compared", "in", "Fig", ".", "[", "reference", "]", ",", "which", "also", "shows", "the", "standard", "deviation", ".", "ELUs", "yield", "on", "average", "a", "test", "error", "of", "28.75", "(", "0.24", ")", "%", ",", "while", "SReLUs", ",", "ReLUs", "and", "LReLUs", "yield", "29.35", "(", "0.29", ")", "%", ",", "31.56", "(", "0.37", ")", "%", "and", "30.59", "(", "0.29", ")", "%", ",", "respectively", ".", "ELUs", "achieve", "both", "lower", "training", "loss", "and", "lower", "test", "error", "than", "ReLUs", ",", "LReLUs", ",", "and", "SReLUs", ".", "Both", "the", "ELU", "training", "and", "test", "performance", "is", "significantly", "better", "than", "for", "other", "activation", "functions", "(", "Wilcoxon", "signed", "-", "rank", "test", "with", "-", "value", "0.001", ")", ".", "Batch", "normalization", "improved", "ReLU", "and", "LReLU", "networks", ",", "but", "did", "not", "improve", "ELU", "and", "SReLU", "networks", "(", "see", "Fig", ".", "[", "reference", "]", ")", ".", "ELU", "networks", "significantly", "outperform", "ReLU", "networks", "with", "batch", "normalization", "(", "Wilcoxon", "signed", "-", "rank", "test", "with", "-", "value", "0.001", ")", ".", "subsection", ":", "Classification", "Performance", "on", "CIFAR", "-", "100", "and", "CIFAR", "-", "10", "The", "following", "experiments", "should", "highlight", "the", "generalization", "capabilities", "of", "ELU", "networks", ".", "The", "CNN", "architecture", "is", "more", "sophisticated", "than", "in", "the", "previous", "subsection", "and", "consists", "of", "18", "convolutional", "layers", "arranged", "in", "stacks", "of", "(", ")", ".", "Initial", "drop", "-", "out", "rate", ",", "Max", "-", "pooling", "after", "each", "stack", ",", "-", "weight", "decay", ",", "momentum", "term", ",", "data", "preprocessing", ",", "padding", ",", "and", "cropping", "were", "as", "in", "previous", "section", ".", "The", "initial", "learning", "rate", "was", "set", "to", "0.01", "and", "decreased", "by", "a", "factor", "of", "10", "after", "35k", "iterations", ".", "The", "mini", "-", "batch", "size", "was", "100", ".", "For", "the", "final", "50k", "iterations", "fine", "-", "tuning", "we", "increased", "the", "drop", "-", "out", "rate", "for", "all", "layers", "in", "a", "stack", "to", "(", ")", ",", "thereafter", "increased", "the", "drop", "-", "out", "rate", "by", "a", "factor", "of", "1.5", "for", "40k", "additional", "iterations", ".", "ELU", "networks", "are", "compared", "to", "following", "recent", "successful", "CNN", "architectures", ":", "AlexNet", ",", "DSN", ",", "NiN", ",", "Maxout", ",", "All", "-", "CNN", ",", "Highway", "Network", "and", "Fractional", "Max", "-", "Pooling", ".", "The", "test", "error", "in", "percent", "misclassification", "are", "given", "in", "Tab", ".", "[", "reference", "]", ".", "ELU", "-", "networks", "are", "the", "second", "best", "on", "CIFAR", "-", "10", "with", "a", "test", "error", "of", "6.55", "%", "but", "still", "they", "are", "among", "the", "top", "10", "best", "results", "reported", "for", "CIFAR", "-", "10", ".", "ELU", "networks", "performed", "best", "on", "CIFAR", "-", "100", "with", "a", "test", "error", "of", "24.28", "%", ".", "This", "is", "the", "best", "published", "result", "on", "CIFAR", "-", "100", ",", "without", "even", "resorting", "to", "multi", "-", "view", "evaluation", "or", "model", "averaging", ".", "subsection", ":", "ImageNet", "Challenge", "Dataset", "Finally", ",", "we", "evaluated", "ELU", "-", "networks", "on", "the", "1000", "-", "class", "ImageNet", "dataset", ".", "It", "contains", "about", "1.3", "M", "training", "color", "images", "as", "well", "as", "additional", "50k", "images", "and", "100k", "images", "for", "validation", "and", "testing", ",", "respectively", ".", "For", "this", "task", ",", "we", "designed", "a", "15", "layer", "CNN", ",", "which", "was", "arranged", "in", "stacks", "of", "(", ")", "layers", "units", "receptive", "fields", "or", "fully", "-", "connected", "(", "FC", ")", ".", "2", "2", "max", "-", "pooling", "with", "a", "stride", "of", "2", "was", "applied", "after", "each", "stack", "and", "spatial", "pyramid", "pooling", "(", "SPP", ")", "with", "3", "levels", "before", "the", "first", "FC", "layer", ".", "For", "network", "regularization", "we", "set", "the", "-", "weight", "decay", "term", "to", "and", "used", "50", "%", "drop", "-", "out", "in", "the", "two", "penultimate", "FC", "layers", ".", "Images", "were", "re", "-", "sized", "to", "256", "256", "pixels", "and", "per", "-", "pixel", "mean", "subtracted", ".", "Trained", "was", "on", "random", "crops", "with", "random", "horizontal", "flipping", ".", "Besides", "that", ",", "we", "did", "not", "augment", "the", "dataset", "during", "training", ".", "Fig", ".", "[", "reference", "]", "shows", "the", "learning", "behavior", "of", "ELU", "vs.", "ReLU", "networks", ".", "Panel", "(", "b", ")", "shows", "that", "ELUs", "start", "reducing", "the", "error", "earlier", ".", "The", "ELU", "-", "network", "already", "reaches", "the", "20", "%", "top", "-", "5", "error", "after", "160k", "iterations", ",", "while", "the", "ReLU", "network", "needs", "200k", "iterations", "to", "reach", "the", "same", "error", "rate", ".", "The", "single", "-", "model", "performance", "was", "evaluated", "on", "the", "single", "center", "crop", "with", "no", "further", "augmentation", "and", "yielded", "a", "top", "-", "5", "validation", "error", "below", "10", "%", ".", "Currently", "ELU", "nets", "are", "5", "%", "slower", "on", "ImageNet", "than", "ReLU", "nets", ".", "The", "difference", "is", "small", "because", "activation", "functions", "generally", "have", "only", "minor", "influence", "on", "the", "overall", "training", "time", ".", "In", "terms", "of", "wall", "clock", "time", ",", "ELUs", "require", "12.15h", "vs.", "ReLUs", "with", "11.48h", "for", "10k", "iterations", ".", "We", "expect", "that", "ELU", "implementations", "can", "be", "improved", ",", "e.g.", "by", "faster", "exponential", "functions", ".", "section", ":", "Conclusion", "We", "have", "introduced", "the", "exponential", "linear", "units", "(", "ELUs", ")", "for", "faster", "and", "more", "precise", "learning", "in", "deep", "neural", "networks", ".", "ELUs", "have", "negative", "values", ",", "which", "allows", "the", "network", "to", "push", "the", "mean", "activations", "closer", "to", "zero", ".", "Therefore", "ELUs", "decrease", "the", "gap", "between", "the", "normal", "gradient", "and", "the", "unit", "natural", "gradient", "and", ",", "thereby", "speed", "up", "learning", ".", "We", "believe", "that", "this", "property", "is", "also", "the", "reason", "for", "the", "success", "of", "activation", "functions", "like", "LReLUs", "and", "PReLUs", "and", "of", "batch", "normalization", ".", "In", "contrast", "to", "LReLUs", "and", "PReLUs", ",", "ELUs", "have", "a", "clear", "saturation", "plateau", "in", "its", "negative", "regime", ",", "allowing", "them", "to", "learn", "a", "more", "robust", "and", "stable", "representation", ".", "Experimental", "results", "show", "that", "ELUs", "significantly", "outperform", "other", "activation", "functions", "on", "different", "vision", "datasets", ".", "Further", "ELU", "networks", "perform", "significantly", "better", "than", "ReLU", "networks", "trained", "with", "batch", "normalization", ".", "ELU", "networks", "achieved", "one", "of", "the", "top", "10", "best", "reported", "results", "on", "CIFAR", "-", "10", "and", "set", "a", "new", "state", "of", "the", "art", "in", "CIFAR", "-", "100", "without", "the", "need", "for", "multi", "-", "view", "test", "evaluation", "or", "model", "averaging", ".", "Furthermore", ",", "ELU", "networks", "produced", "competitive", "results", "on", "the", "ImageNet", "in", "much", "fewer", "epochs", "than", "a", "corresponding", "ReLU", "network", ".", "Given", "their", "outstanding", "performance", ",", "we", "expect", "ELU", "networks", "to", "become", "a", "real", "time", "saver", "in", "convolutional", "networks", ",", "which", "are", "notably", "time", "-", "intensive", "to", "train", "from", "scratch", "otherwise", ".", "paragraph", ":", "Acknowledgment", ".", "We", "thank", "the", "NVIDIA", "Corporation", "for", "supporting", "this", "research", "with", "several", "Titan", "X", "GPUs", "and", "Roland", "Vollgraf", "and", "Martin", "Heusel", "for", "helpful", "discussions", "and", "comments", "on", "this", "work", ".", "bibliography", ":", "References", "appendix", ":", "Inverse", "of", "Block", "Matrices", "theorem", ":", ".", "The", "positive", "definite", "matrix", "M", "is", "in", "block", "format", "with", "matrix", "A", ",", "vector", "b", ",", "and", "scalar", "c.", "The", "inverse", "of", "M", "is", "where", "proof", ":", "Proof", ".", "For", "block", "matrices", "the", "inverse", "is", "where", "the", "matrices", "on", "the", "right", "hand", "side", "are", ":", "Further", "if", "follows", "that", "We", "now", "use", "this", "formula", "for", "being", "a", "vector", "and", "a", "scalar", ".", "We", "obtain", "where", "the", "right", "hand", "side", "matrices", ",", "vectors", ",", "and", "the", "scalar", "are", ":", "Again", "it", "follows", "that", "A", "reformulation", "using", "gives", "\u220e", "appendix", ":", "Quadratic", "Form", "of", "Mean", "and", "Inverse", "Second", "Moment", "theorem", ":", ".", "For", "a", "random", "variable", "a", "holds", "and", "Furthermore", "holds", "proof", ":", "Proof", ".", "The", "Sherman", "-", "Morrison", "Theorem", "states", "Therefore", "we", "have", "Using", "the", "identity", "for", "the", "second", "moment", "and", "Eq", ".", "(", "[", "reference", "]", ")", ",", "we", "get", "The", "last", "inequality", "follows", "from", "the", "fact", "that", "is", "positive", "definite", ".", "From", "last", "equation", ",", "we", "obtain", "further", "For", "the", "mixed", "quadratic", "form", "we", "get", "from", "Eq", ".", "(", "[", "reference", "]", ")", "From", "this", "equation", "follows", "Therefore", "we", "get", "\u220e", "appendix", ":", "Variance", "of", "Mean", "Activations", "in", "ELU", "and", "ReLU", "Networks", "To", "compare", "the", "variance", "of", "median", "activation", "in", "ReLU", "and", "ELU", "networks", ",", "we", "trained", "a", "neural", "network", "with", "5", "hidden", "layers", "of", "256", "hidden", "units", "for", "200", "epochs", "using", "a", "learning", "rate", "of", "0.01", ",", "once", "using", "ReLU", "and", "once", "using", "ELU", "activation", "functions", "on", "the", "MNIST", "dataset", ".", "After", "each", "epoch", ",", "we", "calculated", "the", "median", "activation", "of", "each", "hidden", "unit", "on", "the", "whole", "training", "set", ".", "We", "then", "calculated", "the", "variance", "of", "these", "changes", ",", "which", "is", "depicted", "in", "Figure", "[", "reference", "]", ".", "The", "median", "varies", "much", "more", "in", "ReLU", "networks", ".", "This", "indicates", "that", "ReLU", "networks", "continuously", "try", "to", "correct", "the", "bias", "shift", "introduced", "by", "previous", "weight", "updates", "while", "this", "effect", "is", "much", "less", "prominent", "in", "ELU", "networks", "."]}