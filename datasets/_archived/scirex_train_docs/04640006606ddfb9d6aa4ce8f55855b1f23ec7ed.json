{"coref": {"CIFAR-10": [[184, 185], [375, 376], [2638, 2641], [2653, 2656], [2850, 2851], [2865, 2866], [2989, 2992], [3495, 3498], [3598, 3601], [3989, 3990], [4019, 4022], [4109, 4112], [4630, 4631], [5104, 5107], [5143, 5144], [2657, 2658], [3767, 3768], [4856, 4857], [4956, 4957]], "CIFAR-100": [[184, 185], [375, 376], [2642, 2645], [2850, 2851], [2865, 2866], [3499, 3502], [3605, 3608], [3787, 3790], [3989, 3990], [4023, 4026], [4082, 4085], [4630, 4631], [5108, 5111], [5143, 5144], [2657, 2658], [3767, 3768], [4856, 4857], [4956, 4957]], "Image_Classification": [[370, 372], [4515, 4518]], "Percentage_correct": [], "Percentage_error": [[1337, 1338], [4080, 4081], [4144, 4146], [4017, 4018]], "SVHN": [[186, 187], [1339, 1340], [2646, 2647], [2725, 2726], [2730, 2737], [2758, 2759], [3993, 3994], [4215, 4216], [4322, 4323], [4335, 4336], [5112, 5113], [4978, 4979]], "Wide_ResNet": [[2, 5], [114, 117], [118, 119], [146, 154], [1000, 1005], [1081, 1084], [1299, 1302], [1324, 1332], [1450, 1453], [2382, 2389], [2390, 2395], [2454, 2456], [2490, 2495], [2507, 2513], [2918, 2921], [2996, 3001], [3029, 3035], [3036, 3042], [3137, 3138], [3197, 3200], [3310, 3313], [3436, 3441], [3445, 3450], [3466, 3469], [3476, 3479], [3543, 3548], [3574, 3580], [3718, 3723], [3730, 3734], [3791, 3794], [3883, 3885], [3903, 3905], [4046, 4049], [4103, 4108], [4314, 4319], [4562, 4569], [4691, 4696], [4804, 4806], [4875, 4881], [5082, 5086], [5128, 5130], [5184, 5187], [4290, 4292], [4375, 4377], [4584, 4591], [4858, 4861]]}, "coref_non_salient": {"0": [[390, 392], [2369, 2370], [4739, 4742]], "1": [[1010, 1016], [1379, 1381]], "10": [[2871, 2875], [4040, 4044]], "100": [[166, 172]], "101": [[2336, 2338]], "102": [[2346, 2348]], "103": [[4057, 4058]], "104": [[2113, 2119]], "11": [[574, 576], [1361, 1364]], "12": [[55, 58], [840, 843], [2616, 2622]], "13": [[577, 579], [1123, 1125], [1382, 1384], [2907, 2910], [86, 88], [701, 703], [944, 946], [2295, 2297]], "14": [[258, 259], [2371, 2372], [2417, 2419]], "15": [[2552, 2554], [2685, 2687], [2719, 2721]], "16": [[4828, 4833]], "17": [[1254, 1258], [5069, 5073]], "18": [[4137, 4140], [4159, 4162], [4930, 4932]], "19": [[1106, 1108], [3929, 3931], [4293, 4299], [4301, 4307]], "2": [[1578, 1583], [1584, 1589]], "20": [[932, 933], [1246, 1248], [2962, 2963]], "21": [[5027, 5029]], "22": [[2303, 2305], [4767, 4769]], "23": [[4091, 4093], [4230, 4232]], "24": [[1525, 1528], [1547, 1552]], "25": [[5149, 5152]], "26": [[4570, 4573], [4735, 4738]], "27": [[1022, 1028], [5137, 5142]], "28": [[2593, 2595]], "29": [[1846, 1847], [1848, 1849], [1850, 1851]], "3": [[1515, 1517], [1537, 1538], [2968, 2969], [3139, 3140], [3154, 3155], [3203, 3204], [3971, 3972]], "30": [[3485, 3488], [3582, 3585], [3710, 3713], [3749, 3752], [3813, 3816], [4868, 4872], [4889, 4892], [3631, 3634]], "31": [[4918, 4919]], "32": [[2854, 2856]], "33": [[4775, 4777]], "34": [[4699, 4704]], "35": [[4821, 4823]], "36": [[2235, 2237]], "37": [[4227, 4228]], "38": [[2794, 2795], [4508, 4510]], "39": [[5009, 5010]], "4": [[5, 8], [48, 51], [161, 164], [922, 925], [975, 978], [1056, 1059], [1403, 1406], [2608, 2611], [3564, 3567], [4769, 4774]], "40": [[1293, 1295], [1693, 1695], [1700, 1702], [1973, 1975], [2044, 2046], [2071, 2076], [3224, 3226]], "41": [[4679, 4683]], "42": [[4142, 4143], [4260, 4261], [4926, 4927]], "43": [[3258, 3259]], "44": [[1225, 1229]], "45": [[4171, 4173]], "46": [[4603, 4609]], "47": [[756, 758], [1456, 1458]], "48": [[4131, 4134]], "49": [[35, 36], [156, 157], [1019, 1020], [1213, 1214], [1441, 1442], [3048, 3050], [3086, 3087], [3431, 3432], [3443, 3444], [3492, 3493], [3780, 3781], [4101, 4102], [4184, 4185], [4462, 4463], [4645, 4646], [4887, 4888]], "5": [[2327, 2328], [4782, 4784]], "50": [[1425, 1427], [2839, 2841]], "51": [[4920, 4922]], "52": [[4387, 4388]], "53": [[2590, 2591]], "54": [[5023, 5024]], "55": [[105, 107], [262, 264], [344, 346], [438, 440], [484, 486], [616, 618], [623, 625], [668, 670], [773, 775], [961, 963], [1387, 1389], [1445, 1447], [1492, 1494], [1502, 1504], [1814, 1816], [2353, 2355], [2362, 2364], [2425, 2427], [2459, 2461], [2536, 2538], [3840, 3842], [3880, 3882], [4657, 4659], [5060, 5062], [5166, 5168]], "56": [[2815, 2818]], "57": [[2516, 2520]], "58": [[377, 381]], "59": [[1854, 1856]], "6": [[277, 279], [293, 296], [316, 319], [424, 426], [763, 765], [3776, 3778], [4529, 4531]], "60": [[2333, 2335]], "61": [[4824, 4826]], "62": [[2858, 2860]], "63": [[1199, 1200]], "64": [[3983, 3986]], "65": [[1858, 1860]], "66": [[1897, 1903]], "67": [[337, 341]], "68": [[3978, 3981]], "69": [[329, 330]], "7": [[1169, 1171], [1209, 1211], [1518, 1520], [2540, 2542], [4233, 4235], [4360, 4362]], "70": [[522, 524]], "71": [[4711, 4712]], "72": [[1540, 1546]], "73": [[395, 396]], "74": [[1443, 1444]], "75": [[325, 327]], "76": [[648, 652]], "77": [[404, 406]], "78": [[471, 473], [491, 495]], "79": [[2534, 2535]], "8": [[458, 461], [629, 633], [5207, 5210]], "80": [[4709, 4710]], "81": [[4009, 4011], [4498, 4500], [4676, 4678]], "82": [[874, 875], [887, 888], [1121, 1122], [1126, 1127], [1218, 1219], [1244, 1245], [1262, 1263], [1333, 1334], [1401, 1402], [2572, 2574], [3957, 3958], [4012, 4013], [4014, 4015], [4188, 4189], [4238, 4239], [4262, 4263], [4285, 4286], [4320, 4321], [4346, 4347], [4363, 4364]], "83": [[422, 423]], "84": [[4433, 4436]], "85": [[5132, 5134]], "86": [[2978, 2980]], "87": [[1829, 1832]], "88": [[538, 542]], "89": [[235, 238]], "9": [[753, 755], [1453, 1455], [3067, 3068], [4632, 4634]], "90": [[736, 739]], "91": [[1521, 1524]], "92": [[256, 257]], "93": [[270, 273]], "94": [[642, 644]], "95": [[2163, 2172]], "96": [[451, 454]], "97": [[334, 336]], "98": [[2764, 2766]], "99": [[1673, 1675], [2053, 2055]]}, "doc_id": "04640006606ddfb9d6aa4ce8f55855b1f23ec7ed", "method_subrelations": {"Wide_ResNet": [[[0, 11], "Wide_ResNet"]]}, "n_ary_relations": [{"Material": "CIFAR-10", "Method": "Wide_ResNet", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "96.11"}, {"Material": "CIFAR-10", "Method": "Wide_ResNet", "Metric": "Percentage_error", "Task": "Image_Classification", "score": "3.89"}, {"Material": "CIFAR-100", "Method": "Wide_ResNet", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "81.15"}, {"Material": "CIFAR-100", "Method": "Wide_ResNet", "Metric": "Percentage_error", "Task": "Image_Classification", "score": "18.85"}, {"Material": "SVHN", "Method": "Wide_ResNet", "Metric": "Percentage_error", "Task": "Image_Classification", "score": "1.7"}], "ner": [[2, 5, "Method"], [5, 8, "Method"], [35, 36, "Metric"], [48, 51, "Method"], [55, 58, "Task"], [105, 107, "Method"], [114, 117, "Method"], [118, 119, "Method"], [146, 154, "Method"], [156, 157, "Metric"], [161, 164, "Method"], [166, 172, "Method"], [184, 185, "Material"], [186, 187, "Material"], [235, 238, "Method"], [256, 257, "Method"], [258, 259, "Method"], [262, 264, "Method"], [270, 273, "Task"], [277, 279, "Method"], [293, 296, "Method"], [316, 319, "Method"], [325, 327, "Method"], [329, 330, "Method"], [334, 336, "Method"], [337, 341, "Method"], [344, 346, "Method"], [370, 372, "Task"], [375, 376, "Material"], [377, 381, "Task"], [390, 392, "Method"], [395, 396, "Task"], [404, 406, "Method"], [422, 423, "Task"], [424, 426, "Method"], [438, 440, "Method"], [451, 454, "Method"], [458, 461, "Task"], [471, 473, "Method"], [484, 486, "Method"], [491, 495, "Method"], [522, 524, "Task"], [538, 542, "Method"], [574, 576, "Method"], [577, 579, "Method"], [616, 618, "Method"], [623, 625, "Method"], [629, 633, "Task"], [642, 644, "Task"], [648, 652, "Metric"], [668, 670, "Method"], [736, 739, "Method"], [753, 755, "Method"], [756, 758, "Method"], [763, 765, "Method"], [773, 775, "Method"], [840, 843, "Task"], [874, 875, "Method"], [887, 888, "Method"], [922, 925, "Method"], [932, 933, "Task"], [961, 963, "Method"], [975, 978, "Method"], [1000, 1005, "Method"], [1010, 1016, "Method"], [1019, 1020, "Metric"], [1022, 1028, "Method"], [1056, 1059, "Method"], [1081, 1084, "Method"], [1106, 1108, "Method"], [1121, 1122, "Method"], [1123, 1125, "Method"], [1126, 1127, "Method"], [1169, 1171, "Method"], [1199, 1200, "Method"], [1209, 1211, "Method"], [1213, 1214, "Metric"], [1218, 1219, "Method"], [1225, 1229, "Task"], [1244, 1245, "Method"], [1246, 1248, "Task"], [1254, 1258, "Method"], [1262, 1263, "Method"], [1293, 1295, "Method"], [1299, 1302, "Method"], [1324, 1332, "Method"], [1333, 1334, "Method"], [1337, 1338, "Metric"], [1339, 1340, "Material"], [1361, 1364, "Method"], [1379, 1381, "Method"], [1382, 1384, "Method"], [1387, 1389, "Method"], [1401, 1402, "Method"], [1403, 1406, "Method"], [1425, 1427, "Method"], [1441, 1442, "Metric"], [1443, 1444, "Metric"], [1445, 1447, "Method"], [1450, 1453, "Method"], [1453, 1455, "Method"], [1456, 1458, "Method"], [1492, 1494, "Method"], [1502, 1504, "Method"], [1515, 1517, "Method"], [1518, 1520, "Method"], [1521, 1524, "Method"], [1525, 1528, "Method"], [1537, 1538, "Method"], [1540, 1546, "Method"], [1547, 1552, "Method"], [1578, 1583, "Method"], [1584, 1589, "Method"], [1673, 1675, "Method"], [1693, 1695, "Method"], [1700, 1702, "Method"], [1814, 1816, "Method"], [1829, 1832, "Method"], [1846, 1847, "Method"], [1848, 1849, "Method"], [1850, 1851, "Method"], [1854, 1856, "Method"], [1858, 1860, "Method"], [1897, 1903, "Method"], [1973, 1975, "Method"], [2044, 2046, "Method"], [2053, 2055, "Method"], [2071, 2076, "Method"], [2113, 2119, "Method"], [2163, 2172, "Method"], [2235, 2237, "Metric"], [2303, 2305, "Metric"], [2327, 2328, "Method"], [2333, 2335, "Task"], [2336, 2338, "Task"], [2346, 2348, "Metric"], [2353, 2355, "Method"], [2362, 2364, "Method"], [2369, 2370, "Method"], [2371, 2372, "Method"], [2382, 2389, "Method"], [2390, 2395, "Method"], [2417, 2419, "Method"], [2425, 2427, "Method"], [2454, 2456, "Method"], [2459, 2461, "Method"], [2490, 2495, "Method"], [2507, 2513, "Method"], [2516, 2520, "Task"], [2534, 2535, "Task"], [2536, 2538, "Method"], [2540, 2542, "Method"], [2552, 2554, "Task"], [2572, 2574, "Method"], [2590, 2591, "Method"], [2593, 2595, "Task"], [2608, 2611, "Method"], [2616, 2622, "Task"], [2638, 2641, "Material"], [2642, 2645, "Material"], [2646, 2647, "Material"], [2653, 2656, "Material"], [2685, 2687, "Task"], [2719, 2721, "Task"], [2725, 2726, "Material"], [2730, 2737, "Material"], [2758, 2759, "Material"], [2764, 2766, "Task"], [2794, 2795, "Method"], [2815, 2818, "Method"], [2839, 2841, "Method"], [2850, 2851, "Material"], [2854, 2856, "Method"], [2858, 2860, "Method"], [2865, 2866, "Material"], [2871, 2875, "Method"], [2907, 2910, "Method"], [2918, 2921, "Method"], [2962, 2963, "Task"], [2968, 2969, "Method"], [2978, 2980, "Method"], [2989, 2992, "Material"], [2996, 3001, "Method"], [3029, 3035, "Method"], [3036, 3042, "Method"], [3048, 3050, "Metric"], [3067, 3068, "Method"], [3086, 3087, "Metric"], [3137, 3138, "Method"], [3139, 3140, "Method"], [3154, 3155, "Method"], [3197, 3200, "Method"], [3203, 3204, "Method"], [3224, 3226, "Method"], [3258, 3259, "Task"], [3310, 3313, "Method"], [3431, 3432, "Metric"], [3436, 3441, "Method"], [3443, 3444, "Metric"], [3445, 3450, "Method"], [3466, 3469, "Method"], [3476, 3479, "Method"], [3485, 3488, "Method"], [3492, 3493, "Metric"], [3495, 3498, "Material"], [3499, 3502, "Material"], [3543, 3548, "Method"], [3564, 3567, "Method"], [3574, 3580, "Method"], [3582, 3585, "Method"], [3598, 3601, "Material"], [3605, 3608, "Material"], [3710, 3713, "Method"], [3718, 3723, "Method"], [3730, 3734, "Method"], [3749, 3752, "Method"], [3776, 3778, "Method"], [3780, 3781, "Metric"], [3787, 3790, "Material"], [3791, 3794, "Method"], [3813, 3816, "Method"], [3840, 3842, "Method"], [3880, 3882, "Method"], [3883, 3885, "Method"], [3903, 3905, "Method"], [3929, 3931, "Method"], [3957, 3958, "Method"], [3971, 3972, "Method"], [3978, 3981, "Method"], [3983, 3986, "Metric"], [3989, 3990, "Material"], [3993, 3994, "Material"], [4009, 4011, "Method"], [4012, 4013, "Method"], [4014, 4015, "Method"], [4019, 4022, "Material"], [4023, 4026, "Material"], [4040, 4044, "Method"], [4046, 4049, "Method"], [4057, 4058, "Method"], [4080, 4081, "Metric"], [4082, 4085, "Material"], [4091, 4093, "Method"], [4101, 4102, "Metric"], [4103, 4108, "Method"], [4109, 4112, "Material"], [4131, 4134, "Method"], [4137, 4140, "Metric"], [4142, 4143, "Metric"], [4144, 4146, "Metric"], [4159, 4162, "Metric"], [4171, 4173, "Method"], [4184, 4185, "Metric"], [4188, 4189, "Method"], [4215, 4216, "Material"], [4227, 4228, "Method"], [4230, 4232, "Method"], [4233, 4235, "Method"], [4238, 4239, "Method"], [4260, 4261, "Metric"], [4262, 4263, "Method"], [4285, 4286, "Method"], [4293, 4299, "Method"], [4301, 4307, "Method"], [4314, 4319, "Method"], [4320, 4321, "Method"], [4322, 4323, "Material"], [4335, 4336, "Material"], [4346, 4347, "Method"], [4360, 4362, "Method"], [4363, 4364, "Method"], [4387, 4388, "Task"], [4433, 4436, "Method"], [4462, 4463, "Metric"], [4498, 4500, "Method"], [4508, 4510, "Method"], [4515, 4518, "Task"], [4529, 4531, "Method"], [4562, 4569, "Method"], [4570, 4573, "Method"], [4603, 4609, "Method"], [4630, 4631, "Material"], [4632, 4634, "Method"], [4645, 4646, "Metric"], [4657, 4659, "Method"], [4676, 4678, "Method"], [4679, 4683, "Method"], [4691, 4696, "Method"], [4699, 4704, "Task"], [4709, 4710, "Method"], [4711, 4712, "Method"], [4735, 4738, "Method"], [4739, 4742, "Method"], [4767, 4769, "Metric"], [4769, 4774, "Method"], [4775, 4777, "Method"], [4782, 4784, "Method"], [4804, 4806, "Method"], [4821, 4823, "Method"], [4824, 4826, "Method"], [4828, 4833, "Metric"], [4868, 4872, "Method"], [4875, 4881, "Method"], [4887, 4888, "Metric"], [4889, 4892, "Method"], [4918, 4919, "Method"], [4920, 4922, "Method"], [4930, 4932, "Metric"], [5009, 5010, "Method"], [5023, 5024, "Task"], [5027, 5029, "Method"], [5060, 5062, "Method"], [5069, 5073, "Method"], [5082, 5086, "Method"], [5104, 5107, "Material"], [5108, 5111, "Material"], [5112, 5113, "Material"], [5128, 5130, "Method"], [5132, 5134, "Method"], [5137, 5142, "Method"], [5143, 5144, "Material"], [5149, 5152, "Method"], [5166, 5168, "Method"], [5184, 5187, "Method"], [5207, 5210, "Task"], [86, 88, "Method"], [701, 703, "Method"], [944, 946, "Method"], [2295, 2297, "Method"], [2657, 2658, "Material"], [3631, 3634, "Method"], [3767, 3768, "Material"], [4017, 4018, "Metric"], [4290, 4292, "Method"], [4375, 4377, "Method"], [4584, 4591, "Method"], [4856, 4857, "Material"], [4858, 4861, "Method"], [4926, 4927, "Metric"], [4956, 4957, "Material"], [4978, 4979, "Material"]], "sections": [[0, 232], [232, 1448], [1448, 1949], [1949, 2172], [2172, 2254], [2254, 2514], [2514, 2627], [2627, 2964], [2964, 3150], [3150, 3319], [3319, 3955], [3955, 4414], [4414, 4765], [4765, 4908], [4908, 5049], [5049, 5211], [5211, 5263], [5263, 5266]], "sentences": [[0, 5], [5, 26], [26, 68], [68, 108], [108, 137], [137, 196], [196, 215], [215, 222], [222, 232], [232, 235], [235, 274], [274, 290], [290, 308], [308, 342], [342, 388], [388, 410], [410, 427], [427, 455], [455, 487], [487, 512], [512, 543], [543, 560], [560, 595], [595, 619], [619, 626], [626, 665], [665, 692], [692, 706], [706, 709], [709, 718], [718, 723], [723, 729], [729, 734], [734, 735], [735, 740], [740, 745], [745, 746], [746, 776], [776, 794], [794, 835], [835, 845], [845, 864], [864, 891], [891, 901], [901, 934], [934, 969], [969, 996], [996, 1006], [1006, 1043], [1043, 1073], [1073, 1119], [1119, 1126], [1126, 1142], [1142, 1163], [1163, 1194], [1194, 1220], [1220, 1252], [1252, 1282], [1282, 1296], [1296, 1342], [1342, 1354], [1354, 1375], [1375, 1394], [1394, 1418], [1418, 1448], [1448, 1453], [1453, 1492], [1492, 1501], [1501, 1530], [1530, 1547], [1547, 1554], [1554, 1557], [1557, 1590], [1590, 1610], [1610, 1618], [1618, 1637], [1637, 1647], [1647, 1668], [1668, 1676], [1676, 1736], [1736, 1768], [1768, 1781], [1781, 1793], [1793, 1799], [1799, 1809], [1809, 1861], [1861, 1890], [1890, 1908], [1908, 1933], [1933, 1949], [1949, 1957], [1957, 1979], [1979, 1999], [1999, 2007], [2007, 2031], [2031, 2047], [2047, 2081], [2081, 2093], [2093, 2121], [2121, 2172], [2172, 2181], [2181, 2196], [2196, 2242], [2242, 2254], [2254, 2260], [2260, 2277], [2277, 2309], [2309, 2349], [2349, 2379], [2379, 2420], [2420, 2429], [2429, 2438], [2438, 2442], [2442, 2497], [2497, 2506], [2506, 2507], [2507, 2514], [2514, 2520], [2520, 2536], [2536, 2569], [2569, 2585], [2585, 2606], [2606, 2627], [2627, 2631], [2631, 2653], [2653, 2657], [2657, 2684], [2684, 2714], [2714, 2725], [2725, 2755], [2755, 2759], [2759, 2762], [2762, 2785], [2785, 2808], [2808, 2831], [2831, 2845], [2845, 2861], [2861, 2896], [2896, 2905], [2905, 2922], [2922, 2948], [2948, 2964], [2964, 2972], [2972, 2994], [2994, 3014], [3014, 3036], [3036, 3043], [3043, 3067], [3067, 3103], [3103, 3125], [3125, 3150], [3150, 3157], [3157, 3181], [3181, 3227], [3227, 3246], [3246, 3275], [3275, 3284], [3284, 3299], [3299, 3319], [3319, 3325], [3325, 3341], [3341, 3360], [3360, 3370], [3370, 3397], [3397, 3434], [3434, 3452], [3452, 3470], [3470, 3476], [3476, 3479], [3479, 3503], [3503, 3536], [3536, 3572], [3572, 3622], [3622, 3672], [3672, 3685], [3685, 3714], [3714, 3734], [3734, 3761], [3761, 3832], [3832, 3901], [3901, 3939], [3939, 3955], [3955, 3961], [3961, 3976], [3976, 3995], [3995, 4014], [4014, 4067], [4067, 4094], [4094, 4125], [4125, 4163], [4163, 4186], [4186, 4207], [4207, 4217], [4217, 4227], [4227, 4244], [4244, 4269], [4269, 4279], [4279, 4293], [4293, 4311], [4311, 4345], [4345, 4352], [4352, 4378], [4378, 4396], [4396, 4404], [4404, 4414], [4414, 4420], [4420, 4448], [4448, 4458], [4458, 4484], [4484, 4532], [4532, 4555], [4555, 4584], [4584, 4587], [4587, 4622], [4622, 4647], [4647, 4669], [4669, 4688], [4688, 4713], [4713, 4746], [4746, 4765], [4765, 4769], [4769, 4790], [4790, 4819], [4819, 4851], [4851, 4861], [4861, 4873], [4873, 4898], [4898, 4908], [4908, 4912], [4912, 4928], [4928, 4955], [4955, 4977], [4977, 5004], [5004, 5011], [5011, 5022], [5022, 5030], [5030, 5049], [5049, 5052], [5052, 5074], [5074, 5125], [5125, 5182], [5182, 5194], [5194, 5211], [5211, 5214], [5214, 5239], [5239, 5251], [5251, 5263], [5263, 5266]], "words": ["document", ":", "Wide", "Residual", "Networks", "Deep", "residual", "networks", "were", "shown", "to", "be", "able", "to", "scale", "up", "to", "thousands", "of", "layers", "and", "still", "have", "improving", "performance", ".", "However", ",", "each", "fraction", "of", "a", "percent", "of", "improved", "accuracy", "costs", "nearly", "doubling", "the", "number", "of", "layers", ",", "and", "so", "training", "very", "deep", "residual", "networks", "has", "a", "problem", "of", "diminishing", "feature", "reuse", ",", "which", "makes", "these", "networks", "very", "slow", "to", "train", ".", "To", "tackle", "these", "problems", ",", "in", "this", "paper", "we", "conduct", "a", "detailed", "experimental", "study", "on", "the", "architecture", "of", "ResNet", "blocks", ",", "based", "on", "which", "we", "propose", "a", "novel", "architecture", "where", "we", "decrease", "depth", "and", "increase", "width", "of", "residual", "networks", ".", "We", "call", "the", "resulting", "network", "structures", "wide", "residual", "networks", "(", "WRNs", ")", "and", "show", "that", "these", "are", "far", "superior", "over", "their", "commonly", "used", "thin", "and", "very", "deep", "counterparts", ".", "For", "example", ",", "we", "demonstrate", "that", "even", "a", "simple", "16", "-", "layer", "-", "deep", "wide", "residual", "network", "outperforms", "in", "accuracy", "and", "efficiency", "all", "previous", "deep", "residual", "networks", ",", "including", "thousand", "-", "layer", "-", "deep", "networks", ",", "achieving", "new", "state", "-", "of", "-", "the", "-", "art", "results", "on", "CIFAR", ",", "SVHN", ",", "COCO", ",", "and", "significant", "improvements", "on", "ImageNet", ".", "Our", "code", "and", "models", "are", "available", "at", "https:", "//", "github.com", "/", "szagoruyko", "/", "wide", "-", "residual", "-", "networks", ".", "[", "reference", "]", "[", "reference", "]", "SergeyZagoruykosergey.zagoruyko@enpc.fr1", "NikosKomodakisnikos.komodakis@enpc.fr1", "Universit\u00e9Paris", "-", "Est", ",", "\u00c9coledesPontsParisTech", "Paris", ",", "France", "SergeyZagoruykoandNikosKomodakisWideresidualnetworks", "section", ":", "Introduction", "Convolutional", "neural", "networks", "have", "seen", "a", "gradual", "increase", "of", "the", "number", "of", "layers", "in", "the", "last", "few", "years", ",", "starting", "from", "AlexNet", ",", "VGG", ",", "Inception", "to", "Residual", "networks", ",", "corresponding", "to", "improvements", "in", "many", "image", "recognition", "tasks", ".", "The", "superiority", "of", "deep", "networks", "has", "been", "spotted", "in", "several", "works", "in", "the", "recent", "years", ".", "However", ",", "training", "deep", "neural", "networks", "has", "several", "difficulties", ",", "including", "exploding", "/", "vanishing", "gradients", "and", "degradation", ".", "Various", "techniques", "were", "suggested", "to", "enable", "training", "of", "deeper", "neural", "networks", ",", "such", "as", "well", "-", "designed", "initialization", "strategies", ",", "better", "optimizers", ",", "skip", "connections", ",", "knowledge", "transfer", "and", "layer", "-", "wise", "training", ".", "The", "latest", "residual", "networks", "had", "a", "large", "success", "winning", "ImageNet", "and", "COCO", "2015", "competition", "and", "achieving", "state", "-", "of", "-", "the", "-", "art", "in", "several", "benchmarks", ",", "including", "object", "classification", "on", "ImageNet", "and", "CIFAR", ",", "object", "detection", "and", "segmentation", "on", "PASCAL", "VOC", "and", "MS", "COCO", ".", "Compared", "to", "Inception", "architectures", "they", "show", "better", "generalization", ",", "meaning", "the", "features", "can", "be", "utilized", "in", "transfer", "learning", "with", "better", "efficiency", ".", "Also", ",", "follow", "-", "up", "work", "showed", "that", "residual", "links", "speed", "up", "convergence", "of", "deep", "networks", ".", "Recent", "follow", "-", "up", "work", "explored", "the", "order", "of", "activations", "in", "residual", "networks", ",", "presenting", "identity", "mappings", "in", "residual", "blocks", "and", "improving", "training", "of", "very", "deep", "networks", ".", "Successful", "training", "of", "very", "deep", "networks", "was", "also", "shown", "to", "be", "possible", "through", "the", "use", "of", "highway", "networks", ",", "which", "is", "an", "architecture", "that", "had", "been", "proposed", "prior", "to", "residual", "networks", ".", "The", "essential", "difference", "between", "residual", "and", "highway", "networks", "is", "that", "in", "the", "latter", "residual", "links", "are", "gated", "and", "weights", "of", "these", "gates", "are", "learned", ".", "Therefore", ",", "up", "to", "this", "point", ",", "the", "study", "of", "residual", "networks", "has", "focused", "mainly", "on", "the", "order", "of", "activations", "inside", "a", "ResNet", "block", "and", "the", "depth", "of", "residual", "networks", ".", "In", "this", "work", "we", "attempt", "to", "conduct", "an", "experimental", "study", "that", "goes", "beyond", "the", "above", "points", ".", "By", "doing", "so", ",", "our", "goal", "is", "to", "explore", "a", "much", "richer", "set", "of", "network", "architectures", "of", "ResNet", "blocks", "and", "thoroughly", "examine", "how", "several", "other", "different", "aspects", "besides", "the", "order", "of", "activations", "affect", "performance", ".", "As", "we", "explain", "below", ",", "such", "an", "exploration", "of", "architectures", "has", "led", "to", "new", "interesting", "findings", "with", "great", "practical", "importance", "concerning", "residual", "networks", ".", "Width", "vs", "depth", "in", "residual", "networks", ".", "The", "problem", "of", "shallow", "vs", "deep", "networks", "has", "been", "in", "discussion", "for", "a", "long", "time", "in", "machine", "learning", "with", "pointers", "to", "the", "circuit", "complexity", "theory", "literature", "showing", "that", "shallow", "circuits", "can", "require", "exponentially", "more", "components", "than", "deeper", "circuits", ".", "The", "authors", "of", "residual", "networks", "tried", "to", "make", "them", "as", "thin", "as", "possible", "in", "favor", "of", "increasing", "their", "depth", "and", "having", "less", "parameters", ",", "and", "even", "introduced", "a", "\u00a1", "\u00a1", "bottleneck", "\u00bf", "\u00bf", "block", "which", "makes", "ResNet", "blocks", "even", "thinner", ".", "[", "basic", "]", "[", "scale=0.4", "]", "images", "/", "basic_a.pdf", "[", "bottleneck", "]", "[", "scale=0.4", "]", "images", "/", "basic_b.pdf", "[", "basic", "-", "wide", "]", "[", "scale=0.4", "]", "images", "/", "basic_c.pdf", "[", "wide", "-", "dropout", "]", "[", "scale=0.4", "]", "images", "/", "basic_d.pdf", "We", "note", ",", "however", ",", "that", "the", "residual", "block", "with", "identity", "mapping", "that", "allows", "to", "train", "very", "deep", "networks", "is", "at", "the", "same", "time", "a", "weakness", "of", "residual", "networks", ".", "As", "gradient", "flows", "through", "the", "network", "there", "is", "nothing", "to", "force", "it", "to", "go", "through", "residual", "block", "weights", "and", "it", "can", "avoid", "learning", "anything", "during", "training", ",", "so", "it", "is", "possible", "that", "there", "is", "either", "only", "a", "few", "blocks", "that", "learn", "useful", "representations", ",", "or", "many", "blocks", "share", "very", "little", "information", "with", "small", "contribution", "to", "the", "final", "goal", ".", "This", "problem", "was", "formulated", "as", "diminishing", "feature", "reuse", "in", ".", "The", "authors", "of", "tried", "to", "address", "this", "problem", "with", "the", "idea", "of", "randomly", "disabling", "residual", "blocks", "during", "training", ".", "This", "method", "can", "be", "viewed", "as", "a", "special", "case", "of", "dropout", ",", "where", "each", "residual", "block", "has", "an", "identity", "scalar", "weight", "on", "which", "dropout", "is", "applied", ".", "The", "effectiveness", "of", "this", "approach", "proves", "the", "hypothesis", "above", ".", "Motivated", "by", "the", "above", "observation", ",", "our", "work", "builds", "on", "top", "of", "and", "tries", "to", "answer", "the", "question", "of", "how", "wide", "deep", "residual", "networks", "should", "be", "and", "address", "the", "problem", "of", "training", ".", "In", "this", "context", ",", "we", "show", "that", "the", "widening", "of", "ResNet", "blocks", "(", "if", "done", "properly", ")", "provides", "a", "much", "more", "effective", "way", "of", "improving", "performance", "of", "residual", "networks", "compared", "to", "increasing", "their", "depth", ".", "In", "particular", ",", "we", "present", "wider", "deep", "residual", "networks", "that", "significantly", "improve", "over", ",", "having", "50", "times", "less", "layers", "and", "being", "more", "than", "2", "times", "faster", ".", "We", "call", "the", "resulting", "network", "architectures", "wide", "residual", "networks", ".", "For", "instance", ",", "our", "wide", "16", "-", "layer", "deep", "network", "has", "the", "same", "accuracy", "as", "a", "1000", "-", "layer", "thin", "deep", "network", "and", "a", "comparable", "number", "of", "parameters", ",", "although", "being", "several", "times", "faster", "to", "train", ".", "This", "type", "of", "experiments", "thus", "seem", "to", "indicate", "that", "the", "main", "power", "of", "deep", "residual", "networks", "is", "in", "residual", "blocks", ",", "and", "that", "the", "effect", "of", "depth", "is", "supplementary", ".", "We", "note", "that", "one", "can", "train", "even", "better", "wide", "residual", "networks", "that", "have", "twice", "as", "many", "parameters", "(", "and", "more", ")", ",", "which", "suggests", "that", "to", "further", "improve", "performance", "by", "increasing", "depth", "of", "thin", "networks", "one", "needs", "to", "add", "thousands", "of", "layers", "in", "this", "case", ".", "Use", "of", "dropout", "in", "ResNet", "blocks", ".", "Dropout", "was", "first", "introduced", "in", "and", "then", "was", "adopted", "by", "many", "successful", "architectures", "as", "etc", ".", "It", "was", "mostly", "applied", "on", "top", "layers", "that", "had", "a", "large", "number", "of", "parameters", "to", "prevent", "feature", "coadaptation", "and", "overfitting", ".", "It", "was", "then", "mainly", "substituted", "by", "batch", "normalization", "which", "was", "introduced", "as", "a", "technique", "to", "reduce", "internal", "covariate", "shift", "in", "neural", "network", "activations", "by", "normalizing", "them", "to", "have", "specific", "distribution", ".", "It", "also", "works", "as", "a", "regularizer", "and", "the", "authors", "experimentally", "showed", "that", "a", "network", "with", "batch", "normalization", "achieves", "better", "accuracy", "than", "a", "network", "with", "dropout", ".", "In", "our", "case", ",", "as", "widening", "of", "residual", "blocks", "results", "in", "an", "increase", "of", "the", "number", "of", "parameters", ",", "we", "studied", "the", "effect", "of", "dropout", "to", "regularize", "training", "and", "prevent", "overfitting", ".", "Previously", ",", "dropout", "in", "residual", "networks", "was", "studied", "in", "with", "dropout", "being", "inserted", "in", "the", "identity", "part", "of", "the", "block", ",", "and", "the", "authors", "showed", "negative", "effects", "of", "that", ".", "Instead", ",", "we", "argue", "here", "that", "dropout", "should", "be", "inserted", "between", "convolutional", "layers", ".", "Experimental", "results", "on", "wide", "residual", "networks", "show", "that", "this", "leads", "to", "consistent", "gains", ",", "yielding", "even", "new", "state", "-", "of", "-", "the", "-", "art", "results", "(", "e.g", ",", "16", "-", "layer", "-", "deep", "wide", "residual", "network", "with", "dropout", "achieves", "1.64", "%", "error", "on", "SVHN", ")", ".", "In", "summary", ",", "the", "contributions", "of", "this", "work", "are", "as", "follows", ":", "We", "present", "a", "detailed", "experimental", "study", "of", "residual", "network", "architectures", "that", "thoroughly", "examines", "several", "important", "aspects", "of", "ResNet", "block", "structure", ".", "We", "propose", "a", "novel", "widened", "architecture", "for", "ResNet", "blocks", "that", "allows", "for", "residual", "networks", "with", "significantly", "improved", "performance", ".", "We", "propose", "a", "new", "way", "of", "utilizing", "dropout", "within", "deep", "residual", "networks", "so", "as", "to", "properly", "regularize", "them", "and", "prevent", "overfitting", "during", "training", ".", "Last", ",", "we", "show", "that", "our", "proposed", "ResNet", "architectures", "achieve", "state", "-", "of", "-", "the", "-", "art", "results", "on", "several", "datasets", "dramatically", "improving", "accuracy", "and", "speed", "of", "residual", "networks", ".", "section", ":", "Wide", "residual", "networks", "Residual", "block", "with", "identity", "mapping", "can", "be", "represented", "by", "the", "following", "formula", ":", "where", "and", "are", "input", "and", "output", "of", "the", "-", "th", "unit", "in", "the", "network", ",", "is", "a", "residual", "function", "and", "are", "parameters", "of", "the", "block", ".", "Residual", "network", "consists", "of", "sequentially", "stacked", "residual", "blocks", ".", "In", "residual", "networks", "consisted", "of", "two", "type", "of", "blocks", ":", "basic", "-", "with", "two", "consecutive", "convolutions", "with", "batch", "normalization", "and", "ReLU", "preceding", "convolution", ":", "conv\u00d733", "-", "conv\u00d733", "Fig", ".", "[", "reference", "]", "bottleneck", "-", "with", "one", "convolution", "surrounded", "by", "dimensionality", "reducing", "and", "expanding", "convolution", "layers", ":", "conv\u00d711", "-", "conv\u00d733", "-", "conv\u00d711", "Fig", ".", "[", "reference", "]", "Compared", "to", "the", "original", "architecture", "in", "the", "order", "of", "batch", "normalization", ",", "activation", "and", "convolution", "in", "residual", "block", "was", "changed", "from", "conv", "-", "BN", "-", "ReLU", "to", "BN", "-", "ReLU", "-", "conv", ".", "As", "the", "latter", "was", "shown", "to", "train", "faster", "and", "achieve", "better", "results", "we", "do", "n\u2019t", "consider", "the", "original", "version", ".", "Furthermore", ",", "so", "-", "called", "\u00a1", "\u00a1", "bottleneck", "\u00bf", "\u00bf", "blocks", "were", "initially", "used", "to", "make", "blocks", "less", "computationally", "expensive", "to", "increase", "the", "number", "of", "layers", ".", "As", "we", "want", "to", "study", "the", "effect", "of", "widening", "and", "\u00a1", "\u00a1", "bottleneck", "\u00bf", "\u00bf", "is", "used", "to", "make", "networks", "thinner", "we", "do", "n\u2019t", "consider", "it", "too", ",", "focusing", "instead", "on", "\u00a1", "\u00a1", "basic", "\u00bf", "\u00bf", "residual", "architecture", ".", "There", "are", "essentially", "three", "simple", "ways", "to", "increase", "representational", "power", "of", "residual", "blocks", ":", "to", "add", "more", "convolutional", "layers", "per", "block", "to", "widen", "the", "convolutional", "layers", "by", "adding", "more", "feature", "planes", "to", "increase", "filter", "sizes", "in", "convolutional", "layers", "As", "small", "filters", "were", "shown", "to", "be", "very", "effective", "in", "several", "works", "including", "we", "do", "not", "consider", "using", "filters", "larger", "than", ".", "Let", "us", "also", "introduce", "two", "factors", ",", "deepening", "factor", "and", "widening", "factor", ",", "where", "is", "the", "number", "of", "convolutions", "in", "a", "block", "and", "multiplies", "the", "number", "of", "features", "in", "convolutional", "layers", ",", "thus", "the", "baseline", "\u00a1", "\u00a1", "basic", "\u00bf", "\u00bf", "block", "corresponds", "to", ",", ".", "Figures", "[", "reference", "]", "and", "[", "reference", "]", "show", "schematic", "examples", "of", "\u00a1", "\u00a1", "basic", "\u00bf", "\u00bf", "and", "\u00a1", "\u00a1", "basic", "-", "wide", "\u00bf", "\u00bf", "blocks", "respectively", ".", "The", "general", "structure", "of", "our", "residual", "networks", "is", "illustrated", "in", "table", "[", "reference", "]", ":", "it", "consists", "of", "an", "initial", "convolutional", "layer", "conv1", "that", "is", "followed", "by", "3", "groups", "(", "each", "of", "size", ")", "of", "residual", "blocks", "conv2", ",", "conv3", "and", "conv4", ",", "followed", "by", "average", "pooling", "and", "final", "classification", "layer", ".", "The", "size", "of", "conv1", "is", "fixed", "in", "all", "of", "our", "experiments", ",", "while", "the", "introduced", "widening", "factor", "scales", "the", "width", "of", "the", "residual", "blocks", "in", "the", "three", "groups", "conv2", "-", "4", "(", "e.g", ",", "the", "original", "\u00a1", "\u00a1", "basic", "\u00bf", "\u00bf", "architecture", "is", "equivalent", "to", ")", ".", "We", "want", "to", "study", "the", "effect", "of", "representational", "power", "of", "residual", "block", "and", ",", "to", "that", "end", ",", "we", "perform", "and", "test", "several", "modifications", "to", "the", "\u00a1", "\u00a1", "basic", "\u00bf", "\u00bf", "architecture", ",", "which", "are", "detailed", "in", "the", "following", "subsections", ".", "subsection", ":", "Type", "of", "convolutions", "in", "residual", "block", "Let", "denote", "residual", "block", "structure", ",", "where", "is", "a", "list", "with", "the", "kernel", "sizes", "of", "the", "convolutional", "layers", "in", "a", "block", ".", "For", "example", ",", "denotes", "a", "residual", "block", "with", "and", "convolutional", "layers", "(", "we", "always", "assume", "square", "spatial", "kernels", ")", ".", "Note", "that", ",", "as", "we", "do", "not", "consider", "\u00a1", "\u00a1", "bottleneck", "\u00bf", "\u00bf", "blocks", "as", "explained", "earlier", ",", "the", "number", "of", "feature", "planes", "is", "always", "kept", "the", "same", "across", "the", "block", ".", "We", "would", "like", "to", "answer", "the", "question", "of", "how", "important", "each", "of", "the", "convolutional", "layers", "of", "the", "\u00a1", "\u00a1", "basic", "\u00bf", "\u00bf", "residual", "architecture", "is", "and", "if", "they", "can", "be", "substituted", "by", "a", "less", "computationally", "expensive", "layer", "or", "even", "a", "combination", "of", "and", "convolutional", "layers", ",", "e.g", ",", "or", ".", "This", "can", "increase", "or", "decrease", "the", "representational", "power", "of", "the", "block", ".", "We", "thus", "experiment", "with", "the", "following", "combinations", "(", "note", "that", "the", "last", "combination", ",", "i.e.", ",", "is", "similar", "to", "effective", "Network", "-", "in", "-", "Network", "architecture", ")", ":", "-", "original", "\u00a1", "\u00a1", "basic", "\u00bf", "\u00bf", "block", "-", "with", "one", "extra", "layer", "-", "with", "the", "same", "dimensionality", "of", "all", "convolutions", ",", "\u00a1", "\u00a1", "straightened", "\u00bf", "\u00bf", "bottleneck", "-", "the", "network", "has", "alternating", "-", "convolutions", "everywhere", "-", "similar", "idea", "to", "the", "previous", "block", "-", "Network", "-", "in", "-", "Network", "style", "block", "subsection", ":", "Number", "of", "convolutional", "layers", "per", "residual", "block", "We", "also", "experiment", "with", "the", "block", "deepening", "factor", "to", "see", "how", "it", "affects", "performance", ".", "The", "comparison", "has", "to", "be", "done", "among", "networks", "with", "the", "same", "number", "of", "parameters", ",", "so", "in", "this", "case", "we", "need", "to", "build", "networks", "with", "different", "and", "(", "where", "denotes", "the", "total", "number", "of", "blocks", ")", "while", "ensuring", "that", "network", "complexity", "is", "kept", "roughly", "constant", ".", "This", "means", ",", "for", "instance", ",", "that", "should", "decrease", "whenever", "increases", ".", "subsection", ":", "Width", "of", "residual", "blocks", "In", "addition", "to", "the", "above", "modifications", ",", "we", "experiment", "with", "the", "widening", "factor", "of", "a", "block", ".", "While", "the", "number", "of", "parameters", "increases", "linearly", "with", "(", "the", "deepening", "factor", ")", "and", "(", "the", "number", "of", "ResNet", "blocks", ")", ",", "number", "of", "parameters", "and", "computational", "complexity", "are", "quadratic", "in", ".", "However", ",", "it", "is", "more", "computationally", "effective", "to", "widen", "the", "layers", "than", "have", "thousands", "of", "small", "kernels", "as", "GPU", "is", "much", "more", "efficient", "in", "parallel", "computations", "on", "large", "tensors", ",", "so", "we", "are", "interested", "in", "an", "optimal", "to", "ratio", ".", "One", "argument", "for", "wider", "residual", "networks", "would", "be", "that", "almost", "all", "architectures", "before", "residual", "networks", ",", "including", "the", "most", "successful", "Inception", "and", "VGG", ",", "were", "much", "wider", "compared", "to", ".", "For", "example", ",", "residual", "networks", "WRN", "-", "22", "-", "8", "and", "WRN", "-", "16", "-", "10", "(", "see", "next", "paragraph", "for", "explanation", "of", "this", "notation", ")", "are", "very", "similar", "in", "width", ",", "depth", "and", "number", "of", "parameters", "to", "VGG", "architectures", ".", "We", "further", "refer", "to", "original", "residual", "networks", "with", "as", "\u00a1", "\u00a1", "thin", "\u00bf", "\u00bf", "and", "to", "networks", "with", "as", "\u00a1", "\u00a1", "wide\u00bf\u00bf.", "In", "the", "rest", "of", "the", "paper", "we", "use", "the", "following", "notation", ":", "WRN", "-", "-", "denotes", "a", "residual", "network", "that", "has", "a", "total", "number", "of", "convolutional", "layers", "and", "a", "widening", "factor", "(", "for", "example", ",", "network", "with", "40", "layers", "and", "times", "wider", "than", "original", "would", "be", "denoted", "as", "WRN", "-", "40", "-", "2", ")", ".", "Also", ",", "when", "applicable", "we", "append", "block", "type", ",", "e.g", "WRN", "-", "40", "-", "2", "-", ".", "subsection", ":", "Dropout", "in", "residual", "blocks", "As", "widening", "increases", "the", "number", "of", "parameters", "we", "would", "like", "to", "study", "ways", "of", "regularization", ".", "Residual", "networks", "already", "have", "batch", "normalization", "that", "provides", "a", "regularization", "effect", ",", "however", "it", "requires", "heavy", "data", "augmentation", ",", "which", "we", "would", "like", "to", "avoid", ",", "and", "it", "\u2019s", "not", "always", "possible", ".", "We", "add", "a", "dropout", "layer", "into", "each", "residual", "block", "between", "convolutions", "as", "shown", "in", "fig", ".", "[", "reference", "]", "and", "after", "ReLU", "to", "perturb", "batch", "normalization", "in", "the", "next", "residual", "block", "and", "prevent", "it", "from", "overfitting", ".", "In", "very", "deep", "residual", "networks", "that", "should", "help", "deal", "with", "diminishing", "feature", "reuse", "problem", "enforcing", "learning", "in", "different", "residual", "blocks", ".", "section", ":", "Experimental", "results", "For", "experiments", "we", "chose", "well", "-", "known", "CIFAR", "-", "10", ",", "CIFAR", "-", "100", ",", "SVHN", "and", "ImageNet", "image", "classification", "datasets", ".", "CIFAR", "-", "10", "and", "CIFAR", "-", "100", "datasets", "consist", "of", "color", "images", "drawn", "from", "10", "and", "100", "classes", "split", "into", "50", ",", "000", "train", "and", "10", ",", "000", "test", "images", ".", "For", "data", "augmentation", "we", "do", "horizontal", "flips", "and", "take", "random", "crops", "from", "image", "padded", "by", "4", "pixels", "on", "each", "side", ",", "filling", "missing", "pixels", "with", "reflections", "of", "original", "image", ".", "We", "do", "n\u2019t", "use", "heavy", "data", "augmentation", "as", "proposed", "in", ".", "SVHN", "is", "a", "dataset", "of", "Google", "\u2019s", "Street", "View", "House", "Numbers", "images", "and", "contains", "about", "600", ",", "000", "digit", "images", ",", "coming", "from", "a", "significantly", "harder", "real", "world", "problem", ".", "For", "experiments", "on", "SVHN", "we", "do", "n\u2019t", "do", "any", "image", "preprocessing", ",", "except", "dividing", "images", "by", "255", "to", "provide", "them", "in", "[", "0", ",", "1", "]", "range", "as", "input", ".", "All", "of", "our", "experiments", "except", "ImageNet", "are", "based", "on", "architecture", "with", "pre", "-", "activation", "residual", "blocks", "and", "we", "use", "it", "as", "baseline", ".", "For", "ImageNet", ",", "we", "find", "that", "using", "pre", "-", "activation", "in", "networks", "with", "less", "than", "100", "layers", "does", "not", "make", "any", "significant", "difference", "and", "so", "we", "decide", "to", "use", "the", "original", "ResNet", "architecture", "in", "this", "case", ".", "Unless", "mentioned", "otherwise", ",", "for", "CIFAR", "we", "follow", "the", "image", "preprocessing", "of", "with", "ZCA", "whitening", ".", "However", ",", "for", "some", "CIFAR", "experiments", "we", "instead", "use", "simple", "mean", "/", "std", "normalization", "such", "that", "we", "can", "directly", "compare", "with", "and", "other", "ResNet", "related", "works", "that", "make", "use", "of", "this", "type", "of", "preprocessing", ".", "In", "the", "following", "we", "describe", "our", "findings", "w.r.t", ".", "the", "different", "ResNet", "block", "architectures", "and", "also", "analyze", "the", "performance", "of", "our", "proposed", "wide", "residual", "networks", ".", "We", "note", "that", "for", "all", "experiments", "related", "to", "\u00a1", "\u00a1", "type", "of", "convolutions", "in", "a", "block", "\u00bf", "\u00bf", "and", "\u00a1", "\u00a1", "number", "of", "convolutions", "per", "block", "\u00bf", "\u00bf", "we", "use", "and", "reduced", "depth", "compared", "to", "in", "order", "to", "speed", "up", "training", ".", "subsubsection", ":", "Type", "of", "convolutions", "in", "a", "block", "We", "start", "by", "reporting", "results", "using", "trained", "networks", "with", "different", "block", "types", "(", "reported", "results", "are", "on", "CIFAR", "-", "10", ")", ".", "We", "used", "WRN", "-", "40", "-", "2", "for", "blocks", ",", ",", "and", "as", "these", "blocks", "have", "only", "one", "convolution", ".", "To", "keep", "the", "number", "of", "parameters", "comparable", "we", "trained", "other", "networks", "with", "less", "layers", ":", "WRN", "-", "28", "-", "2", "-", "and", "WRN", "-", "22", "-", "2", "-", ".", "We", "provide", "the", "results", "including", "test", "accuracy", "in", "median", "over", "5", "runs", "and", "time", "per", "training", "epoch", "in", "the", "table", "[", "reference", "]", ".", "Block", "turned", "out", "to", "be", "the", "best", "by", "a", "little", "margin", ",", "and", "with", "are", "very", "close", "to", "in", "accuracy", "having", "less", "parameters", "and", "less", "layers", ".", "is", "faster", "than", "others", "by", "a", "small", "margin", ".", "Based", "on", "the", "above", ",", "blocks", "with", "comparable", "number", "of", "parameters", "turned", "out", "to", "give", "more", "or", "less", "the", "same", "results", ".", "Due", "to", "this", "fact", ",", "we", "hereafter", "restrict", "our", "attention", "to", "only", "WRNs", "with", "convolutions", "so", "as", "to", "be", "also", "consistent", "with", "other", "methods", ".", "subsubsection", ":", "Number", "of", "convolutions", "per", "block", "We", "next", "proceed", "with", "the", "experiments", "related", "to", "varying", "the", "deepening", "factor", "(", "which", "represents", "the", "number", "of", "convolutional", "layers", "per", "block", ")", ".", "We", "show", "indicative", "results", "in", "table", "[", "reference", "]", ",", "where", "in", "this", "case", "we", "took", "WRN", "-", "40", "-", "2", "with", "convolutions", "and", "trained", "several", "networks", "with", "different", "deepening", "factor", ",", "same", "number", "of", "parameters", "(", "2.2", ")", "and", "same", "number", "of", "convolutional", "layers", ".", "As", "can", "be", "noticed", ",", "turned", "out", "to", "be", "the", "best", ",", "whereas", "and", "had", "the", "worst", "performance", ".", "We", "speculate", "that", "this", "is", "probably", "due", "to", "the", "increased", "difficulty", "in", "optimization", "as", "a", "result", "of", "the", "decreased", "number", "of", "residual", "connections", "in", "the", "last", "two", "cases", ".", "Furthermore", ",", "turned", "out", "to", "be", "quite", "worse", ".", "The", "conclusion", "is", "that", "is", "optimal", "in", "terms", "of", "number", "of", "convolutions", "per", "block", ".", "For", "this", "reason", ",", "in", "the", "remaining", "experiments", "we", "only", "consider", "wide", "residual", "networks", "with", "a", "block", "of", "type", ".", "subsubsection", ":", "Width", "of", "residual", "blocks", "As", "we", "try", "to", "increase", "widening", "parameter", "we", "have", "to", "decrease", "total", "number", "of", "layers", ".", "To", "find", "an", "optimal", "ratio", "we", "experimented", "with", "from", "2", "to", "12", "and", "depth", "from", "16", "to", "40", ".", "The", "results", "are", "presented", "in", "table", "[", "reference", "]", ".", "As", "can", "be", "seen", ",", "all", "networks", "with", "40", ",", "22", "and", "16", "layers", "see", "consistent", "gains", "when", "width", "is", "increased", "by", "1", "to", "12", "times", ".", "On", "the", "other", "hand", ",", "when", "keeping", "the", "same", "fixed", "widening", "factor", "or", "and", "varying", "depth", "from", "16", "to", "28", "there", "is", "a", "consistent", "improvement", ",", "however", "when", "we", "further", "increase", "depth", "to", "40", "accuracy", "decreases", "(", "e.g", ",", "WRN", "-", "40", "-", "8", "loses", "in", "accuracy", "to", "WRN", "-", "22", "-", "8", ")", ".", "We", "show", "additional", "results", "in", "table", "[", "reference", "]", "where", "we", "compare", "thin", "and", "wide", "residual", "networks", ".", "As", "can", "be", "observed", ",", "wide", "WRN", "-", "40", "-", "4", "compares", "favorably", "to", "thin", "ResNet", "-", "1001", "as", "it", "achieves", "better", "accuracy", "on", "both", "CIFAR", "-", "10", "and", "CIFAR", "-", "100", ".", "Yet", ",", "it", "is", "interesting", "that", "these", "networks", "have", "comparable", "number", "of", "parameters", ",", "8.9", "and", "10.2", ",", "suggesting", "that", "depth", "does", "not", "add", "regularization", "effects", "compared", "to", "width", "at", "this", "level", ".", "As", "we", "show", "further", "in", "benchmarks", ",", "WRN", "-", "40", "-", "4", "is", "8", "times", "faster", "to", "train", ",", "so", "evidently", "depth", "to", "width", "ratio", "in", "the", "original", "thin", "residual", "networks", "is", "far", "from", "optimal", ".", "Also", ",", "wide", "WRN", "-", "28", "-", "10", "outperforms", "thin", "ResNet", "-", "1001", "by", "0.92", "%", "(", "with", "the", "same", "minibatch", "size", "during", "training", ")", "on", "CIFAR", "-", "10", "and", "3.46", "%", "on", "CIFAR", "-", "100", ",", "having", "36", "times", "less", "layers", "(", "see", "table", "[", "reference", "]", ")", ".", "We", "note", "that", "the", "result", "of", "4.64", "%", "with", "ResNet", "-", "1001", "was", "obtained", "with", "batch", "size", "64", ",", "whereas", "we", "use", "a", "batch", "size", "128", "in", "all", "of", "our", "experiments", "(", "i.e.", ",", "all", "other", "results", "reported", "in", "table", "[", "reference", "]", "are", "with", "batch", "size", "128", ")", ".", "Training", "curves", "for", "these", "networks", "are", "presented", "in", "Figure", "[", "reference", "]", ".", "Despite", "previous", "arguments", "that", "depth", "gives", "regularization", "effects", "and", "width", "causes", "network", "to", "overfit", ",", "we", "successfully", "train", "networks", "with", "several", "times", "more", "parameters", "than", "ResNet", "-", "1001", ".", "For", "instance", ",", "wide", "WRN", "-", "28", "-", "10", "(", "table", "[", "reference", "]", ")", "and", "wide", "WRN", "-", "40", "-", "10", "(", "table", "[", "reference", "]", ")", "have", "respectively", "and", "times", "more", "parameters", "than", "ResNet", "-", "1001", "and", "both", "outperform", "it", "by", "a", "significant", "margin", ".", "In", "general", ",", "we", "observed", "that", "CIFAR", "mean", "/", "std", "preprocessing", "allows", "training", "wider", "and", "deeper", "networks", "with", "better", "accuracy", ",", "and", "achieved", "18.3", "%", "on", "CIFAR", "-", "100", "using", "WRN", "-", "40", "-", "10", "with", "parameters", "(", "table", "[", "reference", "]", ")", ",", "giving", "a", "total", "improvement", "of", "4.4", "%", "over", "ResNet", "-", "1001", "and", "establishing", "a", "new", "state", "-", "of", "-", "the", "-", "art", "result", "on", "this", "dataset", ".", "To", "summarize", ":", "widening", "consistently", "improves", "performance", "across", "residual", "networks", "of", "different", "depth", ";", "increasing", "both", "depth", "and", "width", "helps", "until", "the", "number", "of", "parameters", "becomes", "too", "high", "and", "stronger", "regularization", "is", "needed", ";", "there", "does", "n\u2019t", "seem", "to", "be", "a", "regularization", "effect", "from", "very", "high", "depth", "in", "residual", "networks", "as", "wide", "networks", "with", "the", "same", "number", "of", "parameters", "as", "thin", "ones", "can", "learn", "same", "or", "better", "representations", ".", "Furthermore", ",", "wide", "networks", "can", "successfully", "learn", "with", "a", "2", "or", "more", "times", "larger", "number", "of", "parameters", "than", "thin", "ones", ",", "which", "would", "require", "doubling", "the", "depth", "of", "thin", "networks", ",", "making", "them", "infeasibly", "expensive", "to", "train", ".", "[", "scale=0.42", "]", ".", "/", "images", "/", "cifar10.pdf", "[", "scale=0.42", "]", ".", "/", "images", "/", "cifar100.pdf", "subsubsection", ":", "Dropout", "in", "residual", "blocks", "We", "trained", "networks", "with", "dropout", "inserted", "into", "residual", "block", "between", "convolutions", "on", "all", "datasets", ".", "We", "used", "cross", "-", "validation", "to", "determine", "dropout", "probability", "values", ",", "0.3", "on", "CIFAR", "and", "0.4", "on", "SVHN", ".", "Also", ",", "we", "did", "n\u2019t", "have", "to", "increase", "number", "of", "training", "epochs", "compared", "to", "baseline", "networks", "without", "dropout", ".", "Dropout", "decreases", "test", "error", "on", "CIFAR", "-", "10", "and", "CIFAR", "-", "100", "by", "0.11", "%", "and", "0.4", "%", "correnspondingly", "(", "over", "median", "of", "5", "runs", "and", "mean", "/", "std", "preprocessing", ")", "with", "WRN", "-", "28", "-", "10", ",", "and", "gives", "improvements", "with", "other", "ResNets", "as", "well", "(", "table", "[", "reference", "]", ")", ".", "To", "our", "knowledge", ",", "that", "was", "the", "first", "result", "to", "approach", "20", "%", "error", "on", "CIFAR", "-", "100", ",", "even", "outperforming", "methods", "with", "heavy", "data", "augmentation", ".", "There", "is", "only", "a", "slight", "drop", "in", "accuracy", "with", "WRN", "-", "16", "-", "4", "on", "CIFAR", "-", "10", "which", "we", "speculate", "is", "due", "to", "the", "relatively", "small", "number", "of", "parameters", ".", "We", "notice", "a", "disturbing", "effect", "in", "residual", "network", "training", "after", "the", "first", "learning", "rate", "drop", "when", "both", "loss", "and", "validation", "error", "suddenly", "start", "to", "go", "up", "and", "oscillate", "on", "high", "values", "until", "the", "next", "learning", "rate", "drop", ".", "We", "found", "out", "that", "it", "is", "caused", "by", "weight", "decay", ",", "however", "making", "it", "lower", "leads", "to", "a", "significant", "drop", "in", "accuracy", ".", "Interestingly", ",", "dropout", "partially", "removes", "this", "effect", "in", "most", "cases", ",", "see", "figures", "[", "reference", "]", ",", "[", "reference", "]", ".", "The", "effect", "of", "dropout", "becomes", "more", "evident", "on", "SVHN", ".", "This", "is", "probably", "due", "to", "the", "fact", "that", "we", "do", "n\u2019t", "do", "any", "data", "augmentation", "and", "batch", "normalization", "overfits", ",", "so", "dropout", "adds", "a", "regularization", "effect", ".", "Evidence", "for", "this", "can", "be", "found", "on", "training", "curves", "in", "figure", "[", "reference", "]", "where", "the", "loss", "without", "dropout", "drops", "to", "very", "low", "values", ".", "The", "results", "are", "presented", "in", "table", "[", "reference", "]", ".", "We", "observe", "significant", "improvements", "from", "using", "dropout", "on", "both", "thin", "and", "wide", "networks", ".", "Thin", "50", "-", "layer", "deep", "network", "even", "outperforms", "thin", "152", "-", "layer", "deep", "network", "with", "stochastic", "depth", ".", "We", "additionally", "trained", "WRN", "-", "16", "-", "8", "with", "dropout", "on", "SVHN", "(", "table", "[", "reference", "]", ")", ",", "which", "achieves", "1.54", "%", "on", "SVHN", "-", "the", "best", "published", "result", "to", "our", "knowledge", ".", "Without", "dropout", "it", "achieves", "1.81", "%", ".", "Overall", ",", "despite", "the", "arguments", "of", "combining", "with", "batch", "normalization", ",", "dropout", "shows", "itself", "as", "an", "effective", "techique", "of", "regularization", "of", "thin", "and", "wide", "networks", ".", "It", "can", "be", "used", "to", "further", "improve", "results", "from", "widening", ",", "while", "also", "being", "complementary", "to", "it", ".", "[", "scale=0.42", "]", ".", "/", "images", "/", "svhn.pdf", "[", "scale=0.42", "]", ".", "/", "images", "/", "svhn", "-", "dropout.pdf", "subsubsection", ":", "ImageNet", "and", "COCO", "experiments", "For", "ImageNet", "we", "first", "experiment", "with", "non", "-", "bottleneck", "ResNet", "-", "18", "and", "ResNet", "-", "34", ",", "trying", "to", "gradually", "increase", "their", "width", "from", "1.0", "to", "3.0", ".", "The", "results", "are", "shown", "in", "table", "[", "reference", "]", ".", "Increasing", "width", "gradually", "increases", "accuracy", "of", "both", "networks", ",", "and", "networks", "with", "a", "comparable", "number", "of", "parameters", "achieve", "similar", "results", ",", "despite", "having", "different", "depth", ".", "Althouth", "these", "networks", "have", "a", "large", "number", "of", "parameters", ",", "they", "are", "outperfomed", "by", "bottleneck", "networks", ",", "which", "is", "probably", "either", "due", "to", "that", "bottleneck", "architecture", "is", "simply", "better", "suited", "for", "ImageNet", "classification", "task", ",", "or", "due", "to", "that", "this", "more", "complex", "task", "needs", "a", "deeper", "network", ".", "To", "test", "this", ",", "we", "took", "the", "ResNet", "-", "50", ",", "and", "tried", "to", "make", "it", "wider", "by", "increasing", "inner", "layer", "width", ".", "With", "widening", "factor", "of", "2.0", "the", "resulting", "WRN", "-", "50", "-", "2", "-", "bottleneck", "outperforms", "ResNet", "-", "152", "having", "3", "times", "less", "layers", ",", "and", "being", "significantly", "faster", ".", "WRN", "-", "50", "-", "2", "-", "bottleneck", "is", "only", "slightly", "worse", "and", "almost", "faster", "than", "the", "best", "-", "performing", "pre", "-", "activation", "ResNet", "-", "200", ",", "althouth", "having", "slightly", "more", "parameters", "(", "table", "[", "reference", "]", ")", ".", "In", "general", ",", "we", "find", "that", ",", "unlike", "CIFAR", ",", "ImageNet", "networks", "need", "more", "width", "at", "the", "same", "depth", "to", "achieve", "the", "same", "accuracy", ".", "It", "is", "however", "clear", "that", "it", "is", "unnecessary", "to", "have", "residual", "networks", "with", "more", "than", "50", "layers", "due", "to", "computational", "reasons", ".", "We", "did", "n\u2019t", "try", "to", "train", "bigger", "bottleneck", "networks", "as", "8", "-", "GPU", "machines", "are", "needed", "for", "that", ".", "We", "also", "used", "WRN", "-", "34", "-", "2", "to", "participate", "in", "COCO", "2016", "object", "detection", "challenge", ",", "using", "a", "combination", "of", "MultiPathNet", "and", "LocNet", ".", "Despite", "having", "only", "34", "layers", ",", "this", "model", "achieves", "state", "-", "of", "-", "the", "-", "art", "single", "model", "performance", ",", "outperforming", "even", "ResNet", "-", "152", "and", "Inception", "-", "v4", "-", "based", "models", ".", "Finally", ",", "in", "table", "[", "reference", "]", "we", "summarize", "our", "best", "WRN", "results", "over", "various", "commonly", "used", "datasets", ".", "subsubsection", ":", "Computational", "efficiency", "Thin", "and", "deep", "residual", "networks", "with", "small", "kernels", "are", "against", "the", "nature", "of", "GPU", "computations", "because", "of", "their", "sequential", "structure", ".", "Increasing", "width", "helps", "effectively", "balance", "computations", "in", "much", "more", "optimal", "way", ",", "so", "that", "wide", "networks", "are", "many", "times", "more", "efficient", "than", "thin", "ones", "as", "our", "benchmarks", "show", ".", "We", "use", "cudnn", "v5", "and", "Titan", "X", "to", "measure", "forward", "+", "backward", "update", "times", "with", "minibatch", "size", "32", "for", "several", "networks", ",", "the", "results", "are", "in", "the", "figure", "[", "reference", "]", ".", "We", "show", "that", "our", "best", "CIFAR", "wide", "WRN", "-", "28", "-", "10", "is", "1.6", "times", "faster", "than", "thin", "ResNet", "-", "1001", ".", "Furthermore", ",", "wide", "WRN", "-", "40", "-", "4", ",", "which", "has", "approximately", "the", "same", "accuracy", "as", "ResNet", "-", "1001", ",", "is", "8", "times", "faster", ".", "[", "scale=0.6", "]", ".", "/", "images", "/", "benchmark", "-", "edited.pdf", "subsubsection", ":", "Implementation", "details", "In", "all", "our", "experiments", "we", "use", "SGD", "with", "Nesterov", "momentum", "and", "cross", "-", "entropy", "loss", ".", "The", "initial", "learning", "rate", "is", "set", "to", "0.1", ",", "weight", "decay", "to", "0.0005", ",", "dampening", "to", "0", ",", "momentum", "to", "0.9", "and", "minibatch", "size", "to", "128", ".", "On", "CIFAR", "learning", "rate", "dropped", "by", "0.2", "at", "60", ",", "120", "and", "160", "epochs", "and", "we", "train", "for", "total", "200", "epochs", ".", "On", "SVHN", "initial", "learning", "rate", "is", "set", "to", "0.01", "and", "we", "drop", "it", "at", "80", "and", "120", "epochs", "by", "0.1", ",", "training", "for", "total", "160", "epochs", ".", "Our", "implementation", "is", "based", "on", "Torch", ".", "We", "use", "to", "reduce", "memory", "footprints", "of", "all", "our", "networks", ".", "For", "ImageNet", "experiments", "we", "used", "fb.resnet.torch", "implementation", ".", "Our", "code", "and", "models", "are", "available", "at", "https:", "//", "github.com", "/", "szagoruyko", "/", "wide", "-", "residual", "-", "networks", ".", "section", ":", "Conclusions", "We", "presented", "a", "study", "on", "the", "width", "of", "residual", "networks", "as", "well", "as", "on", "the", "use", "of", "dropout", "in", "residual", "architectures", ".", "Based", "on", "this", "study", ",", "we", "proposed", "a", "wide", "residual", "network", "architecture", "that", "provides", "state", "-", "of", "-", "the", "-", "art", "results", "on", "several", "commonly", "used", "benchmark", "datasets", "(", "including", "CIFAR", "-", "10", ",", "CIFAR", "-", "100", ",", "SVHN", "and", "COCO", ")", ",", "as", "well", "as", "significant", "improvements", "on", "ImageNet", ".", "We", "demonstrate", "that", "wide", "networks", "with", "only", "16", "layers", "can", "significantly", "outperform", "1000", "-", "layer", "deep", "networks", "on", "CIFAR", ",", "as", "well", "as", "that", "50", "-", "layer", "outperform", "152", "-", "layer", "on", "ImageNet", ",", "thus", "showing", "that", "the", "main", "power", "of", "residual", "networks", "is", "in", "residual", "blocks", ",", "and", "not", "in", "extreme", "depth", "as", "claimed", "earlier", ".", "Also", ",", "wide", "residual", "networks", "are", "several", "times", "faster", "to", "train", ".", "We", "think", "that", "these", "intriguing", "findings", "will", "help", "further", "advances", "in", "research", "in", "deep", "neural", "networks", ".", "section", ":", "Acknowledgements", "We", "thank", "startup", "company", "VisionLabs", "and", "Eugenio", "Culurciello", "for", "giving", "us", "access", "to", "their", "clusters", ",", "without", "them", "ImageNet", "experiments", "would", "n\u2019t", "be", "possible", ".", "We", "also", "thank", "Adam", "Lerer", "and", "Sam", "Gross", "for", "helpful", "discussions", ".", "Work", "supported", "by", "EC", "project", "FP7", "-", "ICT", "-", "611145", "ROBOSPECT", ".", "bibliography", ":", "References"]}