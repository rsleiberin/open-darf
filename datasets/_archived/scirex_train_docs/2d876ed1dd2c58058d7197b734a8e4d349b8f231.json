{"coref": {"BLEU_score": [], "IWSLT2015_German-English": [[3159, 3160], [3163, 3164]], "Machine_Translation": [[271, 273], [1662, 1664], [3085, 3091], [4036, 4038], [139, 141], [313, 315], [550, 552], [2037, 2039], [3110, 3112], [3689, 3691], [3776, 3778]], "QRNN": [[2, 7], [46, 51], [52, 53], [149, 150], [463, 468], [473, 474], [484, 485], [509, 510], [527, 529], [576, 581], [663, 664], [1061, 1063], [1090, 1092], [1135, 1137], [1156, 1157], [1172, 1174], [1342, 1344], [1449, 1452], [1462, 1464], [1487, 1489], [1573, 1574], [1584, 1586], [1591, 1593], [1600, 1602], [1645, 1646], [1668, 1669], [1674, 1675], [1765, 1771], [2015, 2016], [2041, 2043], [2076, 2078], [2171, 2178], [2243, 2245], [2316, 2318], [2381, 2383], [2401, 2403], [2429, 2432], [2447, 2449], [2535, 2536], [2547, 2552], [2643, 2644], [2669, 2671], [2694, 2695], [2740, 2744], [2773, 2774], [2795, 2796], [2864, 2865], [2906, 2907], [2952, 2954], [2979, 2981], [3094, 3101], [3204, 3211], [3352, 3353], [3369, 3370], [3409, 3414], [3525, 3527], [3554, 3555], [3589, 3590], [3615, 3616], [3750, 3755], [3886, 3887], [3903, 3904], [3962, 3963], [3991, 3992], [93, 94], [1323, 1324]]}, "coref_non_salient": {"0": [[892, 896], [3124, 3129]], "1": [[178, 183], [950, 953]], "10": [[2089, 2093], [2325, 2327]], "100": [[3798, 3803]], "101": [[590, 594]], "102": [[58, 61], [469, 472]], "103": [[3295, 3297]], "104": [[3459, 3460]], "105": [[430, 437]], "106": [[2188, 2194]], "107": [[3198, 3199]], "108": [[173, 175]], "109": [[1236, 1238]], "11": [[96, 98], [230, 231], [3906, 3908]], "110": [[1653, 1659]], "111": [[3780, 3782]], "112": [[1257, 1262], [2810, 2816]], "113": [[3276, 3278]], "114": [[7, 10], [165, 168]], "115": [[2583, 2584]], "116": [[1066, 1070]], "117": [[1176, 1179]], "118": [[2714, 2715]], "119": [[2404, 2408]], "12": [[1192, 1194], [2207, 2209], [3066, 3068]], "120": [[1184, 1186]], "121": [[1243, 1248]], "122": [[1453, 1457]], "123": [[1254, 1256]], "124": [[2525, 2528]], "125": [[3035, 3040]], "126": [[659, 661]], "127": [[411, 413]], "128": [[279, 281]], "129": [[424, 426]], "13": [[1438, 1442], [2680, 2684]], "130": [[2767, 2769]], "131": [[1166, 1167]], "132": [[1277, 1279]], "133": [[793, 794]], "134": [[198, 201]], "135": [[2856, 2859]], "136": [[3897, 3902]], "137": [[1220, 1222], [1329, 1332]], "138": [[1409, 1411]], "139": [[694, 699]], "14": [[2418, 2420], [2421, 2422], [2493, 2495], [2926, 2927], [2852, 2853]], "140": [[3738, 3742]], "141": [[384, 386]], "142": [[1445, 1447]], "143": [[1494, 1496]], "144": [[2586, 2587]], "145": [[194, 197]], "146": [[232, 234]], "15": [[99, 101], [2726, 2728]], "16": [[840, 843], [2451, 2454]], "17": [[2210, 2211], [2575, 2576], [2976, 2977], [3264, 3265]], "18": [[3507, 3510], [3580, 3583]], "19": [[2386, 2388], [2391, 2393]], "2": [[1703, 1707], [3250, 3252], [3260, 3262]], "20": [[3288, 3290], [3356, 3359], [4076, 4078], [4084, 4086]], "21": [[1198, 1199], [1233, 1234], [1383, 1384], [2633, 2634], [3333, 3336]], "22": [[4121, 4122]], "23": [[1948, 1950], [1989, 1993]], "24": [[1678, 1679], [1968, 1970], [3330, 3331]], "25": [[4019, 4023]], "26": [[408, 410], [1146, 1150]], "27": [[1215, 1218], [2719, 2721], [3047, 3049]], "28": [[75, 79], [2360, 2363]], "29": [[131, 133], [241, 243], [307, 309], [2071, 2073], [3645, 3647], [3651, 3653]], "3": [[121, 125], [2259, 2262]], "30": [[2249, 2251], [3977, 3979]], "31": [[672, 675], [701, 702], [766, 768]], "32": [[3465, 3473]], "33": [[128, 130], [245, 253], [543, 545], [2029, 2031]], "34": [[3300, 3305], [4025, 4030], [4102, 4104]], "35": [[804, 806], [1347, 1349], [1388, 1390]], "36": [[2800, 2801]], "37": [[3999, 4003]], "38": [[738, 740], [846, 848]], "39": [[3743, 3748]], "4": [[566, 568], [1056, 1058], [1983, 1985], [2059, 2061], [3024, 3026]], "40": [[191, 193], [1650, 1652]], "41": [[1670, 1671], [1681, 1682], [1757, 1758], [1883, 1884], [3695, 3696]], "42": [[3223, 3225]], "43": [[3432, 3435], [3503, 3506], [3548, 3551]], "44": [[2947, 2949], [3069, 3070]], "45": [[3767, 3768]], "46": [[3934, 3938]], "47": [[1710, 1715], [1743, 1747]], "48": [[1227, 1228], [1289, 1290], [2543, 2544], [2628, 2629], [2672, 2673], [1339, 1340], [2702, 2703], [2761, 2762], [2784, 2785]], "49": [[420, 422], [2959, 2962]], "5": [[236, 239], [532, 535], [1115, 1118], [2019, 2022]], "50": [[89, 91], [215, 217]], "51": [[3495, 3500]], "52": [[2414, 2416]], "53": [[3711, 3716]], "54": [[184, 185], [290, 291], [1195, 1196], [2677, 2678], [2871, 2872], [3055, 3056], [3643, 3644], [557, 558], [867, 868], [914, 915], [2044, 2045], [2268, 2269], [2708, 2709], [2712, 2713], [2748, 2749], [2804, 2805], [2880, 2881], [2899, 2900], [2903, 2904], [2930, 2931], [3328, 3329], [3375, 3376], [3514, 3515], [3676, 3677], [3909, 3910]], "55": [[997, 1000], [3595, 3601]], "56": [[37, 38], [169, 170], [202, 203], [255, 256], [287, 288], [507, 508], [3397, 3398], [3955, 3956], [4009, 4010]], "57": [[626, 628], [630, 632]], "58": [[159, 161], [1472, 1475], [3399, 3401]], "59": [[3284, 3285]], "6": [[3425, 3431], [3584, 3587]], "60": [[2272, 2276]], "61": [[3383, 3388]], "62": [[3622, 3627]], "63": [[2222, 2224], [2589, 2591]], "64": [[2923, 2925]], "65": [[1549, 1551]], "66": [[2933, 2935]], "67": [[598, 600], [825, 827]], "68": [[665, 666], [763, 764], [3242, 3244], [3655, 3656]], "69": [[537, 542], [2023, 2028], [2081, 2087]], "7": [[335, 338], [1083, 1086], [1468, 1470], [1501, 1507]], "70": [[1636, 1640], [1831, 1835]], "71": [[3702, 3705]], "72": [[1719, 1724]], "73": [[1541, 1543]], "74": [[1544, 1546]], "75": [[3565, 3568]], "76": [[1074, 1080]], "77": [[2331, 2334]], "78": [[3865, 3868]], "79": [[3114, 3122]], "8": [[2996, 2997], [3020, 3021]], "80": [[3341, 3342]], "81": [[3719, 3721]], "82": [[339, 340], [379, 380], [482, 483], [595, 596], [605, 606], [633, 634], [3630, 3631], [3953, 3954]], "83": [[3518, 3521]], "84": [[1225, 1226]], "85": [[365, 370]], "86": [[2825, 2832]], "87": [[2502, 2503]], "88": [[2049, 2052], [3914, 3917]], "89": [[2461, 2464]], "9": [[63, 65], [602, 604], [3698, 3700], [3726, 3733]], "90": [[487, 489], [609, 611]], "91": [[357, 360]], "92": [[799, 801]], "93": [[2219, 2220]], "94": [[2939, 2941]], "95": [[2579, 2582]], "96": [[4033, 4035]], "97": [[498, 499]], "98": [[2911, 2915]], "99": [[1516, 1518]]}, "doc_id": "2d876ed1dd2c58058d7197b734a8e4d349b8f231", "method_subrelations": {"QRNN": [[[0, 4], "QRNN"]]}, "n_ary_relations": [{"Material": "IWSLT2015_German-English", "Method": "QRNN", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "19.41"}], "ner": [[2, 7, "Method"], [7, 10, "Method"], [37, 38, "Method"], [46, 51, "Method"], [52, 53, "Method"], [58, 61, "Task"], [63, 65, "Method"], [75, 79, "Method"], [89, 91, "Method"], [96, 98, "Metric"], [99, 101, "Method"], [121, 125, "Metric"], [128, 130, "Task"], [131, 133, "Task"], [149, 150, "Method"], [159, 161, "Task"], [165, 168, "Method"], [169, 170, "Method"], [173, 175, "Method"], [178, 183, "Method"], [184, 185, "Method"], [191, 193, "Method"], [194, 197, "Method"], [198, 201, "Task"], [202, 203, "Method"], [215, 217, "Method"], [230, 231, "Metric"], [232, 234, "Method"], [236, 239, "Task"], [241, 243, "Task"], [245, 253, "Task"], [255, 256, "Method"], [271, 273, "Task"], [279, 281, "Task"], [287, 288, "Method"], [290, 291, "Method"], [307, 309, "Task"], [335, 338, "Method"], [339, 340, "Method"], [357, 360, "Task"], [365, 370, "Method"], [379, 380, "Method"], [384, 386, "Method"], [408, 410, "Method"], [411, 413, "Task"], [420, 422, "Method"], [424, 426, "Method"], [430, 437, "Method"], [463, 468, "Method"], [469, 472, "Task"], [473, 474, "Method"], [482, 483, "Method"], [484, 485, "Method"], [487, 489, "Task"], [498, 499, "Metric"], [507, 508, "Method"], [509, 510, "Method"], [527, 529, "Method"], [532, 535, "Task"], [537, 542, "Task"], [543, 545, "Task"], [566, 568, "Metric"], [576, 581, "Method"], [590, 594, "Method"], [595, 596, "Method"], [598, 600, "Method"], [602, 604, "Method"], [605, 606, "Method"], [609, 611, "Task"], [626, 628, "Method"], [630, 632, "Method"], [633, 634, "Method"], [659, 661, "Method"], [663, 664, "Method"], [665, 666, "Method"], [672, 675, "Method"], [694, 699, "Task"], [701, 702, "Method"], [738, 740, "Method"], [763, 764, "Method"], [766, 768, "Method"], [793, 794, "Method"], [799, 801, "Method"], [804, 806, "Method"], [825, 827, "Method"], [840, 843, "Method"], [846, 848, "Method"], [892, 896, "Task"], [950, 953, "Method"], [997, 1000, "Method"], [1056, 1058, "Metric"], [1061, 1063, "Method"], [1066, 1070, "Method"], [1074, 1080, "Method"], [1083, 1086, "Method"], [1090, 1092, "Method"], [1115, 1118, "Task"], [1135, 1137, "Method"], [1146, 1150, "Method"], [1156, 1157, "Method"], [1166, 1167, "Task"], [1172, 1174, "Method"], [1176, 1179, "Method"], [1184, 1186, "Method"], [1192, 1194, "Method"], [1195, 1196, "Method"], [1198, 1199, "Method"], [1215, 1218, "Method"], [1220, 1222, "Method"], [1225, 1226, "Method"], [1227, 1228, "Method"], [1233, 1234, "Method"], [1236, 1238, "Task"], [1243, 1248, "Method"], [1254, 1256, "Method"], [1257, 1262, "Method"], [1277, 1279, "Method"], [1289, 1290, "Method"], [1329, 1332, "Method"], [1342, 1344, "Method"], [1347, 1349, "Method"], [1383, 1384, "Method"], [1388, 1390, "Method"], [1409, 1411, "Method"], [1438, 1442, "Method"], [1445, 1447, "Method"], [1449, 1452, "Method"], [1453, 1457, "Method"], [1462, 1464, "Method"], [1468, 1470, "Method"], [1472, 1475, "Task"], [1487, 1489, "Method"], [1494, 1496, "Method"], [1501, 1507, "Method"], [1516, 1518, "Method"], [1541, 1543, "Metric"], [1544, 1546, "Metric"], [1549, 1551, "Task"], [1573, 1574, "Method"], [1584, 1586, "Method"], [1591, 1593, "Method"], [1600, 1602, "Method"], [1636, 1640, "Method"], [1645, 1646, "Method"], [1650, 1652, "Method"], [1653, 1659, "Task"], [1662, 1664, "Task"], [1668, 1669, "Method"], [1670, 1671, "Method"], [1674, 1675, "Method"], [1678, 1679, "Method"], [1681, 1682, "Method"], [1703, 1707, "Method"], [1710, 1715, "Method"], [1719, 1724, "Method"], [1743, 1747, "Method"], [1757, 1758, "Method"], [1765, 1771, "Method"], [1831, 1835, "Method"], [1883, 1884, "Method"], [1948, 1950, "Method"], [1968, 1970, "Method"], [1983, 1985, "Metric"], [1989, 1993, "Method"], [2015, 2016, "Method"], [2019, 2022, "Task"], [2023, 2028, "Task"], [2029, 2031, "Task"], [2041, 2043, "Method"], [2049, 2052, "Method"], [2059, 2061, "Metric"], [2071, 2073, "Task"], [2076, 2078, "Method"], [2081, 2087, "Task"], [2089, 2093, "Material"], [2171, 2178, "Method"], [2188, 2194, "Method"], [2207, 2209, "Method"], [2210, 2211, "Task"], [2219, 2220, "Method"], [2222, 2224, "Metric"], [2243, 2245, "Method"], [2249, 2251, "Method"], [2259, 2262, "Metric"], [2272, 2276, "Method"], [2316, 2318, "Method"], [2325, 2327, "Material"], [2331, 2334, "Method"], [2360, 2363, "Method"], [2381, 2383, "Method"], [2386, 2388, "Method"], [2391, 2393, "Method"], [2401, 2403, "Method"], [2404, 2408, "Task"], [2414, 2416, "Method"], [2418, 2420, "Material"], [2421, 2422, "Material"], [2429, 2432, "Method"], [2447, 2449, "Method"], [2451, 2454, "Method"], [2461, 2464, "Method"], [2493, 2495, "Material"], [2502, 2503, "Task"], [2525, 2528, "Method"], [2535, 2536, "Method"], [2543, 2544, "Method"], [2547, 2552, "Method"], [2575, 2576, "Task"], [2579, 2582, "Method"], [2583, 2584, "Method"], [2586, 2587, "Method"], [2589, 2591, "Metric"], [2628, 2629, "Method"], [2633, 2634, "Method"], [2643, 2644, "Method"], [2669, 2671, "Method"], [2672, 2673, "Method"], [2677, 2678, "Method"], [2680, 2684, "Method"], [2694, 2695, "Method"], [2714, 2715, "Method"], [2719, 2721, "Method"], [2726, 2728, "Method"], [2740, 2744, "Method"], [2767, 2769, "Metric"], [2773, 2774, "Method"], [2795, 2796, "Method"], [2800, 2801, "Metric"], [2810, 2816, "Method"], [2825, 2832, "Method"], [2856, 2859, "Method"], [2864, 2865, "Method"], [2871, 2872, "Method"], [2906, 2907, "Method"], [2911, 2915, "Method"], [2923, 2925, "Method"], [2926, 2927, "Material"], [2933, 2935, "Metric"], [2939, 2941, "Method"], [2947, 2949, "Method"], [2952, 2954, "Method"], [2959, 2962, "Method"], [2976, 2977, "Task"], [2979, 2981, "Method"], [2996, 2997, "Method"], [3020, 3021, "Method"], [3024, 3026, "Metric"], [3035, 3040, "Method"], [3047, 3049, "Method"], [3055, 3056, "Method"], [3066, 3068, "Method"], [3069, 3070, "Method"], [3085, 3091, "Task"], [3094, 3101, "Method"], [3114, 3122, "Task"], [3124, 3129, "Task"], [3159, 3160, "Material"], [3163, 3164, "Material"], [3198, 3199, "Material"], [3204, 3211, "Method"], [3223, 3225, "Method"], [3242, 3244, "Method"], [3250, 3252, "Method"], [3260, 3262, "Method"], [3264, 3265, "Task"], [3276, 3278, "Method"], [3284, 3285, "Task"], [3288, 3290, "Method"], [3295, 3297, "Method"], [3300, 3305, "Metric"], [3330, 3331, "Method"], [3333, 3336, "Method"], [3341, 3342, "Method"], [3352, 3353, "Method"], [3356, 3359, "Method"], [3369, 3370, "Method"], [3383, 3388, "Method"], [3397, 3398, "Method"], [3399, 3401, "Task"], [3409, 3414, "Method"], [3425, 3431, "Method"], [3432, 3435, "Method"], [3459, 3460, "Method"], [3465, 3473, "Method"], [3495, 3500, "Method"], [3503, 3506, "Method"], [3507, 3510, "Method"], [3518, 3521, "Method"], [3525, 3527, "Method"], [3548, 3551, "Method"], [3554, 3555, "Method"], [3565, 3568, "Method"], [3580, 3583, "Method"], [3584, 3587, "Method"], [3589, 3590, "Method"], [3595, 3601, "Method"], [3615, 3616, "Method"], [3622, 3627, "Method"], [3630, 3631, "Method"], [3643, 3644, "Method"], [3645, 3647, "Task"], [3651, 3653, "Task"], [3655, 3656, "Method"], [3695, 3696, "Method"], [3698, 3700, "Method"], [3702, 3705, "Method"], [3711, 3716, "Method"], [3719, 3721, "Method"], [3726, 3733, "Method"], [3738, 3742, "Method"], [3743, 3748, "Task"], [3750, 3755, "Method"], [3767, 3768, "Method"], [3780, 3782, "Method"], [3798, 3803, "Metric"], [3865, 3868, "Method"], [3886, 3887, "Method"], [3897, 3902, "Method"], [3903, 3904, "Method"], [3906, 3908, "Metric"], [3914, 3917, "Method"], [3934, 3938, "Metric"], [3953, 3954, "Method"], [3955, 3956, "Method"], [3962, 3963, "Method"], [3977, 3979, "Method"], [3991, 3992, "Method"], [3999, 4003, "Task"], [4009, 4010, "Method"], [4019, 4023, "Metric"], [4025, 4030, "Metric"], [4033, 4035, "Task"], [4036, 4038, "Task"], [4076, 4078, "Method"], [4084, 4086, "Method"], [4102, 4104, "Metric"], [4121, 4122, "Method"], [93, 94, "Method"], [139, 141, "Task"], [313, 315, "Task"], [550, 552, "Task"], [557, 558, "Method"], [867, 868, "Method"], [914, 915, "Method"], [1323, 1324, "Method"], [1339, 1340, "Method"], [2037, 2039, "Task"], [2044, 2045, "Method"], [2268, 2269, "Method"], [2702, 2703, "Method"], [2708, 2709, "Method"], [2712, 2713, "Method"], [2748, 2749, "Method"], [2761, 2762, "Method"], [2784, 2785, "Method"], [2804, 2805, "Method"], [2852, 2853, "Material"], [2880, 2881, "Method"], [2899, 2900, "Method"], [2903, 2904, "Method"], [2930, 2931, "Method"], [3110, 3112, "Task"], [3328, 3329, "Method"], [3375, 3376, "Method"], [3514, 3515, "Method"], [3676, 3677, "Method"], [3689, 3691, "Task"], [3776, 3778, "Task"], [3909, 3910, "Method"]], "sections": [[0, 162], [162, 569], [569, 1108], [1108, 2006], [2006, 2069], [2069, 2384], [2384, 3083], [3083, 3389], [3389, 3820], [3820, 4011], [4011, 4014], [4014, 4017], [4017, 4126]], "sentences": [[0, 7], [7, 44], [44, 86], [86, 107], [107, 126], [126, 162], [162, 165], [165, 202], [202, 215], [215, 232], [232, 255], [255, 285], [285, 335], [335, 362], [362, 379], [379, 408], [408, 461], [461, 473], [473, 506], [506, 525], [525, 553], [553, 569], [569, 572], [572, 597], [597, 625], [625, 649], [649, 685], [685, 718], [718, 732], [732, 760], [760, 785], [785, 802], [802, 853], [853, 897], [897, 917], [917, 943], [943, 966], [966, 1016], [1016, 1059], [1059, 1081], [1081, 1108], [1108, 1111], [1111, 1140], [1140, 1166], [1166, 1167], [1167, 1187], [1187, 1222], [1222, 1230], [1230, 1257], [1257, 1289], [1289, 1322], [1322, 1336], [1336, 1362], [1362, 1398], [1398, 1431], [1431, 1453], [1453, 1457], [1457, 1471], [1471, 1499], [1499, 1538], [1538, 1567], [1567, 1594], [1594, 1620], [1620, 1636], [1636, 1683], [1683, 1748], [1748, 1759], [1759, 1783], [1783, 1831], [1831, 1872], [1872, 1885], [1885, 1891], [1891, 1904], [1904, 1935], [1935, 1962], [1962, 1988], [1988, 2006], [2006, 2009], [2009, 2040], [2040, 2062], [2062, 2069], [2069, 2073], [2073, 2095], [2095, 2134], [2134, 2157], [2157, 2196], [2196, 2210], [2210, 2229], [2229, 2252], [2252, 2277], [2277, 2292], [2292, 2301], [2301, 2328], [2328, 2350], [2350, 2384], [2384, 2388], [2388, 2409], [2409, 2426], [2426, 2446], [2446, 2458], [2458, 2491], [2491, 2515], [2515, 2537], [2537, 2562], [2562, 2575], [2575, 2588], [2588, 2615], [2615, 2628], [2628, 2654], [2654, 2664], [2664, 2699], [2699, 2729], [2729, 2760], [2760, 2778], [2778, 2819], [2819, 2848], [2848, 2882], [2882, 2928], [2928, 2950], [2950, 2968], [2968, 2993], [2993, 3027], [3027, 3050], [3050, 3081], [3081, 3083], [3083, 3091], [3091, 3130], [3130, 3165], [3165, 3190], [3190, 3232], [3232, 3248], [3248, 3264], [3264, 3284], [3284, 3298], [3298, 3311], [3311, 3337], [3337, 3362], [3362, 3389], [3389, 3393], [3393, 3409], [3409, 3439], [3439, 3474], [3474, 3522], [3522, 3544], [3544, 3578], [3578, 3614], [3614, 3628], [3628, 3648], [3648, 3678], [3678, 3692], [3692, 3722], [3722, 3749], [3749, 3786], [3786, 3820], [3820, 3823], [3823, 3863], [3863, 3886], [3886, 3903], [3903, 3929], [3929, 3950], [3950, 3988], [3988, 4011], [4011, 4014], [4014, 4017], [4017, 4023], [4023, 4071], [4071, 4126]], "words": ["document", ":", "Quasi", "-", "Recurrent", "Neural", "Networks", "Recurrent", "neural", "networks", "are", "a", "powerful", "tool", "for", "modeling", "sequential", "data", ",", "but", "the", "dependence", "of", "each", "timestep", "\u2019s", "computation", "on", "the", "previous", "timestep", "\u2019s", "output", "limits", "parallelism", "and", "makes", "RNNs", "unwieldy", "for", "very", "long", "sequences", ".", "We", "introduce", "quasi", "-", "recurrent", "neural", "networks", "(", "QRNNs", ")", ",", "an", "approach", "to", "neural", "sequence", "modeling", "that", "alternates", "convolutional", "layers", ",", "which", "apply", "in", "parallel", "across", "timesteps", ",", "and", "a", "minimalist", "recurrent", "pooling", "function", "that", "applies", "in", "parallel", "across", "channels", ".", "Despite", "lacking", "trainable", "recurrent", "layers", ",", "stacked", "QRNNs", "have", "better", "predictive", "accuracy", "than", "stacked", "LSTMs", "of", "the", "same", "hidden", "size", ".", "Due", "to", "their", "increased", "parallelism", ",", "they", "are", "up", "to", "16", "times", "faster", "at", "train", "and", "test", "time", ".", "Experiments", "on", "language", "modeling", ",", "sentiment", "classification", ",", "and", "character", "-", "level", "neural", "machine", "translation", "demonstrate", "these", "advantages", "and", "underline", "the", "viability", "of", "QRNNs", "as", "a", "basic", "building", "block", "for", "a", "variety", "of", "sequence", "tasks", ".", "section", ":", "Introduction", "Recurrent", "neural", "networks", "(", "RNNs", ")", ",", "including", "gated", "variants", "such", "as", "the", "long", "short", "-", "term", "memory", "(", "LSTM", ")", "Hochreiter1997", "have", "become", "the", "standard", "model", "architecture", "for", "deep", "learning", "approaches", "to", "sequence", "modeling", "tasks", ".", "RNNs", "repeatedly", "apply", "a", "function", "with", "trainable", "parameters", "to", "a", "hidden", "state", ".", "Recurrent", "layers", "can", "also", "be", "stacked", ",", "increasing", "network", "depth", ",", "representational", "power", "and", "often", "accuracy", ".", "RNN", "applications", "in", "the", "natural", "language", "domain", "range", "from", "sentence", "classification", "Wang2015", "to", "word", "-", "and", "character", "-", "level", "language", "modeling", "Zaremba2014", ".", "RNNs", "are", "also", "commonly", "the", "basic", "building", "block", "for", "more", "complex", "models", "for", "tasks", "such", "as", "machine", "translation", "Bahdanau2015", ",", "Luong2015", ",", "Bradbury2016", "or", "question", "answering", "Kumar2016", ",", "Xiong2016", ".", "Unfortunately", "standard", "RNNs", ",", "including", "LSTMs", ",", "are", "limited", "in", "their", "capability", "to", "handle", "tasks", "involving", "very", "long", "sequences", ",", "such", "as", "document", "classification", "or", "character", "-", "level", "machine", "translation", ",", "as", "the", "computation", "of", "features", "or", "states", "for", "different", "parts", "of", "the", "document", "can", "not", "occur", "in", "parallel", ".", "Convolutional", "neural", "networks", "(", "CNNs", ")", "Krizhevsky2012", ",", "though", "more", "popular", "on", "tasks", "involving", "image", "data", ",", "have", "also", "been", "applied", "to", "sequence", "encoding", "tasks", "Zhang2015", ".", "Such", "models", "apply", "time", "-", "invariant", "filter", "functions", "in", "parallel", "to", "windows", "along", "the", "input", "sequence", ".", "CNNs", "possess", "several", "advantages", "over", "recurrent", "models", ",", "including", "increased", "parallelism", "and", "better", "scaling", "to", "long", "sequences", "such", "as", "those", "often", "seen", "with", "character", "-", "level", "language", "data", ".", "Convolutional", "models", "for", "sequence", "processing", "have", "been", "more", "successful", "when", "combined", "with", "RNN", "layers", "in", "a", "hybrid", "architecture", "Lee2016", ",", "because", "traditional", "max", "-", "and", "average", "-", "pooling", "approaches", "to", "combining", "convolutional", "features", "across", "timesteps", "assume", "time", "invariance", "and", "hence", "can", "not", "make", "full", "use", "of", "large", "-", "scale", "sequence", "order", "information", ".", "We", "present", "quasi", "-", "recurrent", "neural", "networks", "for", "neural", "sequence", "modeling", ".", "QRNNs", "address", "both", "drawbacks", "of", "standard", "models", ":", "like", "CNNs", ",", "QRNNs", "allow", "for", "parallel", "computation", "across", "both", "timestep", "and", "minibatch", "dimensions", ",", "enabling", "high", "throughput", "and", "good", "scaling", "to", "long", "sequences", ".", "Like", "RNNs", ",", "QRNNs", "allow", "the", "output", "to", "depend", "on", "the", "overall", "order", "of", "elements", "in", "the", "sequence", ".", "We", "describe", "QRNN", "variants", "tailored", "to", "several", "natural", "language", "tasks", ",", "including", "document", "-", "level", "sentiment", "classification", ",", "language", "modeling", ",", "and", "character", "-", "level", "machine", "translation", ".", "These", "models", "outperform", "strong", "LSTM", "baselines", "on", "all", "three", "tasks", "while", "dramatically", "reducing", "computation", "time", ".", "section", ":", "Model", "Each", "layer", "of", "a", "quasi", "-", "recurrent", "neural", "network", "consists", "of", "two", "kinds", "of", "subcomponents", ",", "analogous", "to", "convolution", "and", "pooling", "layers", "in", "CNNs", ".", "The", "convolutional", "component", ",", "like", "convolutional", "layers", "in", "CNNs", ",", "allows", "fully", "parallel", "computation", "across", "both", "minibatches", "and", "spatial", "dimensions", ",", "in", "this", "case", "the", "sequence", "dimension", ".", "The", "pooling", "component", ",", "like", "pooling", "layers", "in", "CNNs", ",", "lacks", "trainable", "parameters", "and", "allows", "fully", "parallel", "computation", "across", "minibatch", "and", "feature", "dimensions", ".", "Given", "an", "input", "sequence", "of", "-", "dimensional", "vectors", ",", "the", "convolutional", "subcomponent", "of", "a", "QRNN", "performs", "convolutions", "in", "the", "timestep", "dimension", "with", "a", "bank", "of", "filters", ",", "producing", "a", "sequence", "of", "-", "dimensional", "candidate", "vectors", ".", "In", "order", "to", "be", "useful", "for", "tasks", "that", "include", "prediction", "of", "the", "next", "token", ",", "the", "filters", "must", "not", "allow", "the", "computation", "for", "any", "given", "timestep", "to", "access", "information", "from", "future", "timesteps", ".", "That", "is", ",", "with", "filters", "of", "width", ",", "each", "depends", "only", "on", "through", ".", "This", "concept", ",", "known", "as", "a", "masked", "convolution", "vandenOord2016", ",", "is", "implemented", "by", "padding", "the", "input", "to", "the", "left", "by", "the", "convolution", "\u2019s", "filter", "size", "minus", "one", ".", "We", "apply", "additional", "convolutions", "with", "separate", "filter", "banks", "to", "obtain", "sequences", "of", "vectors", "for", "the", "elementwise", "gates", "that", "are", "needed", "for", "the", "pooling", "function", ".", "While", "the", "candidate", "vectors", "are", "passed", "through", "a", "nonlinearity", ",", "the", "gates", "use", "an", "elementwise", "sigmoid", ".", "If", "the", "pooling", "function", "requires", "a", "forget", "gate", "and", "an", "output", "gate", "at", "each", "timestep", ",", "the", "full", "set", "of", "computations", "in", "the", "convolutional", "component", "is", "then", ":", "where", ",", ",", "and", ",", "each", "in", ",", "are", "the", "convolutional", "filter", "banks", "and", "denotes", "a", "masked", "convolution", "along", "the", "timestep", "dimension", ".", "Note", "that", "if", "the", "filter", "width", "is", "2", ",", "these", "equations", "reduce", "to", "the", "LSTM", "-", "like", "Convolution", "filters", "of", "larger", "width", "effectively", "compute", "higher", "-", "gram", "features", "at", "each", "timestep", ";", "thus", "larger", "widths", "are", "especially", "important", "for", "character", "-", "level", "tasks", ".", "Suitable", "functions", "for", "the", "pooling", "subcomponent", "can", "be", "constructed", "from", "the", "familiar", "elementwise", "gates", "of", "the", "traditional", "LSTM", "cell", ".", "We", "seek", "a", "function", "controlled", "by", "gates", "that", "can", "mix", "states", "across", "timesteps", ",", "but", "which", "acts", "independently", "on", "each", "channel", "of", "the", "state", "vector", ".", "The", "simplest", "option", ",", "which", "term", "\u201c", "dynamic", "average", "pooling", "\u201d", ",", "uses", "only", "a", "forget", "gate", ":", "where", "denotes", "elementwise", "multiplication", ".", "The", "function", "may", "also", "include", "an", "output", "gate", ":", "Or", "the", "recurrence", "relation", "may", "include", "an", "independent", "input", "and", "forget", "gate", ":", "We", "term", "these", "three", "options", "f", "-", "pooling", ",", "fo", "-", "pooling", ",", "and", "ifo", "-", "pooling", "respectively", ";", "in", "each", "case", "we", "initialize", "or", "to", "zero", ".", "Although", "the", "recurrent", "parts", "of", "these", "functions", "must", "be", "calculated", "for", "each", "timestep", "in", "sequence", ",", "their", "simplicity", "and", "parallelism", "along", "feature", "dimensions", "means", "that", ",", "in", "practice", ",", "evaluating", "them", "over", "even", "long", "sequences", "requires", "a", "negligible", "amount", "of", "computation", "time", ".", "A", "single", "QRNN", "layer", "thus", "performs", "an", "input", "-", "dependent", "pooling", ",", "followed", "by", "a", "gated", "linear", "combination", "of", "convolutional", "features", ".", "As", "with", "convolutional", "neural", "networks", ",", "two", "or", "more", "QRNN", "layers", "should", "be", "stacked", "to", "create", "a", "model", "with", "the", "capacity", "to", "approximate", "more", "complex", "functions", ".", "subsection", ":", "Variants", "Motivated", "by", "several", "common", "natural", "language", "tasks", ",", "and", "the", "long", "history", "of", "work", "on", "related", "architectures", ",", "we", "introduce", "several", "extensions", "to", "the", "stacked", "QRNN", "described", "above", ".", "Notably", ",", "many", "extensions", "to", "both", "recurrent", "and", "convolutional", "models", "can", "be", "applied", "directly", "to", "the", "QRNN", "as", "it", "combines", "elements", "of", "both", "model", "types", ".", "Regularization", "An", "important", "extension", "to", "the", "stacked", "QRNN", "is", "a", "robust", "regularization", "scheme", "inspired", "by", "recent", "work", "in", "regularizing", "LSTMs", ".", "The", "need", "for", "an", "effective", "regularization", "method", "for", "LSTMs", ",", "and", "dropout", "\u2019s", "relative", "lack", "of", "efficacy", "when", "applied", "to", "recurrent", "connections", ",", "led", "to", "the", "development", "of", "recurrent", "dropout", "schemes", ",", "including", "variational", "inference", "\u2013", "based", "dropout", "Gal2015", "and", "zoneout", "Krueger2016", ".", "These", "schemes", "extend", "dropout", "to", "the", "recurrent", "setting", "by", "taking", "advantage", "of", "the", "repeating", "structure", "of", "recurrent", "networks", ",", "providing", "more", "powerful", "and", "less", "destructive", "regularization", ".", "Variational", "inference", "\u2013", "based", "dropout", "locks", "the", "dropout", "mask", "used", "for", "the", "recurrent", "connections", "across", "timesteps", ",", "so", "a", "single", "RNN", "pass", "uses", "a", "single", "stochastic", "subset", "of", "the", "recurrent", "weights", ".", "Zoneout", "stochastically", "chooses", "a", "new", "subset", "of", "channels", "to", "\u201c", "zone", "out", "\u201d", "at", "each", "timestep", ";", "for", "these", "channels", "the", "network", "copies", "states", "from", "one", "timestep", "to", "the", "next", "without", "modification", ".", "As", "QRNNs", "lack", "recurrent", "weights", ",", "the", "variational", "inference", "approach", "does", "not", "apply", ".", "Thus", "we", "extended", "zoneout", "to", "the", "QRNN", "architecture", "by", "modifying", "the", "pooling", "function", "to", "keep", "the", "previous", "pooling", "state", "for", "a", "stochastic", "subset", "of", "channels", ".", "Conveniently", ",", "this", "is", "equivalent", "to", "stochastically", "setting", "a", "subset", "of", "the", "QRNN", "\u2019s", "gate", "channels", "to", "1", ",", "or", "applying", "dropout", "on", ":", "Thus", "the", "pooling", "function", "itself", "need", "not", "be", "modified", "at", "all", ".", "We", "note", "that", "when", "using", "an", "off", "-", "the", "-", "shelf", "dropout", "layer", "in", "this", "context", ",", "it", "is", "important", "to", "remove", "automatic", "rescaling", "functionality", "from", "the", "implementation", "if", "it", "is", "present", ".", "In", "many", "experiments", ",", "we", "also", "apply", "ordinary", "dropout", "between", "layers", ",", "including", "between", "word", "embeddings", "and", "the", "first", "QRNN", "layer", ".", "Densely", "-", "Connected", "Layers", "We", "can", "also", "extend", "the", "QRNN", "architecture", "using", "techniques", "introduced", "for", "convolutional", "networks", ".", "For", "sequence", "classification", "tasks", ",", "we", "found", "it", "helpful", "to", "use", "skip", "-", "connections", "between", "every", "QRNN", "layer", ",", "a", "technique", "termed", "\u201c", "dense", "convolution", "\u201d", "by", ".", "Where", "traditional", "feed", "-", "forward", "or", "convolutional", "networks", "have", "connections", "only", "between", "subsequent", "layers", ",", "a", "\u201c", "DenseNet", "\u201d", "with", "layers", "has", "feed", "-", "forward", "or", "convolutional", "connections", "between", "every", "pair", "of", "layers", ",", "for", "a", "total", "of", ".", "This", "can", "improve", "gradient", "flow", "and", "convergence", "properties", ",", "especially", "in", "deeper", "networks", ",", "although", "it", "requires", "a", "parameter", "count", "that", "is", "quadratic", "in", "the", "number", "of", "layers", ".", "When", "applying", "this", "technique", "to", "the", "QRNN", ",", "we", "include", "connections", "between", "the", "input", "embeddings", "and", "every", "QRNN", "layer", "and", "between", "every", "pair", "of", "QRNN", "layers", ".", "This", "is", "equivalent", "to", "concatenating", "each", "QRNN", "layer", "\u2019s", "input", "to", "its", "output", "along", "the", "channel", "dimension", "before", "feeding", "the", "state", "into", "the", "next", "layer", ".", "The", "output", "of", "the", "last", "layer", "alone", "is", "then", "used", "as", "the", "overall", "encoding", "result", ".", "Encoder", "\u2013", "Decoder", "Models", "To", "demonstrate", "the", "generality", "of", "QRNNs", ",", "we", "extend", "the", "model", "architecture", "to", "sequence", "-", "to", "-", "sequence", "tasks", ",", "such", "as", "machine", "translation", ",", "by", "using", "a", "QRNN", "as", "encoder", "and", "a", "modified", "QRNN", ",", "enhanced", "with", "attention", ",", "as", "decoder", ".", "The", "motivation", "for", "modifying", "the", "decoder", "is", "that", "simply", "feeding", "the", "last", "encoder", "hidden", "state", "(", "the", "output", "of", "the", "encoder", "\u2019s", "pooling", "layer", ")", "into", "the", "decoder", "\u2019s", "recurrent", "pooling", "layer", ",", "analogously", "to", "conventional", "recurrent", "encoder", "\u2013", "decoder", "architectures", ",", "would", "not", "allow", "the", "encoder", "state", "to", "affect", "the", "gate", "or", "update", "values", "that", "are", "provided", "to", "the", "decoder", "\u2019s", "pooling", "layer", ".", "This", "would", "substantially", "limit", "the", "representational", "power", "of", "the", "decoder", ".", "Instead", ",", "the", "output", "of", "each", "decoder", "QRNN", "layer", "\u2019s", "convolution", "functions", "is", "supplemented", "at", "every", "timestep", "with", "the", "final", "encoder", "hidden", "state", ".", "This", "is", "accomplished", "by", "adding", "the", "result", "of", "the", "convolution", "for", "layer", "(", "e.g.", ",", ",", "in", ")", "with", "broadcasting", "to", "a", "linearly", "projected", "copy", "of", "layer", "\u2019s", "last", "encoder", "state", "(", "e.g.", ",", ",", "in", ")", ":", "where", "the", "tilde", "denotes", "that", "is", "an", "encoder", "variable", ".", "Encoder", "\u2013", "decoder", "models", "which", "operate", "on", "long", "sequences", "are", "made", "significantly", "more", "powerful", "with", "the", "addition", "of", "soft", "attention", "Bahdanau2015", ",", "which", "removes", "the", "need", "for", "the", "entire", "input", "representation", "to", "fit", "into", "a", "fixed", "-", "length", "encoding", "vector", ".", "In", "our", "experiments", ",", "we", "computed", "an", "attentional", "sum", "of", "the", "encoder", "\u2019s", "last", "layer", "\u2019s", "hidden", "states", ".", "We", "used", "the", "dot", "products", "of", "these", "encoder", "hidden", "states", "with", "the", "decoder", "\u2019s", "last", "layer", "\u2019s", "un", "-", "gated", "hidden", "states", ",", "applying", "a", "along", "the", "encoder", "timesteps", ",", "to", "weight", "the", "encoder", "states", "into", "an", "attentional", "sum", "for", "each", "decoder", "timestep", ".", "This", "context", ",", "and", "the", "decoder", "state", ",", "are", "then", "fed", "into", "a", "linear", "layer", "followed", "by", "the", "output", "gate", ":", "where", "is", "the", "last", "layer", ".", "While", "the", "first", "step", "of", "this", "attention", "procedure", "is", "quadratic", "in", "the", "sequence", "length", ",", "in", "practice", "it", "takes", "significantly", "less", "computation", "time", "than", "the", "model", "\u2019s", "linear", "and", "convolutional", "layers", "due", "to", "the", "simple", "and", "highly", "parallel", "dot", "-", "product", "scoring", "function", ".", "section", ":", "Experiments", "We", "evaluate", "the", "performance", "of", "the", "QRNN", "on", "three", "different", "natural", "language", "tasks", ":", "document", "-", "level", "sentiment", "classification", ",", "language", "modeling", ",", "and", "character", "-", "based", "neural", "machine", "translation", ".", "Our", "QRNN", "models", "outperform", "LSTM", "-", "based", "models", "of", "equal", "hidden", "size", "on", "all", "three", "tasks", "while", "dramatically", "improving", "computation", "speed", ".", "Experiments", "were", "implemented", "in", "Chainer", "Tokui2015", ".", "subsection", ":", "Sentiment", "Classification", "We", "evaluate", "the", "QRNN", "architecture", "on", "a", "popular", "document", "-", "level", "sentiment", "classification", "benchmark", ",", "the", "IMDb", "movie", "review", "dataset", "Maas2011", ".", "The", "dataset", "consists", "of", "a", "balanced", "sample", "of", "25", ",", "000", "positive", "and", "25", ",", "000", "negative", "reviews", ",", "divided", "into", "equal", "-", "size", "train", "and", "test", "sets", ",", "with", "an", "average", "document", "length", "of", "231", "words", "Wang2012", ".", "We", "compare", "only", "to", "other", "results", "that", "do", "not", "make", "use", "of", "additional", "unlabeled", "data", "(", "thus", "excluding", "e.g.", ",", "Miyato2016", ")", ".", "Our", "best", "performance", "on", "a", "held", "-", "out", "development", "set", "was", "achieved", "using", "a", "four", "-", "layer", "densely", "-", "connected", "QRNN", "with", "256", "units", "per", "layer", "and", "word", "vectors", "initialized", "using", "300", "-", "dimensional", "cased", "GloVe", "embeddings", "Pennington2014", ".", "Dropout", "of", "0.3", "was", "applied", "between", "layers", ",", "and", "we", "used", "regularization", "of", ".", "Optimization", "was", "performed", "on", "minibatches", "of", "24", "examples", "using", "RMSprop", "Tieleman2012", "with", "learning", "rate", "of", ",", ",", "and", ".", "Small", "batch", "sizes", "and", "long", "sequence", "lengths", "provide", "an", "ideal", "situation", "for", "demonstrating", "the", "QRNN", "\u2019s", "performance", "advantages", "over", "traditional", "recurrent", "architectures", ".", "We", "observed", "a", "speedup", "of", "3.2x", "on", "IMDb", "train", "time", "per", "epoch", "compared", "to", "the", "optimized", "LSTM", "implementation", "provided", "in", "NVIDIA", "\u2019s", "cuDNN", "library", ".", "For", "specific", "batch", "sizes", "and", "sequence", "lengths", ",", "a", "16x", "speed", "gain", "is", "possible", ".", "Figure", "[", "reference", "]", "provides", "extensive", "speed", "comparisons", ".", "In", "Figure", "[", "reference", "]", ",", "we", "visualize", "the", "hidden", "state", "vectors", "of", "the", "final", "QRNN", "layer", "on", "part", "of", "an", "example", "from", "the", "IMDb", "dataset", ".", "Even", "without", "any", "post", "-", "processing", ",", "changes", "in", "the", "hidden", "state", "are", "visible", "and", "interpretable", "in", "regards", "to", "the", "input", ".", "This", "is", "a", "consequence", "of", "the", "elementwise", "nature", "of", "the", "recurrent", "pooling", "function", ",", "which", "delays", "direct", "interaction", "between", "different", "channels", "of", "the", "hidden", "state", "until", "the", "computation", "of", "the", "next", "QRNN", "layer", ".", "subsection", ":", "Language", "Modeling", "We", "replicate", "the", "language", "modeling", "experiment", "of", "Zaremba2014", "and", "Gal2015", "to", "benchmark", "the", "QRNN", "architecture", "for", "natural", "language", "sequence", "prediction", ".", "The", "experiment", "uses", "a", "standard", "preprocessed", "version", "of", "the", "Penn", "Treebank", "(", "PTB", ")", "by", "Mikolov2010", ".", "We", "implemented", "a", "gated", "QRNN", "model", "with", "medium", "hidden", "size", ":", "2", "layers", "with", "640", "units", "in", "each", "layer", ".", "Both", "QRNN", "layers", "use", "a", "convolutional", "filter", "width", "of", "two", "timesteps", ".", "While", "the", "\u201c", "medium", "\u201d", "models", "used", "in", "other", "work", "Zaremba2014", ",", "Gal2015", "consist", "of", "650", "units", "in", "each", "layer", ",", "it", "was", "more", "computationally", "convenient", "to", "use", "a", "multiple", "of", "32", ".", "As", "the", "Penn", "Treebank", "is", "a", "relatively", "small", "dataset", ",", "preventing", "overfitting", "is", "of", "considerable", "importance", "and", "a", "major", "focus", "of", "recent", "research", ".", "It", "is", "not", "obvious", "in", "advance", "which", "of", "the", "many", "RNN", "regularization", "schemes", "would", "perform", "well", "when", "applied", "to", "the", "QRNN", ".", "Our", "tests", "showed", "encouraging", "results", "from", "zoneout", "applied", "to", "the", "QRNN", "\u2019s", "recurrent", "pooling", "layer", ",", "implemented", "as", "described", "in", "Section", "[", "reference", "]", ".", "The", "experimental", "settings", "largely", "followed", "the", "\u201c", "medium", "\u201d", "setup", "of", "Zaremba2014", ".", "Optimization", "was", "performed", "by", "stochastic", "gradient", "descent", "(", "SGD", ")", "without", "momentum", ".", "The", "learning", "rate", "was", "set", "at", "1", "for", "six", "epochs", ",", "then", "decayed", "by", "0.95", "for", "each", "subsequent", "epoch", ",", "for", "a", "total", "of", "72", "epochs", ".", "We", "additionally", "used", "regularization", "of", "and", "rescaled", "gradients", "with", "norm", "above", "10", ".", "Zoneout", "was", "applied", "by", "performing", "dropout", "with", "ratio", "0.1", "on", "the", "forget", "gates", "of", "the", "QRNN", ",", "without", "rescaling", "the", "output", "of", "the", "dropout", "function", ".", "Batches", "consist", "of", "20", "examples", ",", "each", "105", "timesteps", ".", "Comparing", "our", "results", "on", "the", "gated", "QRNN", "with", "zoneout", "to", "the", "results", "of", "LSTMs", "with", "both", "ordinary", "and", "variational", "dropout", "in", "Table", "[", "reference", "]", ",", "we", "see", "that", "the", "QRNN", "is", "highly", "competitive", ".", "The", "QRNN", "without", "zoneout", "strongly", "outperforms", "both", "our", "medium", "LSTM", "and", "the", "medium", "LSTM", "of", "Zaremba2014", "which", "do", "not", "use", "recurrent", "dropout", "and", "is", "even", "competitive", "with", "variational", "LSTMs", ".", "This", "may", "be", "due", "to", "the", "limited", "computational", "capacity", "that", "the", "QRNN", "\u2019s", "pooling", "layer", "has", "relative", "to", "the", "LSTM", "\u2019s", "recurrent", "weights", ",", "providing", "structural", "regularization", "over", "the", "recurrence", ".", "Without", "zoneout", ",", "early", "stopping", "based", "upon", "validation", "loss", "was", "required", "as", "the", "QRNN", "would", "begin", "overfitting", ".", "By", "applying", "a", "small", "amount", "of", "zoneout", "(", ")", ",", "no", "early", "stopping", "is", "required", "and", "the", "QRNN", "achieves", "competitive", "levels", "of", "perplexity", "to", "the", "variational", "LSTM", "of", "Gal2015", ",", "which", "had", "variational", "inference", "based", "dropout", "of", "0.2", "applied", "recurrently", ".", "Their", "best", "performing", "variation", "also", "used", "Monte", "Carlo", "(", "MC", ")", "dropout", "averaging", "at", "test", "time", "of", "1000", "different", "masks", ",", "making", "it", "computationally", "more", "expensive", "to", "run", ".", "When", "training", "on", "the", "PTB", "dataset", "with", "an", "NVIDIA", "K40", "GPU", ",", "we", "found", "that", "the", "QRNN", "is", "substantially", "faster", "than", "a", "standard", "LSTM", ",", "even", "when", "comparing", "against", "the", "optimized", "cuDNN", "LSTM", ".", "In", "Figure", "[", "reference", "]", "we", "provide", "a", "breakdown", "of", "the", "time", "taken", "for", "Chainer", "\u2019s", "default", "LSTM", ",", "the", "cuDNN", "LSTM", ",", "and", "QRNN", "to", "perform", "a", "full", "forward", "and", "backward", "pass", "on", "a", "single", "batch", "during", "training", "of", "the", "RNN", "LM", "on", "PTB", ".", "For", "both", "LSTM", "implementations", ",", "running", "time", "was", "dominated", "by", "the", "RNN", "computations", ",", "even", "with", "the", "highly", "optimized", "cuDNN", "implementation", ".", "For", "the", "QRNN", "implementation", ",", "however", ",", "the", "\u201c", "RNN", "\u201d", "layers", "are", "no", "longer", "the", "bottleneck", ".", "Indeed", ",", "there", "are", "diminishing", "returns", "from", "further", "optimization", "of", "the", "QRNN", "itself", "as", "the", "softmax", "and", "optimization", "overhead", "take", "equal", "or", "greater", "time", ".", "Note", "that", "the", "softmax", ",", "over", "a", "vocabulary", "size", "of", "only", "10", ",", "000", "words", ",", "is", "relatively", "small", ";", "for", "tasks", "with", "larger", "vocabularies", ",", "the", "softmax", "would", "likely", "dominate", "computation", "time", ".", "It", "is", "also", "important", "to", "note", "that", "the", "cuDNN", "library", "\u2019s", "RNN", "primitives", "do", "not", "natively", "support", "any", "form", "of", "recurrent", "dropout", ".", "That", "is", ",", "running", "an", "LSTM", "that", "uses", "a", "state", "-", "of", "-", "the", "-", "art", "regularization", "scheme", "at", "cuDNN", "-", "like", "speeds", "would", "likely", "require", "an", "entirely", "custom", "kernel", ".", "Batch", "size", "subsection", ":", "Character", "-", "level", "Neural", "Machine", "Translation", "We", "evaluate", "the", "sequence", "-", "to", "-", "sequence", "QRNN", "architecture", "described", "in", "[", "reference", "]", "on", "a", "challenging", "neural", "machine", "translation", "task", ",", "IWSLT", "German", "\u2013", "English", "spoken", "-", "domain", "translation", ",", "applying", "fully", "character", "-", "level", "segmentation", ".", "This", "dataset", "consists", "of", "209", ",", "772", "sentence", "pairs", "of", "parallel", "training", "data", "from", "transcribed", "TED", "and", "TEDx", "presentations", ",", "with", "a", "mean", "sentence", "length", "of", "103", "characters", "for", "German", "and", "93", "for", "English", ".", "We", "remove", "training", "sentences", "with", "more", "than", "300", "characters", "in", "English", "or", "German", ",", "and", "use", "a", "unified", "vocabulary", "of", "187", "Unicode", "code", "points", ".", "Our", "best", "performance", "on", "a", "development", "set", "(", "TED.tst2013", ")", "was", "achieved", "using", "a", "four", "-", "layer", "encoder", "\u2013", "decoder", "QRNN", "with", "320", "units", "per", "layer", ",", "no", "dropout", "or", "regularization", ",", "and", "gradient", "rescaling", "to", "a", "maximum", "magnitude", "of", "5", ".", "Inputs", "were", "supplied", "to", "the", "encoder", "reversed", ",", "while", "the", "encoder", "convolutions", "were", "not", "masked", ".", "The", "first", "encoder", "layer", "used", "convolutional", "filter", "width", ",", "while", "the", "other", "encoder", "layers", "used", ".", "Optimization", "was", "performed", "for", "10", "epochs", "on", "minibatches", "of", "16", "examples", "using", "Adam", "kingma2014adam", "with", ",", ",", ",", "and", ".", "Decoding", "was", "performed", "using", "beam", "search", "with", "beam", "width", "8", "and", "length", "normalization", ".", "The", "modified", "log", "-", "probability", "ranking", "criterion", "is", "provided", "in", "the", "appendix", ".", "Results", "using", "this", "architecture", "were", "compared", "to", "an", "equal", "-", "sized", "four", "-", "layer", "encoder", "\u2013", "decoder", "LSTM", "with", "attention", ",", "applying", "dropout", "of", "0.2", ".", "We", "again", "optimized", "using", "Adam", ";", "other", "hyperparameters", "were", "equal", "to", "their", "values", "for", "the", "QRNN", "and", "the", "same", "beam", "search", "procedure", "was", "applied", ".", "Table", "[", "reference", "]", "shows", "that", "the", "QRNN", "outperformed", "the", "character", "-", "level", "LSTM", ",", "almost", "matching", "the", "performance", "of", "a", "word", "-", "level", "attentional", "baseline", ".", "section", ":", "Related", "Work", "Exploring", "alternatives", "to", "traditional", "RNNs", "for", "sequence", "tasks", "is", "a", "major", "area", "of", "current", "research", ".", "Quasi", "-", "recurrent", "neural", "networks", "are", "related", "to", "several", "such", "recently", "described", "models", ",", "especially", "the", "strongly", "-", "typed", "recurrent", "neural", "networks", "(", "T", "-", "RNN", ")", "introduced", "by", ".", "While", "the", "motivation", "and", "constraints", "described", "in", "that", "work", "are", "different", ",", "\u2019s", "concepts", "of", "\u201c", "learnware", "\u201d", "and", "\u201c", "firmware", "\u201d", "parallel", "our", "discussion", "of", "convolution", "-", "like", "and", "pooling", "-", "like", "subcomponents", ".", "As", "the", "use", "of", "a", "fully", "connected", "layer", "for", "recurrent", "connections", "violates", "the", "constraint", "of", "\u201c", "strong", "typing", "\u201d", ",", "all", "strongly", "-", "typed", "RNN", "architectures", "(", "including", "the", "T", "-", "RNN", ",", "T", "-", "GRU", ",", "and", "T", "-", "LSTM", ")", "are", "also", "quasi", "-", "recurrent", ".", "However", ",", "some", "QRNN", "models", "(", "including", "those", "with", "attention", "or", "skip", "-", "connections", ")", "are", "not", "\u201c", "strongly", "typed", "\u201d", ".", "In", "particular", ",", "a", "T", "-", "RNN", "differs", "from", "a", "QRNN", "as", "described", "in", "this", "paper", "with", "filter", "size", "1", "and", "f", "-", "pooling", "only", "in", "the", "absence", "of", "an", "activation", "function", "on", ".", "Similarly", ",", "T", "-", "GRUs", "and", "T", "-", "LSTMs", "differ", "from", "QRNNs", "with", "filter", "size", "2", "and", "fo", "-", "or", "ifo", "-", "pooling", "respectively", "in", "that", "they", "lack", "on", "and", "use", "rather", "than", "sigmoid", "on", ".", "The", "QRNN", "is", "also", "related", "to", "work", "in", "hybrid", "convolutional", "\u2013", "recurrent", "models", ".", "Zhou2015b", "apply", "CNNs", "at", "the", "word", "level", "to", "generate", "-", "gram", "features", "used", "by", "an", "LSTM", "for", "text", "classification", ".", "Xiao2016", "also", "tackle", "text", "classification", "by", "applying", "convolutions", "at", "the", "character", "level", ",", "with", "a", "stride", "to", "reduce", "sequence", "length", ",", "then", "feeding", "these", "features", "into", "a", "bidirectional", "LSTM", ".", "A", "similar", "approach", "was", "taken", "by", "Lee2016", "for", "character", "-", "level", "machine", "translation", ".", "Their", "model", "\u2019s", "encoder", "uses", "a", "convolutional", "layer", "followed", "by", "max", "-", "pooling", "to", "reduce", "sequence", "length", ",", "a", "four", "-", "layer", "highway", "network", ",", "and", "a", "bidirectional", "GRU", ".", "The", "parallelism", "of", "the", "convolutional", ",", "pooling", ",", "and", "highway", "layers", "allows", "training", "speed", "comparable", "to", "subword", "-", "level", "models", "without", "hard", "-", "coded", "text", "segmentation", ".", "The", "QRNN", "encoder", "\u2013", "decoder", "model", "shares", "the", "favorable", "parallelism", "and", "path", "-", "length", "properties", "exhibited", "by", "the", "ByteNet", "Kalchbrenner2016", ",", "an", "architecture", "for", "character", "-", "level", "machine", "translation", "based", "on", "residual", "convolutions", "over", "binary", "trees", ".", "Their", "model", "was", "constructed", "to", "achieve", "three", "desired", "properties", ":", "parallelism", ",", "linear", "-", "time", "computational", "complexity", ",", "and", "short", "paths", "between", "any", "pair", "of", "words", "in", "order", "to", "better", "propagate", "gradient", "signals", ".", "section", ":", "Conclusion", "Intuitively", ",", "many", "aspects", "of", "the", "semantics", "of", "long", "sequences", "are", "context", "-", "invariant", "and", "can", "be", "computed", "in", "parallel", "(", "e.g.", ",", "convolutionally", ")", ",", "but", "some", "aspects", "require", "long", "-", "distance", "context", "and", "must", "be", "computed", "recurrently", ".", "Many", "existing", "neural", "network", "architectures", "either", "fail", "to", "take", "advantage", "of", "the", "contextual", "information", "or", "fail", "to", "take", "advantage", "of", "the", "parallelism", ".", "QRNNs", "exploit", "both", "parallelism", "and", "context", ",", "exhibiting", "advantages", "from", "both", "convolutional", "and", "recurrent", "neural", "networks", ".", "QRNNs", "have", "better", "predictive", "accuracy", "than", "LSTM", "-", "based", "models", "of", "equal", "hidden", "size", ",", "even", "though", "they", "use", "fewer", "parameters", "and", "run", "substantially", "faster", ".", "Our", "experiments", "show", "that", "the", "speed", "and", "accuracy", "advantages", "remain", "consistent", "across", "tasks", "and", "at", "both", "word", "and", "character", "levels", ".", "Extensions", "to", "both", "CNNs", "and", "RNNs", "are", "often", "directly", "applicable", "to", "the", "QRNN", ",", "while", "the", "model", "\u2019s", "hidden", "states", "are", "more", "interpretable", "than", "those", "of", "other", "recurrent", "architectures", "as", "its", "channels", "maintain", "their", "independence", "across", "timesteps", ".", "We", "believe", "that", "QRNNs", "can", "serve", "as", "a", "building", "block", "for", "long", "-", "sequence", "tasks", "that", "were", "previously", "impractical", "with", "traditional", "RNNs", ".", "bibliography", ":", "References", "section", ":", "Appendix", "subsection", ":", "Beam", "search", "ranking", "criterion", "The", "modified", "log", "-", "probability", "ranking", "criterion", "we", "used", "in", "beam", "search", "for", "translation", "experiments", "is", ":", "where", "is", "a", "length", "normalization", "parameter", "Wu2016", ",", "is", "the", "th", "output", "character", ",", "and", "is", "a", "\u201c", "target", "length", "\u201d", "equal", "to", "the", "source", "sentence", "length", "plus", "five", "characters", ".", "This", "reduces", "at", "to", "ordinary", "beam", "search", "with", "probabilities", ":", "and", "at", "to", "beam", "search", "with", "probabilities", "normalized", "by", "length", "(", "up", "to", "the", "target", "length", ")", ":", "Conveniently", ",", "this", "ranking", "criterion", "can", "be", "computed", "at", "intermediate", "beam", "-", "search", "timesteps", ",", "obviating", "the", "need", "to", "apply", "a", "separate", "reranking", "on", "complete", "hypotheses", "."]}