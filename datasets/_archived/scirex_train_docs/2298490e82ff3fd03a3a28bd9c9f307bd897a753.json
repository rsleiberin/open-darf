{"coref": {"Bounding_Box_AP": [[3576, 3577], [3623, 3624], [4139, 4141], [4142, 4143], [4528, 4529], [4603, 4604], [4616, 4617]], "COCO": [[175, 177], [217, 222], [3572, 3573], [1086, 1087], [1160, 1161], [1277, 1278], [3687, 3688]], "GHM-C": [[148, 151], [187, 190], [1023, 1026], [1141, 1144], [1221, 1224], [2388, 2391], [2466, 2469], [4841, 4844]], "GHM-C___GHM-R": [], "GHM-R": [[152, 155], [191, 194], [1145, 1148], [1225, 1228], [4845, 4848]], "Object_Detection": [[268, 270], [1286, 1288], [1289, 1291], [1450, 1452], [1520, 1522], [825, 827], [1345, 1347], [1445, 1447], [1783, 1785]]}, "coref_non_salient": {"0": [[13, 17], [18, 22], [199, 203], [256, 260], [280, 284], [291, 295], [304, 308], [1184, 1188], [1257, 1260], [1355, 1359], [1360, 1364], [1372, 1376], [1425, 1430], [1471, 1475], [1483, 1488], [1493, 1497], [1536, 1540], [1938, 1943], [2645, 2647], [4647, 4649], [4660, 4664], [4675, 4679], [4711, 4715], [4718, 4722], [4873, 4877], [4888, 4892], [348, 352], [1548, 1552]], "1": [[1448, 1449], [2627, 2630], [3961, 3964]], "10": [[237, 238], [886, 887], [1440, 1441], [3793, 3796]], "11": [[2, 8], [1504, 1505], [3797, 3798], [4893, 4894], [4690, 4691], [4731, 4732]], "12": [[2536, 2539], [2965, 2967], [3202, 3205], [4329, 4333], [4347, 4351]], "13": [[1312, 1313], [1385, 1387], [1388, 1391], [1620, 1621]], "14": [[884, 885], [2008, 2010], [2064, 2066], [2937, 2940], [3382, 3384], [4366, 4367]], "15": [[163, 165], [1217, 1220], [1533, 1534], [1778, 1779], [2077, 2078], [3351, 3352], [3424, 3425], [3488, 3489], [4511, 4513], [4744, 4745], [4855, 4856]], "16": [[1262, 1265], [4421, 4423]], "17": [[133, 138], [1135, 1137], [1651, 1653], [4018, 4021]], "18": [[4686, 4687], [4895, 4898]], "19": [[2635, 2637], [2850, 2852]], "2": [[356, 360], [368, 372], [1524, 1526], [1561, 1565]], "20": [[721, 723], [2528, 2529]], "21": [[166, 169], [1079, 1083]], "22": [[94, 97], [813, 816], [1199, 1202], [1762, 1765], [2110, 2112], [2382, 2385]], "23": [[2955, 2956], [3883, 3885]], "24": [[365, 367], [1544, 1547], [1734, 1736], [2443, 2446], [4811, 4813]], "25": [[234, 236], [401, 403], [1028, 1030], [1118, 1120], [1215, 1216], [1677, 1679], [2371, 2373], [2396, 2398], [2502, 2504], [3223, 3224], [3248, 3249], [3315, 3316], [4432, 4434], [4454, 4456], [4468, 4470], [4693, 4694], [425, 427], [2357, 2359]], "26": [[2678, 2679], [2894, 2895]], "27": [[4255, 4256]], "28": [[1611, 1616], [1657, 1659], [1665, 1666], [3343, 3344], [3426, 3427], [3436, 3438], [3472, 3474], [3528, 3530], [3647, 3649], [4636, 4637], [4655, 4656], [4751, 4753], [4857, 4860]], "29": [[2558, 2560], [2845, 2847]], "3": [[118, 121], [1826, 1830], [4040, 4043], [4095, 4097], [4125, 4127], [4481, 4483], [4548, 4549], [4570, 4573], [4592, 4593], [4791, 4793]], "30": [[3867, 3869]], "31": [[1455, 1458], [1469, 1470], [3566, 3568]], "32": [[2957, 2958]], "33": [[806, 809]], "34": [[4814, 4818]], "35": [[3872, 3873]], "36": [[4102, 4105], [4108, 4112]], "37": [[98, 99], [111, 112], [817, 818], [845, 846], [881, 882], [901, 902], [975, 976], [1056, 1057], [1203, 1204], [1212, 1213], [1250, 1251], [2281, 2282], [3213, 3214], [3434, 3435], [4868, 4869], [985, 986], [1071, 1072], [1091, 1092], [1123, 1124], [1709, 1710], [2274, 2275], [2360, 2361], [2411, 2412], [2522, 2523], [3064, 3065], [3448, 3449], [3633, 3634], [3996, 3997], [4006, 4007], [4224, 4225], [4304, 4305], [4320, 4321], [4372, 4373], [4486, 4487], [4505, 4506], [4533, 4534], [4555, 4556], [4576, 4577], [4609, 4610], [4650, 4651], [4705, 4706], [4739, 4740], [4746, 4747]], "38": [[3524, 3525], [4299, 4301]], "39": [[2898, 2904]], "4": [[122, 127], [412, 417], [1103, 1107], [1527, 1532], [2896, 2897], [2941, 2942], [2984, 2985], [3047, 3048], [3971, 3972], [4171, 4172]], "40": [[2959, 2961]], "41": [[2541, 2543]], "42": [[3831, 3833]], "43": [[215, 216], [4588, 4589]], "44": [[2545, 2547]], "45": [[3974, 3977], [4825, 4829]], "46": [[1476, 1477], [3780, 3781]], "47": [[1738, 1740], [2448, 2450]], "48": [[4640, 4642]], "49": [[3920, 3922]], "5": [[3789, 3790], [3834, 3837], [3850, 3853]], "50": [[374, 375]], "51": [[1517, 1519]], "52": [[1339, 1341], [3782, 3784]], "53": [[2270, 2271]], "54": [[1442, 1443]], "55": [[181, 185]], "56": [[1682, 1688]], "57": [[3965, 3968]], "58": [[484, 487], [489, 492]], "59": [[464, 466], [1513, 1514], [4258, 4259], [4354, 4355]], "6": [[2093, 2095], [2746, 2750], [2756, 2761], [4275, 4278], [4314, 4318]], "60": [[4901, 4903]], "61": [[1304, 1306]], "62": [[1307, 1311]], "63": [[1047, 1050]], "64": [[3629, 3630]], "7": [[1064, 1067], [3076, 3079], [3406, 3407], [4024, 4027], [4695, 4697]], "8": [[1694, 1698], [2283, 2285], [2890, 2891], [3215, 3217], [3341, 3342], [3348, 3350], [3857, 3859], [4082, 4085]], "9": [[129, 132], [145, 147], [991, 993], [3092, 3094], [4245, 4247], [4418, 4420], [4524, 4525], [4838, 4840]]}, "doc_id": "2298490e82ff3fd03a3a28bd9c9f307bd897a753", "method_subrelations": {"GHM-C___GHM-R": [[[0, 5], "GHM-C"], [[8, 13], "GHM-R"]]}, "n_ary_relations": [{"Material": "COCO", "Method": "GHM-C___GHM-R", "Metric": "Bounding_Box_AP", "Task": "Object_Detection", "score": "41.6"}], "ner": [[2, 8, "Method"], [13, 17, "Method"], [18, 22, "Method"], [94, 97, "Method"], [98, 99, "Method"], [111, 112, "Method"], [118, 121, "Metric"], [122, 127, "Method"], [129, 132, "Method"], [133, 138, "Method"], [145, 147, "Method"], [148, 151, "Method"], [152, 155, "Method"], [163, 165, "Task"], [166, 169, "Task"], [175, 177, "Material"], [181, 185, "Method"], [187, 190, "Method"], [191, 194, "Method"], [199, 203, "Method"], [215, 216, "Metric"], [217, 222, "Material"], [234, 236, "Method"], [237, 238, "Method"], [256, 260, "Method"], [268, 270, "Task"], [280, 284, "Method"], [291, 295, "Method"], [304, 308, "Method"], [356, 360, "Method"], [365, 367, "Task"], [368, 372, "Method"], [374, 375, "Method"], [401, 403, "Method"], [412, 417, "Method"], [464, 466, "Task"], [484, 487, "Metric"], [489, 492, "Metric"], [721, 723, "Method"], [806, 809, "Method"], [813, 816, "Method"], [817, 818, "Method"], [845, 846, "Method"], [881, 882, "Method"], [884, 885, "Method"], [886, 887, "Method"], [901, 902, "Method"], [975, 976, "Method"], [991, 993, "Method"], [1023, 1026, "Method"], [1028, 1030, "Method"], [1047, 1050, "Method"], [1056, 1057, "Method"], [1064, 1067, "Method"], [1079, 1083, "Task"], [1103, 1107, "Method"], [1118, 1120, "Method"], [1135, 1137, "Method"], [1141, 1144, "Method"], [1145, 1148, "Method"], [1184, 1188, "Method"], [1199, 1202, "Method"], [1203, 1204, "Method"], [1212, 1213, "Method"], [1215, 1216, "Method"], [1217, 1220, "Task"], [1221, 1224, "Method"], [1225, 1228, "Method"], [1250, 1251, "Method"], [1257, 1260, "Method"], [1262, 1265, "Method"], [1286, 1288, "Task"], [1289, 1291, "Task"], [1304, 1306, "Task"], [1307, 1311, "Method"], [1312, 1313, "Method"], [1339, 1341, "Method"], [1355, 1359, "Method"], [1360, 1364, "Method"], [1372, 1376, "Method"], [1385, 1387, "Method"], [1388, 1391, "Method"], [1425, 1430, "Method"], [1440, 1441, "Method"], [1442, 1443, "Method"], [1448, 1449, "Method"], [1450, 1452, "Task"], [1455, 1458, "Metric"], [1469, 1470, "Metric"], [1471, 1475, "Method"], [1476, 1477, "Method"], [1483, 1488, "Method"], [1493, 1497, "Method"], [1504, 1505, "Method"], [1513, 1514, "Task"], [1517, 1519, "Method"], [1520, 1522, "Task"], [1524, 1526, "Method"], [1527, 1532, "Method"], [1533, 1534, "Task"], [1536, 1540, "Method"], [1544, 1547, "Task"], [1561, 1565, "Method"], [1611, 1616, "Task"], [1651, 1653, "Method"], [1657, 1659, "Task"], [1665, 1666, "Task"], [1677, 1679, "Method"], [1682, 1688, "Metric"], [1694, 1698, "Task"], [1734, 1736, "Task"], [1738, 1740, "Task"], [1762, 1765, "Method"], [1778, 1779, "Task"], [1826, 1830, "Metric"], [1938, 1943, "Method"], [2008, 2010, "Method"], [2064, 2066, "Method"], [2077, 2078, "Task"], [2093, 2095, "Method"], [2110, 2112, "Method"], [2270, 2271, "Method"], [2281, 2282, "Method"], [2283, 2285, "Task"], [2371, 2373, "Method"], [2382, 2385, "Method"], [2388, 2391, "Method"], [2396, 2398, "Method"], [2443, 2446, "Task"], [2448, 2450, "Task"], [2466, 2469, "Method"], [2502, 2504, "Method"], [2528, 2529, "Method"], [2536, 2539, "Method"], [2541, 2543, "Method"], [2545, 2547, "Method"], [2558, 2560, "Metric"], [2627, 2630, "Method"], [2635, 2637, "Task"], [2645, 2647, "Method"], [2678, 2679, "Method"], [2746, 2750, "Method"], [2756, 2761, "Method"], [2845, 2847, "Metric"], [2850, 2852, "Task"], [2890, 2891, "Task"], [2894, 2895, "Method"], [2896, 2897, "Method"], [2898, 2904, "Method"], [2937, 2940, "Method"], [2941, 2942, "Method"], [2955, 2956, "Method"], [2957, 2958, "Method"], [2959, 2961, "Method"], [2965, 2967, "Method"], [2984, 2985, "Method"], [3047, 3048, "Method"], [3076, 3079, "Method"], [3092, 3094, "Method"], [3202, 3205, "Method"], [3213, 3214, "Method"], [3215, 3217, "Task"], [3223, 3224, "Method"], [3248, 3249, "Method"], [3315, 3316, "Method"], [3341, 3342, "Task"], [3343, 3344, "Task"], [3348, 3350, "Task"], [3351, 3352, "Task"], [3382, 3384, "Method"], [3406, 3407, "Method"], [3424, 3425, "Task"], [3426, 3427, "Task"], [3434, 3435, "Method"], [3436, 3438, "Task"], [3472, 3474, "Task"], [3488, 3489, "Task"], [3524, 3525, "Metric"], [3528, 3530, "Task"], [3566, 3568, "Metric"], [3572, 3573, "Material"], [3576, 3577, "Metric"], [3623, 3624, "Metric"], [3629, 3630, "Metric"], [3647, 3649, "Task"], [3780, 3781, "Method"], [3782, 3784, "Method"], [3789, 3790, "Method"], [3793, 3796, "Method"], [3797, 3798, "Method"], [3831, 3833, "Task"], [3834, 3837, "Method"], [3850, 3853, "Method"], [3857, 3859, "Task"], [3867, 3869, "Method"], [3872, 3873, "Task"], [3883, 3885, "Method"], [3920, 3922, "Metric"], [3961, 3964, "Method"], [3965, 3968, "Task"], [3971, 3972, "Method"], [3974, 3977, "Task"], [4018, 4021, "Method"], [4024, 4027, "Method"], [4040, 4043, "Metric"], [4082, 4085, "Task"], [4095, 4097, "Metric"], [4102, 4105, "Metric"], [4108, 4112, "Metric"], [4125, 4127, "Metric"], [4139, 4141, "Metric"], [4142, 4143, "Metric"], [4171, 4172, "Method"], [4245, 4247, "Method"], [4255, 4256, "Task"], [4258, 4259, "Task"], [4275, 4278, "Method"], [4299, 4301, "Metric"], [4314, 4318, "Method"], [4329, 4333, "Method"], [4347, 4351, "Method"], [4354, 4355, "Task"], [4366, 4367, "Method"], [4418, 4420, "Method"], [4421, 4423, "Method"], [4432, 4434, "Method"], [4454, 4456, "Method"], [4468, 4470, "Method"], [4481, 4483, "Metric"], [4511, 4513, "Task"], [4524, 4525, "Method"], [4528, 4529, "Metric"], [4548, 4549, "Metric"], [4570, 4573, "Metric"], [4588, 4589, "Metric"], [4592, 4593, "Metric"], [4603, 4604, "Metric"], [4616, 4617, "Metric"], [4636, 4637, "Task"], [4640, 4642, "Task"], [4647, 4649, "Method"], [4655, 4656, "Task"], [4660, 4664, "Method"], [4675, 4679, "Method"], [4686, 4687, "Method"], [4693, 4694, "Method"], [4695, 4697, "Method"], [4711, 4715, "Method"], [4718, 4722, "Method"], [4744, 4745, "Task"], [4751, 4753, "Task"], [4791, 4793, "Metric"], [4811, 4813, "Task"], [4814, 4818, "Task"], [4825, 4829, "Task"], [4838, 4840, "Method"], [4841, 4844, "Method"], [4845, 4848, "Method"], [4855, 4856, "Task"], [4857, 4860, "Task"], [4868, 4869, "Method"], [4873, 4877, "Method"], [4888, 4892, "Method"], [4893, 4894, "Method"], [4895, 4898, "Method"], [4901, 4903, "Method"], [348, 352, "Method"], [425, 427, "Method"], [825, 827, "Task"], [985, 986, "Method"], [1071, 1072, "Method"], [1086, 1087, "Material"], [1091, 1092, "Method"], [1123, 1124, "Method"], [1160, 1161, "Material"], [1277, 1278, "Material"], [1345, 1347, "Task"], [1445, 1447, "Task"], [1548, 1552, "Method"], [1620, 1621, "Method"], [1709, 1710, "Method"], [1783, 1785, "Task"], [2274, 2275, "Method"], [2357, 2359, "Method"], [2360, 2361, "Method"], [2411, 2412, "Method"], [2522, 2523, "Method"], [3064, 3065, "Method"], [3448, 3449, "Method"], [3633, 3634, "Method"], [3687, 3688, "Material"], [3996, 3997, "Method"], [4006, 4007, "Method"], [4224, 4225, "Method"], [4304, 4305, "Method"], [4320, 4321, "Method"], [4372, 4373, "Method"], [4486, 4487, "Method"], [4505, 4506, "Method"], [4533, 4534, "Method"], [4555, 4556, "Method"], [4576, 4577, "Method"], [4609, 4610, "Method"], [4650, 4651, "Method"], [4690, 4691, "Method"], [4705, 4706, "Method"], [4731, 4732, "Method"], [4739, 4740, "Method"], [4746, 4747, "Method"]], "sections": [[0, 253], [253, 1280], [1280, 1284], [1284, 1515], [1515, 1760], [1760, 1765], [1765, 2091], [2091, 2272], [2272, 2534], [2534, 2539], [2539, 2678], [2678, 2894], [2894, 3062], [3062, 3677], [3677, 3769], [3769, 3773], [3773, 3870], [3870, 3994], [3994, 4028], [4028, 4147], [4147, 4236], [4236, 4397], [4397, 4484], [4484, 4490], [4490, 4643], [4643, 4723], [4723, 4797], [4797, 4937], [4937, 4979], [4979, 4982]], "sentences": [[0, 8], [8, 63], [63, 88], [88, 108], [108, 139], [139, 172], [172, 204], [204, 244], [244, 253], [253, 256], [256, 271], [271, 296], [296, 327], [327, 341], [341, 361], [361, 392], [392, 423], [423, 442], [442, 467], [467, 503], [503, 538], [538, 556], [556, 581], [581, 596], [596, 627], [627, 655], [655, 659], [659, 683], [683, 727], [727, 758], [758, 779], [779, 801], [801, 844], [844, 878], [878, 895], [895, 899], [899, 931], [931, 955], [955, 990], [990, 1004], [1004, 1051], [1051, 1076], [1076, 1121], [1121, 1138], [1138, 1166], [1166, 1173], [1173, 1209], [1209, 1248], [1248, 1280], [1280, 1284], [1284, 1289], [1289, 1307], [1307, 1344], [1344, 1365], [1365, 1379], [1379, 1394], [1394, 1440], [1440, 1462], [1462, 1476], [1476, 1498], [1498, 1515], [1515, 1523], [1523, 1535], [1535, 1556], [1556, 1581], [1581, 1610], [1610, 1626], [1626, 1644], [1644, 1660], [1660, 1691], [1691, 1708], [1708, 1742], [1742, 1760], [1760, 1765], [1765, 1769], [1769, 1799], [1799, 1824], [1824, 1831], [1831, 1851], [1851, 1865], [1865, 1883], [1883, 1890], [1890, 1926], [1926, 1928], [1928, 1944], [1944, 1976], [1976, 2001], [2001, 2030], [2030, 2059], [2059, 2091], [2091, 2095], [2095, 2118], [2118, 2129], [2129, 2145], [2145, 2175], [2175, 2193], [2193, 2208], [2208, 2228], [2228, 2255], [2255, 2272], [2272, 2278], [2278, 2310], [2310, 2322], [2322, 2350], [2350, 2386], [2386, 2409], [2409, 2451], [2451, 2458], [2458, 2461], [2461, 2480], [2480, 2498], [2498, 2518], [2518, 2534], [2534, 2539], [2539, 2544], [2544, 2577], [2577, 2590], [2590, 2626], [2626, 2638], [2638, 2663], [2663, 2678], [2678, 2683], [2683, 2704], [2704, 2711], [2711, 2715], [2715, 2724], [2724, 2742], [2742, 2793], [2793, 2804], [2804, 2825], [2825, 2849], [2849, 2865], [2865, 2881], [2881, 2894], [2894, 2898], [2898, 2937], [2937, 2962], [2962, 2998], [2998, 3024], [3024, 3033], [3033, 3062], [3062, 3068], [3068, 3091], [3091, 3123], [3123, 3142], [3142, 3176], [3176, 3210], [3210, 3238], [3238, 3264], [3264, 3296], [3296, 3312], [3312, 3353], [3353, 3368], [3368, 3389], [3389, 3392], [3392, 3403], [3403, 3428], [3428, 3439], [3439, 3455], [3455, 3459], [3459, 3468], [3468, 3484], [3484, 3510], [3510, 3526], [3526, 3543], [3543, 3558], [3558, 3569], [3569, 3592], [3592, 3632], [3632, 3666], [3666, 3677], [3677, 3680], [3680, 3690], [3690, 3714], [3714, 3738], [3738, 3756], [3756, 3769], [3769, 3773], [3773, 3778], [3778, 3801], [3801, 3816], [3816, 3829], [3829, 3840], [3840, 3854], [3854, 3870], [3870, 3874], [3874, 3886], [3886, 3910], [3910, 3943], [3943, 3959], [3959, 3969], [3969, 3994], [3994, 4000], [4000, 4028], [4028, 4032], [4032, 4047], [4047, 4076], [4076, 4090], [4090, 4099], [4099, 4118], [4118, 4147], [4147, 4153], [4153, 4155], [4155, 4171], [4171, 4177], [4177, 4202], [4202, 4214], [4214, 4236], [4236, 4240], [4240, 4257], [4257, 4282], [4282, 4284], [4284, 4302], [4302, 4334], [4334, 4342], [4342, 4363], [4363, 4380], [4380, 4397], [4397, 4404], [4404, 4406], [4406, 4424], [4424, 4471], [4471, 4484], [4484, 4490], [4490, 4497], [4497, 4514], [4514, 4539], [4539, 4560], [4560, 4562], [4562, 4581], [4581, 4594], [4594, 4596], [4596, 4609], [4609, 4643], [4643, 4650], [4650, 4665], [4665, 4680], [4680, 4698], [4698, 4700], [4700, 4723], [4723, 4727], [4727, 4754], [4754, 4764], [4764, 4766], [4766, 4784], [4784, 4797], [4797, 4802], [4802, 4837], [4837, 4862], [4862, 4904], [4904, 4937], [4937, 4940], [4940, 4962], [4962, 4979], [4979, 4982]], "words": ["document", ":", "Gradient", "Harmonized", "Single", "-", "stage", "Detector", "Despite", "the", "great", "success", "of", "two", "-", "stage", "detectors", ",", "single", "-", "stage", "detector", "is", "still", "a", "more", "elegant", "and", "efficient", "way", ",", "yet", "suffers", "from", "the", "two", "well", "-", "known", "disharmonies", "during", "training", ",", "i.e.", "the", "huge", "difference", "in", "quantity", "between", "positive", "and", "negative", "examples", "as", "well", "as", "between", "easy", "and", "hard", "examples", ".", "In", "this", "work", ",", "we", "first", "point", "out", "that", "the", "essential", "effect", "of", "the", "two", "disharmonies", "can", "be", "summarized", "in", "term", "of", "the", "gradient", ".", "Further", ",", "we", "propose", "a", "novel", "gradient", "harmonizing", "mechanism", "(", "GHM", ")", "to", "be", "a", "hedging", "for", "the", "disharmonies", ".", "The", "philosophy", "behind", "GHM", "can", "be", "easily", "embedded", "into", "both", "classification", "loss", "function", "like", "cross", "-", "entropy", "(", "CE", ")", "and", "regression", "loss", "function", "like", "smooth", "-", "(", ")", "loss", ".", "To", "this", "end", ",", "two", "novel", "loss", "functions", "called", "GHM", "-", "C", "and", "GHM", "-", "R", "are", "designed", "to", "balancing", "the", "gradient", "flow", "for", "anchor", "classification", "and", "bounding", "box", "refinement", ",", "respectively", ".", "Ablation", "study", "on", "MS", "COCO", "demonstrates", "that", "without", "laborious", "hyper", "-", "parameter", "tuning", ",", "both", "GHM", "-", "C", "and", "GHM", "-", "R", "can", "bring", "substantial", "improvement", "for", "single", "-", "stage", "detector", ".", "Without", "any", "whistles", "and", "bells", ",", "the", "proposed", "model", "achieves", "41.6", "mAP", "on", "COCO", "test", "-", "dev", "set", "which", "surpass", "the", "state", "-", "of", "-", "the", "-", "art", "method", ",", "Focal", "Loss", "(", "FL", ")", "+", ",", "by", "0.8", ".", "The", "code", "is", "released", "to", "facilitate", "future", "research", ".", "section", ":", "Introduction", "One", "-", "stage", "approach", "is", "the", "most", "efficient", "and", "elegant", "framework", "for", "object", "detection", ".", "But", "for", "a", "long", "time", ",", "the", "performance", "of", "one", "-", "stage", "detectors", "has", "a", "large", "gap", "from", "that", "of", "two", "-", "stage", "detectors", ".", "The", "most", "challenging", "problem", "for", "the", "training", "of", "one", "-", "stage", "detector", "is", "the", "serious", "imbalance", "between", "easy", "and", "hard", "examples", "as", "well", "as", "that", "between", "positive", "and", "negative", "examples", ".", "The", "huge", "number", "of", "easy", "and", "background", "examples", "tend", "to", "overwhelm", "the", "training", ".", "But", "these", "problems", "are", "not", "existed", "for", "two", "-", "stage", "detectors", ",", "owing", "to", "the", "proposal", "-", "driven", "mechanism", ".", "To", "handle", "the", "former", "imbalance", "problem", ",", "example", "mining", "based", "methods", "such", "as", "OHEM", "are", "in", "common", "use", ",", "but", "they", "directly", "abandon", "most", "examples", "and", "the", "training", "is", "inefficient", ".", "For", "the", "latter", "imbalance", ",", "the", "recent", "work", ",", "Focal", "Loss", ",", "has", "tried", "to", "address", "it", "by", "rectifying", "the", "cross", "-", "entropy", "loss", "function", "to", "a", "elaborately", "designed", "form", ".", "However", ",", "Focal", "Loss", "adopts", "two", "hyper", "-", "parameters", "which", "should", "be", "tuned", "with", "a", "lot", "of", "efforts", ".", "And", "it", "is", "a", "static", "loss", "which", "is", "not", "adaptive", "for", "the", "changing", "of", "data", "distribution", ",", "which", "varies", "along", "with", "the", "training", "process", ".", "In", "this", "work", ",", "we", "first", "point", "out", "that", "the", "class", "imbalance", "can", "be", "summarized", "to", "the", "imbalance", "in", "difficulty", "and", "the", "imbalance", "in", "difficulty", "can", "be", "summarized", "to", "the", "imbalance", "in", "gradient", "norm", "distribution", ".", "If", "a", "positive", "example", "is", "well", "-", "classified", ",", "it", "is", "an", "easy", "example", "and", "the", "model", "benefit", "little", "from", "it", ",", "i.e.", "a", "little", "magnitude", "of", "gradient", "will", "be", "produced", "by", "this", "sample", ".", "And", "a", "misclassified", "example", "should", "attract", "attention", "of", "the", "model", "no", "matter", "which", "class", "it", "belongs", "to", ".", "So", "if", "viewed", "globally", ",", "the", "large", "amount", "of", "negative", "examples", "tends", "to", "be", "easy", "to", "classify", "and", "the", "hard", "examples", "are", "usually", "positive", ".", "So", "the", "two", "kind", "of", "imbalance", "can", "be", "roughly", "summed", "up", "as", "attribute", "imbalance", ".", "Moreover", ",", "we", "claim", "that", "the", "imbalance", "of", "examples", "with", "different", "attributes", "(", "hard", "/", "easy", "and", "pos", "/", "neg", ")", "can", "be", "implied", "by", "the", "distribution", "of", "gradient", "norm", ".", "The", "density", "of", "examples", "w.r.t", ".", "gradient", "norm", ",", "which", "we", "call", "as", "gradient", "density", "for", "convenient", ",", "varies", "largely", "as", "showed", "in", "the", "left", "of", "Fig", ".", "[", "reference", "]", ".", "The", "examples", "with", "very", "small", "gradient", "norm", "have", "a", "quite", "large", "density", "which", "is", "corresponding", "to", "the", "large", "amount", "of", "easy", "negative", "examples", ".", "Although", "one", "easy", "example", "has", "less", "contribution", "on", "the", "global", "gradient", "than", "a", "hard", "example", ",", "the", "total", "contribution", "of", "the", "huge", "amount", "of", "easy", "examples", "can", "overwhelm", "the", "contribution", "of", "the", "minority", "of", "hard", "examples", "and", "the", "training", "process", "will", "be", "inefficient", ".", "Besides", ",", "we", "also", "discover", "that", "the", "density", "of", "examples", "with", "very", "large", "gradient", "norm", "(", "very", "hard", "examples", ")", "is", "slightly", "larger", "than", "the", "density", "of", "the", "medium", "examples", ".", "And", "we", "consider", "these", "very", "hard", "examples", "mostly", "as", "outliers", "since", "they", "exist", "stably", "even", "when", "the", "model", "is", "converged", ".", "The", "outliers", "may", "affect", "the", "stability", "of", "model", "since", "their", "gradients", "may", "have", "a", "large", "discrepancy", "from", "the", "other", "common", "examples", ".", "Inspired", "by", "the", "analysis", "of", "gradient", "norm", "distribution", ",", "we", "propose", "a", "gradient", "harmonizing", "mechanism", "(", "GHM", ")", "to", "train", "the", "one", "-", "stage", "object", "detection", "model", "in", "an", "efficient", ",", "which", "focuses", "on", "the", "harmony", "of", "gradient", "contribution", "of", "different", "examples", ".", "The", "GHM", "first", "performs", "statistics", "on", "the", "number", "of", "examples", "with", "similar", "attributes", "w.r.t", "their", "gradient", "density", "and", "then", "attach", "a", "harmonizing", "parameter", "to", "the", "gradient", "of", "each", "example", "according", "to", "the", "density", ".", "The", "effect", "of", "GHM", "compared", "with", "CE", "and", "FL", "is", "illustrated", "in", "the", "right", "of", "Fig", ".", "[", "reference", "]", ".", "Training", "with", "GHM", ",", "the", "huge", "amount", "of", "cumulated", "gradient", "produced", "by", "easy", "examples", "can", "be", "largely", "down", "-", "weighted", "and", "the", "outliers", "can", "be", "relatively", "down", "-", "weighted", "as", "well", ".", "In", "the", "end", ",", "the", "contribution", "of", "each", "kind", "of", "examples", "will", "be", "balanced", "and", "the", "training", "can", "be", "more", "efficient", "and", "stable", ".", "In", "practice", ",", "the", "modification", "of", "gradient", "can", "be", "equivalently", "implemented", "by", "reformulating", "the", "loss", "function", ",", "we", "embed", "the", "GHM", "into", "the", "classification", "loss", ",", "which", "is", "denoted", "as", "GHM", "-", "C", "loss", ".", "This", "loss", "function", "is", "elegantly", "formulated", "without", "many", "hyper", "-", "parameters", "to", "tune", ".", "Since", "the", "gradient", "density", "is", "a", "statistical", "variable", "depending", "on", "the", "examples", "distribution", "in", "a", "mini", "-", "batch", ",", "GHM", "-", "C", "is", "a", "dynamic", "loss", "that", "can", "adapt", "to", "the", "change", "of", "data", "distribution", "in", "each", "batch", "as", "well", "as", "to", "the", "updating", "of", "model", ".", "To", "showcase", "the", "generality", "of", "GHM", ",", "we", "also", "adopt", "it", "in", "the", "box", "regression", "branch", "as", "the", "form", "of", "GHM", "-", "R", "loss", ".", "Experiments", "on", "the", "bounding", "box", "detection", "track", "of", "the", "challenging", "COCO", "benchmark", "show", "that", "the", "GHM", "-", "C", "loss", "has", "a", "large", "gain", "compared", "to", "the", "traditional", "cross", "-", "entropy", "loss", "and", "slightly", "surpasses", "the", "state", "-", "of", "-", "the", "-", "art", "Focal", "Loss", ".", "And", "the", "GHM", "-", "R", "loss", "also", "has", "better", "performance", "than", "the", "commonly", "used", "smooth", "loss", ".", "The", "combination", "of", "GHM", "-", "C", "and", "GHM", "-", "R", "attains", "a", "new", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "COCO", "tes", "-", "dev", "set", ".", "Our", "main", "contributions", "are", "as", "follows", ":", "We", "reveal", "the", "essential", "principle", "behind", "the", "significant", "example", "imbalance", "in", "one", "-", "stage", "detector", "in", "term", "of", "gradient", "norm", "distribution", ",", "and", "propose", "a", "novel", "gradient", "harmonizing", "mechanism", "(", "GHM", ")", "to", "handle", "it", ".", "We", "embed", "the", "GHM", "into", "the", "loss", "for", "classification", "and", "regression", "as", "GHM", "-", "C", "and", "GHM", "-", "R", "respectively", ",", "which", "rectify", "the", "gradient", "contribution", "of", "examples", "with", "different", "attributes", "and", "is", "robust", "to", "hyper", "-", "parameters", ".", "Collaborating", "with", "GHM", ",", "we", "can", "easily", "train", "a", "single", "stage", "detector", "without", "any", "data", "sampling", "strategy", "and", "achieve", "the", "state", "-", "of", "-", "the", "-", "art", "result", "on", "COCO", "benchmark", ".", "section", ":", "Related", "Work", "subsubsection", ":", "Object", "Detection", ":", "Object", "detection", "is", "one", "of", "the", "most", "basic", "and", "important", "task", "in", "the", "field", "of", "computer", "vision", ".", "Deep", "convolutional", "neural", "network", "(", "CNN", ")", "based", "methods", ",", "e.g.", ",", "have", "become", "more", "and", "more", "developed", "and", "achieved", "great", "success", "in", "recent", "years", ",", "owing", "to", "the", "significant", "progress", "of", "network", "architecture", "such", "as", ".", "Advanced", "object", "detection", "frameworks", "can", "be", "divided", "into", "two", "categories", ":", "one", "-", "stage", "detector", "and", "two", "-", "stage", "detector", ".", "Most", "state", "of", "the", "art", "methods", "use", "two", "-", "stage", "detectors", ",", "e.g.", ".", "They", "are", "mainly", "based", "on", "the", "Region", "CNN", "(", "R", "-", "CNN", ")", "architecture", ".", "These", "approaches", "first", "obtain", "a", "manageable", "number", "of", "region", "proposals", "called", "region", "of", "interest", "(", "RoI", ")", "from", "the", "nearly", "infinite", "candidate", "regions", "and", "then", "use", "the", "network", "to", "evaluate", "each", "RoI.", "One", "-", "stage", "detectors", "have", "the", "advantage", "of", "simple", "structures", "and", "high", "speed", ".", "SSD", ",", "YOLO", "for", "generic", "object", "detection", "and", "RSA", "for", "face", "detection", "have", "achieved", "good", "speed", "/", "accuracy", "trade", "-", "off", ".", "However", ",", "they", "can", "hardly", "surpass", "the", "accuracy", "of", "two", "-", "stage", "detectors", ".", "RetinaNet", "is", "the", "state", "of", "the", "art", "one", "-", "stage", "object", "detector", "that", "achieve", "comparable", "performance", "to", "two", "-", "stage", "detectors", ".", "It", "adopts", "an", "architecture", "modified", "from", "RPN", "and", "focuses", "on", "addressing", "the", "class", "imbalance", "during", "training", ".", "subsubsection", ":", "Object", "Functions", "for", "Object", "Detector", ":", "Most", "detection", "models", "use", "cross", "entropy", "based", "loss", "function", "for", "classification", ".", "While", "one", "-", "stage", "detectors", "face", "a", "problem", "of", "extreme", "class", "imbalance", "that", "two", "-", "stage", "detectors", "do", "not", "have", ".", "Earlier", "methods", "try", "to", "use", "hard", "example", "mining", "methods", ",", "e.g.", ",", "but", "they", "discard", "most", "examples", "and", "can", "not", "handle", "the", "problem", "well", ".", "Recently", "the", "work", "reformulate", "the", "cross", "-", "entropy", "loss", "so", "that", "easy", "negatives", "are", "down", "-", "weighted", "and", "the", "hard", "examples", "are", "unaffected", "or", "even", "up", "-", "weighted", ".", "For", "stable", "training", "of", "box", "regression", ",", "Fast", "R", "-", "CNN", "introduces", "the", "smooth", "loss", ".", "This", "loss", "reduces", "the", "impact", "of", "outliers", "so", "that", "the", "training", "of", "model", "can", "be", "more", "stable", ".", "Almost", "all", "the", "following", "works", "take", "the", "smooth", "loss", "as", "a", "default", "for", "box", "regression", ".", "The", "work", "tries", "to", "improve", "regression", "performance", "by", "changing", "the", "target", "to", "a", "distribution", "and", "using", "a", "histogram", "loss", "to", "calculate", "the", "K", "-", "L", "divergence", "of", "prediction", "and", "target", ".", "The", "work", "balances", "multi", "-", "task", "losses", "by", "dynamically", "tuning", "gradient", "magnitude", "of", "different", "task", "branches", ".", "Our", "GHM", "based", "loss", "harmonizes", "the", "contribution", "of", "examples", "on", "the", "basis", "of", "the", "distribution", "of", "their", "gradient", ",", "so", "that", "it", "can", "handle", "both", "the", "class", "imbalance", "and", "the", "outliers", "problem", "well", ".", "It", "can", "also", "adapt", "the", "weights", "to", "the", "changing", "of", "data", "distribution", "in", "each", "mini", "-", "batch", ".", "section", ":", "Gradient", "Harmonizing", "Mechanism", "subsection", ":", "Problem", "Description", "Similar", "to", ",", "our", "efforts", "here", "are", "focused", "on", "classification", "in", "one", "-", "stage", "object", "detection", "where", "the", "classes", "(", "foreground", "/", "background", ")", "of", "examples", "are", "quite", "imbalanced", ".", "For", "a", "candidate", "box", ",", "let", "be", "the", "probability", "predicted", "by", "the", "model", "and", "be", "its", "ground", "-", "truth", "label", "for", "a", "certain", "class", ".", "Consider", "the", "binary", "cross", "entropy", "loss", ":", "Let", "x", "be", "the", "direct", "output", "of", "the", "model", "such", "that", ",", "we", "have", "the", "gradient", "with", "regard", "to", "x", ":", "We", "define", "as", "follows", ":", "equals", "to", "the", "norm", "of", "gradient", "w.r.t", ".", "The", "value", "of", "represents", "attribute", "(", "e.g.", "easy", "or", "hard", ")", "of", "an", "example", "and", "implies", "the", "example", "\u2019s", "impact", "on", "the", "global", "gradient", ".", "Although", "the", "strict", "definition", "of", "gradient", "is", "on", "the", "whole", "parameter", "space", ",", "which", "means", "is", "a", "relative", "norm", "of", "an", "example", "\u2019s", "gradient", ",", "we", "call", "as", "gradient", "norm", "in", "this", "paper", "for", "convenience", ".", "Fig", ".", "[", "reference", "]", "shows", "the", "distribution", "of", "from", "a", "converged", "one", "-", "stage", "detection", "model", ".", "Since", "the", "easy", "negatives", "have", "a", "dominant", "number", ",", "we", "use", "log", "axis", "to", "display", "the", "fraction", "of", "examples", "to", "demonstrate", "the", "details", "of", "the", "variance", "of", "examples", "with", "different", "attributes", ".", "It", "can", "be", "seen", "that", "the", "number", "of", "very", "easy", "examples", "is", "extremely", "large", ",", "which", "have", "a", "great", "impact", "on", "the", "global", "gradient", ".", "Moreover", ",", "we", "can", "see", "that", "a", "converged", "model", "still", "ca", "n\u2019t", "handle", "some", "very", "hard", "examples", "whose", "number", "is", "even", "larger", "than", "the", "examples", "with", "medium", "difficulty", ".", "These", "very", "hard", "examples", "can", "be", "regarded", "as", "outliers", "since", "their", "gradient", "directions", "tends", "to", "vary", "largely", "from", "the", "gradient", "directions", "of", "the", "large", "amount", "of", "other", "examples", ".", "That", "is", ",", "if", "the", "converged", "model", "is", "forced", "to", "learn", "to", "classify", "these", "outliers", "better", ",", "the", "classification", "of", "the", "large", "number", "of", "other", "examples", "tends", "to", "be", "less", "accurate", ".", "subsection", ":", "Gradient", "Density", "To", "handle", "the", "problem", "of", "the", "disharmony", "of", "gradient", "norm", "distribution", ",", "we", "introduce", "a", "harmonizing", "approach", "with", "regard", "to", "gradient", "density", ".", "Gradient", "density", "function", "of", "training", "examples", "is", "formulated", "as", "Equation", ".", "[", "reference", "]", ":", "where", "is", "the", "gradient", "norm", "of", "the", "k", "-", "th", "example", ".", "And", "The", "gradient", "density", "of", "denotes", "the", "number", "of", "examples", "lying", "in", "the", "region", "centered", "at", "with", "a", "length", "of", "and", "normalized", "by", "the", "valid", "length", "of", "the", "region", ".", "Now", "we", "define", "the", "gradient", "density", "harmonizing", "parameter", "as", ":", "where", "is", "the", "total", "number", "of", "examples", ".", "To", "better", "comprehend", "the", "gradient", "density", "harmonizing", "parameter", ",", "we", "can", "rewrite", "it", "as", ".", "The", "denominator", "is", "a", "normalizer", "indicating", "the", "fraction", "of", "examples", "with", "neighborhood", "gradients", "to", "the", "i", "-", "th", "example", ".", "If", "the", "examples", "are", "uniformly", "distributed", "with", "regard", "to", "gradient", ",", "for", "any", "and", "each", "example", "will", "have", "the", "same", ",", "which", "means", "nothing", "is", "changed", ".", "Otherwise", ",", "the", "examples", "with", "large", "density", "will", "be", "relatively", "down", "-", "weighted", "by", "the", "normalizer", ".", "subsection", ":", "GHM", "-", "C", "Loss", "We", "embed", "the", "GHM", "into", "classification", "loss", "by", "regarding", "as", "the", "loss", "weight", "of", "the", "i", "-", "th", "example", "and", "the", "gradient", "density", "harmonized", "form", "of", "loss", "function", "is", ":", "Fig", ".", "[", "reference", "]", "illustrates", "the", "reformulated", "gradient", "norm", "of", "different", "losses", ".", "Here", "we", "take", "the", "original", "gradient", "norm", "of", "CE", ",", "i.e.", ",", "as", "the", "x", "-", "axis", "for", "convenient", "view", "since", "the", "density", "is", "calculated", "according", "to", ".", "We", "can", "see", "that", "the", "curves", "of", "Focal", "Loss", "and", "GHM", "-", "C", "loss", "have", "similar", "trend", ",", "which", "implies", "that", "Focal", "Loss", "with", "the", "best", "hyper", "-", "parameters", "is", "similar", "with", "uniform", "gradient", "harmonizing", ".", "Furthermore", ",", "GHM", "-", "C", "has", "one", "more", "merit", "that", "Focal", "loss", "ignores", ":", "down", "-", "weighting", "the", "gradient", "contribution", "of", "outliers", ".", "With", "our", "GHM", "-", "C", "loss", ",", "the", "huge", "number", "of", "very", "easy", "examples", "are", "largely", "down", "-", "weighted", "and", "the", "outliers", "are", "slightly", "down", "-", "weighted", "as", "well", ",", "which", "simultaneously", "addresses", "the", "attribute", "imbalance", "problem", "and", "the", "outliers", "problem", ".", "From", "the", "right", "figure", "in", "Fig", ".", "[", "reference", "]", "we", "can", "better", "see", "that", "GHM", "-", "C", "harmonizes", "the", "total", "gradient", "contribution", "of", "different", "group", "of", "examples", ".", "Since", "the", "gradient", "density", "is", "calculated", "every", "iteration", ",", "the", "weights", "of", "examples", "are", "not", "fixed", "w.r.t", ".", "(", "or", ")", "like", "focal", "loss", "but", "adaptive", "to", "current", "state", "of", "model", "and", "mini", "-", "batch", "of", "data", ".", "The", "dynamic", "property", "of", "GHM", "-", "C", "loss", "makes", "the", "training", "more", "efficient", "and", "robust", ".", "subsection", ":", "Unit", "Region", "Approximation", "subsubsection", ":", "Complexity", "Analysis", ":", "The", "naive", "algorithm", "to", "calculate", "the", "gradient", "density", "values", "of", "all", "examples", "has", "a", "time", "complexity", "of", ",", "which", "can", "be", "easily", "attained", "from", "Equations", "[", "reference", "]", "and", "[", "reference", "]", ".", "Even", "parallel", "computed", ",", "each", "computing", "unit", "still", "bears", "a", "computation", "of", ".", "And", "as", "far", "as", "we", "know", ",", "the", "best", "algorithm", "first", "sort", "the", "examples", "by", "gradient", "norm", "with", "a", "complexity", "of", "and", "then", "use", "a", "queue", "to", "scan", "the", "examples", "and", "get", "their", "density", "with", ".", "This", "sorting", "based", "method", "can", "not", "gain", "much", "from", "parallel", "computing", ".", "Since", "of", "an", "image", "in", "one", "-", "stage", "detector", "can", "be", "or", "even", ",", "to", "directly", "calculate", "the", "gradient", "density", "is", "quite", "time", "consuming", ".", "So", "we", "introduce", "an", "alternative", "approach", "to", "approximately", "attain", "the", "gradient", "density", "of", "examples", ".", "subsubsection", ":", "Unit", "Region", ":", "We", "divide", "the", "range", "space", "of", "into", "individual", "unit", "regions", "with", "a", "length", "of", ",", "and", "there", "are", "unit", "regions", ".", "Let", "be", "the", "unit", "region", "with", "index", "j", "so", "that", ".", "Let", "denote", "the", "number", "of", "examples", "lying", "in", ".", "We", "define", "s.t", ".", ",", "which", "is", "the", "index", "function", "to", "the", "unit", "region", "that", "lies", "in", ".", "Then", "we", "define", "the", "approximate", "gradient", "density", "function", "as", ":", "Then", "we", "have", "the", "approximate", "gradient", "density", "harmonizing", "parameter", ":", "Consider", "the", "special", "case", "where", ":", "there", "are", "just", "one", "unit", "region", "and", "all", "examples", "lie", "in", "it", ",", "so", "obviously", "every", "and", "each", "example", "keep", "their", "original", "gradient", "contribution", ".", "Finally", "we", "have", "the", "reformulated", "loss", "function", ":", "From", "Equation", ".", "[", "reference", "]", "we", "can", "see", "that", "the", "examples", "lying", "in", "the", "same", "unit", "region", "share", "the", "same", "gradient", "density", ".", "So", "we", "can", "use", "the", "algorithm", "of", "histogram", "statistics", "and", "the", "computation", "of", "all", "the", "gradient", "density", "values", "has", "a", "time", "complexity", "of", ".", "And", "parallel", "computing", "can", "be", "applied", "so", "that", "each", "computing", "unit", "has", "a", "computation", "of", ".", "In", "practice", ",", "we", "can", "attain", "good", "performance", "with", "quite", "small", "number", "of", "unit", "regions", ".", "That", "is", "is", "fairly", "small", "and", "the", "calculation", "of", "loss", "is", "efficient", ".", "subsubsection", ":", "EMA", ":", "Mini", "-", "batch", "statistics", "based", "methods", "usually", "face", "a", "problem", ":", "when", "many", "extreme", "data", "are", "just", "sampled", "in", "one", "mini", "-", "batch", ",", "the", "statistical", "result", "will", "be", "a", "serious", "noise", "and", "the", "training", "will", "be", "unstable", ".", "Exponential", "moving", "average", "(", "EMA", ")", "is", "a", "common", "used", "method", "to", "address", "this", "problem", ",", "e.g.", ",", "SGD", "with", "momentum", "and", "Batch", "Normalization", ".", "Since", "in", "the", "approximation", "algorithm", "the", "gradient", "densities", "come", "from", "the", "numbers", "of", "examples", "in", "the", "unit", "regions", ",", "we", "can", "apply", "EMA", "on", "each", "unit", "region", "to", "obtain", "more", "stable", "gradient", "densities", "for", "examples", ".", "Let", "be", "the", "number", "of", "examples", "in", "the", "j", "-", "th", "unit", "region", "in", "the", "t", "-", "th", "iteration", "and", "be", "the", "moving", "averaged", "number", ".", "We", "have", ":", "where", "is", "the", "momentum", "parameter", ".", "We", "use", "the", "averaged", "number", "to", "calculate", "the", "gradient", "density", "instead", "of", ":", "With", "EMA", ",", "the", "gradient", "density", "will", "be", "more", "smooth", "and", "insensitive", "to", "extreme", "data", ".", "subsection", ":", "GHM", "-", "R", "Loss", "Consider", "the", "parameterized", "offsets", ",", ",", "predicted", "by", "box", "regression", "branch", "and", "the", "target", "offsets", ",", ",", "computed", "from", "ground", "-", "truth", ".", "The", "regression", "loss", "usually", "adopts", "the", "smooth", "loss", "function", ":", "where", "where", "is", "the", "division", "point", "between", "the", "quadric", "part", "and", "the", "linear", "part", ",", "and", "usually", "set", "to", "in", "practice", ".", "Since", ",", "the", "gradient", "of", "smooth", "loss", "w.r.t", "can", "be", "expressed", "as", ":", "where", "is", "the", "sign", "function", ".", "Note", "that", "all", "the", "examples", "with", "larger", "than", "the", "division", "point", "have", "the", "same", "gradient", "norm", ",", "which", "makes", "the", "distinguishing", "of", "examples", "with", "different", "attributes", "impossible", "if", "depending", "on", "the", "gradient", "norm", ".", "An", "alternative", "choice", "is", "directly", "using", "as", "the", "measurement", "of", "different", "attributes", ",", "but", "the", "new", "problem", "is", "can", "reach", "to", "infinite", "in", "theory", "and", "the", "unit", "region", "approximation", "can", "not", "be", "implemented", ".", "To", "conveniently", "apply", "GHM", "on", "regression", "loss", ",", "we", "first", "modify", "the", "traditional", "loss", "into", "a", "more", "elegant", "form", ":", "This", "loss", "shares", "similar", "property", "with", "loss", ":", "when", "d", "is", "small", "it", "approximates", "a", "quadric", "function", "(", "loss", ")", "and", "when", "d", "is", "large", "is", "approximate", "a", "linear", "function", "(", "loss", ")", ".", "We", "denote", "the", "modified", "loss", "function", "as", "Authentic", "Smooth", "(", ")", "loss", "for", "its", "good", "property", "of", "authentic", "smoothness", ",", "which", "means", "all", "the", "degrees", "of", "derivatives", "are", "existed", "and", "continuous", ".", "In", "contrast", ",", "the", "second", "derivative", "of", "smooth", "loss", "does", "not", "exist", "at", "the", "point", ".", "Furthermore", ",", "the", "loss", "has", "an", "elegant", "form", "of", "gradient", "w.r.t", ":", "The", "range", "of", "the", "gradient", "is", "just", ",", "so", "the", "calculation", "of", "density", "in", "unit", "regions", "for", "loss", "in", "regression", "is", "as", "convenient", "as", "CE", "loss", "in", "classification", ".", "In", "practice", ",", "we", "set", "for", "loss", "to", "keep", "the", "same", "performance", "with", "loss", ".", "We", "define", "as", "the", "gradient", "norm", "of", "loss", "and", "the", "gradient", "distribution", "of", "a", "converged", "model", "is", "illustrated", "in", "Fig", ".", "[", "reference", "]", "We", "can", "see", "that", "there", "are", "large", "number", "of", "outliers", ".", "Note", "that", "the", "regression", "is", "only", "performed", "on", "the", "positive", "examples", "so", "it", "is", "reasonable", "for", "the", "different", "distribution", "trend", "between", "classification", "and", "regression", ".", "Above", "all", ",", "we", "can", "apply", "GHM", "on", "regression", "loss", ":", "The", "reformulated", "gradient", "contribution", "of", "loss", ",", "loss", "and", "GHM", "-", "R", "loss", "in", "Fig", ".", "[", "reference", "]", ".", "The", "x", "-", "axis", "adopts", "for", "convenient", "comparison", ".", "We", "emphasize", "that", "in", "box", "regression", "not", "all", "the", "\u201c", "easy", "examples", "\u201d", "are", "unimportant", ".", "An", "easy", "example", "in", "classification", "is", "usually", "a", "background", "region", "with", "a", "very", "low", "predicted", "probability", "and", "will", "be", "definitely", "excluded", "from", "the", "final", "candidates", ".", "Thus", "the", "improvement", "of", "this", "kind", "of", "examples", "makes", "nearly", "no", "contribution", "to", "the", "precision", ".", "But", "in", "box", "regression", ",", "an", "easy", "example", "still", "has", "deviation", "from", "the", "ground", "truth", "location", ".", "Better", "prediction", "of", "any", "example", "will", "directly", "improve", "the", "quality", "of", "the", "final", "candidates", ".", "Moreover", ",", "advanced", "datasets", "care", "more", "about", "the", "localization", "accuracy", ".", "For", "example", ",", "COCO", "takes", "the", "average", "AP", "from", "the", "IoU", "threshold", "0.5", "to", "0.95", "as", "the", "metric", "to", "evaluate", "an", "algorithm", ".", "In", "this", "metric", ",", "the", "some", "of", "the", "so", "called", "easy", "examples", "(", "those", "having", "small", "errors", ")", "are", "also", "important", "because", "reducing", "the", "errors", "of", "them", "can", "directly", "improve", "the", "AP", "at", "high", "threshold", "(", "e.g.", "AP@IoU=0.75", ")", ".", "Our", "GHM", "-", "R", "loss", "can", "harmonize", "the", "contribution", "of", "easy", "and", "hard", "examples", "for", "box", "regression", "by", "up", "-", "weighting", "the", "important", "part", "of", "easy", "examples", "and", "down", "-", "weighting", "the", "outliers", ".", "Experiments", "show", "that", "it", "can", "attain", "better", "performance", "than", "and", ".", "section", ":", "Experiments", "We", "evaluate", "our", "approach", "on", "the", "challenging", "COCO", "benchmark", ".", "For", "training", ",", "we", "follow", "the", "common", "used", "practice", "to", "divide", "the", "40k", "validation", "set", "into", "a", "35k", "subset", "and", "a", "5k", "subset", ".", "The", "union", "of", "the", "35k", "validation", "subset", "and", "the", "whole", "80k", "training", "set", "are", "used", "for", "training", "together", "and", "denoted", "as", "trainval35k", "set", ".", "The", "5k", "validation", "subset", "is", "denoted", "as", "minival", "set", "and", "our", "ablation", "study", "is", "performed", "on", "it", ".", "While", "our", "main", "results", "are", "reported", "on", "the", "test", "-", "dev", "set", ".", "subsection", ":", "Implementation", "Details", "subsubsection", ":", "Network", "Setting", ":", "We", "use", "RetinaNet", "as", "network", "architecture", "and", "all", "the", "experiments", "adopt", "ResNet", "as", "backbone", "with", "Feature", "Pyramid", "Network", "(", "FPN", ")", "structure", ".", "Anchors", "use", "3", "scales", "and", "3", "aspect", "ratios", "for", "convenient", "comparison", "with", "focal", "loss", ".", "The", "input", "image", "scale", "is", "set", "as", "800", "pixel", "for", "all", "experiments", ".", "For", "all", "ablation", "studies", ",", "ResNet", "-", "50", "is", "used", ".", "While", "the", "final", "model", "evaluated", "on", "test", "-", "dev", "adopts", "ResNeXt", "-", "101", ".", "In", "contrast", "to", "focal", "loss", ",", "our", "approach", "does", "n\u2019t", "need", "a", "specialized", "bias", "initialization", ".", "subsubsection", ":", "Optimization", ":", "All", "the", "models", "are", "optimized", "by", "the", "common", "used", "SGD", "algorithm", ".", "We", "train", "the", "models", "on", "8", "GPUs", "with", "2", "images", "on", "each", "GPU", "so", "that", "the", "effective", "mini", "-", "batch", "size", "is", "16", ".", "All", "models", "are", "trained", "for", "14", "epochs", "with", "an", "initial", "learning", "rate", "of", "0.01", ",", "which", "is", "decreased", "by", "a", "factor", "0.1", "at", "the", "9th", "epoch", "and", "again", "at", "the", "12th", "epoch", ".", "We", "also", "use", "a", "weight", "decay", "parameter", "of", "0.0001", "and", "a", "momentum", "parameter", "of", "0.9", ".", "The", "only", "data", "augmentation", "operation", "is", "horizontal", "image", "flipping", ".", "For", "the", "EMA", "used", "in", "gradient", "density", "calculation", ",", "we", "use", "for", "all", "experiments", "since", "the", "results", "are", "insensitive", "to", "the", "exact", "value", "of", ".", "subsection", ":", "GHM", "-", "C", "Loss", "To", "focus", "on", "the", "effect", "of", "GHM", "-", "C", "loss", "function", ",", "experiments", "in", "this", "section", "all", "adopt", "smooth", "loss", "function", "with", "for", "the", "box", "regression", "branch", ".", "subsubsection", ":", "Baseline", ":", "We", "have", "trained", "a", "model", "with", "the", "standard", "cross", "entropy", "loss", "as", "the", "baseline", ".", "The", "standard", "initialization", "will", "lead", "to", "quick", "divergence", ",", "so", "we", "follow", "focal", "loss", "to", "initialize", "the", "bias", "term", "of", "the", "last", "layer", "to", "with", "to", "avoid", "divergence", ".", "However", "with", "the", "specialized", "initialization", "the", "loss", "of", "classification", "is", "very", "small", ",", "so", "we", "up", "-", "weight", "the", "classification", "loss", "by", "20", "to", "make", "the", "begging", "loss", "value", "reasonable", "(", "the", "begging", "classification", "loss", "value", "is", "around", "1", "now", ")", ".", "But", "when", "the", "model", "converge", ",", "the", "classification", "loss", "is", "still", "very", "small", "and", "we", "finally", "obtain", "a", "model", "with", "an", "Average", "Precision", "(", "AP", ")", "of", "28.6", ".", "subsubsection", ":", "Number", "of", "Unit", "Region", "Table", ".", "[", "reference", "]", "shows", "the", "results", "of", "varying", "which", "is", "the", "number", "of", "unit", "regions", ".", "EMA", "is", "not", "applied", "here", ".", "When", "is", "too", "small", ",", "the", "density", "can", "not", "have", "a", "good", "variation", "over", "different", "gradient", "norm", "and", "the", "performance", "is", "not", "so", "good", ".", "So", "we", "can", "gain", "more", "when", "increases", "when", "is", "not", "large", ".", "However", "is", "not", "necessarily", "very", "large", ",", "when", ",", "the", "GHM", "-", "C", "loss", "yields", "a", "large", "enough", "improvement", "over", "baseline", ".", "subsubsection", ":", "Speed", ":", "Since", "our", "approach", "is", "a", "loss", "function", ",", "it", "does", "n\u2019t", "change", "the", "time", "for", "inference", ".", "For", "training", ",", "a", "small", "of", "30", "is", "enough", "to", "attain", "good", "performance", ",", "so", "time", "consumed", "by", "gradient", "density", "calculation", "is", "not", "long", ".", "Table", ".", "[", "reference", "]", "shows", "the", "average", "time", "for", "each", "iteration", "during", "training", "as", "well", "as", "average", "precision", ".", "Here", "\u201c", "GHM", "-", "C", "Standard", "\u201d", "is", "implemented", "using", "the", "original", "definition", "of", "gradient", "density", "and", "\u201c", "GHM", "-", "C", "RU", "\u201d", "represents", "the", "implementation", "of", "region", "unit", "approximation", "algorithm", ".", "The", "experiments", "are", "performed", "on", "1080Ti", "GPUs", ".", "We", "can", "see", "that", "our", "region", "unit", "approximation", "algorithm", "speed", "up", "the", "training", "by", "magnitudes", "with", "negligible", "harm", "to", "performance", ".", "While", "compared", "with", "CE", ",", "the", "slow", "down", "of", "GHM", "-", "C", "loss", "is", "also", "acceptable", ".", "Since", "our", "loss", "is", "not", "fully", "GPU", "implemented", "now", ",", "there", "is", "still", "room", "for", "improvement", ".", "subsubsection", ":", "Comparison", "with", "Other", "Methods", ":", "Table", ".", "[", "reference", "]", "shows", "the", "results", "using", "our", "loss", "compared", "with", "other", "loss", "functions", "or", "sampling", "strategy", ".", "Since", "the", "reported", "results", "on", "of", "models", "using", "focal", "loss", "is", "trained", "with", "the", "input", "image", "scale", "of", "600", "pixels", ",", "for", "fair", "comparison", "we", "have", "re", "-", "trained", "a", "focal", "loss", "using", "a", "scale", "of", "800", "pixels", "and", "keep", "the", "best", "parameters", "of", "focal", "loss", ".", "We", "can", "see", "our", "loss", "has", "slightly", "better", "performance", "than", "focal", "loss", ".", "subsection", ":", "GHM", "-", "R", "Loss", "subsubsection", ":", "Comparison", "with", "Other", "Losses", ":", "The", "experiments", "here", "adopt", "the", "best", "configuration", "of", "GHM", "-", "C", "loss", "for", "the", "classification", "branch", ".", "So", "the", "first", "baseline", "is", "the", "model", "(", "trained", "using", "loss", ")", "with", "an", "AP", "of", "35.8", "showed", "in", "GHM", "-", "C", "loss", "experiments", ".", "We", "adopts", "for", "loss", "to", "get", "comparable", "results", "with", "loss", "and", "obtain", "a", "fair", "baseline", "for", "GHM", "-", "R", "loss", ".", "Table", ".", "[", "reference", "]", "shows", "the", "results", "of", "the", "baseline", "and", "loss", "as", "well", "as", "GHM", "-", "R", "loss", ".", "We", "can", "see", "a", "gain", "of", "0.7", "mAP", "based", "on", "the", "loss", ".", "Table", ".", "[", "reference", "]", "shows", "the", "details", "of", "AP", "at", "different", "IoU", "thresholds", ".", "GHM", "-", "R", "loss", "slightly", "lowers", "the", "AP@IoU=0.5", "but", "gains", "when", "the", "threshold", "is", "higher", ",", "which", "demonstrates", "our", "proposition", "that", "the", "so", "called", "easy", "examples", "in", "regression", "is", "important", "for", "accurate", "localization", ".", "subsubsection", ":", "Two", "-", "Stage", "Detector", ":", "GHM", "-", "R", "loss", "for", "regression", "is", "not", "limited", "to", "one", "-", "stage", "detectors", ".", "So", "we", "have", "done", "experiments", "to", "verify", "the", "effect", "on", "two", "-", "stage", "detectors", ".", "Our", "baseline", "method", "is", "faster", "-", "RCNN", "with", "Res50", "-", "FPN", "model", "using", "loss", "for", "box", "regression", ".", "Table", ".", "[", "reference", "]", "shows", "that", "GHM", "-", "R", "loss", "works", "for", "two", "-", "stage", "detector", "as", "well", "as", "one", "-", "stage", "detector", ".", "subsection", ":", "Main", "Results", "We", "use", "the", "32x8d", "FPN", "-", "ResNext101", "backbone", "and", "RetinaNet", "model", "with", "GHM", "-", "C", "loss", "for", "classification", "and", "GHM", "-", "R", "loss", "for", "box", "regression", ".", "The", "experiments", "are", "performed", "on", "test", "-", "dev", "set", ".", "Table", ".", "[", "reference", "]", "shows", "our", "main", "result", "compared", "with", "state", "-", "of", "-", "the", "-", "art", "methods", ".", "Our", "approach", "achieves", "excellent", "performance", "and", "outperforms", "focal", "loss", "in", "most", "metrics", ".", "section", ":", "Conclusion", "and", "Discussion", "In", "this", "work", ",", "we", "focus", "on", "the", "two", "imbalance", "problems", "in", "single", "-", "stage", "detectors", "and", "summarize", "these", "two", "problems", "to", "the", "disharmony", "in", "gradient", "density", "with", "regard", "to", "the", "difficulty", "of", "samples", ".", "Two", "loss", "functions", ",", "GHM", "-", "C", "and", "GHM", "-", "R", "are", "proposed", "to", "conquer", "the", "disharmony", "in", "classification", "and", "bounding", "box", "regression", "respectively", ".", "Experiments", "show", "that", "the", "collaborate", "with", "GHM", ",", "the", "performance", "of", "single", "-", "stage", "detector", "can", "easily", "surpass", "modern", "state", "-", "of", "-", "the", "-", "art", "two", "-", "stage", "detectors", "like", "FPN", "and", "Mask", "-", "RCNN", "with", "the", "same", "network", "backbone", ".", "Despite", "of", "the", "improvement", "of", "select", "uniform", "distribution", "to", "be", "the", "target", ",", "we", "still", "hold", "the", "opinion", "that", "the", "optimal", "distribution", "of", "gradient", "is", "hard", "to", "define", "and", "requires", "further", "research", ".", "section", ":", "Acknowledgments", "We", "sincerely", "appreciate", "the", "technical", "and", "GPU", "support", "from", "Mr.", "Changbao", "Wang", ",", "Quanquan", "Li", "and", "Junjie", "Yan", "at", "Sensetime", "Research", ".", "And", "we", "also", "acknowledge", "the", "early", "discussion", "with", "Prof", ".", "Wanli", "Ouyang", "from", "University", "of", "Sydney", ".", "bibliography", ":", "References"]}