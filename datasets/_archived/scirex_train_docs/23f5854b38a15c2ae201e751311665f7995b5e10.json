{"coref": {"Collaborative_Filtering": [[3, 5], [16, 18], [45, 48], [195, 199], [310, 312], [323, 325], [358, 360], [423, 426], [454, 456], [526, 529], [2145, 2147], [4063, 4066], [4255, 4257], [6559, 6561], [6912, 6915], [7138, 7140], [7920, 7922]], "Million_Song_Dataset": [[4951, 4954], [4955, 4956], [4972, 4975], [6868, 6870]], "MovieLens_20M": [[4845, 4849], [4850, 4854], [4922, 4926], [5805, 5809], [6386, 6390], [6630, 6634], [6738, 6742], [7046, 7050], [7283, 7287], [7325, 7328], [7487, 7491], [7712, 7716], [7734, 7738]], "Mult-DAE": [[500, 503], [3191, 3193], [3373, 3375], [3384, 3387], [3421, 3424], [3522, 3524], [3540, 3543], [3696, 3699], [3775, 3778], [4356, 4358], [4680, 4683], [4767, 4770], [4798, 4801], [5079, 5082], [5492, 5495], [5743, 5746], [5766, 5769], [5789, 5792], [6099, 6101], [6146, 6149], [6575, 6578], [6610, 6613], [6626, 6629], [6656, 6657], [6786, 6789], [6847, 6850], [6853, 6854], [6871, 6874], [7185, 7186], [7200, 7203], [7241, 7244], [7297, 7300], [7308, 7311], [7394, 7397], [7498, 7501], [7680, 7683], [7783, 7786], [7817, 7820], [7841, 7844], [7897, 7900], [8027, 8029], [8030, 8033], [8047, 8050], [8102, 8103], [3339, 3341], [3550, 3552], [4331, 4333], [4345, 4347], [5578, 5581], [6087, 6089], [7013, 7016]], "Mult-VAE_PR": [[2832, 2836], [3364, 3368], [3410, 3414], [3645, 3649], [3687, 3691], [3752, 3756], [4675, 4679], [4703, 4707], [4762, 4766], [4784, 4788], [5074, 5078], [5487, 5491], [5645, 5649], [5685, 5689], [5709, 5713], [5738, 5742], [5784, 5788], [6141, 6145], [6566, 6570], [6605, 6609], [6622, 6624], [6651, 6655], [6814, 6818], [7008, 7012], [7156, 7160], [7176, 7180], [7195, 7199], [7208, 7212], [7228, 7232], [7251, 7255], [7288, 7292], [7303, 7307], [7389, 7393], [7461, 7465], [7606, 7610], [7628, 7632], [7677, 7679], [7755, 7759], [7799, 7803], [7831, 7835], [7996, 8000], [8042, 8046], [8054, 8058], [8097, 8101], [8147, 8151]], "Netflix": [[4900, 4902], [4903, 4904], [6055, 6057], [6635, 6639], [7320, 7322], [4916, 4918]], "Recall_20": [], "Recall_50": []}, "coref_non_salient": {"0": [[23, 28], [3140, 3145]], "1": [[82, 85], [247, 249], [320, 322], [540, 542], [775, 777], [2504, 2506], [4472, 4474]], "10": [[5631, 5635], [5866, 5871]], "100": [[2717, 2720]], "101": [[1802, 1808]], "102": [[5697, 5701], [6831, 6835]], "103": [[1307, 1310]], "104": [[1374, 1377]], "105": [[4208, 4210]], "106": [[6465, 6466]], "107": [[5454, 5458]], "108": [[6125, 6127]], "109": [[2274, 2279]], "11": [[234, 236], [291, 293], [655, 657], [1576, 1578]], "110": [[2882, 2884]], "111": [[555, 559]], "112": [[5479, 5480], [5963, 5964], [7381, 7382]], "113": [[6059, 6062]], "114": [[1709, 1712]], "115": [[2907, 2909]], "116": [[3169, 3171]], "117": [[3219, 3221]], "118": [[496, 499]], "119": [[3163, 3167]], "12": [[55, 57], [75, 77], [185, 187], [598, 600], [807, 809], [1748, 1750], [2829, 2831], [4463, 4465], [4747, 4749], [6891, 6893], [6903, 6905], [6999, 7001], [7075, 7077], [7142, 7144], [7959, 7961]], "120": [[1333, 1337]], "121": [[1339, 1343]], "122": [[5369, 5371]], "123": [[6121, 6124]], "124": [[6133, 6137]], "125": [[1065, 1069]], "126": [[2921, 2923]], "127": [[6391, 6392]], "128": [[6461, 6464]], "129": [[6199, 6201]], "13": [[191, 193], [623, 625], [1594, 1596], [7948, 7951]], "130": [[5990, 5997]], "131": [[2245, 2248]], "132": [[94, 96]], "133": [[2946, 2948]], "134": [[6035, 6036], [6686, 6687], [7301, 7302], [7661, 7662], [7693, 7694], [7748, 7749]], "135": [[5733, 5735]], "136": [[1852, 1858]], "137": [[19, 21], [457, 459]], "138": [[72, 73], [512, 513]], "139": [[2310, 2312]], "14": [[472, 480], [720, 725]], "140": [[5894, 5897]], "141": [[1319, 1323]], "142": [[62, 64], [3479, 3481]], "143": [[1302, 1304], [6900, 6902], [7114, 7116]], "144": [[1983, 1985], [2030, 2032], [3582, 3584], [3815, 3817], [5511, 5513], [7353, 7355]], "145": [[551, 554]], "146": [[5883, 5889]], "147": [[6159, 6160]], "148": [[6556, 6558]], "149": [[3590, 3593]], "15": [[627, 630], [828, 832], [1604, 1608], [4451, 4457], [4755, 4759], [7513, 7516]], "150": [[4337, 4340], [4475, 4478], [6286, 6289]], "151": [[3902, 3904]], "152": [[1823, 1825], [1914, 1916], [2189, 2191], [7223, 7227]], "153": [[3595, 3598]], "154": [[5906, 5907]], "155": [[1643, 1647]], "156": [[1412, 1419]], "157": [[487, 492]], "158": [[2937, 2944]], "159": [[1948, 1951]], "16": [[637, 641], [672, 677]], "160": [[1352, 1355]], "161": [[811, 813]], "17": [[3417, 3420], [4794, 4796], [7238, 7240], [7779, 7782]], "18": [[2625, 2628], [2677, 2678], [2805, 2807], [6362, 6364], [6702, 6704]], "19": [[1753, 1754], [3586, 3587]], "2": [[1084, 1091], [1098, 1100], [1290, 1292], [3741, 3744], [7869, 7871]], "20": [[38, 41], [400, 404], [462, 467], [7933, 7936]], "21": [[546, 548], [5034, 5038]], "22": [[2173, 2174], [3664, 3665], [4280, 4282], [7362, 7363]], "23": [[864, 865], [2530, 2532], [4085, 4087]], "24": [[4176, 4178], [6074, 6075]], "25": [[119, 120], [2674, 2675], [2705, 2706], [4020, 4021]], "26": [[2629, 2631], [2637, 2639], [2670, 2672], [8017, 8019]], "27": [[1258, 1260], [1402, 1404], [3850, 3852], [4567, 4570], [5872, 5875]], "28": [[1833, 1835], [2038, 2040], [3214, 3217], [3248, 3250], [3575, 3578], [3764, 3766]], "29": [[4382, 4384], [4426, 4427], [4523, 4524], [4560, 4561], [6238, 6239], [6317, 6318], [6659, 6660], [6684, 6685]], "3": [[407, 408], [632, 633], [1379, 1381], [4865, 4868], [7467, 7468], [7612, 7613]], "30": [[3883, 3884], [4430, 4431]], "31": [[563, 568], [617, 619], [1570, 1575], [6979, 6984]], "32": [[2785, 2787], [2839, 2841]], "33": [[2843, 2846], [4647, 4650], [5861, 5864], [6666, 6669]], "34": [[59, 61], [3135, 3138], [4113, 4115]], "35": [[5835, 5836], [6024, 6025], [6283, 6285]], "36": [[7153, 7155], [7507, 7509]], "37": [[1106, 1110], [1146, 1150], [6646, 6650]], "38": [[133, 136], [872, 876], [4095, 4099], [4103, 4107]], "39": [[5793, 5794], [6218, 6219]], "4": [[2281, 2284], [2857, 2860]], "40": [[1760, 1762], [1817, 1819], [1862, 1864]], "41": [[4504, 4506]], "42": [[138, 141], [867, 871], [4180, 4183]], "43": [[34, 37], [6836, 6839], [7937, 7940]], "44": [[5039, 5040], [5103, 5104], [5174, 5175], [5201, 5202]], "45": [[4261, 4269], [4729, 4737]], "46": [[3329, 3330], [5749, 5750]], "47": [[5619, 5620]], "48": [[7888, 7891]], "49": [[1906, 1908], [2121, 2123]], "5": [[1094, 1096], [1276, 1278], [1751, 1752], [3269, 3271]], "50": [[13, 14], [446, 447], [460, 461], [756, 757], [773, 774], [796, 797], [2117, 2118], [2470, 2471], [2820, 2821], [3239, 3240], [3275, 3276], [3564, 3565], [3604, 3605], [3652, 3653], [3923, 3924], [3931, 3932], [3959, 3960], [3990, 3991], [4018, 4019], [4082, 4083], [4202, 4203], [4416, 4417], [7918, 7919], [842, 843], [884, 885], [1458, 1459], [1962, 1963], [2177, 2178], [2365, 2366], [2827, 2828], [3133, 3134], [3201, 3202], [3619, 3620], [3972, 3973], [4235, 4236], [5575, 5576], [5778, 5779], [7859, 7860], [7981, 7982], [7994, 7995]], "51": [[1713, 1715], [2915, 2917]], "52": [[419, 421], [483, 485], [2847, 2849], [4252, 4254], [4640, 4642], [6304, 6306], [7953, 7955]], "53": [[6178, 6181]], "54": [[6204, 6206]], "55": [[5876, 5877], [5892, 5893]], "56": [[1356, 1361], [4616, 4621]], "57": [[5227, 5228], [5233, 5234], [5248, 5249]], "58": [[3818, 3819], [3830, 3831]], "59": [[1265, 1267], [1634, 1638]], "6": [[5582, 5590], [5690, 5694], [6791, 6799], [6820, 6828]], "60": [[2520, 2522], [4039, 4041]], "61": [[1157, 1159], [5521, 5525]], "62": [[4168, 4172]], "63": [[7105, 7108]], "64": [[1405, 1406], [2109, 2110], [3121, 3122], [3188, 3189], [3301, 3302], [3434, 3435], [3446, 3447], [3487, 3488], [3519, 3520], [3538, 3539], [3800, 3801], [3898, 3899], [4579, 4580]], "65": [[4479, 4480], [4512, 4513], [4530, 4531], [4562, 4563], [6290, 6291], [6324, 6325], [6413, 6414], [6721, 6722], [6851, 6852], [6856, 6857]], "66": [[2249, 2250], [2255, 2256], [2271, 2272], [2379, 2380], [2384, 2385], [2454, 2455], [2474, 2475], [2534, 2535], [4089, 4090]], "67": [[6432, 6435]], "68": [[1236, 1238], [1467, 1469]], "69": [[5974, 5976], [6677, 6679]], "7": [[344, 347], [535, 539], [1251, 1253], [1396, 1400], [2184, 2188], [6918, 6922]], "70": [[69, 71], [509, 511], [2999, 3001]], "71": [[2306, 2308], [2342, 2344]], "72": [[52, 54], [1054, 1056], [1247, 1249], [1765, 1767], [2083, 2085], [2483, 2485], [2498, 2500], [3675, 3677], [3827, 3829], [4059, 4061], [4116, 4118], [5502, 5504], [7944, 7946]], "73": [[5761, 5765], [5774, 5776], [6259, 6261]], "74": [[5048, 5049], [5117, 5118], [5230, 5231]], "75": [[216, 220], [741, 744], [7769, 7773], [8108, 8111]], "76": [[5042, 5047], [5222, 5226]], "77": [[4441, 4442]], "78": [[4654, 4658]], "79": [[2765, 2767]], "8": [[1598, 1603], [3842, 3847]], "80": [[5968, 5969], [6033, 6034], [6076, 6077]], "81": [[125, 127], [858, 860]], "82": [[5838, 5841]], "83": [[2815, 2816]], "84": [[577, 581]], "85": [[6453, 6456], [6858, 6861], [6878, 6883]], "86": [[3475, 3477], [3529, 3531], [3600, 3602], [6713, 6715]], "87": [[963, 964], [2564, 2565], [3243, 3244]], "88": [[0, 2], [10, 12], [443, 445], [1910, 1912], [2114, 2116], [3928, 3930], [4741, 4745]], "89": [[2991, 2992]], "9": [[167, 170], [917, 921], [8080, 8086]], "90": [[5677, 5679]], "91": [[762, 766]], "92": [[2104, 2106]], "93": [[7520, 7522]], "94": [[1172, 1174]], "95": [[5473, 5475]], "96": [[5383, 5384]], "97": [[3160, 3162]], "98": [[7023, 7026]], "99": [[4110, 4112]]}, "doc_id": "23f5854b38a15c2ae201e751311665f7995b5e10", "method_subrelations": {"Mult-DAE": [[[0, 8], "Mult-DAE"]], "Mult-VAE_PR": [[[0, 11], "Mult-VAE_PR"]]}, "n_ary_relations": [{"Material": "Million_Song_Dataset", "Method": "Mult-DAE", "Metric": "Recall_20", "Task": "Collaborative_Filtering", "score": "0.266"}, {"Material": "Million_Song_Dataset", "Method": "Mult-VAE_PR", "Metric": "Recall_20", "Task": "Collaborative_Filtering", "score": "0.266"}, {"Material": "Million_Song_Dataset", "Method": "Mult-DAE", "Metric": "Recall_50", "Task": "Collaborative_Filtering", "score": "0.363"}, {"Material": "Million_Song_Dataset", "Method": "Mult-VAE_PR", "Metric": "Recall_50", "Task": "Collaborative_Filtering", "score": "0.364"}, {"Material": "MovieLens_20M", "Method": "Mult-DAE", "Metric": "Recall_20", "Task": "Collaborative_Filtering", "score": "0.387"}, {"Material": "MovieLens_20M", "Method": "Mult-VAE_PR", "Metric": "Recall_20", "Task": "Collaborative_Filtering", "score": "0.395"}, {"Material": "MovieLens_20M", "Method": "Mult-DAE", "Metric": "Recall_50", "Task": "Collaborative_Filtering", "score": "0.524"}, {"Material": "MovieLens_20M", "Method": "Mult-VAE_PR", "Metric": "Recall_50", "Task": "Collaborative_Filtering", "score": "0.537"}, {"Material": "Netflix", "Method": "Mult-DAE", "Metric": "Recall_20", "Task": "Collaborative_Filtering", "score": "0.344"}, {"Material": "Netflix", "Method": "Mult-VAE_PR", "Metric": "Recall_20", "Task": "Collaborative_Filtering", "score": "0.351"}, {"Material": "Netflix", "Method": "Mult-DAE", "Metric": "Recall_50", "Task": "Collaborative_Filtering", "score": "0.438"}, {"Material": "Netflix", "Method": "Mult-VAE_PR", "Metric": "Recall_50", "Task": "Collaborative_Filtering", "score": "0.444"}], "ner": [[0, 2, "Method"], [3, 5, "Task"], [10, 12, "Method"], [13, 14, "Method"], [16, 18, "Task"], [19, 21, "Task"], [23, 28, "Method"], [34, 37, "Method"], [38, 41, "Method"], [45, 48, "Task"], [52, 54, "Method"], [55, 57, "Method"], [59, 61, "Method"], [62, 64, "Task"], [69, 71, "Task"], [72, 73, "Task"], [75, 77, "Method"], [82, 85, "Task"], [94, 96, "Metric"], [119, 120, "Method"], [125, 127, "Method"], [133, 136, "Method"], [138, 141, "Method"], [167, 170, "Method"], [185, 187, "Method"], [191, 193, "Method"], [195, 199, "Task"], [216, 220, "Method"], [234, 236, "Method"], [247, 249, "Task"], [291, 293, "Method"], [310, 312, "Task"], [320, 322, "Task"], [323, 325, "Task"], [344, 347, "Method"], [358, 360, "Task"], [400, 404, "Method"], [407, 408, "Task"], [419, 421, "Method"], [423, 426, "Task"], [443, 445, "Method"], [446, 447, "Method"], [454, 456, "Task"], [457, 459, "Task"], [460, 461, "Method"], [462, 467, "Method"], [472, 480, "Method"], [483, 485, "Method"], [487, 492, "Task"], [496, 499, "Method"], [500, 503, "Method"], [509, 511, "Task"], [512, 513, "Task"], [526, 529, "Task"], [535, 539, "Method"], [540, 542, "Task"], [546, 548, "Metric"], [551, 554, "Metric"], [555, 559, "Metric"], [563, 568, "Metric"], [577, 581, "Task"], [598, 600, "Method"], [617, 619, "Metric"], [623, 625, "Method"], [627, 630, "Method"], [632, 633, "Task"], [637, 641, "Task"], [655, 657, "Method"], [672, 677, "Task"], [720, 725, "Method"], [741, 744, "Method"], [756, 757, "Method"], [762, 766, "Task"], [773, 774, "Method"], [775, 777, "Task"], [796, 797, "Method"], [807, 809, "Method"], [811, 813, "Task"], [828, 832, "Method"], [858, 860, "Method"], [864, 865, "Method"], [867, 871, "Method"], [872, 876, "Method"], [917, 921, "Method"], [963, 964, "Task"], [1054, 1056, "Method"], [1065, 1069, "Method"], [1084, 1091, "Method"], [1094, 1096, "Method"], [1098, 1100, "Method"], [1106, 1110, "Method"], [1146, 1150, "Method"], [1157, 1159, "Method"], [1172, 1174, "Method"], [1236, 1238, "Method"], [1247, 1249, "Method"], [1251, 1253, "Method"], [1258, 1260, "Method"], [1265, 1267, "Method"], [1276, 1278, "Method"], [1290, 1292, "Method"], [1302, 1304, "Method"], [1307, 1310, "Task"], [1319, 1323, "Method"], [1333, 1337, "Metric"], [1339, 1343, "Task"], [1352, 1355, "Method"], [1356, 1361, "Task"], [1374, 1377, "Method"], [1379, 1381, "Task"], [1396, 1400, "Method"], [1402, 1404, "Method"], [1405, 1406, "Method"], [1412, 1419, "Method"], [1467, 1469, "Method"], [1570, 1575, "Metric"], [1576, 1578, "Method"], [1594, 1596, "Method"], [1598, 1603, "Method"], [1604, 1608, "Method"], [1634, 1638, "Method"], [1643, 1647, "Method"], [1709, 1712, "Method"], [1713, 1715, "Method"], [1748, 1750, "Method"], [1751, 1752, "Method"], [1753, 1754, "Method"], [1760, 1762, "Task"], [1765, 1767, "Method"], [1802, 1808, "Method"], [1817, 1819, "Task"], [1823, 1825, "Method"], [1833, 1835, "Method"], [1852, 1858, "Method"], [1862, 1864, "Task"], [1906, 1908, "Method"], [1910, 1912, "Method"], [1914, 1916, "Method"], [1948, 1951, "Task"], [1983, 1985, "Method"], [2030, 2032, "Method"], [2038, 2040, "Method"], [2083, 2085, "Method"], [2104, 2106, "Method"], [2109, 2110, "Method"], [2114, 2116, "Method"], [2117, 2118, "Method"], [2121, 2123, "Method"], [2145, 2147, "Task"], [2173, 2174, "Task"], [2184, 2188, "Method"], [2189, 2191, "Method"], [2245, 2248, "Metric"], [2249, 2250, "Method"], [2255, 2256, "Method"], [2271, 2272, "Method"], [2274, 2279, "Method"], [2281, 2284, "Method"], [2306, 2308, "Method"], [2310, 2312, "Method"], [2342, 2344, "Method"], [2379, 2380, "Method"], [2384, 2385, "Method"], [2454, 2455, "Method"], [2470, 2471, "Method"], [2474, 2475, "Method"], [2483, 2485, "Method"], [2498, 2500, "Method"], [2504, 2506, "Task"], [2520, 2522, "Method"], [2530, 2532, "Method"], [2534, 2535, "Method"], [2564, 2565, "Task"], [2625, 2628, "Metric"], [2629, 2631, "Method"], [2637, 2639, "Method"], [2670, 2672, "Method"], [2674, 2675, "Method"], [2677, 2678, "Metric"], [2705, 2706, "Method"], [2717, 2720, "Metric"], [2765, 2767, "Method"], [2785, 2787, "Metric"], [2805, 2807, "Metric"], [2815, 2816, "Metric"], [2820, 2821, "Method"], [2829, 2831, "Method"], [2832, 2836, "Method"], [2839, 2841, "Metric"], [2843, 2846, "Method"], [2847, 2849, "Method"], [2857, 2860, "Method"], [2882, 2884, "Method"], [2907, 2909, "Method"], [2915, 2917, "Method"], [2921, 2923, "Method"], [2937, 2944, "Method"], [2946, 2948, "Task"], [2991, 2992, "Task"], [2999, 3001, "Task"], [3121, 3122, "Method"], [3135, 3138, "Method"], [3140, 3145, "Method"], [3160, 3162, "Task"], [3163, 3167, "Task"], [3169, 3171, "Method"], [3188, 3189, "Method"], [3191, 3193, "Method"], [3214, 3217, "Method"], [3219, 3221, "Method"], [3239, 3240, "Method"], [3243, 3244, "Task"], [3248, 3250, "Method"], [3269, 3271, "Method"], [3275, 3276, "Method"], [3301, 3302, "Method"], [3329, 3330, "Method"], [3364, 3368, "Method"], [3373, 3375, "Method"], [3384, 3387, "Method"], [3410, 3414, "Method"], [3417, 3420, "Method"], [3421, 3424, "Method"], [3434, 3435, "Method"], [3446, 3447, "Method"], [3475, 3477, "Metric"], [3479, 3481, "Task"], [3487, 3488, "Method"], [3519, 3520, "Method"], [3522, 3524, "Method"], [3529, 3531, "Metric"], [3538, 3539, "Method"], [3540, 3543, "Method"], [3564, 3565, "Method"], [3575, 3578, "Method"], [3582, 3584, "Method"], [3586, 3587, "Method"], [3590, 3593, "Metric"], [3595, 3598, "Method"], [3600, 3602, "Metric"], [3604, 3605, "Method"], [3645, 3649, "Method"], [3652, 3653, "Method"], [3664, 3665, "Task"], [3675, 3677, "Method"], [3687, 3691, "Method"], [3696, 3699, "Method"], [3741, 3744, "Method"], [3752, 3756, "Method"], [3764, 3766, "Method"], [3775, 3778, "Method"], [3800, 3801, "Method"], [3815, 3817, "Method"], [3818, 3819, "Method"], [3827, 3829, "Method"], [3830, 3831, "Method"], [3842, 3847, "Method"], [3850, 3852, "Method"], [3883, 3884, "Task"], [3898, 3899, "Method"], [3902, 3904, "Task"], [3923, 3924, "Method"], [3928, 3930, "Method"], [3931, 3932, "Method"], [3959, 3960, "Method"], [3990, 3991, "Method"], [4018, 4019, "Method"], [4020, 4021, "Method"], [4039, 4041, "Method"], [4059, 4061, "Method"], [4063, 4066, "Task"], [4082, 4083, "Method"], [4085, 4087, "Method"], [4089, 4090, "Method"], [4095, 4099, "Method"], [4103, 4107, "Method"], [4110, 4112, "Method"], [4113, 4115, "Method"], [4116, 4118, "Method"], [4168, 4172, "Method"], [4176, 4178, "Method"], [4180, 4183, "Method"], [4202, 4203, "Method"], [4208, 4210, "Metric"], [4252, 4254, "Method"], [4255, 4257, "Task"], [4261, 4269, "Method"], [4280, 4282, "Task"], [4337, 4340, "Method"], [4356, 4358, "Method"], [4382, 4384, "Method"], [4416, 4417, "Method"], [4426, 4427, "Method"], [4430, 4431, "Task"], [4441, 4442, "Task"], [4451, 4457, "Method"], [4463, 4465, "Method"], [4472, 4474, "Task"], [4475, 4478, "Method"], [4479, 4480, "Method"], [4504, 4506, "Method"], [4512, 4513, "Method"], [4523, 4524, "Method"], [4530, 4531, "Method"], [4560, 4561, "Method"], [4562, 4563, "Method"], [4567, 4570, "Method"], [4579, 4580, "Method"], [4616, 4621, "Task"], [4640, 4642, "Method"], [4647, 4650, "Method"], [4654, 4658, "Task"], [4675, 4679, "Method"], [4680, 4683, "Method"], [4703, 4707, "Method"], [4729, 4737, "Method"], [4741, 4745, "Method"], [4747, 4749, "Method"], [4755, 4759, "Method"], [4762, 4766, "Method"], [4767, 4770, "Method"], [4784, 4788, "Method"], [4794, 4796, "Method"], [4798, 4801, "Method"], [4845, 4849, "Material"], [4850, 4854, "Material"], [4865, 4868, "Task"], [4900, 4902, "Material"], [4903, 4904, "Material"], [4922, 4926, "Material"], [4951, 4954, "Material"], [4955, 4956, "Material"], [4972, 4975, "Material"], [5034, 5038, "Metric"], [5039, 5040, "Metric"], [5042, 5047, "Method"], [5048, 5049, "Method"], [5074, 5078, "Method"], [5079, 5082, "Method"], [5103, 5104, "Metric"], [5117, 5118, "Method"], [5174, 5175, "Metric"], [5201, 5202, "Metric"], [5222, 5226, "Method"], [5227, 5228, "Method"], [5230, 5231, "Method"], [5233, 5234, "Method"], [5369, 5371, "Method"], [5383, 5384, "Task"], [5454, 5458, "Method"], [5473, 5475, "Method"], [5479, 5480, "Method"], [5487, 5491, "Method"], [5492, 5495, "Method"], [5502, 5504, "Method"], [5511, 5513, "Method"], [5521, 5525, "Method"], [5582, 5590, "Method"], [5619, 5620, "Method"], [5631, 5635, "Method"], [5645, 5649, "Method"], [5677, 5679, "Method"], [5685, 5689, "Method"], [5690, 5694, "Method"], [5697, 5701, "Method"], [5709, 5713, "Method"], [5733, 5735, "Task"], [5738, 5742, "Method"], [5743, 5746, "Method"], [5749, 5750, "Method"], [5761, 5765, "Method"], [5766, 5769, "Method"], [5774, 5776, "Method"], [5784, 5788, "Method"], [5789, 5792, "Method"], [5793, 5794, "Method"], [5805, 5809, "Material"], [5835, 5836, "Metric"], [5838, 5841, "Metric"], [5861, 5864, "Method"], [5866, 5871, "Method"], [5872, 5875, "Method"], [5876, 5877, "Method"], [5883, 5889, "Method"], [5892, 5893, "Method"], [5894, 5897, "Method"], [5906, 5907, "Method"], [5963, 5964, "Method"], [5968, 5969, "Method"], [5974, 5976, "Method"], [5990, 5997, "Task"], [6024, 6025, "Metric"], [6033, 6034, "Method"], [6035, 6036, "Method"], [6055, 6057, "Material"], [6059, 6062, "Task"], [6074, 6075, "Method"], [6076, 6077, "Method"], [6099, 6101, "Method"], [6121, 6124, "Method"], [6125, 6127, "Task"], [6133, 6137, "Method"], [6141, 6145, "Method"], [6146, 6149, "Method"], [6159, 6160, "Metric"], [6178, 6181, "Method"], [6199, 6201, "Method"], [6204, 6206, "Method"], [6218, 6219, "Method"], [6238, 6239, "Method"], [6259, 6261, "Method"], [6283, 6285, "Metric"], [6286, 6289, "Method"], [6290, 6291, "Method"], [6304, 6306, "Method"], [6317, 6318, "Method"], [6324, 6325, "Method"], [6362, 6364, "Metric"], [6386, 6390, "Material"], [6391, 6392, "Material"], [6413, 6414, "Method"], [6432, 6435, "Method"], [6453, 6456, "Method"], [6461, 6464, "Task"], [6465, 6466, "Method"], [6556, 6558, "Method"], [6559, 6561, "Task"], [6566, 6570, "Method"], [6575, 6578, "Method"], [6605, 6609, "Method"], [6610, 6613, "Method"], [6622, 6624, "Method"], [6626, 6629, "Method"], [6630, 6634, "Material"], [6635, 6639, "Material"], [6646, 6650, "Method"], [6651, 6655, "Method"], [6656, 6657, "Method"], [6659, 6660, "Method"], [6666, 6669, "Method"], [6677, 6679, "Method"], [6684, 6685, "Method"], [6686, 6687, "Method"], [6702, 6704, "Metric"], [6713, 6715, "Metric"], [6721, 6722, "Method"], [6738, 6742, "Material"], [6786, 6789, "Method"], [6791, 6799, "Method"], [6814, 6818, "Method"], [6820, 6828, "Method"], [6831, 6835, "Method"], [6836, 6839, "Method"], [6847, 6850, "Method"], [6851, 6852, "Method"], [6853, 6854, "Method"], [6856, 6857, "Method"], [6858, 6861, "Method"], [6868, 6870, "Material"], [6871, 6874, "Method"], [6878, 6883, "Method"], [6891, 6893, "Method"], [6900, 6902, "Method"], [6903, 6905, "Method"], [6912, 6915, "Task"], [6918, 6922, "Method"], [6979, 6984, "Metric"], [6999, 7001, "Method"], [7008, 7012, "Method"], [7023, 7026, "Method"], [7046, 7050, "Material"], [7075, 7077, "Method"], [7105, 7108, "Method"], [7114, 7116, "Method"], [7138, 7140, "Task"], [7142, 7144, "Method"], [7153, 7155, "Method"], [7156, 7160, "Method"], [7176, 7180, "Method"], [7185, 7186, "Method"], [7195, 7199, "Method"], [7200, 7203, "Method"], [7208, 7212, "Method"], [7223, 7227, "Method"], [7228, 7232, "Method"], [7238, 7240, "Method"], [7241, 7244, "Method"], [7251, 7255, "Method"], [7283, 7287, "Material"], [7288, 7292, "Method"], [7297, 7300, "Method"], [7301, 7302, "Method"], [7303, 7307, "Method"], [7308, 7311, "Method"], [7320, 7322, "Material"], [7325, 7328, "Material"], [7353, 7355, "Method"], [7362, 7363, "Task"], [7381, 7382, "Method"], [7389, 7393, "Method"], [7394, 7397, "Method"], [7461, 7465, "Method"], [7467, 7468, "Task"], [7487, 7491, "Material"], [7498, 7501, "Method"], [7507, 7509, "Method"], [7513, 7516, "Method"], [7520, 7522, "Task"], [7606, 7610, "Method"], [7612, 7613, "Task"], [7628, 7632, "Method"], [7661, 7662, "Method"], [7677, 7679, "Method"], [7680, 7683, "Method"], [7693, 7694, "Method"], [7712, 7716, "Material"], [7734, 7738, "Material"], [7748, 7749, "Method"], [7755, 7759, "Method"], [7769, 7773, "Method"], [7779, 7782, "Method"], [7783, 7786, "Method"], [7799, 7803, "Method"], [7817, 7820, "Method"], [7831, 7835, "Method"], [7841, 7844, "Method"], [7869, 7871, "Method"], [7888, 7891, "Metric"], [7897, 7900, "Method"], [7918, 7919, "Method"], [7920, 7922, "Task"], [7933, 7936, "Method"], [7937, 7940, "Method"], [7944, 7946, "Method"], [7948, 7951, "Method"], [7953, 7955, "Method"], [7959, 7961, "Method"], [7996, 8000, "Method"], [8017, 8019, "Method"], [8027, 8029, "Method"], [8030, 8033, "Method"], [8042, 8046, "Method"], [8047, 8050, "Method"], [8054, 8058, "Method"], [8080, 8086, "Method"], [8097, 8101, "Method"], [8102, 8103, "Method"], [8108, 8111, "Method"], [8147, 8151, "Method"], [842, 843, "Method"], [884, 885, "Method"], [1458, 1459, "Method"], [1962, 1963, "Method"], [2177, 2178, "Method"], [2365, 2366, "Method"], [2827, 2828, "Method"], [3133, 3134, "Method"], [3201, 3202, "Method"], [3339, 3341, "Method"], [3550, 3552, "Method"], [3619, 3620, "Method"], [3972, 3973, "Method"], [4235, 4236, "Method"], [4331, 4333, "Method"], [4345, 4347, "Method"], [4916, 4918, "Material"], [5248, 5249, "Method"], [5575, 5576, "Method"], [5578, 5581, "Method"], [5778, 5779, "Method"], [6087, 6089, "Method"], [7013, 7016, "Method"], [7859, 7860, "Method"], [7981, 7982, "Method"], [7994, 7995, "Method"]], "sections": [[0, 5], [5, 231], [231, 922], [922, 1050], [1050, 1758], [1758, 1904], [1904, 2374], [2374, 2837], [2837, 3116], [3116, 3662], [3662, 3919], [3919, 4248], [4248, 4666], [4666, 4824], [4824, 5028], [5028, 5263], [5263, 5844], [5844, 6513], [6513, 7906], [7906, 8165], [8165, 8167]], "sentences": [[0, 5], [5, 8], [8, 22], [22, 49], [49, 65], [65, 86], [86, 107], [107, 121], [121, 142], [142, 178], [178, 205], [205, 231], [231, 234], [234, 244], [244, 264], [264, 283], [283, 310], [310, 323], [323, 344], [344, 369], [369, 383], [383, 410], [410, 439], [439, 460], [460, 493], [493, 504], [504, 540], [540, 586], [586, 592], [592, 631], [631, 704], [704, 734], [734, 755], [755, 778], [778, 801], [801, 802], [802, 814], [814, 833], [833, 834], [834, 853], [853, 877], [877, 892], [892, 922], [922, 925], [925, 950], [950, 957], [957, 968], [968, 973], [973, 992], [992, 998], [998, 1005], [1005, 1009], [1009, 1010], [1010, 1012], [1012, 1030], [1030, 1039], [1039, 1050], [1050, 1053], [1053, 1069], [1069, 1077], [1077, 1097], [1097, 1100], [1100, 1110], [1110, 1124], [1124, 1145], [1145, 1150], [1150, 1163], [1163, 1188], [1188, 1203], [1203, 1211], [1211, 1246], [1246, 1255], [1255, 1279], [1279, 1295], [1295, 1323], [1323, 1344], [1344, 1381], [1381, 1385], [1385, 1407], [1407, 1444], [1444, 1464], [1464, 1477], [1477, 1505], [1505, 1539], [1539, 1557], [1557, 1583], [1583, 1609], [1609, 1612], [1612, 1617], [1617, 1625], [1625, 1629], [1629, 1642], [1642, 1649], [1649, 1650], [1650, 1651], [1651, 1660], [1660, 1672], [1672, 1674], [1674, 1700], [1700, 1716], [1716, 1724], [1724, 1725], [1725, 1726], [1726, 1746], [1746, 1758], [1758, 1762], [1762, 1789], [1789, 1808], [1808, 1809], [1809, 1814], [1814, 1819], [1819, 1835], [1835, 1841], [1841, 1859], [1859, 1886], [1886, 1896], [1896, 1904], [1904, 1913], [1913, 1942], [1942, 1958], [1958, 1964], [1964, 1987], [1987, 2017], [2017, 2040], [2040, 2063], [2063, 2068], [2068, 2071], [2071, 2085], [2085, 2117], [2117, 2137], [2137, 2161], [2161, 2176], [2176, 2208], [2208, 2239], [2239, 2252], [2252, 2262], [2262, 2264], [2264, 2288], [2288, 2309], [2309, 2334], [2334, 2364], [2364, 2374], [2374, 2381], [2381, 2419], [2419, 2444], [2444, 2467], [2467, 2507], [2507, 2529], [2529, 2566], [2566, 2572], [2572, 2588], [2588, 2621], [2621, 2644], [2644, 2659], [2659, 2673], [2673, 2709], [2709, 2752], [2752, 2755], [2755, 2768], [2768, 2783], [2783, 2809], [2809, 2822], [2822, 2837], [2837, 2842], [2842, 2885], [2885, 2910], [2910, 2945], [2945, 2993], [2993, 3015], [3015, 3019], [3019, 3052], [3052, 3074], [3074, 3093], [3093, 3101], [3101, 3116], [3116, 3122], [3122, 3151], [3151, 3163], [3163, 3176], [3176, 3217], [3217, 3235], [3235, 3272], [3272, 3291], [3291, 3294], [3294, 3327], [3327, 3360], [3360, 3380], [3380, 3388], [3388, 3425], [3425, 3456], [3456, 3482], [3482, 3489], [3489, 3505], [3505, 3528], [3528, 3540], [3540, 3549], [3549, 3563], [3563, 3571], [3571, 3599], [3599, 3612], [3612, 3621], [3621, 3631], [3631, 3642], [3642, 3662], [3662, 3665], [3665, 3684], [3684, 3712], [3712, 3740], [3740, 3751], [3751, 3767], [3767, 3769], [3769, 3770], [3770, 3791], [3791, 3802], [3802, 3832], [3832, 3838], [3838, 3893], [3893, 3919], [3919, 3923], [3923, 3928], [3928, 3948], [3948, 3964], [3964, 3968], [3968, 3977], [3977, 3985], [3985, 4012], [4012, 4032], [4032, 4077], [4077, 4084], [4084, 4094], [4094, 4099], [4099, 4119], [4119, 4143], [4143, 4160], [4160, 4164], [4164, 4187], [4187, 4204], [4204, 4216], [4216, 4225], [4225, 4229], [4229, 4248], [4248, 4252], [4252, 4258], [4258, 4318], [4318, 4344], [4344, 4376], [4376, 4407], [4407, 4425], [4425, 4443], [4443, 4457], [4457, 4459], [4459, 4475], [4475, 4507], [4507, 4521], [4521, 4545], [4545, 4556], [4556, 4567], [4567, 4585], [4585, 4589], [4589, 4612], [4612, 4659], [4659, 4666], [4666, 4670], [4670, 4684], [4684, 4696], [4696, 4702], [4702, 4703], [4703, 4738], [4738, 4739], [4739, 4760], [4760, 4761], [4761, 4775], [4775, 4810], [4810, 4824], [4824, 4827], [4827, 4845], [4845, 4856], [4856, 4869], [4869, 4888], [4888, 4900], [4900, 4906], [4906, 4920], [4920, 4922], [4922, 4939], [4939, 4951], [4951, 4958], [4958, 4975], [4975, 4979], [4979, 4991], [4991, 5016], [5016, 5028], [5028, 5031], [5031, 5051], [5051, 5072], [5072, 5102], [5102, 5134], [5134, 5174], [5174, 5179], [5179, 5199], [5199, 5222], [5222, 5230], [5230, 5231], [5231, 5263], [5263, 5267], [5267, 5293], [5293, 5306], [5306, 5363], [5363, 5385], [5385, 5395], [5395, 5426], [5426, 5471], [5471, 5485], [5485, 5504], [5504, 5536], [5536, 5554], [5554, 5568], [5568, 5598], [5598, 5604], [5604, 5614], [5614, 5628], [5628, 5642], [5642, 5682], [5682, 5702], [5702, 5721], [5721, 5736], [5736, 5758], [5758, 5770], [5770, 5781], [5781, 5804], [5804, 5816], [5816, 5827], [5827, 5844], [5844, 5847], [5847, 5872], [5872, 5890], [5890, 5908], [5908, 5968], [5968, 5998], [5998, 6029], [6029, 6068], [6068, 6086], [6086, 6113], [6113, 6150], [6150, 6164], [6164, 6197], [6197, 6213], [6213, 6216], [6216, 6227], [6227, 6249], [6249, 6262], [6262, 6286], [6286, 6296], [6296, 6315], [6315, 6335], [6335, 6378], [6378, 6425], [6425, 6445], [6445, 6457], [6457, 6467], [6467, 6471], [6471, 6485], [6485, 6495], [6495, 6496], [6496, 6513], [6513, 6519], [6519, 6533], [6533, 6545], [6545, 6547], [6547, 6562], [6562, 6564], [6564, 6579], [6579, 6582], [6582, 6595], [6595, 6604], [6604, 6622], [6622, 6640], [6640, 6680], [6680, 6718], [6718, 6734], [6734, 6738], [6738, 6775], [6775, 6801], [6801, 6812], [6812, 6819], [6819, 6841], [6841, 6853], [6853, 6865], [6865, 6888], [6888, 6895], [6895, 6923], [6923, 6954], [6954, 6956], [6956, 6963], [6963, 6994], [6994, 7037], [7037, 7046], [7046, 7062], [7062, 7071], [7071, 7074], [7074, 7084], [7084, 7122], [7122, 7134], [7134, 7149], [7149, 7174], [7174, 7187], [7187, 7216], [7216, 7249], [7249, 7274], [7274, 7316], [7316, 7328], [7328, 7364], [7364, 7379], [7379, 7404], [7404, 7417], [7417, 7429], [7429, 7436], [7436, 7453], [7453, 7482], [7482, 7496], [7496, 7505], [7505, 7517], [7517, 7520], [7520, 7552], [7552, 7560], [7560, 7582], [7582, 7591], [7591, 7600], [7600, 7627], [7627, 7638], [7638, 7660], [7660, 7684], [7684, 7710], [7710, 7727], [7727, 7750], [7750, 7795], [7795, 7836], [7836, 7871], [7871, 7873], [7873, 7897], [7897, 7906], [7906, 7909], [7909, 7927], [7927, 7941], [7941, 7956], [7956, 7974], [7974, 8002], [8002, 8020], [8020, 8035], [8035, 8087], [8087, 8115], [8115, 8146], [8146, 8165], [8165, 8167]], "words": ["Variational", "Autoencoders", "for", "Collaborative", "Filtering", "section", ":", "ABSTRACT", "We", "extend", "variational", "autoencoders", "(", "vaes", ")", "to", "collaborative", "filtering", "for", "implicit", "feedback", ".", "This", "non", "-", "linear", "probabilistic", "model", "enables", "us", "to", "go", "beyond", "the", "limited", "modeling", "capacity", "of", "linear", "factor", "models", "which", "still", "largely", "dominate", "collaborative", "filtering", "research", ".", "We", "introduce", "a", "generative", "model", "with", "multinomial", "likelihood", "and", "use", "Bayesian", "inference", "for", "parameter", "estimation", ".", "Despite", "widespread", "use", "in", "language", "modeling", "and", "economics", ",", "the", "multinomial", "likelihood", "receives", "less", "attention", "in", "the", "recommender", "systems", "literature", ".", "We", "introduce", "a", "different", "regularization", "parameter", "for", "the", "learning", "objective", ",", "which", "proves", "to", "be", "crucial", "for", "achieving", "competitive", "performance", ".", "Remarkably", ",", "there", "is", "an", "efficient", "way", "to", "tune", "the", "parameter", "using", "annealing", ".", "The", "resulting", "model", "and", "learning", "algorithm", "has", "information", "-", "theoretic", "connections", "to", "maximum", "entropy", "discrimination", "and", "the", "information", "bottleneck", "principle", ".", "Empirically", ",", "we", "show", "that", "the", "proposed", "approach", "significantly", "outperforms", "several", "state", "-", "of", "-", "the", "-", "art", "baselines", ",", "including", "two", "recently", "-", "proposed", "neural", "network", "approaches", ",", "on", "several", "real", "-", "world", "datasets", ".", "We", "also", "provide", "extended", "experiments", "comparing", "the", "multinomial", "likelihood", "with", "other", "commonly", "used", "likelihood", "functions", "in", "the", "latent", "factor", "collaborative", "filtering", "literature", "and", "show", "favorable", "results", ".", "Finally", ",", "we", "identify", "the", "pros", "and", "cons", "of", "employing", "a", "principled", "Bayesian", "inference", "approach", "and", "characterize", "settings", "where", "it", "provides", "the", "most", "significant", "improvements", ".", "section", ":", "INTRODUCTION", "Recommender", "systems", "are", "an", "integral", "component", "of", "the", "web", ".", "In", "a", "typical", "recommendation", "system", ",", "we", "observe", "how", "a", "set", "of", "users", "interacts", "with", "a", "set", "of", "items", ".", "Using", "this", "data", ",", "we", "seek", "to", "show", "users", "a", "set", "of", "previously", "unseen", "items", "they", "will", "like", ".", "As", "the", "web", "grows", "in", "size", ",", "good", "recommendation", "systems", "will", "play", "an", "important", "part", "in", "helping", "users", "interact", "more", "effectively", "with", "larger", "amounts", "of", "content", ".", "Collaborative", "filtering", "is", "among", "the", "most", "widely", "applied", "approaches", "in", "recommender", "systems", ".", "Collaborative", "filtering", "predicts", "what", "items", "a", "user", "will", "prefer", "by", "discovering", "and", "exploiting", "the", "similarity", "patterns", "across", "users", "and", "items", ".", "Latent", "factor", "models", "[", "reference", "][", "reference", "][", "reference", "]", "still", "largely", "dominate", "the", "collaborative", "filtering", "research", "literature", "due", "to", "their", "simplicity", "and", "effectiveness", ".", "However", ",", "these", "models", "are", "inherently", "linear", ",", "which", "limits", "their", "modeling", "capacity", ".", "Previous", "work", "[", "reference", "]", "has", "demonstrated", "that", "adding", "carefully", "crafted", "non", "-", "linear", "features", "into", "the", "linear", "latent", "factor", "models", "can", "significantly", "boost", "recommendation", "performance", ".", "Recently", ",", "a", "growing", "body", "of", "work", "involves", "applying", "neural", "networks", "to", "the", "collaborative", "filtering", "setting", "with", "promising", "results", "[", "reference", "][", "reference", "][", "reference", "][", "reference", "]", ".", "Here", ",", "we", "extend", "variational", "autoencoders", "(", "vaes", ")", "[", "reference", "][", "reference", "]", "to", "collaborative", "filtering", "for", "implicit", "feedback", ".", "Vaes", "generalize", "linear", "latent", "-", "factor", "models", "and", "enable", "us", "to", "explore", "non", "-", "linear", "probabilistic", "latent", "-", "variable", "models", ",", "powered", "by", "neural", "networks", ",", "on", "large", "-", "scale", "recommendation", "datasets", ".", "We", "propose", "a", "neural", "generative", "model", "with", "multinomial", "conditional", "likelihood", ".", "Despite", "being", "widely", "used", "in", "language", "modeling", "and", "economics", "[", "reference", "][", "reference", "]", ",", "multinomial", "likelihoods", "appear", "less", "studied", "in", "the", "collaborative", "filtering", "literature", ",", "particularly", "within", "the", "context", "of", "latent", "-", "factor", "models", ".", "Recommender", "systems", "are", "often", "evaluated", "using", "rankingbased", "measures", ",", "such", "as", "mean", "average", "precision", "and", "normalized", "discounted", "cumulative", "gain", "[", "reference", "]", ".", "Top", "-", "N", "ranking", "loss", "is", "difficult", "to", "optimize", "directly", "and", "previous", "work", "on", "direct", "ranking", "loss", "minimization", "resorts", "to", "relaxations", "and", "approximations", "[", "reference", "][", "reference", "]", ".", "Here", ",", "we", "show", "that", "the", "multinomial", "likelihoods", "are", "well", "-", "suited", "for", "modeling", "implicit", "feedback", "data", ",", "and", "are", "a", "closer", "proxy", "to", "the", "ranking", "loss", "relative", "to", "more", "popular", "likelihood", "functions", "such", "as", "Gaussian", "and", "logistic", ".", "Though", "recommendation", "is", "often", "considered", "a", "big", "-", "data", "problem", "(", "due", "to", "the", "huge", "numbers", "of", "users", "and", "items", "typically", "present", "in", "a", "recommender", "system", ")", ",", "we", "argue", "that", ",", "in", "contrast", ",", "it", "represents", "a", "uniquely", "challenging", "\"", "small", "-", "data", "\"", "problem", ":", "most", "users", "only", "interact", "with", "a", "tiny", "proportion", "of", "the", "items", "and", "our", "goal", "is", "to", "collectively", "make", "informed", "inference", "about", "each", "user", "'s", "preference", ".", "To", "make", "use", "of", "the", "sparse", "signals", "from", "users", "and", "avoid", "overfitting", ",", "we", "build", "a", "probabilistic", "latent", "-", "variable", "model", "that", "shares", "statistical", "strength", "among", "users", "and", "items", ".", "Empirically", ",", "we", "show", "that", "employing", "a", "principled", "Bayesian", "approach", "is", "more", "robust", "regardless", "of", "the", "scarcity", "of", "the", "data", ".", "Although", "vaes", "have", "been", "extensively", "studied", "for", "image", "modeling", "and", "generation", ",", "there", "is", "surprisingly", "little", "work", "applying", "vaes", "to", "recommender", "systems", ".", "We", "find", "that", "two", "adjustments", "are", "essential", "to", "getting", "state", "-", "of", "-", "the", "-", "art", "results", "with", "vaes", "on", "this", "task", ":", "\u2022", "First", ",", "we", "use", "a", "multinomial", "likelihood", "for", "the", "data", "distribution", ".", "We", "show", "that", "this", "simple", "choice", "realizes", "models", "that", "outperform", "the", "more", "commonly", "used", "Gaussian", "and", "logistic", "likelihoods", ".", "\u2022", "Second", ",", "we", "reinterpret", "and", "adjust", "the", "standard", "vae", "objective", ",", "which", "we", "argue", "is", "over", "-", "regularized", ".", "We", "draw", "connections", "between", "the", "learning", "algorithm", "resulting", "from", "our", "proposed", "regularization", "and", "the", "information", "-", "bottleneck", "principle", "and", "maximum", "-", "entropy", "discrimination", ".", "The", "result", "is", "a", "recipe", "that", "makes", "vaes", "practical", "solutions", "to", "this", "important", "problem", ".", "Empirically", ",", "our", "methods", "significantly", "outperform", "state", "-", "of", "-", "the", "-", "art", "baselines", "on", "several", "real", "-", "world", "datasets", ",", "including", "two", "recently", "proposed", "neural", "-", "network", "approaches", ".", "section", ":", "METHOD", "We", "use", "u", "\u2208", "{", "1", ",", ".", ".", ".", ",", "U", "}", "to", "index", "users", "and", "i", "\u2208", "{", "1", ",", ".", ".", ".", ",", "I", "}", "to", "index", "items", ".", "In", "this", "work", ",", "we", "consider", "learning", "with", "implicit", "feedback", "[", "reference", "][", "reference", "]", ".", "The", "user", "-", "by", "-", "item", "interaction", "matrix", "is", "the", "click", "1", "matrix", "X", "\u2208", "N", "U", "\u00d7I", ".", "The", "lower", "case", "x", "u", "=", "[", "x", "u1", ",", ".", ".", ".", ",", "x", "uI", "]", "\u22a4", "\u2208", "N", "I", "is", "a", "bag", "-", "ofwords", "vector", "with", "the", "number", "of", "clicks", "for", "each", "item", "from", "user", "u.", "For", "simplicity", ",", "we", "binarize", "the", "click", "matrix", ".", "It", "is", "straightforward", "to", "extend", "it", "to", "general", "count", "data", ".", "section", ":", "Model", "The", "generative", "process", "we", "consider", "in", "this", "paper", "is", "similar", "to", "the", "deep", "latent", "Gaussian", "model", "[", "reference", "]", ".", "For", "each", "user", "u", ",", "the", "model", "starts", "by", "sampling", "a", "K", "-", "dimensional", "latent", "representation", "z", "u", "from", "a", "standard", "Gaussian", "prior", ".", "The", "latent", "representation", "z", "u", "is", "transformed", "via", "a", "non", "-", "linear", "function", "f", "\u03b8", "(", "\u00b7", ")", "\u2208", "R", "I", "to", "produce", "a", "probability", "distribution", "over", "I", "items", "\u03c0", "(", "z", "u", ")", "from", "which", "the", "click", "history", "x", "u", "is", "assumed", "to", "have", "been", "drawn", ":", "The", "non", "-", "linear", "function", "f", "\u03b8", "(", "\u00b7", ")", "is", "a", "multilayer", "perceptron", "with", "parameters", "\u03b8", ".", "The", "output", "of", "this", "transformation", "is", "normalized", "via", "a", "softmax", "function", "to", "produce", "a", "probability", "vector", "\u03c0", "(", "z", "u", ")", "\u2208", "S", "I", "\u22121", "(", "an", "(", "I", "\u2212", "1", ")-", "simplex", ")", "over", "the", "entire", "item", "set", ".", "Given", "the", "total", "number", "of", "clicks", "N", "u", "=", "i", "x", "ui", "from", "user", "u", ",", "the", "observed", "bag", "-", "of", "-", "words", "vector", "x", "u", "is", "assumed", "to", "be", "sampled", "from", "a", "multinomial", "distribution", "with", "probability", "\u03c0", "(", "z", "u", ")", ".", "This", "generative", "model", "generalizes", "the", "latentfactor", "model", "-", "we", "can", "recover", "classical", "matrix", "factorization", "[", "reference", "]", "by", "setting", "f", "\u03b8", "(", "\u00b7", ")", "to", "be", "linear", "and", "using", "a", "Gaussian", "likelihood", ".", "The", "log", "-", "likelihood", "for", "user", "u", "(", "conditioned", "on", "the", "latent", "representation", ")", "is", ":", "This", "multinomial", "likelihood", "is", "commonly", "used", "in", "language", "models", ",", "e.g.", ",", "latent", "Dirichlet", "allocation", "[", "reference", "]", ",", "and", "economics", ",", "e.g.", ",", "multinomial", "logit", "choice", "model", "[", "reference", "]", ".", "It", "is", "also", "used", "in", "the", "cross", "-", "entropy", "loss", "2", "for", "multi", "-", "class", "classification", ".", "For", "example", ",", "it", "has", "been", "used", "in", "recurrent", "neural", "networks", "for", "session", "-", "based", "sequential", "recommendation", "[", "reference", "][", "reference", "][", "reference", "][", "reference", "][", "reference", "]", "and", "in", "feedward", "neural", "networks", "applied", "to", "Youtube", "recommendation", "[", "reference", "]", ".", "The", "multinomial", "likelihood", "is", "less", "well", "studied", "in", "the", "context", "of", "latent", "-", "factor", "models", "such", "as", "matrix", "factorization", "and", "autoencoders", ".", "A", "notable", "exception", "is", "the", "collaborative", "competitive", "filtering", "(", "CCF", ")", "model", "[", "reference", "]", "and", "its", "successors", ",", "which", "take", "advantage", "of", "more", "fine", "-", "grained", "information", "about", "what", "options", "were", "presented", "to", "which", "users", ".", "(", "If", "such", "information", "is", "available", ",", "it", "can", "also", "be", "incorporated", "into", "our", "vae", "-", "based", "approach", ".", ")", "We", "believe", "the", "multinomial", "distribution", "is", "well", "suited", "to", "modeling", "click", "data", ".", "The", "likelihood", "of", "the", "click", "matrix", "(", "Eq", ".", "2", ")", "rewards", "the", "model", "for", "putting", "probability", "mass", "on", "the", "non", "-", "zero", "entries", "in", "x", "u", ".", "But", "the", "model", "has", "a", "limited", "budget", "of", "probability", "mass", ",", "since", "\u03c0", "(", "z", "u", ")", "must", "sum", "to", "1", ";", "the", "items", "must", "compete", "for", "this", "limited", "budget", "[", "reference", "]", ".", "The", "model", "should", "therefore", "assign", "more", "probability", "mass", "to", "items", "that", "are", "more", "likely", "to", "be", "clicked", ".", "To", "the", "extent", "that", "it", "can", ",", "it", "will", "perform", "well", "under", "the", "top", "-", "N", "ranking", "loss", "that", "recommender", "systems", "are", "commonly", "evaluated", "on", ".", "By", "way", "of", "comparison", ",", "we", "present", "two", "popular", "choices", "of", "likelihood", "functions", "used", "in", "latent", "-", "factor", "collaborative", "filtering", ":", "Gaussian", "and", "logistic", "likelihoods", ".", "Define", "f", "\u03b8", "(", "z", "u", ")", "\u2261", "[", "f", "u1", ",", ".", ".", ".", ",", "f", "uI", "]", "\u22a4", "as", "the", "output", "of", "the", "generative", "function", "f", "\u03b8", "(", "\u00b7", ")", ".", "The", "Gaussian", "log", "-", "likelihood", "for", "user", "u", "is", "We", "adopt", "the", "convention", "in", "Hu", "et", "al", ".", "[", "reference", "]", "and", "introduce", "a", "\"", "confidence", "\"", "weight", "c", "x", "ui", "\u2261", "c", "ui", "where", "c", "1", ">", "c", "0", "to", "balance", "the", "unobserved", "0", "'s", "which", "far", "outnumber", "the", "observed", "1", "'s", "in", "most", "click", "data", ".", "This", "is", "also", "equivalent", "to", "training", "the", "model", "with", "unweighted", "Gaussian", "likelihood", "and", "negative", "sampling", ".", "The", "logistic", "log", "-", "likelihood", "3", "for", "user", "u", "is", "where", "\u03c3", "(", "x", ")", "=", "1", "/(", "1", "+", "exp", "(", "\u2212x", ")", ")", "is", "the", "logistic", "function", ".", "We", "compare", "multinomial", "likelihood", "with", "Gaussian", "and", "logistic", "in", "Section", "4", ".", "section", ":", "Variational", "inference", "To", "learn", "the", "generative", "model", "in", "Eq", ".", "1", ",", "we", "are", "interested", "in", "estimating", "\u03b8", "(", "the", "parameters", "of", "f", "\u03b8", "(", "\u00b7", ")", ")", ".", "To", "do", "so", ",", "for", "each", "data", "point", "we", "need", "to", "approximate", "the", "intractable", "posterior", "distribution", "p", "(", "z", "u", "|", "x", "u", ")", ".", "We", "resort", "to", "variational", "inference", "[", "reference", "]", ".", "Variational", "inference", "approximates", "the", "true", "intractable", "posterior", "with", "a", "simpler", "variational", "distribution", "q", "(", "z", "u", ")", ".", "We", "set", "q", "(", "z", "u", ")", "to", "be", "a", "fully", "factorized", "(", "diagonal", ")", "Gaussian", "distribution", ":", "The", "objective", "of", "variational", "inference", "is", "to", "optimize", "the", "free", "variational", "parameters", "{", "\u00b5", "u", ",", "\u03c3", "2", "u", "}", "so", "that", "the", "Kullback", "-", "Leiber", "divergence", "KL", "(", "q", "(", "z", "u", ")", "\u2225p", "(", "z", "u", "|x", "u", ")", ")", "is", "minimized", ".", "section", ":", "Amortized", "inference", "and", "the", "variational", "autoencoder", ":", "With", "variational", "inference", "the", "number", "of", "parameters", "to", "optimize", "{", "\u00b5", "u", ",", "\u03c3", "2", "u", "}", "grows", "with", "the", "number", "of", "users", "and", "items", "in", "the", "dataset", ".", "This", "can", "become", "a", "bottleneck", "for", "commercial", "recommender", "systems", "with", "millions", "of", "users", "and", "items", ".", "The", "variational", "autoencoder", "(", "vae", ")", "[", "reference", "][", "reference", "]", "replaces", "individual", "variational", "parameters", "with", "a", "data", "-", "dependent", "function", "(", "commonly", "called", "an", "inference", "model", ")", ":", "parametrized", "by", "\u03d5", "with", "both", "\u00b5", "\u03d5", "(", "x", "u", ")", "and", "\u03c3", "\u03d5", "(", "x", "u", ")", "being", "K", "-", "vectors", "and", "sets", "the", "variational", "distribution", "as", "follows", ":", "That", "is", ",", "using", "the", "observed", "data", "x", "u", "as", "input", ",", "the", "inference", "model", "outputs", "the", "corresponding", "variational", "parameters", "of", "variational", "distribution", "q", "\u03d5", "(", "z", "u", "|", "x", "u", ")", ",", "which", ",", "when", "optimized", ",", "approximates", "the", "intractable", "posterior", "p", "(", "z", "u", "|", "x", "u", ")", ".", "[", "reference", "]", "Putting", "q", "\u03d5", "(", "z", "u", "|", "x", "u", ")", "and", "the", "generative", "model", "p", "\u03b8", "(", "x", "u", "|", "z", "u", ")", "together", "in", "Figure", "2c", ",", "we", "end", "up", "with", "a", "neural", "architecture", "that", "resembles", "an", "autoencoder", "-", "hence", "the", "name", "variational", "autoencoder", ".", "Vaes", "make", "use", "of", "amortized", "inference", "[", "reference", "]", ":", "they", "flexibly", "reuse", "inferences", "to", "answer", "related", "new", "problems", ".", "This", "is", "well", "aligned", "with", "the", "ethos", "of", "collaborative", "filtering", ":", "analyze", "user", "preferences", "by", "exploiting", "the", "similarity", "patterns", "inferred", "from", "past", "experiences", ".", "In", "Section", "2.4", ",", "we", "discuss", "how", "this", "enables", "us", "to", "perform", "prediction", "efficiently", ".", "Learning", "vaes", ":", "As", "is", "standard", "when", "learning", "latent", "-", "variable", "models", "with", "variational", "inference", "[", "reference", "]", ",", "we", "can", "lower", "-", "bound", "the", "log", "marginal", "likelihood", "of", "the", "data", ".", "This", "forms", "the", "objective", "we", "seek", "to", "maximize", "for", "user", "u", "(", "the", "objective", "function", "of", "the", "dataset", "is", "obtained", "by", "averaging", "the", "objective", "function", "over", "all", "the", "users", ")", ":", "This", "is", "commonly", "known", "as", "the", "evidence", "lower", "bound", "(", "elbo", ")", ".", "Note", "that", "the", "elbo", "is", "a", "function", "of", "both", "\u03b8", "and", "\u03d5.", "We", "can", "obtain", "an", "unbiased", "estimate", "of", "elbo", "by", "sampling", "z", "u", "\u223c", "q", "\u03d5", "and", "perform", "stochastic", "gradient", "ascent", "to", "optimize", "it", ".", "However", ",", "the", "challenge", "is", "that", "we", "can", "not", "trivially", "take", "gradients", "with", "respect", "to", "\u03d5", "through", "this", "sampling", "process", ".", "The", "reparametrization", "trick", "[", "reference", "][", "reference", "]", "sidesteps", "this", "issue", ":", "we", "sample", "\u03f5", "\u223c", "N", "(", "0", ",", "I", "K", ")", "and", "reparametrize", "By", "doing", "so", ",", "the", "stochasticity", "in", "the", "sampling", "process", "is", "isolated", "and", "the", "gradient", "with", "respect", "to", "\u03d5", "can", "be", "back", "-", "propagated", "through", "the", "sampled", "z", "u", ".", "The", "vae", "training", "procedure", "is", "summarized", "in", "Algorithm", "1", ".", "section", ":", "Alternative", "interpretation", "of", "elbo", ".", "We", "can", "view", "elbo", "defined", "in", "Eq", ".", "5", "from", "a", "different", "perspective", ":", "the", "first", "term", "can", "be", "interpreted", "as", "(", "negative", ")", "reconstruction", "error", ",", "while", "the", "second", "KL", "term", "can", "be", "viewed", "as", "regularization", ".", "It", "is", "this", "perspective", "we", "work", "with", "because", "it", "allows", "us", "to", "make", "a", "trade", "-", "off", "that", "forms", "the", "crux", "of", "our", "method", ".", "From", "this", "perspective", ",", "it", "is", "natural", "to", "extend", "the", "elbo", "by", "introducing", "a", "parameter", "\u03b2", "to", "control", "the", "strength", "of", "regularization", ":", "While", "the", "original", "vae", "(", "trained", "with", "elbo", "in", "Eq", ".", "5", ")", "is", "a", "powerful", "generative", "model", ";", "we", "might", "ask", "whether", "we", "need", "all", "the", "statistical", "properties", "of", "a", "generative", "model", "for", "tackling", "problems", "in", "recommender", "systems", ".", "In", "particular", ",", "if", "we", "are", "willing", "to", "sacrifice", "the", "ability", "to", "perform", "ancestral", "sampling", ",", "can", "we", "improve", "our", "performance", "?", "The", "regularization", "view", "of", "the", "elbo", "(", "Eq", ".", "6", ")", "introduces", "a", "trade", "-", "off", "between", "how", "well", "we", "can", "fit", "the", "data", "and", "how", "close", "the", "approximate", "posterior", "stays", "to", "the", "prior", "during", "learning", ".", "We", "propose", "using", "\u03b2", "1", ".", "This", "means", "we", "are", "no", "longer", "optimizing", "a", "lower", "bound", "on", "the", "log", "marginal", "likelihood", ".", "If", "\u03b2", "<", "1", ",", "then", "we", "are", "also", "weakening", "the", "influence", "of", "the", "prior", "constraint", "Figure", "1", "illustrates", "the", "basic", "idea", "(", "we", "observe", "the", "same", "trend", "consistently", "across", "datasets", ")", ".", "Here", "we", "plot", "the", "validation", "ranking", "metric", "without", "KL", "annealing", "(", "blue", "solid", ")", "and", "with", "KL", "annealing", "all", "the", "way", "to", "\u03b2", "=", "1", "(", "green", "dashed", ",", "\u03b2", "reaches", "1", "at", "around", "80", "epochs", ")", ".", "As", "we", "can", "see", ",", "the", "performance", "is", "poor", "without", "any", "KL", "annealing", ".", "With", "annealing", ",", "the", "validation", "performance", "first", "increases", "as", "the", "training", "proceeds", "and", "then", "drops", "as", "\u03b2", "gets", "close", "to", "1", "to", "a", "value", "that", "is", "only", "slightly", "better", "than", "doing", "no", "annealing", "at", "all", ".", "Having", "identified", "the", "best", "\u03b2", "based", "on", "the", "peak", "validation", "metric", ",", "we", "can", "retrain", "the", "model", "with", "the", "same", "annealing", "schedule", ",", "but", "stop", "increasing", "\u03b2", "after", "reaching", "that", "value", "(", "shown", "as", "red", "dot", "-", "dashed", "in", "Figure", "1", ")", ".", "[", "reference", "]", "This", "might", "be", "sub", "-", "optimal", "compared", "to", "a", "thorough", "grid", "search", ".", "However", ",", "it", "is", "much", "more", "efficient", ",", "and", "gives", "us", "competitive", "empirical", "performance", ".", "If", "the", "computational", "budget", "is", "scarce", ",", "then", "within", "a", "single", "run", ",", "we", "can", "stop", "increasing", "\u03b2", "when", "we", "notice", "the", "validation", "metric", "dropping", ".", "Such", "a", "procedure", "incurs", "no", "additional", "runtime", "to", "learning", "a", "standard", "vae", ".", "We", "denote", "this", "partially", "regularized", "vae", "with", "multinomial", "likelihood", "as", "Mult", "-", "vae", "pr", ".", "section", ":", "Computational", "Burden", ".", "Previous", "collaborative", "filtering", "models", "with", "neural", "networks", "[", "reference", "][", "reference", "]", "are", "trained", "with", "stochastic", "gradient", "descent", "where", "in", "each", "step", "a", "single", "(", "user", ",", "item", ")", "entry", "from", "the", "click", "matrix", "is", "randomly", "sampled", "to", "perform", "a", "gradient", "update", ".", "In", "Algorithm", "1", "we", "subsample", "users", "and", "take", "their", "entire", "click", "history", "(", "complete", "rows", "of", "the", "click", "matrix", ")", "to", "update", "model", "parameters", ".", "This", "eliminates", "the", "necessity", "of", "negative", "sampling", "(", "and", "consequently", "the", "hyperparameter", "tuning", "for", "picking", "the", "number", "of", "negative", "examples", ")", ",", "commonly", "used", "in", "the", "(", "user", ",", "item", ")", "entry", "subsampling", "scheme", ".", "A", "computational", "challenge", "that", "comes", "with", "our", "approach", ",", "however", ",", "is", "that", "when", "the", "number", "of", "items", "is", "huge", ",", "computing", "the", "multinomial", "probability", "\u03c0", "(", "z", "u", ")", "could", "be", "computationally", "expensive", ",", "since", "it", "requires", "computing", "the", "predictions", "for", "all", "the", "items", "for", "normalization", ".", "This", "is", "a", "common", "challenge", "for", "language", "modeling", "where", "the", "size", "of", "the", "vocabulary", "is", "in", "the", "order", "of", "millions", "or", "more", "[", "reference", "]", ".", "In", "our", "experiments", "on", "some", "medium", "-", "to", "-", "large", "datasets", "with", "less", "than", "50", "K", "items", "(", "Section", "4.1", ")", ",", "this", "has", "not", "yet", "come", "up", "as", "a", "computational", "bottleneck", ".", "If", "this", "becomes", "a", "bottleneck", "when", "working", "with", "larger", "item", "sets", ",", "one", "can", "easily", "apply", "the", "simple", "and", "[", "reference", "]", "We", "found", "this", "to", "give", "slightly", "better", "results", "than", "keeping", "\u03b2", "at", "the", "best", "value", "throughout", "the", "training", ".", "effective", "method", "proposed", "by", "Botev", "et", "al", ".", "[", "reference", "]", "to", "approximate", "the", "normalization", "factor", "for", "\u03c0", "(", "z", "u", ")", ".", "section", ":", "A", "taxonomy", "of", "autoencoders", "In", "Section", "2.2", ",", "we", "introduced", "maximum", "marginal", "likelihood", "estimation", "of", "vaes", "using", "approximate", "Bayesian", "inference", "under", "a", "non", "-", "linear", "generative", "model", "(", "Eq", ".", "1", ")", ".", "We", "now", "describe", "our", "work", "from", "the", "perspective", "of", "learning", "autoencoders", ".", "Maximum", "-", "likelihood", "estimation", "in", "a", "regular", "autoencoder", "takes", "the", "following", "form", ":", "There", "are", "two", "key", "distinctions", "of", "note", ":", "(", "1", ")", "The", "autoencoder", "(", "and", "denoising", "autoencoder", ")", "effectively", "optimizes", "the", "first", "term", "in", "the", "vae", "objective", "(", "Eq", ".", "5", "and", "Eq", ".", "6", ")", "using", "a", "delta", "variational", "distribution", "is", "a", "\u03b4", "distribution", "with", "mass", "only", "at", "the", "output", "of", "\u0434", "\u03d5", "(", "x", "u", ")", ".", "Contrast", "this", "to", "the", "vae", ",", "where", "the", "learning", "is", "done", "using", "a", "variational", "distribution", ",", "i.e.", ",", "\u0434", "\u03d5", "(", "x", "u", ")", "outputs", "the", "parameters", "(", "mean", "and", "variance", ")", "of", "a", "Gaussian", "distribution", ".", "This", "means", "that", "vae", "has", "the", "ability", "to", "capture", "per", "-", "data", "-", "point", "variances", "in", "the", "latent", "state", "z", "u", ".", "In", "practice", ",", "we", "find", "that", "learning", "autoencoders", "is", "extremely", "prone", "to", "overfitting", "as", "the", "network", "learns", "to", "put", "all", "the", "probability", "mass", "to", "the", "non", "-", "zero", "entries", "in", "x", "u", ".", "By", "introducing", "dropout", "[", "reference", "]", "at", "the", "input", "layer", ",", "the", "denoising", "autoencoder", "(", "dae", ")", "is", "less", "prone", "to", "overfitting", "and", "we", "find", "that", "it", "also", "gives", "competitive", "empirical", "results", ".", "In", "addition", "to", "the", "Mult", "-", "vae", "pr", ",", "we", "also", "study", "a", "denoising", "autoencoder", "with", "a", "multinomial", "likelihood", ".", "We", "denote", "this", "model", "Mult", "-", "dae", ".", "In", "Section", "4", "we", "characterize", "the", "tradeoffs", "in", "what", "is", "gained", "and", "lost", "by", "explicitly", "parameterizing", "the", "per", "-", "user", "variance", "with", "Mult", "-", "vae", "pr", "versus", "using", "a", "point", "-", "estimation", "in", "Mult", "-", "dae", ".", "To", "provide", "a", "unified", "view", "of", "different", "variants", "of", "autoencoders", "and", "clarify", "where", "our", "work", "stands", ",", "we", "depict", "variants", "of", "autoencoders", "commonly", "found", "in", "the", "literature", "in", "Figure", "2", ".", "For", "each", "one", ",", "we", "specify", "the", "model", "(", "dotted", "arrows", "denote", "a", "sampling", "operation", ")", "and", "describe", "the", "training", "objective", "used", "in", "parameter", "estimation", ".", "In", "Figure", "2a", "we", "have", "autoencoder", ".", "It", "is", "trained", "to", "reconstruct", "input", "with", "the", "same", "objective", "as", "in", "Eq", ".", "7", ".", "Adding", "noise", "to", "the", "input", "(", "or", "the", "intermediate", "hidden", "representation", ")", "of", "an", "autoencoder", "yields", "the", "denoising", "autoencoder", "in", "Figure", "2b", ".", "The", "training", "objective", "is", "the", "same", "as", "that", "of", "an", "autoencoder", ".", "Mult", "-", "dae", "belongs", "to", "this", "model", "class", ".", "Collaborative", "denoising", "autoencoder", "[", "reference", "]", "is", "a", "variant", "of", "this", "model", "class", ".", "The", "vae", "is", "depicted", "in", "Figure", "2c", ".", "Rather", "than", "using", "a", "delta", "variational", "distribution", ",", "it", "uses", "an", "inference", "model", "parametrized", "by", "\u03d5", "to", "produce", "the", "mean", "and", "variance", "of", "the", "approximating", "variational", "distribution", ".", "The", "training", "objective", "of", "the", "vae", "is", "given", "in", "Eq", ".", "6", ".", "Setting", "\u03b2", "to", "1", "recovers", "the", "original", "vae", "formulation", "[", "reference", "][", "reference", "]", ".", "Higgins", "et", "al", ".", "[", "reference", "]", "study", "the", "case", "where", "\u03b2", ">", "1", ".", "Our", "model", ",", "Mult", "-", "vae", "pr", "corresponds", "to", "learning", "vaes", "with", "\u03b2", "\u2208", "[", "0", ",", "1", "]", ".", "section", ":", "Prediction", "We", "now", "describe", "how", "we", "make", "predictions", "given", "a", "trained", "generative", "model", "of", "the", "form", "Eq", ".", "1", ".", "For", "both", ",", "Mult", "-", "vae", "pr", "(", "Section", "2.2", ")", "or", "Mult", "-", "dae", "(", "Section", "2.3", ")", ",", "we", "make", "predictions", "in", "the", "same", "way", ".", "Given", "a", "user", "'s", "click", "history", "x", ",", "we", "rank", "all", "the", "items", "based", "on", "the", "un", "-", "normalized", "predicted", "multinomial", "probability", "f", "\u03b8", "(", "z", ")", ".", "The", "latent", "representation", "z", "for", "x", "is", "constructed", "as", "follows", ":", "For", "Mult", "-", "vae", "pr", ",", "we", "simply", "take", "the", "mean", "of", "the", "variational", "distribution", "z", "=", "\u00b5", "\u03d5", "(", "x", ")", ";", "for", "Mult", "-", "dae", ",", "we", "take", "the", "output", "z", "=", "\u0434", "\u03d5", "(", "x", ")", ".", "It", "is", "easy", "to", "see", "the", "advantage", "of", "using", "autoencoders", ".", "We", "can", "effectively", "make", "predictions", "for", "users", "by", "evaluating", "two", "functions", "-", "the", "inference", "model", "(", "encoder", ")", "\u0434", "\u03d5", "(", "\u00b7", ")", "and", "the", "generative", "model", "(", "decoder", ")", "f", "\u03b8", "(", "\u00b7", ")", ".", "For", "most", "of", "the", "latent", "factor", "collaborative", "filtering", "model", ",", "e.g.", ",", "matrix", "factorization", "[", "reference", "][", "reference", "]", ",", "when", "given", "the", "click", "history", "of", "a", "user", "that", "is", "not", "present", "in", "the", "training", "data", ",", "normally", "we", "need", "to", "perform", "some", "form", "of", "optimization", "to", "obtain", "the", "latent", "factor", "for", "this", "user", ".", "This", "makes", "the", "use", "of", "autoencoders", "particularly", "attractive", "in", "industrial", "applications", ",", "where", "it", "is", "important", "that", "predictions", "be", "made", "cheaply", "and", "with", "low", "latency", ".", "section", ":", "RELATED", "WORK", "Vaes", "on", "sparse", "data", ".", "Variational", "autoencoders", "(", "vaes", ")", "[", "reference", "][", "reference", "]", "have", "seen", "much", "application", "to", "images", "since", "their", "inception", ".", "Doersch", "[", "reference", "]", "presents", "a", "review", "on", "different", "applications", "of", "vae", "to", "image", "data", ".", "Miao", "et", "al", ".", "[", "reference", "]", "study", "vaes", "on", "text", "data", ".", "More", "recent", "results", "from", "Krishnan", "et", "al", ".", "[", "reference", "]", "find", "that", "vaes", "(", "trained", "with", "Eq", ".", "5", ")", "suffer", "from", "underfitting", "when", "modeling", "large", ",", "sparse", ",", "high", "-", "dimensional", "data", ".", "We", "notice", "similar", "issues", "when", "fitting", "vae", "without", "annealing", "(", "Figure", "1", ")", "or", "annealing", "to", "\u03b2", "=", "1", ".", "By", "giving", "up", "the", "ability", "to", "perform", "ancestral", "sampling", "in", "the", "model", ",", "and", "setting", "\u03b2", "\u2264", "1", ",", "the", "resulting", "model", "is", "no", "longer", "a", "proper", "generative", "model", "though", "for", "collaborative", "filtering", "tasks", "we", "always", "make", "predictions", "conditional", "on", "users", "'", "click", "history", ".", "Information", "-", "theoretic", "connection", "with", "vae", ".", "The", "regularization", "view", "of", "the", "elbo", "in", "Eq", ".", "6", "resembles", "maximum", "-", "entropy", "discrimination", "[", "reference", "]", ".", "Maximum", "-", "entropy", "discrimination", "attempts", "to", "combine", "discriminative", "estimation", "with", "Bayesian", "inference", "and", "generative", "modeling", ".", "In", "our", "case", ",", "in", "Eq", ".", "6", ",", "\u03b2", "acts", "as", "a", "knob", "to", "balance", "discriminative", "and", "generative", "aspects", "of", "the", "model", ".", "The", "procedure", "in", "Eq", ".", "6", "has", "information", "-", "theoretic", "connections", "described", "in", "Alemi", "et", "al", ".", "[", "reference", "]", ".", "The", "authors", "propose", "the", "deep", "variational", "information", "bottleneck", ",", "which", "is", "a", "variational", "approximation", "to", "the", "information", "bottleneck", "principle", "[", "reference", "]", ".", "They", "show", "that", "as", "a", "special", "case", "they", "can", "recover", "the", "learning", "objective", "used", "by", "vaes", ".", "They", "report", "more", "robust", "supervised", "classification", "performance", "with", "\u03b2", "<", "1", ".", "This", "is", "consistent", "with", "our", "findings", "as", "well", ".", "Higgins", "et", "al", ".", "[", "reference", "]", "proposed", "\u03b2", "-", "vae", ",", "which", "leads", "to", "the", "same", "objective", "as", "Eq", ".", "6", ".", "section", ":", "They", "motivate", "Neural", "networks", "for", "collaborative", "filtering", ".", "Early", "work", "on", "neural", "-", "network", "-", "based", "collaborative", "filtering", "models", "focus", "on", "explicit", "feedback", "data", "and", "evaluates", "on", "the", "task", "of", "rating", "predictions", "[", "reference", "][", "reference", "][", "reference", "][", "reference", "]", ".", "The", "importance", "of", "implicit", "feedback", "has", "been", "gradually", "recognized", ",", "and", "consequently", "most", "recent", "research", ",", "such", "as", "this", "work", ",", "has", "focused", "on", "it", ".", "The", "two", "papers", "that", "are", "most", "closely", "related", "to", "our", "approaches", "are", "collaborative", "denoising", "autoencoder", "[", "reference", "]", "and", "neural", "collaborative", "filtering", "[", "reference", "]", ".", "Collaborative", "denoising", "autoencoder", "(", "cdae", ")", "[", "reference", "]", "augments", "the", "standard", "denoising", "autoencoder", ",", "described", "in", "Section", "2.3", ",", "by", "adding", "a", "per", "-", "user", "latent", "factor", "to", "the", "input", ".", "The", "number", "of", "parameters", "of", "the", "cdae", "model", "grows", "linearly", "with", "both", "the", "number", "of", "users", "as", "well", "as", "the", "number", "of", "items", ",", "making", "it", "more", "prone", "to", "overfitting", ".", "In", "contrast", ",", "the", "number", "of", "parameters", "in", "the", "vae", "grows", "linearly", "with", "the", "number", "of", "items", ".", "The", "cdae", "also", "requires", "additional", "optimization", "to", "obtain", "the", "latent", "factor", "for", "unseen", "users", "to", "make", "predicion", ".", "In", "the", "paper", ",", "the", "authors", "investigate", "the", "Gaussian", "and", "logistic", "likelihood", "loss", "functions", "-", "as", "we", "show", ",", "the", "multinomial", "likelihood", "is", "significantly", "more", "robust", "for", "use", "in", "recommender", "systems", ".", "Neural", "collaborative", "filtering", "(", "ncf", ")", "[", "reference", "]", "explore", "a", "model", "with", "non", "-", "linear", "interactions", "between", "the", "user", "and", "item", "latent", "factors", "rather", "than", "the", "commonly", "used", "dot", "product", ".", "The", "authors", "demonstrate", "improvements", "of", "ncf", "over", "standard", "baselines", "on", "two", "small", "datasets", ".", "Similar", "to", "cdae", ",", "the", "number", "of", "parameters", "of", "ncf", "also", "grows", "linearly", "with", "both", "the", "number", "of", "users", "as", "well", "as", "items", ".", "We", "find", "that", "this", "becomes", "problematic", "for", "much", "larger", "datasets", ".", "We", "compare", "with", "both", "cdae", "and", "ncf", "in", "Section", "4", ".", "Asymmetric", "matrix", "factorization", "[", "reference", "]", "may", "also", "be", "interpreted", "as", "an", "autoencoder", ",", "as", "elaborated", "in", "Steck", "[", "reference", "]", ".", "We", "can", "recover", "this", "work", "by", "setting", "both", "f", "\u03b8", "(", "\u00b7", ")", "and", "\u0434", "\u03d5", "(", "\u00b7", ")", "to", "be", "linear", ".", "Besides", "being", "applied", "in", "session", "-", "based", "sequential", "recommendation", "(", "see", "Section", "2.1", ")", ",", "various", "approaches", "[", "reference", "][", "reference", "][", "reference", "][", "reference", "]", "have", "applied", "neural", "networks", "to", "incorporate", "side", "information", "into", "collaborative", "filtering", "models", "to", "better", "handle", "the", "cold", "-", "start", "problem", ".", "These", "approaches", "are", "complementary", "to", "ours", ".", "section", ":", "EMPIRICAL", "STUDY", "We", "evaluate", "the", "performance", "of", "Mult", "-", "vae", "pr", "and", "Mult", "-", "dae", ".", "We", "provide", "insights", "into", "their", "performance", "by", "exploring", "the", "resulting", "fits", ".", "We", "highlight", "the", "following", "results", ":", "\u2022", "Mult", "-", "vae", "pr", "achieves", "state", "-", "of", "-", "the", "-", "art", "results", "on", "three", "realworld", "datasets", "when", "compared", "with", "various", "baselines", ",", "including", "recently", "proposed", "neural", "-", "network", "-", "based", "collaborative", "filtering", "models", ".", "\u2022", "For", "the", "denoising", "and", "variational", "autoencoder", ",", "the", "multinomial", "likelihood", "compares", "favorably", "over", "the", "more", "common", "Gaussian", "and", "logistic", "likelihoods", ".", "\u2022", "Both", "Mult", "-", "vae", "pr", "and", "Mult", "-", "dae", "produce", "competitive", "empirical", "results", ".", "We", "identify", "when", "parameterizing", "the", "uncertainty", "explicitly", "as", "in", "Mult", "-", "vae", "pr", "does", "better", "/", "worse", "than", "the", "point", "estimate", "used", "by", "Mult", "-", "dae", "and", "list", "pros", "and", "cons", "for", "both", "approaches", ".", "The", "source", "code", "to", "reproduce", "the", "experimental", "results", "is", "available", "on", "GitHub", "6", ".", "section", ":", "Datasets", "We", "study", "three", "medium", "-", "to", "large", "-", "scale", "user", "-", "item", "consumption", "datasets", "from", "various", "domains", ":", "MovieLens", "-", "20", "M", "(", "ML", "-", "20", "M", ")", ":", "These", "are", "user", "-", "movie", "ratings", "collected", "from", "a", "movie", "recommendation", "service", ".", "We", "binarize", "the", "explicit", "data", "by", "keeping", "ratings", "of", "four", "or", "higher", "and", "interpret", "them", "as", "implicit", "feedback", ".", "We", "only", "keep", "users", "who", "have", "watched", "at", "least", "five", "movies", ".", "Netflix", "Prize", "(", "Netflix", ")", ":", "This", "is", "the", "user", "-", "movie", "ratings", "data", "from", "the", "Netflix", "Prize", "7", ".", "Similar", "to", "ML", "-", "20", "M", ",", "we", "binarize", "explicit", "data", "by", "keeping", "ratings", "of", "four", "or", "higher", ".", "We", "only", "keep", "users", "who", "have", "watched", "at", "least", "five", "movies", ".", "Million", "Song", "Dataset", "(", "MSD", ")", ":", "This", "data", "contains", "the", "user", "-", "song", "play", "counts", "released", "as", "part", "of", "the", "Million", "Song", "Dataset", "[", "reference", "]", ".", "We", "binarize", "play", "counts", "and", "interpret", "them", "as", "implicit", "preference", "data", ".", "We", "only", "keep", "users", "with", "at", "least", "20", "songs", "in", "their", "listening", "history", "and", "songs", "that", "are", "listened", "to", "by", "at", "least", "200", "users", ".", "Table", "1", "summarizes", "the", "dimensions", "of", "all", "the", "datasets", "after", "preprocessing", ".", "section", ":", "Metrics", "We", "use", "two", "ranking", "-", "based", "metrics", ":", "Recall@R", "and", "the", "truncated", "normalized", "discounted", "cumulative", "gain", "(", "NDCG@R", ")", ".", "For", "each", "user", ",", "both", "metrics", "compare", "the", "predicted", "rank", "of", "the", "held", "-", "out", "items", "with", "their", "true", "rank", ".", "For", "both", "Mult", "-", "vae", "pr", "and", "Mult", "-", "dae", ",", "we", "get", "the", "predicted", "rank", "by", "sorting", "the", "un", "-", "normalized", "multinomial", "probability", "f", "\u03b8", "(", "z", ")", ".", "While", "Recall@R", "considers", "all", "items", "ranked", "within", "the", "first", "R", "to", "be", "equally", "important", ",", "NDCG@R", "uses", "a", "monotonically", "increasing", "discount", "to", "emphasize", "the", "importance", "of", "higher", "ranks", "versus", "lower", "ones", ".", "Formally", ",", "define", "\u03c9", "(", "r", ")", "as", "the", "item", "at", "rank", "r", ",", "I", "[", "\u00b7", "]", "is", "the", "indicator", "function", ",", "and", "I", "u", "is", "the", "set", "of", "held", "-", "out", "items", "that", "user", "u", "clicked", "on", ".", "Recall@R", "for", "user", "u", "is", "The", "expression", "in", "the", "denominator", "is", "the", "minimum", "of", "R", "and", "the", "number", "of", "items", "clicked", "on", "by", "user", "u.", "This", "normalizes", "Recall@R", "to", "have", "a", "maximum", "of", "1", ",", "which", "corresponds", "to", "ranking", "all", "relevant", "items", "in", "the", "top", "R", "positions", ".", "Truncated", "discounted", "cumulative", "gain", "(", "DCG@R", ")", "is", "NDCG@R", "is", "the", "DCG@R", "linearly", "normalized", "to", "[", "0", ",", "1", "]", "after", "dividing", "by", "the", "best", "possible", "DCG@R", ",", "where", "all", "the", "held", "-", "out", "items", "are", "ranked", "at", "the", "top", ".", "section", ":", "Experimental", "setup", "We", "study", "the", "performance", "of", "various", "models", "under", "strong", "generalization", "[", "reference", "]", ":", "We", "split", "all", "users", "into", "training", "/", "validation", "/", "test", "sets", ".", "We", "train", "models", "using", "the", "entire", "click", "history", "of", "the", "training", "users", ".", "To", "evaluate", ",", "we", "take", "part", "of", "the", "click", "history", "from", "held", "-", "out", "(", "validation", "and", "test", ")", "users", "to", "learn", "the", "necessary", "user", "-", "level", "representations", "for", "the", "model", "and", "then", "compute", "metrics", "by", "looking", "at", "how", "well", "the", "model", "ranks", "the", "rest", "of", "the", "unseen", "click", "history", "from", "the", "held", "-", "out", "users", ".", "This", "is", "relatively", "more", "difficult", "than", "weak", "generalization", "where", "the", "user", "'s", "click", "history", "can", "appear", "during", "both", "training", "and", "evaluation", ".", "We", "consider", "it", "more", "realistic", "and", "robust", "as", "well", ".", "In", "the", "last", "row", "of", "Table", "1", ",", "we", "list", "the", "number", "of", "held", "-", "out", "users", "(", "we", "use", "the", "same", "number", "of", "users", "for", "validation", "and", "test", ")", ".", "For", "each", "held", "-", "out", "user", ",", "we", "randomly", "choose", "80", "%", "of", "the", "click", "history", "as", "the", "\"", "fold", "-", "in", "\"", "set", "to", "learn", "the", "necessary", "user", "-", "level", "representation", "and", "report", "metrics", "on", "the", "remaining", "20", "%", "of", "the", "click", "history", ".", "We", "select", "model", "hyperparameters", "and", "architectures", "by", "evaluating", "NDCG@100", "on", "the", "validation", "users", ".", "For", "both", "Mult", "-", "vae", "pr", "and", "Mult", "-", "dae", ",", "we", "keep", "the", "architecture", "for", "the", "generative", "model", "f", "\u03b8", "(", "\u00b7", ")", "and", "the", "inference", "model", "\u0434", "\u03d5", "(", "\u00b7", ")", "symmetrical", "and", "explore", "multilayer", "perceptron", "(", "mlp", ")", "with", "0", ",", "1", ",", "and", "2", "hidden", "layers", ".", "We", "set", "the", "dimension", "of", "the", "latent", "representation", "K", "to", "200", "and", "any", "hidden", "layer", "to", "600", ".", "As", "a", "concrete", "example", ",", "recall", "I", "is", "the", "total", "number", "of", "items", ",", "the", "overall", "architecture", "for", "a", "Mult", "-", "vae", "pr", "/", "Mult", "-", "dae", "with", "1", "-", "hidden", "-", "layer", "mlp", "generative", "model", "would", "be", "[", "I", "\u2192", "600", "\u2192", "200", "\u2192", "600", "\u2192", "I", "]", ".", "We", "find", "that", "going", "deeper", "does", "not", "improve", "performance", ".", "The", "best", "performing", "architectures", "are", "mlps", "with", "either", "0", "or", "1", "hidden", "layers", ".", "We", "use", "a", "tanh", "non", "-", "linearity", "as", "the", "activation", "function", "between", "layers", ".", "Note", "that", "for", "Mult", "-", "vae", "pr", ",", "since", "the", "output", "of", "\u0434", "\u03d5", "(", "\u00b7", ")", "is", "used", "as", "the", "mean", "and", "variance", "of", "a", "Gaussian", "random", "variable", ",", "we", "do", "not", "apply", "an", "activation", "function", "to", "it", ".", "Thus", ",", "the", "Mult", "-", "vae", "pr", "with", "0", "-", "hiddenlayer", "mlp", "is", "effectively", "a", "log", "-", "linear", "model", ".", "We", "tune", "the", "regularization", "parameter", "\u03b2", "for", "Mult", "-", "vae", "pr", "following", "the", "procedure", "described", "in", "Section", "2.2.2", ".", "We", "anneal", "the", "Kullback", "-", "Leibler", "term", "linearly", "for", "200", ",", "000", "gradient", "updates", ".", "For", "both", "Mult", "-", "vae", "pr", "and", "Mult", "-", "dae", ",", "we", "apply", "dropout", "at", "the", "input", "layer", "with", "probability", "0.5", ".", "We", "apply", "a", "weight", "decay", "of", "0.01", "for", "Mult", "-", "dae", ".", "We", "do", "not", "apply", "weight", "decay", "for", "any", "vae", "models", ".", "We", "train", "both", "Mult", "-", "vae", "pr", "and", "Mult", "-", "dae", "using", "Adam", "[", "reference", "]", "with", "batch", "size", "of", "500", "users", ".", "For", "ML", "-", "20", "M", ",", "we", "train", "for", "200", "epochs", ".", "We", "train", "for", "100", "epochs", "on", "the", "other", "two", "datasets", ".", "We", "keep", "the", "model", "with", "the", "best", "validation", "NDCG@100", "and", "report", "test", "set", "metrics", "with", "it", ".", "section", ":", "Baselines", "We", "compare", "results", "with", "the", "following", "standard", "state", "-", "of", "-", "the", "-", "art", "collaborative", "filtering", "models", ",", "both", "linear", "and", "non", "-", "linear", ":", "Weighted", "matrix", "factorization", "(", "wmf", ")", "[", "reference", "]", ":", "a", "linear", "low", "-", "rank", "factorization", "model", ".", "We", "train", "wmf", "with", "alternating", "least", "squares", ";", "this", "generally", "leads", "to", "better", "performance", "than", "with", "SGD", ".", "We", "set", "the", "weights", "on", "all", "the", "0", "'s", "to", "1", "and", "tune", "the", "weights", "on", "all", "the", "1", "'s", "in", "the", "click", "matrix", "among", "{", "2", ",", "5", ",", "10", ",", "30", ",", "50", ",", "100", "}", ",", "as", "well", "as", "the", "latent", "representation", "dimension", "K", "\u2208", "{", "100", ",", "200", "}", "by", "evaluating", "NDCG@100", "on", "validation", "users", ".", "Slim", "[", "reference", "]", ":", "a", "linear", "model", "which", "learns", "a", "sparse", "item", "-", "to", "-", "item", "similarity", "matrix", "by", "solving", "a", "constrained", "\u2113", "1", "-", "regularized", "optimization", "problem", ".", "We", "grid", "-", "search", "both", "of", "the", "regularization", "parameters", "over", "{", "0.1", ",", "0.5", ",", "1", ",", "5", "}", "and", "report", "the", "setting", "with", "the", "best", "NDCG@100", "on", "validation", "users", ".", "We", "did", "not", "evaluate", "Slim", "on", "MSD", "because", "the", "dataset", "is", "too", "large", "for", "it", "to", "finish", "in", "a", "reasonable", "amount", "of", "time", "(", "for", "the", "Netflix", "dataset", ",", "the", "parallelized", "grid", "search", "took", "about", "two", "weeks", ")", ".", "We", "also", "found", "that", "the", "faster", "approximation", "of", "Slim", "[", "reference", "]", "did", "not", "yield", "competitive", "performance", ".", "Collaborative", "denoising", "autoencoder", "(", "cdae", ")", "[", "reference", "]", ":", "augments", "the", "standard", "denoising", "autoencoder", "by", "adding", "a", "per", "-", "user", "latent", "factor", "to", "the", "input", ".", "We", "change", "the", "(", "user", ",", "item", ")", "entry", "subsampling", "strategy", "in", "SGD", "training", "in", "the", "original", "paper", "to", "the", "user", "-", "level", "subsampling", "as", "we", "did", "with", "Mult", "-", "vae", "pr", "and", "Mult", "-", "dae", ".", "We", "generally", "find", "that", "this", "leads", "to", "more", "stable", "convergence", "and", "better", "performance", ".", "We", "set", "the", "dimension", "of", "the", "bottleneck", "layer", "to", "200", ",", "and", "use", "a", "weighted", "square", "loss", ",", "equivalent", "to", "what", "the", "square", "loss", "with", "negative", "sampling", "used", "in", "the", "original", "paper", ".", "We", "apply", "tanh", "activation", "at", "both", "the", "bottleneck", "layer", "as", "well", "as", "the", "output", "layer", ".", "[", "reference", "]", "We", "use", "Adam", "with", "a", "batch", "size", "of", "500", "users", ".", "As", "mentioned", "in", "Section", "3", ",", "the", "number", "of", "parameters", "for", "cdae", "grows", "linearly", "with", "the", "number", "of", "users", "and", "items", ".", "Thus", ",", "it", "is", "crucial", "to", "control", "overfitting", "by", "applying", "weight", "decay", ".", "We", "select", "the", "weight", "decay", "parameter", "over", "{", "0.01", ",", "0.1", ",", "\u00b7", "\u00b7", "\u00b7", ",", "100", "}", "by", "examining", "the", "validation", "NDCG@100", ".", "Neural", "collaborative", "filtering", "(", "ncf", ")", "[", "reference", "]", ":", "explores", "non", "-", "linear", "interactions", "(", "via", "a", "neural", "network", ")", "between", "the", "user", "and", "item", "latent", "factors", ".", "Similar", "to", "cdae", ",", "the", "number", "of", "parameters", "for", "ncf", "grows", "linearly", "with", "the", "number", "of", "users", "and", "items", ".", "We", "use", "the", "publicly", "available", "source", "code", "provided", "by", "the", "authors", ",", "yet", "can", "not", "obtain", "competitive", "performance", "on", "the", "datasets", "used", "in", "this", "paper", "-", "the", "validation", "metrics", "drop", "within", "the", "first", "few", "epochs", "over", "a", "wide", "range", "of", "regularization", "parameters", ".", "The", "authors", "kindly", "provided", "the", "two", "datasets", "(", "ML", "-", "1", "M", "and", "Pinterest", ")", "used", "in", "the", "original", "paper", ",", "as", "well", "as", "the", "training", "/", "test", "split", ",", "therefore", "we", "separately", "compare", "with", "ncf", "on", "these", "two", "relatively", "smaller", "datasets", "in", "the", "empirical", "study", ".", "In", "particular", ",", "we", "compare", "with", "the", "hybrid", "NeuCF", "model", "which", "gives", "the", "best", "performance", "in", "He", "et", "al", ".", "[", "reference", "]", ",", "both", "with", "and", "without", "pre", "-", "training", ".", "We", "also", "experiment", "with", "Bayesian", "personalized", "ranking", "(", "bpr", ")", "[", "reference", "]", ".", "However", ",", "the", "performance", "is", "not", "on", "par", "with", "the", "other", "baselines", "above", ".", "This", "is", "consistent", "with", "some", "other", "studies", "with", "similar", "baselines", "[", "reference", "]", ".", "Therefore", ",", "we", "do", "not", "include", "bpr", "in", "the", "following", "results", "and", "analysis", ".", "section", ":", "Experimental", "results", "and", "analysis", "In", "this", "section", ",", "we", "quantitatively", "compare", "our", "proposed", "methods", "with", "various", "baselines", ".", "In", "addition", ",", "we", "aim", "to", "answer", "the", "following", "two", "questions", ":", "1", ".", "How", "does", "multinomial", "likelihood", "compare", "with", "other", "commonly", "used", "likelihood", "models", "for", "collaborative", "filtering", "?", "2", ".", "When", "does", "Mult", "-", "vae", "pr", "perform", "better", "/", "worse", "than", "Mult", "-", "dae", "?", "Quantitative", "results", ".", "Table", "2", "summarizes", "the", "results", "between", "our", "proposed", "methods", "and", "various", "baselines", ".", "Each", "metric", "is", "averaged", "across", "all", "test", "users", ".", "Both", "Mult", "-", "vae", "pr", "and", "Mult", "-", "dae", "significantly", "outperform", "the", "baselines", "across", "datasets", "and", "metrics", ".", "Multvae", "pr", "significantly", "outperforms", "Mult", "-", "dae", "on", "ML", "-", "20", "M", "and", "Netflix", "data", "-", "sets", ".", "In", "most", "of", "the", "cases", ",", "non", "-", "linear", "models", "(", "Mult", "-", "vae", "pr", ",", "Multdae", ",", "and", "cdae", ")", "prove", "to", "be", "more", "powerful", "collaborative", "filtering", "models", "than", "state", "-", "of", "-", "the", "-", "art", "linear", "models", ".", "The", "inferior", "results", "of", "cdae", "on", "MSD", "are", "possibly", "due", "to", "overfitting", "with", "the", "huge", "number", "of", "users", "and", "items", ",", "as", "validation", "metrics", "drop", "within", "the", "first", "few", "epochs", "even", "though", "the", "training", "objective", "continues", "improving", ".", "We", "compare", "with", "ncf", "on", "the", "two", "relatively", "smaller", "datasets", "used", "in", "Hu", "et", "al", ".", "[", "reference", "]", ":", "ML", "-", "1", "M", "(", "6", ",", "040", "users", ",", "3", ",", "704", "items", ",", "4.47", "%", "density", ")", "and", "Pinterest", "(", "55", ",", "187", "users", ",", "9", ",", "916", "items", ",", "0.27", "%", "density", ")", ".", "Because", "of", "the", "size", "of", "these", "two", "datasets", ",", "we", "use", "Mult", "-", "dae", "with", "a", "0", "-", "hidden", "-", "layer", "mlp", "generative", "model", "-", "the", "overall", "architecture", "is", "[", "I", "\u2192", "200", "\u2192", "I", "]", ".", "(", "Recall", "Mult", "-", "vae", "pr", "with", "a", "0", "-", "hidden", "-", "layer", "mlp", "generative", "model", "is", "effectively", "a", "log", "-", "linear", "model", "with", "limited", "modeling", "capacity", ".", ")", "Table", "3", "summarizes", "the", "results", "between", "Mult", "-", "dae", "and", "ncf", ".", "Multdae", "significantly", "outperforms", "ncf", "without", "pre", "-", "training", "on", "both", "datasets", ".", "On", "the", "larger", "Pinterest", "dataset", ",", "Mult", "-", "dae", "even", "improves", "over", "the", "pre", "-", "trained", "ncf", "model", "by", "a", "big", "margin", ".", "How", "well", "does", "multinomial", "likelihood", "perform", "?", "Despite", "being", "commonly", "used", "in", "language", "models", ",", "multinomial", "likelihoods", "have", "typically", "received", "less", "attention", "in", "the", "collaborative", "filtering", "literature", ",", "especially", "with", "latent", "-", "factor", "models", ".", "Most", "previous", "work", "builds", "on", "Gaussian", "likelihoods", "(", "square", "loss", ",", "Eq", ".", "3", ")", "[", "reference", "][", "reference", "][", "reference", "]", "or", "logistic", "likelihood", "(", "log", "loss", ",", "Eq", ".", "4", ")", "[", "reference", "][", "reference", "]", "instead", ".", "We", "argue", "in", "Section", "2.1", "that", "multinomial", "likelihood", "is", "in", "fact", "a", "good", "proxy", "for", "the", "top", "-", "N", "ranking", "loss", "and", "is", "well", "-", "suited", "for", "implicit", "feedback", "data", ".", "To", "demonstrate", "the", "effectiveness", "of", "multinomial", "likelihood", ",", "we", "take", "the", "best", "-", "performing", "Mult", "-", "vae", "pr", "and", "Mult", "-", "dae", "model", "on", "each", "dataset", "and", "swap", "the", "likelihood", "distribution", "model", "for", "the", "data", "while", "keeping", "everything", "else", "exactly", "the", "same", ".", "Table", "4", "summarizes", "the", "results", "of", "different", "likelihoods", "on", "ML", "-", "20", "M", "(", "the", "results", "on", "the", "other", "two", "datasets", "are", "similar", ".", ")", "We", "tune", "the", "hyperparameters", "for", "each", "likelihood", "separately", ".", "[", "reference", "]", "The", "multinomial", "likelihood", "performs", "better", "than", "the", "other", "likelihoods", ".", "The", "gap", "between", "logistic", "and", "multinomial", "likelihood", "is", "closer", "-", "this", "is", "understandable", "since", "multinomial", "likelihood", "can", "be", "approximated", "by", "individual", "binary", "logistic", "likelihood", ",", "a", "strategy", "commonly", "adopted", "in", "language", "modeling", "[", "reference", "][", "reference", "]", ".", "We", "wish", "to", "emphasize", "that", "the", "choice", "of", "likelihood", "remains", "datadependent", ".", "For", "the", "task", "of", "collaborative", "filtering", ",", "the", "multinomial", "likelihood", "achieves", "excellent", "empirical", "results", ".", "The", "methodology", "behind", "the", "partial", "regularization", "in", "Mult", "-", "vae", "pr", ",", "however", ",", "is", "a", "technique", "we", "hypothesize", "will", "generalize", "to", "other", "domains", ".", "When", "does", "Mult", "-", "vae", "pr", "perform", "better", "/", "worse", "than", "Multdae", "?", "In", "Table", "2", "we", "can", "see", "that", "both", "Mult", "-", "vae", "pr", "and", "Mult", "-", "dae", "produce", "competitive", "empirical", "results", "with", "Mult", "-", "vae", "pr", "being", "comparably", "better", ".", "It", "is", "natural", "to", "wonder", "when", "a", "variational", "Bayesian", "inference", "approach", "(", "Mult", "-", "vae", "pr", ")", "will", "win", "over", "using", "a", "point", "estimate", "(", "Mult", "-", "dae", ")", "and", "vice", "versa", ".", "Intuitively", ",", "Mult", "-", "vae", "pr", "imposes", "stronger", "modeling", "assumptions", "and", "therefore", "could", "be", "more", "robust", "when", "user", "-", "item", "interaction", "data", "is", "scarce", ".", "To", "study", "this", ",", "we", "considered", "two", "datasets", ":", "ML", "-", "20", "M", "where", "Mult", "-", "vae", "pr", "has", "the", "largest", "margin", "over", "Mult", "-", "dae", "and", "MSD", "where", "Mult", "-", "vae", "pr", "and", "Mult", "-", "dae", "have", "roughly", "similar", "performance", ".", "The", "results", "on", "the", "Netflix", "dataset", "are", "similar", "to", "ML", "-", "20M.", "We", "break", "down", "test", "users", "into", "quintiles", "based", "on", "their", "activity", "level", "in", "the", "fold", "-", "in", "set", "which", "is", "provided", "as", "input", "to", "the", "inference", "model", "\u0434", "\u03d5", "(", "\u00b7", ")", "to", "make", "prediction", ".", "The", "activity", "level", "is", "simply", "the", "number", "of", "items", "each", "user", "has", "clicked", "on", ".", "We", "compute", "NDCG@100", "for", "each", "group", "of", "users", "using", "both", "Mult", "-", "vae", "pr", "and", "Mult", "-", "dae", "and", "plot", "results", "in", "Figure", "3", ".", "This", "summarizes", "how", "performance", "differs", "across", "users", "with", "various", "levels", "of", "activity", ".", "In", "Figure", "3", ",", "we", "show", "performance", "across", "increasing", "user", "activity", ".", "Error", "bars", "represents", "one", "standard", "error", ".", "For", "each", "subplot", ",", "a", "paired", "t", "-", "test", "is", "performed", "and", "statistical", "significance", "is", "marked", ".", "Although", "there", "are", "slight", "variations", "across", "datasets", ",", "Mult", "-", "vae", "pr", "consistently", "improves", "recommendation", "performance", "for", "users", "who", "have", "only", "clicked", "on", "a", "small", "number", "of", "items", ".", "This", "is", "particularly", "prominent", "for", "ML", "-", "20", "M", "(", "Figure", "3a", ")", ".", "Interestingly", ",", "Mult", "-", "dae", "actually", "[", "reference", "]", "Surprisingly", ",", "partial", "regularization", "seems", "less", "effective", "for", "Gaussian", "and", "logistic", ".", "Figure", "3", ":", "NDCG@100", "breakdown", "for", "users", "with", "increasing", "levels", "of", "activity", "(", "starting", "from", "0", "%", ")", ",", "measured", "by", "how", "many", "items", "a", "user", "clicked", "on", "in", "the", "fold", "-", "in", "set", ".", "The", "error", "bars", "represents", "one", "standard", "error", ".", "For", "each", "subplot", ",", "a", "paired", "t", "-", "test", "is", "performed", "and", "*", "indicates", "statistical", "significance", "at", "\u03b1", "=", "0.05", "level", ",", "*", "*", "at", "\u03b1", "=", "0.01", "level", ",", "and", "*", "*", "*", "at", "\u03b1", "=", "0.001", "level", ".", "Although", "details", "vary", "across", "datasets", ",", "Mult", "-", "vae", "pr", "consistently", "improves", "recommendation", "performance", "for", "users", "who", "have", "only", "clicked", "on", "a", "small", "number", "of", "items", ".", "outperforms", "Mult", "-", "vae", "pr", "on", "the", "most", "active", "users", ".", "This", "indicates", "the", "stronger", "prior", "assumption", "could", "potentially", "hurt", "the", "performance", "when", "a", "lot", "of", "data", "is", "available", "for", "a", "user", ".", "For", "MSD", "(", "Figure", "3b", ")", ",", "the", "least", "-", "active", "users", "have", "similar", "performance", "under", "both", "Multvae", "pr", "and", "Mult", "-", "dae", ".", "However", ",", "as", "we", "described", "in", "Section", "4.1", ",", "MSD", "is", "pre", "-", "processed", "so", "that", "a", "user", "has", "at", "least", "listened", "to", "20", "songs", ".", "Meanwhile", "for", "ML", "-", "20", "M", ",", "each", "user", "has", "to", "watch", "at", "least", "5", "movies", ".", "This", "means", "that", "the", "first", "bin", "of", "ML", "-", "20", "M", "has", "much", "lower", "user", "activity", "than", "the", "first", "bin", "of", "MSD", ".", "Overall", ",", "we", "find", "that", "Mult", "-", "vae", "pr", ",", "which", "may", "be", "viewed", "under", "the", "lens", "of", "a", "principled", "Bayesian", "inference", "approach", ",", "is", "more", "robust", "than", "the", "point", "estimate", "approach", "of", "Mult", "-", "dae", ",", "regardless", "of", "the", "scarcity", "of", "the", "data", ".", "More", "importantly", ",", "the", "Mult", "-", "vae", "pr", "is", "less", "sensitive", "to", "the", "choice", "of", "hyperparameters", "-", "weight", "decay", "is", "important", "for", "Mult", "-", "dae", "to", "achieve", "competitive", "performance", ",", "yet", "it", "is", "not", "required", "for", "Mult", "-", "vae", "pr", ".", "On", "the", "other", "hand", ",", "Mult", "-", "dae", "also", "has", "advantages", ":", "it", "requires", "fewer", "parameters", "in", "the", "bottleneck", "layer", "-", "Mult", "-", "vae", "pr", "requires", "two", "sets", "of", "parameters", "to", "obtain", "the", "latent", "representation", "z", ":", "one", "set", "for", "the", "variational", "mean", "\u00b5", "\u03d5", "(", "\u00b7", ")", "and", "another", "for", "the", "variational", "variance", "\u03c3", "\u03d5", "(", "\u00b7", ")", "-", "and", "Mult", "-", "dae", "is", "conceptually", "simpler", "for", "practitioners", ".", "section", ":", "CONCLUSION", "In", "this", "paper", ",", "we", "develop", "a", "variant", "of", "vae", "for", "collaborative", "filtering", "on", "implicit", "feedback", "data", ".", "This", "enables", "us", "to", "go", "beyond", "linear", "factor", "models", "with", "limited", "modeling", "capacity", ".", "We", "introduce", "a", "generative", "model", "with", "a", "multinomial", "likelihood", "function", "parameterized", "by", "neural", "network", ".", "We", "show", "that", "multinomial", "likelihood", "is", "particularly", "well", "suited", "to", "modeling", "user", "-", "item", "implicit", "feedback", "data", ".", "Based", "on", "an", "alternative", "interpretation", "of", "the", "vae", "objective", ",", "we", "introduce", "an", "additional", "regularization", "parameter", "to", "partially", "regularize", "a", "vae", "(", "Mult", "-", "vae", "pr", ")", ".", "We", "also", "provide", "a", "practical", "and", "efficient", "way", "to", "tune", "the", "additional", "parameter", "introduced", "using", "KL", "annealing", ".", "We", "compare", "the", "results", "obtained", "against", "a", "denoising", "autoencoder", "(", "Mult", "-", "dae", ")", ".", "Empirically", ",", "we", "show", "that", "the", "both", "Mult", "-", "vae", "pr", "and", "Mult", "-", "dae", "provide", "competitive", "performance", "with", "Mult", "-", "vae", "pr", "significantly", "outperforming", "the", "state", "-", "of", "-", "the", "-", "art", "baselines", "on", "several", "real", "-", "world", "datasets", ",", "including", "two", "recently", "proposed", "neural", "-", "network", "-", "based", "approaches", ".", "Finally", ",", "we", "identify", "the", "pros", "and", "cons", "of", "both", "Mult", "-", "vae", "pr", "and", "Multdae", "and", "show", "that", "employing", "a", "principled", "Bayesian", "approach", "is", "more", "robust", ".", "In", "future", "work", ",", "we", "would", "like", "to", "futher", "investigate", "the", "tradeoff", "introduced", "by", "the", "additional", "regularization", "parameter", "\u03b2", "and", "gain", "more", "theoretical", "insight", "into", "why", "it", "works", "so", "well", ".", "Extending", "Mult", "-", "vae", "pr", "by", "condition", "on", "side", "information", "might", "also", "be", "a", "way", "to", "improve", "performance", ".", "section", ":"]}