{"coref": {"Accuracy": [[3387, 3392]], "Few-Shot_Image_Classification": [[1962, 1968], [1978, 1983], [2041, 2045], [2094, 2096], [2107, 2109], [2211, 2212], [3304, 3305], [3577, 3581], [4449, 4455]], "Neural_Statistician": [[4, 6], [170, 172], [275, 276], [296, 298], [575, 577], [642, 646], [1499, 1501], [2663, 2665], [3562, 3564], [3737, 3740]], "OMNIGLOT_-_1-Shot_Learning": [[1956, 1957], [2630, 2631], [3236, 3239], [3359, 3361], [3536, 3537], [3583, 3586]], "OMNIGLOT_-_5-Shot_Learning": [[1956, 1957], [2630, 2631], [3236, 3239]]}, "coref_non_salient": {"0": [[86, 90], [2363, 2365]], "1": [[105, 107], [146, 148], [326, 328], [380, 382], [523, 525], [536, 538], [1056, 1058], [1218, 1220], [1263, 1265], [2479, 2481], [3057, 3059], [4142, 4144], [4274, 4276]], "10": [[92, 94], [359, 360], [2331, 2333]], "100": [[2232, 2237]], "101": [[3112, 3117]], "102": [[3374, 3376]], "103": [[2286, 2287]], "104": [[2486, 2488]], "105": [[1356, 1357]], "106": [[2198, 2200]], "107": [[2399, 2400]], "108": [[1044, 1050]], "109": [[648, 650]], "11": [[1014, 1017], [1506, 1508], [1526, 1528], [3969, 3971]], "110": [[1212, 1216]], "111": [[3979, 3980]], "112": [[2387, 2389]], "113": [[4170, 4171]], "114": [[122, 126]], "115": [[2120, 2123]], "116": [[787, 791]], "117": [[1448, 1451]], "118": [[2143, 2144]], "119": [[1267, 1269]], "12": [[1031, 1032], [1446, 1447]], "120": [[1842, 1845]], "121": [[1867, 1869]], "122": [[1352, 1355]], "123": [[1300, 1302]], "124": [[552, 554]], "125": [[142, 144]], "126": [[710, 713]], "13": [[2632, 2633], [3838, 3840], [3859, 3862], [3863, 3864], [4473, 4475]], "14": [[2201, 2205], [2245, 2251]], "15": [[595, 599], [1888, 1893]], "16": [[2046, 2049], [3726, 3727]], "17": [[74, 76], [607, 610], [611, 612], [716, 718], [719, 721], [841, 842], [862, 864], [1456, 1458], [1862, 1864]], "18": [[1938, 1942], [2005, 2009]], "19": [[3981, 3983]], "2": [[730, 731], [762, 763], [1550, 1552], [1657, 1659], [1672, 1674], [3095, 3098], [3508, 3509]], "20": [[179, 181], [283, 285], [663, 665], [955, 957], [979, 981], [1009, 1011], [1084, 1086], [1259, 1261], [1807, 1810], [1815, 1817], [2413, 2416]], "21": [[4314, 4316], [4331, 4333]], "22": [[2217, 2220], [2404, 2408]], "23": [[1460, 1461], [1474, 1475]], "24": [[2222, 2226], [2227, 2230]], "25": [[1120, 1125], [1130, 1132]], "26": [[442, 446], [3524, 3528]], "27": [[338, 340], [1245, 1247], [1919, 1921]], "28": [[3479, 3482], [3974, 3976]], "29": [[116, 117], [1875, 1877]], "3": [[3825, 3829], [3831, 3835]], "30": [[2825, 2827]], "31": [[8, 9], [25, 27]], "32": [[2565, 2568]], "33": [[1618, 1620], [1736, 1738], [1742, 1744], [1859, 1861], [2559, 2561], [4133, 4135]], "34": [[307, 309], [570, 572], [701, 703], [1107, 1109], [1165, 1167], [1511, 1513], [1643, 1645], [1693, 1695], [2467, 2469], [2776, 2778], [2944, 2946], [3107, 3109], [3417, 3419], [3444, 3446], [3484, 3488], [3612, 3614], [3965, 3967], [4406, 4408], [4439, 4441]], "35": [[927, 929], [3998, 3999]], "36": [[2586, 2589], [2605, 2607]], "37": [[2635, 2636], [2910, 2912], [2952, 2954], [2956, 2958], [3368, 3369], [3545, 3546], [2961, 2962], [3381, 3382], [3587, 3588], [3601, 3602]], "38": [[3264, 3270], [4162, 4166]], "39": [[3325, 3326]], "4": [[1999, 2003], [2162, 2163]], "40": [[1590, 1591]], "41": [[1587, 1589]], "42": [[2767, 2769], [2794, 2796], [3119, 3123]], "43": [[2669, 2673], [2682, 2686]], "44": [[3299, 3303]], "45": [[3490, 3493]], "46": [[1733, 1735], [1759, 1761], [1766, 1768], [1789, 1791], [2136, 2138]], "47": [[2411, 2412]], "48": [[585, 588]], "49": [[2805, 2808]], "5": [[991, 994], [1065, 1068], [1614, 1616], [2750, 2753]], "50": [[3759, 3761], [3771, 3773], [3790, 3792]], "51": [[3338, 3340]], "52": [[2290, 2296]], "53": [[3746, 3747]], "54": [[2390, 2394]], "55": [[3751, 3754], [3763, 3766]], "56": [[1603, 1607], [1687, 1691]], "57": [[3730, 3731]], "58": [[2809, 2812]], "59": [[1034, 1037], [1289, 1292]], "6": [[723, 726], [960, 962]], "60": [[3801, 3805]], "61": [[1928, 1932]], "62": [[2145, 2149]], "63": [[2649, 2653]], "64": [[2189, 2193]], "65": [[2366, 2369]], "66": [[2076, 2080]], "67": [[2562, 2564], [2745, 2747]], "68": [[3125, 3127]], "69": [[1202, 1204], [1341, 1343], [1379, 1381], [2732, 2734], [3063, 3065], [3465, 3467], [3955, 3957]], "7": [[511, 515], [517, 519]], "70": [[2323, 2325], [2381, 2383]], "71": [[4225, 4226]], "72": [[1972, 1977]], "73": [[4268, 4272]], "74": [[4311, 4313]], "75": [[1664, 1665]], "76": [[1882, 1883]], "77": [[1818, 1820]], "78": [[756, 758], [768, 770]], "79": [[2799, 2800]], "8": [[617, 619], [2697, 2705]], "80": [[2818, 2823]], "81": [[82, 84]], "82": [[1540, 1543]], "83": [[1562, 1566]], "84": [[205, 213]], "85": [[3341, 3343]], "86": [[4334, 4336]], "87": [[966, 968]], "88": [[2171, 2173]], "89": [[2277, 2281]], "9": [[1958, 1961], [2549, 2553]], "90": [[847, 854]], "91": [[3400, 3402]], "92": [[3345, 3347]], "93": [[1942, 1944]], "94": [[2571, 2573]], "95": [[1206, 1209]], "96": [[2185, 2186]], "97": [[225, 233]], "98": [[376, 378]], "99": [[197, 200]]}, "doc_id": "432d8cba544bf7b09b0455561fea098177a85db1", "method_subrelations": {"Neural_Statistician": [[[0, 19], "Neural_Statistician"]]}, "n_ary_relations": [{"Material": "OMNIGLOT_-_1-Shot_Learning", "Method": "Neural_Statistician", "Metric": "Accuracy", "Task": "Few-Shot_Image_Classification", "score": "98.1%"}, {"Material": "OMNIGLOT_-_5-Shot_Learning", "Method": "Neural_Statistician", "Metric": "Accuracy", "Task": "Few-Shot_Image_Classification", "score": "99.5%"}], "ner": [[4, 6, "Method"], [8, 9, "Method"], [25, 27, "Method"], [74, 76, "Method"], [82, 84, "Task"], [86, 90, "Task"], [92, 94, "Method"], [105, 107, "Method"], [116, 117, "Task"], [122, 126, "Task"], [142, 144, "Task"], [146, 148, "Method"], [170, 172, "Method"], [179, 181, "Method"], [197, 200, "Task"], [205, 213, "Task"], [225, 233, "Task"], [275, 276, "Method"], [283, 285, "Method"], [296, 298, "Method"], [307, 309, "Method"], [326, 328, "Method"], [338, 340, "Method"], [359, 360, "Method"], [376, 378, "Method"], [380, 382, "Method"], [442, 446, "Method"], [511, 515, "Method"], [517, 519, "Method"], [523, 525, "Method"], [536, 538, "Method"], [552, 554, "Method"], [570, 572, "Method"], [575, 577, "Method"], [585, 588, "Method"], [595, 599, "Method"], [607, 610, "Method"], [611, 612, "Method"], [617, 619, "Method"], [642, 646, "Method"], [648, 650, "Method"], [663, 665, "Method"], [701, 703, "Method"], [710, 713, "Method"], [716, 718, "Method"], [719, 721, "Method"], [723, 726, "Method"], [730, 731, "Method"], [756, 758, "Method"], [762, 763, "Method"], [768, 770, "Method"], [787, 791, "Method"], [841, 842, "Method"], [847, 854, "Method"], [862, 864, "Method"], [927, 929, "Method"], [955, 957, "Method"], [960, 962, "Method"], [966, 968, "Method"], [979, 981, "Method"], [991, 994, "Method"], [1009, 1011, "Method"], [1014, 1017, "Method"], [1031, 1032, "Task"], [1034, 1037, "Metric"], [1044, 1050, "Metric"], [1056, 1058, "Method"], [1065, 1068, "Method"], [1084, 1086, "Method"], [1107, 1109, "Method"], [1120, 1125, "Method"], [1130, 1132, "Method"], [1165, 1167, "Method"], [1202, 1204, "Method"], [1206, 1209, "Method"], [1212, 1216, "Method"], [1218, 1220, "Method"], [1245, 1247, "Method"], [1259, 1261, "Method"], [1263, 1265, "Method"], [1267, 1269, "Method"], [1289, 1292, "Metric"], [1300, 1302, "Method"], [1341, 1343, "Method"], [1352, 1355, "Method"], [1356, 1357, "Method"], [1379, 1381, "Method"], [1446, 1447, "Task"], [1448, 1451, "Method"], [1456, 1458, "Method"], [1460, 1461, "Method"], [1474, 1475, "Method"], [1499, 1501, "Method"], [1506, 1508, "Method"], [1511, 1513, "Method"], [1526, 1528, "Method"], [1540, 1543, "Method"], [1550, 1552, "Method"], [1562, 1566, "Method"], [1587, 1589, "Method"], [1590, 1591, "Method"], [1603, 1607, "Method"], [1614, 1616, "Method"], [1618, 1620, "Method"], [1643, 1645, "Method"], [1657, 1659, "Method"], [1664, 1665, "Task"], [1672, 1674, "Method"], [1687, 1691, "Method"], [1693, 1695, "Method"], [1733, 1735, "Method"], [1736, 1738, "Method"], [1742, 1744, "Method"], [1759, 1761, "Method"], [1766, 1768, "Method"], [1789, 1791, "Method"], [1807, 1810, "Method"], [1815, 1817, "Method"], [1818, 1820, "Task"], [1842, 1845, "Method"], [1859, 1861, "Method"], [1862, 1864, "Method"], [1867, 1869, "Method"], [1875, 1877, "Task"], [1882, 1883, "Task"], [1888, 1893, "Method"], [1919, 1921, "Method"], [1928, 1932, "Method"], [1938, 1942, "Method"], [1942, 1944, "Task"], [1956, 1957, "Material"], [1958, 1961, "Method"], [1962, 1968, "Task"], [1972, 1977, "Method"], [1978, 1983, "Task"], [1999, 2003, "Method"], [2005, 2009, "Method"], [2041, 2045, "Task"], [2046, 2049, "Task"], [2076, 2080, "Method"], [2094, 2096, "Task"], [2107, 2109, "Task"], [2120, 2123, "Task"], [2136, 2138, "Method"], [2143, 2144, "Method"], [2145, 2149, "Task"], [2162, 2163, "Method"], [2171, 2173, "Method"], [2185, 2186, "Method"], [2189, 2193, "Method"], [2198, 2200, "Task"], [2201, 2205, "Task"], [2211, 2212, "Task"], [2217, 2220, "Method"], [2222, 2226, "Method"], [2227, 2230, "Method"], [2232, 2237, "Method"], [2245, 2251, "Task"], [2277, 2281, "Task"], [2286, 2287, "Method"], [2290, 2296, "Method"], [2323, 2325, "Task"], [2331, 2333, "Method"], [2363, 2365, "Task"], [2366, 2369, "Task"], [2381, 2383, "Task"], [2387, 2389, "Method"], [2390, 2394, "Method"], [2399, 2400, "Method"], [2404, 2408, "Method"], [2411, 2412, "Method"], [2413, 2416, "Method"], [2467, 2469, "Method"], [2479, 2481, "Method"], [2486, 2488, "Method"], [2549, 2553, "Method"], [2559, 2561, "Method"], [2562, 2564, "Method"], [2565, 2568, "Method"], [2571, 2573, "Method"], [2586, 2589, "Method"], [2605, 2607, "Method"], [2630, 2631, "Material"], [2632, 2633, "Material"], [2635, 2636, "Material"], [2649, 2653, "Method"], [2663, 2665, "Method"], [2669, 2673, "Material"], [2682, 2686, "Material"], [2697, 2705, "Method"], [2732, 2734, "Method"], [2745, 2747, "Method"], [2750, 2753, "Method"], [2767, 2769, "Method"], [2776, 2778, "Method"], [2794, 2796, "Method"], [2799, 2800, "Method"], [2805, 2808, "Method"], [2809, 2812, "Method"], [2818, 2823, "Metric"], [2825, 2827, "Metric"], [2910, 2912, "Material"], [2944, 2946, "Method"], [2952, 2954, "Material"], [2956, 2958, "Material"], [3057, 3059, "Method"], [3063, 3065, "Method"], [3095, 3098, "Method"], [3107, 3109, "Method"], [3112, 3117, "Method"], [3119, 3123, "Method"], [3125, 3127, "Method"], [3236, 3239, "Material"], [3264, 3270, "Task"], [3299, 3303, "Method"], [3304, 3305, "Task"], [3325, 3326, "Method"], [3338, 3340, "Method"], [3341, 3343, "Method"], [3345, 3347, "Task"], [3359, 3361, "Material"], [3368, 3369, "Material"], [3374, 3376, "Metric"], [3387, 3392, "Metric"], [3400, 3402, "Method"], [3417, 3419, "Method"], [3444, 3446, "Method"], [3465, 3467, "Method"], [3479, 3482, "Method"], [3484, 3488, "Method"], [3490, 3493, "Method"], [3508, 3509, "Method"], [3524, 3528, "Method"], [3536, 3537, "Material"], [3545, 3546, "Material"], [3562, 3564, "Method"], [3577, 3581, "Task"], [3583, 3586, "Material"], [3612, 3614, "Method"], [3726, 3727, "Task"], [3730, 3731, "Method"], [3737, 3740, "Method"], [3746, 3747, "Method"], [3751, 3754, "Task"], [3759, 3761, "Method"], [3763, 3766, "Task"], [3771, 3773, "Method"], [3790, 3792, "Method"], [3801, 3805, "Task"], [3825, 3829, "Task"], [3831, 3835, "Task"], [3838, 3840, "Material"], [3859, 3862, "Material"], [3863, 3864, "Material"], [3955, 3957, "Method"], [3965, 3967, "Method"], [3969, 3971, "Method"], [3974, 3976, "Method"], [3979, 3980, "Method"], [3981, 3983, "Method"], [3998, 3999, "Method"], [4133, 4135, "Method"], [4142, 4144, "Method"], [4162, 4166, "Task"], [4170, 4171, "Task"], [4225, 4226, "Method"], [4268, 4272, "Metric"], [4274, 4276, "Method"], [4311, 4313, "Method"], [4314, 4316, "Task"], [4331, 4333, "Task"], [4334, 4336, "Task"], [4406, 4408, "Method"], [4439, 4441, "Method"], [4449, 4455, "Task"], [4473, 4475, "Material"], [2961, 2962, "Material"], [3381, 3382, "Material"], [3587, 3588, "Material"], [3601, 3602, "Material"]], "sections": [[0, 193], [193, 480], [480, 573], [573, 714], [714, 855], [855, 1168], [1168, 1497], [1497, 1703], [1703, 1731], [1731, 1865], [1865, 1936], [1936, 2187], [2187, 2265], [2265, 2353], [2353, 2455], [2455, 2646], [2646, 2908], [2908, 3228], [3228, 3836], [3836, 4107], [4107, 4317], [4317, 4361], [4361, 4364], [4364, 4460], [4460, 4468], [4468, 4471], [4471, 4475]], "sentences": [[0, 6], [6, 23], [23, 36], [36, 64], [64, 95], [95, 111], [111, 127], [127, 163], [163, 193], [193, 196], [196, 214], [214, 258], [258, 277], [277, 299], [299, 349], [349, 359], [359, 361], [361, 383], [383, 409], [409, 412], [412, 440], [440, 480], [480, 484], [484, 490], [490, 505], [505, 516], [516, 529], [529, 544], [544, 551], [551, 573], [573, 577], [577, 614], [614, 640], [640, 651], [651, 698], [698, 700], [700, 714], [714, 718], [718, 735], [735, 767], [767, 800], [800, 824], [824, 855], [855, 859], [859, 877], [877, 905], [905, 936], [936, 958], [958, 982], [982, 1012], [1012, 1043], [1043, 1093], [1093, 1110], [1110, 1119], [1119, 1141], [1141, 1168], [1168, 1172], [1172, 1192], [1192, 1217], [1217, 1232], [1232, 1262], [1262, 1277], [1277, 1344], [1344, 1358], [1358, 1413], [1413, 1443], [1443, 1452], [1452, 1497], [1497, 1501], [1501, 1525], [1525, 1537], [1537, 1549], [1549, 1561], [1561, 1578], [1578, 1592], [1592, 1601], [1601, 1617], [1617, 1633], [1633, 1668], [1668, 1703], [1703, 1707], [1707, 1731], [1731, 1738], [1738, 1762], [1762, 1782], [1782, 1811], [1811, 1837], [1837, 1865], [1865, 1869], [1869, 1884], [1884, 1910], [1910, 1936], [1936, 1942], [1942, 1956], [1956, 1984], [1984, 2019], [2019, 2038], [2038, 2068], [2068, 2097], [2097, 2124], [2124, 2150], [2150, 2187], [2187, 2193], [2193, 2213], [2213, 2239], [2239, 2265], [2265, 2268], [2268, 2282], [2282, 2310], [2310, 2342], [2342, 2353], [2353, 2356], [2356, 2395], [2395, 2409], [2409, 2424], [2424, 2455], [2455, 2459], [2459, 2477], [2477, 2489], [2489, 2522], [2522, 2531], [2531, 2542], [2542, 2565], [2565, 2582], [2582, 2608], [2608, 2646], [2646, 2653], [2653, 2677], [2677, 2690], [2690, 2709], [2709, 2718], [2718, 2724], [2724, 2742], [2742, 2775], [2775, 2813], [2813, 2818], [2818, 2829], [2829, 2838], [2838, 2868], [2868, 2891], [2891, 2908], [2908, 2912], [2912, 2947], [2947, 2955], [2955, 2983], [2983, 2993], [2993, 3001], [3001, 3008], [3008, 3056], [3056, 3077], [3077, 3106], [3106, 3128], [3128, 3163], [3163, 3176], [3176, 3188], [3188, 3198], [3198, 3212], [3212, 3228], [3228, 3231], [3231, 3240], [3240, 3255], [3255, 3271], [3271, 3284], [3284, 3306], [3306, 3316], [3316, 3322], [3322, 3333], [3333, 3396], [3396, 3433], [3433, 3461], [3461, 3476], [3476, 3494], [3494, 3507], [3507, 3514], [3514, 3547], [3547, 3571], [3571, 3590], [3590, 3615], [3615, 3646], [3646, 3656], [3656, 3673], [3673, 3696], [3696, 3707], [3707, 3717], [3717, 3732], [3732, 3767], [3767, 3806], [3806, 3836], [3836, 3840], [3840, 3856], [3856, 3865], [3865, 3872], [3872, 3885], [3885, 3906], [3906, 3928], [3928, 3939], [3939, 3951], [3951, 3964], [3964, 3984], [3984, 3993], [3993, 4022], [4022, 4032], [4032, 4066], [4066, 4082], [4082, 4107], [4107, 4110], [4110, 4123], [4123, 4153], [4153, 4210], [4210, 4229], [4229, 4263], [4263, 4296], [4296, 4317], [4317, 4320], [4320, 4361], [4361, 4364], [4364, 4370], [4370, 4385], [4385, 4388], [4388, 4400], [4400, 4409], [4409, 4419], [4419, 4424], [4424, 4427], [4427, 4434], [4434, 4442], [4442, 4460], [4460, 4468], [4468, 4471], [4471, 4475]], "words": ["document", ":", "Towards", "a", "Neural", "Statistician", "An", "efficient", "learner", "is", "one", "who", "reuses", "what", "they", "already", "know", "to", "tackle", "a", "new", "problem", ".", "For", "a", "machine", "learner", ",", "this", "means", "understanding", "the", "similarities", "amongst", "datasets", ".", "In", "order", "to", "do", "this", ",", "one", "must", "take", "seriously", "the", "idea", "of", "working", "with", "datasets", ",", "rather", "than", "datapoints", ",", "as", "the", "key", "objects", "to", "model", ".", "Towards", "this", "goal", ",", "we", "demonstrate", "an", "extension", "of", "a", "variational", "autoencoder", "that", "can", "learn", "a", "method", "for", "computing", "representations", ",", "or", "statistics", ",", "of", "datasets", "in", "an", "unsupervised", "fashion", ".", "The", "network", "is", "trained", "to", "produce", "statistics", "that", "encapsulate", "a", "generative", "model", "for", "each", "dataset", ".", "Hence", "the", "network", "enables", "efficient", "learning", "from", "new", "datasets", "for", "both", "unsupervised", "and", "supervised", "tasks", ".", "We", "show", "that", "we", "are", "able", "to", "learn", "statistics", "that", "can", "be", "used", "for", ":", "clustering", "datasets", ",", "transferring", "generative", "models", "to", "new", "datasets", ",", "selecting", "representative", "samples", "of", "datasets", "and", "classifying", "previously", "unseen", "classes", ".", "We", "refer", "to", "our", "model", "as", "a", "neural", "statistician", ",", "and", "by", "this", "we", "mean", "a", "neural", "network", "that", "can", "learn", "to", "compute", "summary", "statistics", "of", "datasets", "without", "supervision", ".", "section", ":", "Introduction", "The", "machine", "learning", "community", "is", "well", "-", "practised", "at", "learning", "representations", "of", "data", "-", "points", "and", "sequences", ".", "A", "middle", "-", "ground", "between", "these", "two", "is", "representing", ",", "or", "summarizing", ",", "datasets", "-", "unordered", "collections", "of", "vectors", ",", "such", "as", "photos", "of", "a", "particular", "person", ",", "recordings", "of", "a", "given", "speaker", "or", "a", "document", "as", "a", "bag", "-", "of", "-", "words", ".", "Where", "these", "sets", "take", "the", "form", "of", "i.i.d", "samples", "from", "some", "distribution", ",", "such", "summaries", "are", "called", "statistics", ".", "We", "explore", "the", "idea", "of", "using", "neural", "networks", "to", "learn", "statistics", "and", "we", "refer", "to", "our", "approach", "as", "a", "neural", "statistician", ".", "The", "key", "result", "of", "our", "approach", "is", "a", "statistic", "network", "that", "takes", "as", "input", "a", "set", "of", "vectors", "and", "outputs", "a", "vector", "of", "summary", "statistics", "specifying", "a", "generative", "model", "of", "that", "set", "-", "a", "mean", "and", "variance", "specifying", "a", "Gaussian", "distribution", "in", "a", "latent", "space", "we", "term", "the", "context", ".", "The", "advantages", "of", "our", "approach", "are", "that", "it", "is", ":", "Unsupervised", ":", "It", "provides", "principled", "and", "unsupervised", "way", "to", "learn", "summary", "statistics", "as", "the", "output", "of", "a", "variational", "encoder", "of", "a", "generative", "model", ".", "Data", "efficient", ":", "If", "one", "has", "a", "large", "number", "of", "small", "but", "related", "datasets", ",", "modelling", "the", "datasets", "jointly", "enables", "us", "to", "gain", "statistical", "strength", ".", "Parameter", "Efficient", ":", "By", "using", "summary", "statistics", "instead", "of", "say", "categorical", "labellings", "of", "each", "dataset", ",", "we", "decouple", "the", "number", "of", "parameters", "of", "the", "model", "from", "the", "number", "of", "datasets", ".", "Capable", "of", "few", "-", "shot", "learning", ":", "If", "the", "datasets", "correspond", "to", "examples", "from", "different", "classes", ",", "class", "embeddings", "(", "summary", "statistics", "associated", "with", "examples", "from", "a", "class", ")", ",", "allow", "us", "to", "handle", "new", "classes", "at", "test", "time", ".", "section", ":", "Problem", "Statement", "We", "are", "given", "datasets", "for", ".", "Each", "dataset", "consists", "of", "a", "number", "of", "i.i.d", "samples", "from", "an", "associated", "distribution", "over", ".", "The", "task", "can", "be", "split", "into", "learning", "and", "inference", "components", ".", "The", "learning", "component", "is", "to", "produce", "a", "generative", "model", "for", "each", "dataset", ".", "We", "assume", "there", "is", "a", "common", "underlying", "generative", "process", "such", "that", "for", "drawn", "from", ".", "We", "refer", "to", "as", "the", "context", ".", "The", "inference", "component", "is", "to", "give", "an", "approximate", "posterior", "over", "the", "context", "for", "a", "given", "dataset", "produced", "by", "a", "statistic", "network", ".", "section", ":", "Neural", "Statistician", "In", "order", "to", "exploit", "the", "assumption", "of", "a", "hierarchical", "generative", "process", "over", "datasets", "we", "will", "use", "a", "\u2018", "parameter", "-", "transfer", "approach", "\u2019", "[", "see", "][]", "transfer_survey", "to", "extend", "the", "variational", "autoencoder", "model", "of", "variational_autoencoder", ".", "figure", "Left", ":", "basic", "hierarchical", "model", ",", "where", "the", "plate", "encodes", "the", "fact", "that", "the", "context", "variable", "is", "shared", "across", "each", "item", "in", "a", "given", "dataset", ".", "Center", ":", "full", "neural", "statistician", "model", "with", "three", "latent", "layers", ".", "Each", "collection", "of", "incoming", "edges", "to", "a", "node", "is", "implemented", "as", "a", "neural", "network", ",", "the", "input", "of", "which", "is", "the", "concatenation", "of", "the", "edges", "\u2019", "sources", ",", "the", "output", "of", "which", "is", "a", "parameterization", "of", "a", "distribution", "over", "the", "random", "variable", "represented", "by", "that", "node", ".", "Right", ":", "The", "statistic", "network", ",", "which", "combines", "the", "data", "via", "an", "exchangeable", "statistic", "layer", ".", "subsection", ":", "Variational", "Autoencoder", "The", "variational", "autoencoder", "is", "a", "latent", "variable", "model", "(", "often", "called", "the", "decoder", ")", "with", "parameters", ".", "For", "each", "observed", ",", "a", "corresponding", "latent", "variable", "is", "drawn", "from", "so", "that", "The", "generative", "parameters", "are", "learned", "by", "introducing", "a", "recognition", "network", "(", "also", "called", "an", "encoder", ")", "with", "parameters", ".", "The", "recognition", "network", "gives", "an", "approximate", "posterior", "over", "the", "latent", "variables", "that", "can", "then", "be", "used", "to", "give", "the", "standard", "variational", "lower", "bound", "saul_variational", "on", "the", "single", "-", "datum", "log", "-", "likelihood", ".", "I.e.", ",", "where", "Likewise", "the", "full", "-", "data", "log", "likelihood", "is", "lower", "bounded", "by", "the", "sum", "of", "the", "terms", "over", "the", "whole", "dataset", ".", "We", "can", "then", "optimize", "this", "lower", "bound", "with", "respect", "to", "and", "using", "the", "reparameterization", "trick", "introduced", "by", "variational_autoencoder", "and", "reparam_paper", "to", "get", "a", "Monte", "-", "Carlo", "estimate", "of", "the", "gradient", ".", "subsection", ":", "Basic", "Model", "We", "extend", "the", "variational", "autoencoder", "to", "the", "model", "depicted", "on", "the", "left", "in", "Figure", "[", "reference", "]", ".", "This", "includes", "a", "latent", "variable", ",", "the", "context", ",", "that", "varies", "between", "different", "datasets", "but", "is", "constant", ",", "a", "priori", ",", "for", "items", "within", "the", "same", "dataset", ".", "Now", ",", "the", "likelihood", "of", "the", "parameters", "for", "one", "single", "particular", "dataset", "is", "given", "by", "The", "prior", "is", "chosen", "to", "be", "a", "spherical", "Gaussian", "with", "zero", "mean", "and", "unit", "variance", ".", "The", "conditional", "is", "Gaussian", "with", "diagonal", "covariance", ",", "where", "all", "the", "mean", "and", "variance", "parameters", "depend", "on", "through", "a", "neural", "network", ".", "Similarly", "the", "observation", "model", "will", "be", "a", "simple", "likelihood", "function", "appropriate", "to", "the", "data", "modality", "with", "dependence", "on", "parameterized", "by", "a", "neural", "network", ".", "For", "example", ",", "with", "real", "valued", "data", ",", "a", "diagonal", "Gaussian", "likelihood", "could", "be", "used", "where", "the", "mean", "and", "log", "variance", "of", "are", "created", "from", "via", "a", "neural", "network", ".", "We", "use", "approximate", "inference", "networks", ",", ",", "with", "parameters", "collected", "into", ",", "to", "once", "again", "enable", "the", "calculation", "and", "optimization", "of", "a", "variational", "lower", "bound", "on", "the", "log", "-", "likelihood", ".", "The", "single", "dataset", "log", "likelihood", "lower", "bound", "is", "given", "by", "As", "with", "the", "generative", "distributions", ",", "the", "likelihood", "forms", "for", "and", "are", "diagonal", "Gaussian", "distributions", ",", "where", "all", "the", "mean", "and", "log", "variance", "parameters", "in", "each", "distribution", "are", "produced", "by", "a", "neural", "network", "taking", "the", "conditioning", "variables", "as", "inputs", ".", "Note", "that", "accepts", "as", "input", "a", "dataset", "and", "we", "refer", "to", "this", "as", "the", "statistic", "network", ".", "We", "describe", "this", "in", "Subsection", "[", "reference", "]", ".", "The", "full", "-", "data", "variational", "bound", "is", "given", "by", "summing", "the", "variational", "bound", "for", "each", "dataset", "in", "our", "collection", "of", "datasets", ".", "It", "is", "by", "learning", "the", "difference", "of", "the", "within", "-", "dataset", "and", "between", "-", "dataset", "distributions", "that", "we", "are", "able", "to", "discover", "an", "appropriate", "statistic", "network", ".", "subsection", ":", "Full", "Model", "The", "basic", "model", "works", "well", "for", "modelling", "simple", "datasets", ",", "but", "struggles", "when", "the", "datasets", "have", "complex", "internal", "structure", ".", "To", "increase", "the", "sophistication", "of", "the", "model", "we", "use", "multiple", "stochastic", "layers", "and", "introduce", "skip", "-", "connections", "for", "both", "the", "inference", "and", "generative", "networks", ".", "The", "generative", "model", "is", "shown", "graphically", "in", "Figure", "[", "reference", "]", "in", "the", "center", ".", "The", "probability", "of", "a", "dataset", "is", "then", "given", "by", "where", "the", "are", "again", "Gaussian", "distributions", "where", "the", "mean", "and", "log", "variance", "are", "given", "as", "the", "output", "of", "neural", "networks", ".", "The", "generative", "process", "for", "the", "full", "model", "is", "described", "in", "Algorithm", "[", "reference", "]", ".", "The", "full", "approximate", "posterior", "factorizes", "analogously", "as", "For", "convenience", "we", "give", "the", "variational", "lower", "bound", "as", "sum", "of", "a", "three", "parts", ",", "a", "reconstruction", "term", ",", "a", "context", "divergence", "and", "a", "latent", "divergence", ":", "The", "skip", "-", "connections", "and", "allow", "the", "context", "to", "specify", "a", "more", "precise", "distribution", "for", "each", "latent", "variable", "by", "explaining", "-", "away", "more", "generic", "aspects", "of", "the", "dataset", "at", "each", "stochastic", "layer", ".", "This", "architecture", "was", "inspired", "by", "recent", "work", "on", "probabilistic", "ladder", "networks", "in", "prob_ladder", ".", "Complementing", "these", "are", "the", "skip", "-", "connections", "from", "each", "latent", "variable", "to", "the", "observation", ",", "the", "intuition", "here", "is", "that", "each", "stochastic", "layer", "can", "focus", "on", "representing", "a", "certain", "level", "of", "abstraction", ",", "since", "its", "information", "does", "not", "need", "to", "be", "copied", "into", "the", "next", "layer", ",", "a", "similar", "approach", "was", "used", "in", "auxiliary_ladder", ".", "Once", "again", ",", "note", "that", "we", "are", "maximizing", "the", "lower", "bound", "to", "the", "log", "likelihood", "over", "many", "datasets", ":", "we", "want", "to", "maximize", "the", "expectation", "of", "over", "all", "datasets", ".", "We", "do", "this", "optimization", "using", "stochastic", "gradient", "descent", ".", "In", "contrast", "to", "a", "variational", "autoencoder", "where", "a", "minibatch", "would", "consist", "of", "a", "subsample", "of", "datapoints", "from", "the", "dataset", ",", "we", "use", "minibatches", "consisting", "of", "a", "subsample", "of", "datasets", "-", "tensors", "of", "shape", "(", "batch", "size", ",", "sample", "size", ",", "number", "of", "features", ")", ".", "subsection", ":", "Statistic", "Network", "In", "addition", "to", "the", "standard", "inference", "networks", "we", "require", "a", "statistic", "network", "to", "give", "an", "approximate", "posterior", "over", "the", "context", "given", "a", "dataset", ".", "This", "inference", "network", "must", "capture", "the", "exchangeability", "of", "the", "data", "in", ".", "We", "use", "a", "feedforward", "neural", "network", "consisting", "of", "three", "main", "elements", ":", "An", "instance", "encoder", "that", "takes", "each", "individual", "datapoint", "to", "a", "vector", ".", "An", "exchangeable", "instance", "pooling", "layer", "that", "collapses", "the", "matrix", "to", "a", "single", "pre", "-", "statistic", "vector", ".", "Examples", "include", "elementwise", "means", ",", "sums", ",", "products", ",", "geometric", "means", "and", "maximum", ".", "We", "use", "the", "sample", "mean", "for", "all", "experiments", ".", "A", "final", "post", "-", "pooling", "network", "that", "takes", "to", "a", "parameterization", "of", "a", "diagonal", "Gaussian", ".", "The", "graphical", "model", "for", "this", "is", "given", "at", "the", "right", "of", "Figure", "[", "reference", "]", ".", "We", "note", "that", "the", "humble", "sample", "mean", "already", "gives", "the", "statistic", "network", "a", "great", "deal", "of", "representational", "power", "due", "to", "the", "fact", "that", "the", "instance", "encoder", "can", "learn", "a", "representation", "where", "averaging", "makes", "sense", ".", "For", "example", "since", "the", "instance", "encoder", "can", "approximate", "a", "polynomial", "on", "a", "compact", "domain", ",", "and", "so", "can", "the", "post", "-", "pooling", "network", ",", "a", "statistic", "network", "can", "approximate", "any", "moment", "of", "a", "distribution", ".", "section", ":", "Related", "Work", "Due", "to", "the", "general", "nature", "of", "the", "problem", "considered", ",", "our", "work", "touches", "on", "many", "different", "topics", "which", "we", "now", "attempt", "to", "summarize", ".", "paragraph", ":", "Topic", "models", "and", "graphical", "models", "The", "form", "of", "the", "graphical", "model", "in", "Figure", "[", "reference", "]", "on", "the", "left", "is", "equivalent", "to", "that", "of", "a", "standard", "topic", "model", ".", "In", "contrast", "to", "traditional", "topic", "models", "we", "do", "not", "use", "discrete", "latent", "variables", ",", "or", "restrict", "to", "discrete", "data", ".", "Work", "such", "as", "that", "by", "has", "extended", "topic", "models", "in", "various", "directions", ",", "but", "importantly", "we", "use", "flexible", "conditional", "distributions", "and", "dependency", "structures", "parameterized", "by", "deep", "neural", "networks", ".", "Recent", "work", "has", "explored", "neural", "networks", "for", "document", "models", "[", "see", "e.g.", "][]", "neural_variational_text", "but", "has", "been", "limited", "to", "modelling", "datapoints", "with", "little", "internal", "structure", ".", "Along", "related", "lines", "are", "\u2018", "structured", "variational", "autoencoders", "\u2019", "[", "see", "][]", "structured_vae", ",", "where", "they", "treat", "the", "general", "problem", "of", "integrating", "graphical", "models", "with", "variational", "autoencoders", ".", "paragraph", ":", "Transfer", "learning", "There", "is", "a", "considerable", "literature", "on", "transfer", "learning", ",", "for", "a", "survey", "see", "transfer_survey", ".", "There", "they", "discuss", "\u2018", "parameter", "-", "transfer", "\u2019", "approaches", "whereby", "parameters", "or", "priors", "are", "shared", "across", "datasets", ",", "and", "our", "work", "fits", "into", "that", "paradigm", ".", "For", "examples", "see", "informative_vector_machine", "where", "share", "they", "priors", "between", "Gaussian", "processes", ",", "and", "multitask_svm", "where", "they", "take", "an", "SVM", "-", "like", "approach", "to", "share", "kernels", ".", "paragraph", ":", "One", "-", "shot", "Learning", "Learning", "quickly", "from", "small", "amounts", "of", "data", "is", "a", "topic", "of", "great", "interest", ".", "omniglot", "use", "Bayesian", "program", "induction", "for", "one", "-", "shot", "generation", "and", "classification", ",", "and", "train", "a", "Siamese", "(", ")", "convolutional", "network", "for", "one", "-", "shot", "image", "classification", ".", "We", "note", "the", "relation", "to", "the", "recent", "work", "one_shot_generative", "in", "which", "the", "authors", "use", "a", "conditional", "recurrent", "variational", "autoencoder", "capable", "of", "one", "-", "shot", "generalization", "by", "taking", "as", "extra", "input", "a", "conditioning", "data", "point", ".", "The", "important", "differences", "here", "are", "that", "we", "jointly", "model", "datasets", "and", "datapoints", "and", "consider", "datasets", "of", "any", "size", ".", "Recent", "approaches", "to", "one", "-", "shot", "classification", "are", "matching", "networks", "matching", "(", "which", "was", "concurrent", "with", "the", "initial", "preprint", "of", "this", "work", ")", ",", "and", "related", "previous", "work", "mann", ".", "The", "former", "can", "be", "considered", "a", "kind", "of", "differentiable", "nearest", "neighbour", "classifier", ",", "and", "the", "latter", "augments", "their", "network", "with", "memory", "to", "store", "information", "about", "the", "classification", "problem", ".", "Both", "are", "trained", "end", "-", "to", "-", "end", "for", "the", "classification", "problem", ",", "whereas", "the", "present", "work", "is", "a", "general", "approach", "to", "learning", "representations", "of", "datasets", ".", "Probably", "the", "closest", "previous", "work", "is", "by", "where", "the", "authors", "learn", "a", "topic", "model", "over", "the", "activations", "of", "a", "DBM", "for", "one", "-", "shot", "learning", ".", "Compared", "with", "their", "work", "we", "use", "modern", "architectures", "and", "easier", "to", "train", "VAEs", ",", "in", "particular", "we", "have", "fast", "and", "amortized", "feedforward", "inference", "for", "test", "(", "and", "training", ")", "datasets", ",", "avoiding", "the", "need", "for", "MCMC", ".", "paragraph", ":", "Multiple", "-", "Instance", "Learning", "There", "is", "previous", "work", "on", "classifying", "sets", "in", "multiple", "-", "instance", "learning", ",", "for", "a", "useful", "survey", "see", "classification_with_sets", ".", "Typical", "approaches", "involve", "adapting", "kernel", "based", "methods", "such", "as", "support", "measure", "machines", "support_measure_machines", ",", "support", "distribution", "machines", "support_distribution_machines", "and", "multiple", "-", "instance", "-", "kernels", "multiple_instance_kernels", ".", "We", "do", "not", "consider", "applications", "to", "multiple", "-", "instance", "learning", "type", "problems", "here", ",", "but", "it", "may", "be", "fruitful", "to", "do", "so", "in", "the", "future", ".", "paragraph", ":", "Set2Seq", "In", "very", "related", "work", ",", "set2seq", "explore", "architectures", "for", "mapping", "sets", "to", "sequences", ".", "There", "they", "use", "an", "LSTM", "to", "repeatedly", "compute", "weighted", "-", "averages", "of", "the", "datapoints", "and", "use", "this", "to", "tackle", "problems", "such", "as", "sorting", "a", "list", "of", "numbers", ".", "The", "main", "difference", "between", "their", "work", "and", "ours", "is", "that", "they", "primarily", "consider", "supervised", "problems", ",", "whereas", "we", "present", "a", "general", "unsupervised", "method", "for", "learning", "representations", "of", "sets", "of", "i.i.d", "instances", ".", "In", "future", "work", "we", "may", "also", "explore", "recurrently", "computing", "statistics", ".", "paragraph", ":", "ABC", "There", "has", "also", "been", "work", "on", "learning", "summary", "statistics", "for", "Approximate", "Bayesian", "Computation", "by", "either", "learning", "to", "predict", "the", "parameters", "generating", "a", "sample", "as", "a", "supervised", "problem", ",", "or", "by", "using", "kernel", "embeddings", "as", "infinite", "dimensional", "summary", "statistics", ".", "See", "the", "work", "by", "kernel_bayes", "for", "an", "example", "of", "kernel", "-", "based", "approaches", ".", "More", "recently", "deep_summary_statistics", "used", "deep", "neural", "networks", "to", "predict", "the", "parameters", "generating", "the", "data", ".", "The", "crucial", "differences", "are", "that", "their", "problem", "is", "supervised", ",", "they", "do", "not", "leverage", "any", "exchangeability", "properties", "the", "data", "may", "have", ",", "nor", "can", "it", "deal", "with", "varying", "sample", "sizes", ".", "section", ":", "Experimental", "Results", "Given", "an", "input", "set", "we", "can", "use", "the", "statistic", "network", "to", "calculate", "an", "approximate", "posterior", "over", "contexts", ".", "Under", "the", "generative", "model", ",", "each", "context", "specifies", "a", "conditional", "model", ".", "To", "get", "samples", "from", "the", "model", "corresponding", "to", "the", "most", "likely", "posterior", "value", "of", ",", "we", "set", "to", "the", "mean", "of", "the", "approximate", "posterior", "and", "then", "sample", "directly", "from", "the", "conditional", "distributions", ".", "This", "is", "described", "in", "Algorithm", "[", "reference", "]", ".", "We", "use", "this", "process", "in", "our", "experiments", "to", "show", "samples", ".", "In", "all", "experiments", ",", "we", "use", "the", "Adam", "optimization", "algorithm", "adam", "to", "optimize", "the", "parameters", "of", "the", "generative", "models", "and", "variational", "approximations", ".", "Batch", "normalization", "batchnorm", "is", "implemented", "for", "convolutional", "layers", "and", "we", "always", "use", "a", "batch", "size", "of", ".", "We", "primarily", "use", "the", "Theano", "theano", "framework", "with", "the", "Lasagne", "lasagne", "library", ",", "but", "the", "final", "experiments", "with", "face", "data", "were", "done", "using", "Tensorflow", "tensorflow", ".", "In", "all", "cases", "experiments", "were", "terminated", "after", "a", "given", "number", "of", "epochs", "when", "training", "appeared", "to", "have", "sufficiently", "converged", "(", "epochs", "for", "omniglot", ",", "youtube", "and", "spatial", "MNIST", "examples", ",", "and", "epochs", "for", "the", "synthetic", "experiment", ")", ".", "subsection", ":", "Simple", "1", "-", "D", "Distributions", "In", "our", "first", "experiment", "we", "wanted", "to", "know", "if", "the", "neural", "statistician", "will", "learn", "to", "cluster", "synthetic", "-", "D", "datasets", "by", "distribution", "family", ".", "We", "generated", "a", "collection", "of", "synthetic", "-", "D", "datasets", "each", "containing", "samples", ".", "Datasets", "consist", "of", "samples", "from", "either", "an", "Exponential", ",", "Gaussian", ",", "Uniform", "or", "Laplacian", "distribution", "with", "equal", "probability", ".", "Means", "and", "variances", "are", "sampled", "from", "and", "respectively", ".", "The", "training", "data", "contains", "sets", ".", "The", "architecture", "for", "this", "experiment", "contains", "a", "single", "stochastic", "layer", "with", "units", "for", "and", "units", "for", ",", ".", "The", "model", "and", "variational", "approximation", "are", "each", "a", "diagonal", "Gaussian", "distribution", "with", "all", "mean", "and", "log", "variance", "parameters", "given", "by", "a", "network", "composed", "of", "three", "dense", "layers", "with", "ReLU", "activations", "and", "units", ".", "The", "statistic", "network", "determining", "the", "mean", "and", "log", "variance", "parameters", "of", "posterior", "over", "context", "variables", "is", "composed", "of", "three", "dense", "layers", "before", "and", "after", "pooling", ",", "each", "with", "units", "with", "Rectified", "Linear", "Unit", "(", "ReLU", ")", "activations", ".", "Figure", "[", "reference", "]", "shows", "3", "-", "D", "scatter", "plots", "of", "the", "summary", "statistics", "learned", ".", "Notice", "that", "the", "different", "families", "of", "distribution", "cluster", ".", "It", "is", "interesting", "to", "observe", "that", "the", "Exponential", "cluster", "is", "differently", "orientated", "to", "the", "others", ",", "perhaps", "reflecting", "the", "fact", "that", "it", "is", "the", "only", "non", "-", "symmetric", "distribution", ".", "We", "also", "see", "that", "between", "the", "Gaussian", "and", "Laplacian", "clusters", "there", "is", "an", "area", "of", "ambiguity", "which", "is", "as", "one", "might", "expect", ".", "We", "also", "see", "that", "within", "each", "cluster", "the", "mean", "and", "variance", "are", "mapped", "to", "orthogonal", "directions", ".", "subsection", ":", "Spatial", "MNIST", "Building", "on", "the", "previous", "experiments", "we", "investigate", "2", "-", "D", "datasets", "that", "have", "complex", "structure", ",", "but", "the", "datapoints", "contain", "little", "information", "by", "themselves", ",", "making", "it", "a", "good", "test", "of", "the", "statistic", "network", ".", "We", "created", "a", "dataset", "called", "spatial", "MNIST", ".", "In", "spatial", "MNIST", "each", "image", "from", "MNIST", "mnist", "is", "turned", "into", "a", "dataset", "by", "interpreting", "the", "normalized", "pixel", "intensities", "as", "a", "probability", "density", "and", "sampling", "coordinate", "values", ".", "An", "example", "is", "shown", "in", "Figure", "[", "reference", "]", ".", "This", "creates", "two", "-", "dimensional", "spatial", "datasets", ".", "We", "used", "a", "sample", "size", "of", ".", "Note", "that", "since", "the", "pixel", "coordinates", "are", "discrete", ",", "it", "is", "necessary", "to", "dequantize", "them", "by", "adding", "uniform", "noise", "to", "the", "coordinates", "if", "one", "models", "them", "as", "real", "numbers", ",", "else", "you", "can", "get", "arbitrarily", "high", "densities", "(", "see", "note_evaluation_generative", "for", "a", "discussion", "of", "this", "point", ")", ".", "The", "generative", "architecture", "for", "this", "experiment", "contains", "stochastic", "layers", ",", "each", "with", "units", ",", "and", "a", "single", "layer", "with", "units", ".", "The", "means", "and", "log", "variances", "of", "the", "Gaussian", "likelihood", "for", ",", "and", "each", "subnetwork", "for", "in", "both", "the", "encoder", "and", "decoder", "contained", "dense", "layers", "with", "ReLU", "units", "each", ".", "The", "statistic", "network", "also", "contained", "3", "dense", "layers", "pre", "-", "pooling", "and", "3", "dense", "layers", "post", "pooling", "with", "256", "ReLU", "units", ".", "In", "addition", "to", "being", "able", "to", "sample", "from", "the", "model", "conditioned", "on", "a", "set", "of", "inputs", ",", "we", "can", "also", "summarize", "a", "dataset", "by", "choosing", "a", "subset", "to", "minimise", "the", "KL", "divergence", "of", "from", ".", "We", "do", "this", "greedily", "by", "iteratively", "discarding", "points", "from", "the", "full", "sample", ".", "Pseudocode", "for", "this", "process", "is", "given", "in", "Algorithm", "[", "reference", "]", ".", "The", "results", "are", "shown", "in", "Figure", "[", "reference", "]", ".", "We", "see", "that", "the", "model", "is", "capable", "of", "handling", "complex", "arrangements", "of", "datapoints", ".", "We", "also", "see", "that", "it", "can", "select", "sensible", "subsets", "of", "a", "dataset", "as", "a", "summary", ".", "subsection", ":", "Omniglot", "Next", "we", "work", "with", "the", "OMNIGLOT", "data", "omniglot", ".", "This", "contains", "1628", "classes", "of", "handwritten", "characters", "but", "with", "just", "20", "examples", "per", "class", ".", "This", "makes", "it", "an", "excellent", "test", "-", "bed", "for", "transfer", "/", "few", "-", "shot", "learning", ".", "We", "constructed", "datasets", "by", "splitting", "each", "class", "into", "datasets", "of", "size", "5", ".", "We", "train", "on", "datasets", "drawn", "from", "1200", "classes", "and", "reserve", "the", "remaining", "classes", "to", "test", "few", "-", "shot", "sampling", "and", "classification", ".", "We", "created", "new", "classes", "by", "rotating", "and", "reflecting", "characters", ".", "We", "resized", "the", "images", "to", ".", "We", "sampled", "a", "binarization", "of", "each", "image", "for", "each", "epoch", ".", "We", "also", "randomly", "applied", "the", "dilation", "operator", "from", "computer", "vision", "as", "further", "data", "augmentation", "since", "we", "observed", "that", "the", "stroke", "widths", "are", "quite", "uniform", "in", "the", "OMNIGLOT", "data", ",", "whereas", "there", "is", "substantial", "variation", "in", "MNIST", ",", "this", "augmentation", "improved", "the", "visual", "quality", "of", "the", "few", "-", "shot", "MNIST", "samples", "considerably", "and", "increased", "the", "few", "-", "shot", "classification", "accuracy", "by", "about", "percent", ".", "Finally", "we", "used", "\u2018", "sample", "dropout", "\u2019", "whereby", "a", "random", "subset", "of", "each", "dataset", "was", "removed", "from", "the", "pooling", "in", "the", "statistic", "network", ",", "and", "then", "included", "the", "number", "of", "samples", "remaining", "as", "an", "extra", "feature", ".", "This", "was", "beneficial", "since", "it", "reduced", "overfitting", "and", "also", "allowed", "the", "statistic", "network", "to", "learn", "to", "adjust", "the", "approximate", "posterior", "over", "based", "on", "the", "number", "of", "samples", ".", "We", "used", "a", "single", "stochastic", "layer", "with", "16", "units", "for", ",", "and", "units", "for", ".", "We", "used", "a", "shared", "convolutional", "encoder", "between", "the", "inference", "and", "statistic", "networks", "and", "a", "deconvolutional", "decoder", "network", ".", "Full", "details", "of", "the", "networks", "are", "given", "in", "Appendix", "[", "reference", "]", ".", "The", "decoder", "used", "a", "Bernoulli", "likelihood", ".", "In", "Figure", "[", "reference", "]", "we", "show", "two", "examples", "of", "few", "-", "shot", "learning", "by", "conditioning", "on", "samples", "of", "unseen", "characters", "from", "OMNIGLOT", ",", "and", "conditioning", "on", "samples", "of", "digits", "from", "MNIST", ".", "The", "samples", "are", "mostly", "of", "a", "high", "-", "quality", ",", "and", "this", "shows", "that", "the", "neural", "statistician", "can", "generalize", "even", "to", "new", "datasets", ".", "As", "a", "further", "test", "we", "considered", "few", "-", "shot", "classification", "of", "both", "unseen", "OMNIGLOT", "characters", "and", "MNIST", "digits", ".", "Given", "a", "sets", "of", "labelled", "examples", "of", "each", "class", "(", "for", "MNIST", "say", ")", ",", "we", "computed", "the", "approximate", "posteriors", "using", "the", "statistic", "network", ".", "Then", "for", "each", "test", "image", "we", "also", "computed", "the", "posterior", "and", "classified", "it", "according", "to", "the", "training", "dataset", "minimizing", "the", "KL", "divergence", "from", "the", "test", "context", "to", "the", "training", "context", ".", "This", "process", "is", "described", "in", "Algorithm", "[", "reference", "]", ".", "We", "tried", "this", "with", "either", "1", "or", "5", "labelled", "examples", "per", "class", "and", "either", "or", "classes", ".", "For", "each", "trial", "we", "randomly", "select", "classes", ",", "randomly", "select", "training", "examples", "for", "each", "class", ",", "and", "test", "on", "the", "remaining", "examples", ".", "This", "process", "is", "repeated", "100", "times", "and", "the", "results", "averaged", ".", "The", "results", "are", "shown", "in", "Table", "[", "reference", "]", ".", "We", "compare", "to", "a", "number", "of", "results", "reported", "in", "matching", "including", "mann", "and", "siamese_one_shot", ".", "Overall", "we", "see", "that", "the", "neural", "statistician", "model", "can", "be", "used", "as", "a", "strong", "classifier", ",", "particularly", "for", "the", "-", "way", "tasks", ",", "but", "performs", "worse", "than", "matching", "networks", "for", "the", "-", "way", "tasks", ".", "One", "important", "advantage", "that", "matching", "networks", "have", "is", "that", ",", "whilst", "each", "class", "is", "processed", "independently", "in", "our", "model", ",", "the", "representation", "in", "matching", "networks", "is", "conditioned", "on", "all", "of", "the", "classes", "in", "the", "few", "-", "shot", "problem", ".", "This", "means", "that", "it", "can", "exaggerate", "differences", "between", "similar", "classes", ",", "which", "are", "more", "likely", "to", "appear", "in", "a", "20", "-", "way", "problem", "than", "a", "5", "-", "way", "problem", ".", "subsection", ":", "Youtube", "Faces", "Finally", ",", "we", "provide", "a", "proof", "of", "concept", "for", "generating", "faces", "of", "a", "particular", "person", ".", "We", "use", "the", "Youtube", "Faces", "Database", "from", "youtube_faces", ".", "It", "contains", "videos", "of", "different", "people", ".", "We", "use", "the", "aligned", "and", "cropped", "to", "face", "version", ",", "resized", "to", ".", "The", "validation", "and", "test", "sets", "contain", "unique", "people", "each", ",", "and", "there", "is", "no", "overlap", "of", "persons", "between", "data", "splits", ".", "The", "sets", "were", "created", "by", "sampling", "frames", "randomly", "without", "replacement", "from", "each", "video", ",", "we", "use", "a", "set", "size", "of", "frames", ".", "We", "resample", "the", "sets", "for", "the", "training", "data", "each", "epoch", ".", "Our", "architecture", "for", "this", "problem", "is", "based", "on", "one", "presented", "in", ".", "We", "used", "a", "single", "stochastic", "layer", "with", "dimensional", "latent", "and", "dimensional", "variable", ".", "The", "statistic", "network", "and", "the", "inference", "network", "share", "a", "common", "convolutional", "encoder", ",", "and", "the", "deocder", "uses", "deconvolutional", "layers", ".", "For", "full", "details", "see", "Appendix", "[", "reference", "]", ".", "The", "likelihood", "function", "is", "a", "Gaussian", ",", "but", "where", "the", "variance", "parameters", "are", "shared", "across", "all", "datapoints", ",", "this", "was", "found", "to", "make", "training", "faster", "and", "more", "stable", ".", "The", "results", "are", "shown", "in", "Figure", "[", "reference", "]", ".", "Whilst", "there", "is", "room", "for", "improvement", ",", "we", "see", "that", "it", "is", "possible", "to", "specify", "a", "complex", "distribution", "on", "-", "the", "-", "fly", "with", "a", "set", "of", "photos", "of", "a", "previously", "unseen", "person", ".", "The", "samples", "conditioned", "on", "an", "input", "set", "have", "a", "reasonable", "likeness", "of", "the", "input", "faces", ".", "We", "also", "show", "the", "ability", "of", "the", "model", "to", "generate", "new", "datasets", "and", "see", "that", "the", "samples", "have", "a", "consistent", "identity", "and", "varied", "poses", ".", "section", ":", "Conclusion", "We", "have", "demonstrated", "a", "highly", "flexible", "model", "on", "a", "variety", "of", "tasks", ".", "Going", "forward", "our", "approach", "will", "naturally", "benefit", "from", "advances", "in", "generative", "models", "as", "we", "can", "simply", "upgrade", "our", "base", "generative", "model", ",", "and", "so", "future", "work", "will", "pursue", "this", ".", "Compared", "with", "some", "other", "approaches", "in", "the", "literature", "for", "few", "-", "shot", "learning", ",", "our", "requirement", "for", "supervision", "is", "weaker", ":", "we", "only", "ask", "at", "training", "time", "that", "we", "are", "given", "datasets", ",", "but", "we", "do", "not", "need", "labels", "for", "the", "datasets", ",", "nor", "even", "information", "on", "whether", "two", "datasets", "represent", "the", "same", "or", "different", "classes", ".", "It", "would", "be", "interesting", "then", "to", "explore", "application", "areas", "where", "only", "this", "weaker", "form", "of", "supervision", "is", "available", ".", "There", "are", "two", "important", "limitations", "to", "this", "work", ",", "firstly", "that", "the", "method", "is", "dataset", "hungry", ":", "it", "will", "likely", "not", "learn", "useful", "representations", "of", "datasets", "given", "only", "a", "small", "number", "of", "them", ".", "Secondly", "at", "test", "time", "the", "few", "-", "shot", "fit", "of", "the", "generative", "model", "will", "not", "be", "greatly", "improved", "by", "using", "larger", "datasets", "unless", "the", "model", "was", "also", "trained", "on", "similarly", "large", "datasets", ".", "The", "latter", "limitation", "seems", "like", "a", "promising", "future", "research", "direction", "-", "bridging", "the", "gap", "between", "fast", "adaptation", "and", "slow", "training", ".", "subsubsection", ":", "Acknowledgments", "This", "work", "was", "supported", "in", "part", "by", "the", "EPSRC", "Centre", "for", "Doctoral", "Training", "in", "Data", "Science", ",", "funded", "by", "the", "UK", "Engineering", "and", "Physical", "Sciences", "Research", "Council", "(", "grant", "EP", "/", "L016427", "/", "1", ")", "and", "the", "University", "of", "Edinburgh", ".", "bibliography", ":", "References", "appendix", ":", "Appendix", "A", ":", "Pseudocode", "[", "H", "]", "Sampling", "a", "dataset", "of", "size", "k", "sample", "to", "sample", "to", "sample", "sample", "[", "H", "]", "Sampling", "a", "dataset", "of", "size", "k", "conditioned", "on", "a", "dataset", "of", "size", "m", "Calculate", "approximate", "posterior", "over", "using", "statistic", "network", ".", "Set", "to", "be", "the", "mean", "of", "the", "approximate", "posterior", ".", "to", "sample", "to", "sample", "sample", "[", "H", "]", "Selecting", "a", "representative", "sample", "of", "size", "k", "Calculate", "approximate", "posterior", "over", "using", "statistic", "network", ".", "to", "[", "H", "]", "K", "-", "way", "few", "-", "shot", "classification", "approximate", "posterior", "over", "given", "query", "point", "to", "appendix", ":", "Appendix", "B", ":", "Further", "Experimental", "Details", "subsection", ":", "Omniglot", "subsection", ":", "Youtube", "faces"]}