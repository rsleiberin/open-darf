{"coref": {"BLEU_score": [[167, 168], [202, 203], [2181, 2182], [2600, 2602], [2744, 2745], [3322, 3323], [3784, 3785], [3798, 3799], [2217, 2218], [3371, 3372], [3377, 3378]], "IWSLT2015_Thai-English": [[1853, 1855], [2451, 2453], [2525, 2529], [2531, 2533], [2943, 2945]], "Machine_Translation": [[7, 10], [11, 12], [19, 20], [69, 70], [87, 88], [207, 210], [211, 213], [221, 222], [564, 567], [571, 572], [593, 594], [637, 638], [902, 904], [1317, 1318], [1350, 1351], [1429, 1430], [1500, 1501], [1543, 1544], [1806, 1807], [2136, 2139], [3633, 3634], [4031, 4034], [4275, 4276], [4313, 4314], [34, 35], [235, 236], [273, 274], [924, 925], [1359, 1360], [2438, 2439], [3420, 3421], [3651, 3652], [3947, 3948]], "Seq-Inter": [[1945, 1949], [2720, 2724], [2725, 2728], [3020, 3024], [3025, 3028], [3283, 3286], [3674, 3677], [2792, 2795], [2866, 2869], [2881, 2884], [3064, 3067], [3070, 3073], [3714, 3717]], "Seq-KD": [[2, 7], [1454, 1459], [2662, 2667], [2668, 2671], [2850, 2853], [2930, 2933], [3005, 3008], [3671, 3674], [2771, 2774], [2949, 2952], [3041, 3044], [3176, 3179], [3217, 3220], [3251, 3254], [3350, 3353], [3360, 3363], [3700, 3703]], "Seq-KD___Seq-Inter___Word-KD": [], "WMT2014_English-German": [[1848, 1850], [2444, 2446], [2456, 2460], [2462, 2464], [2787, 2790], [2937, 2939], [3209, 3211], [980, 982], [3340, 3342], [3561, 3563], [3666, 3668]], "Word-KD": [[1354, 1359], [1459, 1464], [2616, 2621], [2622, 2625], [2850, 2853], [2853, 2856], [2930, 2933], [2989, 2992], [3005, 3008], [3671, 3674], [4301, 4306], [2771, 2774], [2914, 2917], [2949, 2952], [2952, 2955], [3037, 3040], [3041, 3044], [3176, 3179], [3217, 3220], [3251, 3254], [3350, 3353], [3360, 3363], [3700, 3703]]}, "coref_non_salient": {"0": [[94, 98], [4288, 4292]], "1": [[3104, 3105], [3410, 3412]], "10": [[719, 721], [737, 738], [2509, 2510], [4154, 4155]], "100": [[1225, 1229]], "101": [[2225, 2228]], "102": [[1322, 1326]], "103": [[2231, 2233]], "104": [[1061, 1062]], "105": [[215, 220]], "106": [[353, 356]], "107": [[492, 494]], "108": [[1105, 1107]], "109": [[4116, 4117]], "11": [[181, 183], [469, 471], [558, 560], [986, 988], [1044, 1046], [1169, 1171], [1314, 1316], [2146, 2148], [4162, 4164]], "110": [[671, 675]], "111": [[1399, 1400]], "112": [[3466, 3470]], "113": [[79, 83]], "114": [[3960, 3964]], "115": [[333, 337]], "116": [[679, 681]], "117": [[580, 584]], "118": [[870, 875]], "119": [[1785, 1789]], "12": [[1578, 1582], [1918, 1923]], "120": [[4346, 4347]], "121": [[3874, 3878]], "122": [[4081, 4085]], "13": [[2322, 2325], [3268, 3271]], "14": [[2781, 2783], [3706, 3708], [3720, 3722]], "15": [[48, 51], [520, 523], [1332, 1335], [4060, 4063]], "16": [[472, 474], [3972, 3974], [4029, 4030]], "17": [[125, 127], [195, 197], [848, 850], [1379, 1381], [1624, 1626], [1764, 1766], [1877, 1879], [2167, 2169], [2505, 2507], [2573, 2575], [2699, 2701], [3050, 3052], [3435, 3439], [3495, 3497], [3777, 3779], [3815, 3817], [4072, 4074], [4113, 4115]], "18": [[929, 932], [939, 942]], "19": [[1075, 1078], [1902, 1905]], "2": [[172, 174], [698, 700], [803, 805], [1742, 1744], [1760, 1762], [1802, 1805], [1884, 1886], [2195, 2197], [2206, 2208], [2378, 2380], [2688, 2690], [3092, 3094], [3498, 3500]], "20": [[404, 406], [440, 443], [4323, 4326]], "21": [[4252, 4253]], "22": [[1303, 1307], [1548, 1552]], "23": [[4254, 4255]], "24": [[75, 77], [99, 101], [163, 165], [634, 636], [988, 990], [1383, 1385], [3518, 3520], [3754, 3756], [3888, 3890], [4293, 4295]], "25": [[3440, 3441], [3471, 3472]], "26": [[3619, 3621], [3944, 3946]], "27": [[4358, 4360]], "28": [[3993, 3997]], "29": [[291, 294], [318, 321]], "3": [[2753, 2757], [3082, 3086]], "30": [[4196, 4199]], "31": [[541, 544], [1143, 1146], [1204, 1207]], "32": [[176, 178], [829, 831], [3515, 3517], [3627, 3629], [3630, 3632], [3751, 3753]], "33": [[2328, 2330], [2361, 2363]], "34": [[1309, 1311], [1725, 1727]], "35": [[4145, 4146]], "36": [[3697, 3699]], "37": [[4128, 4130]], "38": [[169, 171], [795, 797], [3078, 3080], [3248, 3250], [3491, 3493]], "39": [[2127, 2129], [2150, 2152], [2185, 2187], [4244, 4246]], "4": [[526, 528], [532, 534], [667, 669], [683, 685], [702, 704], [835, 837], [999, 1001], [1009, 1011], [1899, 1901], [3127, 3129], [3837, 3839], [3851, 3853], [4096, 4100]], "40": [[3594, 3597]], "41": [[4257, 4260]], "42": [[4348, 4349]], "43": [[3917, 3920]], "44": [[3108, 3112]], "45": [[4191, 4195]], "46": [[4350, 4351]], "47": [[4171, 4172]], "48": [[4247, 4251]], "49": [[4165, 4167]], "5": [[131, 133], [186, 188], [813, 815], [1479, 1481], [1966, 1968], [2519, 2521], [2587, 2589], [2626, 2627], [2672, 2673], [3486, 3488], [3531, 3533], [3623, 3625], [3765, 3767], [4066, 4068]], "50": [[3911, 3913]], "51": [[4135, 4141]], "52": [[726, 731], [1599, 1604], [1864, 1869], [2924, 2929], [3116, 3121], [3403, 3408], [4210, 4215]], "53": [[1165, 1167]], "54": [[428, 429], [4182, 4183]], "55": [[4150, 4151]], "56": [[4271, 4274]], "57": [[3565, 3567]], "58": [[1110, 1111]], "59": [[4361, 4363]], "6": [[1437, 1442], [3826, 3831]], "60": [[2873, 2875], [3193, 3195]], "61": [[295, 297]], "62": [[60, 62]], "63": [[314, 316]], "64": [[25, 27], [232, 234]], "65": [[4201, 4203]], "66": [[4156, 4158], [4365, 4367]], "67": [[488, 489]], "68": [[1777, 1779]], "69": [[1086, 1090]], "7": [[407, 409], [4382, 4384]], "70": [[4352, 4357]], "71": [[537, 538]], "72": [[3336, 3337]], "73": [[2110, 2114]], "74": [[964, 966]], "75": [[464, 465]], "76": [[1619, 1621]], "77": [[418, 421]], "78": [[1386, 1392]], "79": [[1583, 1587]], "8": [[375, 379], [586, 591], [601, 605]], "80": [[453, 455]], "81": [[2173, 2176]], "82": [[1634, 1636]], "83": [[2049, 2051]], "84": [[2133, 2135]], "85": [[4175, 4178]], "86": [[444, 448]], "87": [[2763, 2765]], "88": [[368, 374]], "89": [[2178, 2180]], "9": [[3385, 3389], [3589, 3592]], "90": [[253, 256]], "91": [[2009, 2011]], "92": [[1572, 1576]], "93": [[3936, 3940]], "94": [[4329, 4335]], "95": [[3390, 3392]], "96": [[425, 427]], "97": [[3383, 3385]], "98": [[2962, 2964]], "99": [[4004, 4008]]}, "doc_id": "32a93598e8a338496f04a0ace81b0768c2ef059d", "method_subrelations": {"Seq-KD___Seq-Inter___Word-KD": [[[0, 6], "Seq-KD"], [[9, 18], "Seq-Inter"], [[21, 28], "Word-KD"]]}, "n_ary_relations": [{"Material": "IWSLT2015_Thai-English", "Method": "Seq-KD___Seq-Inter___Word-KD", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "14.2"}, {"Material": "WMT2014_English-German", "Method": "Seq-KD___Seq-Inter___Word-KD", "Metric": "BLEU_score", "Task": "Machine_Translation", "score": "18.5"}], "ner": [[2, 7, "Method"], [7, 10, "Task"], [11, 12, "Task"], [19, 20, "Task"], [25, 27, "Method"], [48, 51, "Method"], [60, 62, "Method"], [69, 70, "Task"], [75, 77, "Method"], [79, 83, "Task"], [87, 88, "Task"], [94, 98, "Method"], [99, 101, "Method"], [125, 127, "Method"], [131, 133, "Method"], [163, 165, "Method"], [167, 168, "Metric"], [169, 171, "Method"], [172, 174, "Method"], [176, 178, "Method"], [181, 183, "Task"], [186, 188, "Method"], [195, 197, "Method"], [202, 203, "Metric"], [207, 210, "Task"], [211, 213, "Task"], [215, 220, "Method"], [221, 222, "Task"], [232, 234, "Method"], [253, 256, "Method"], [291, 294, "Method"], [295, 297, "Method"], [314, 316, "Material"], [318, 321, "Method"], [333, 337, "Method"], [353, 356, "Task"], [368, 374, "Method"], [375, 379, "Task"], [404, 406, "Method"], [407, 409, "Method"], [418, 421, "Method"], [425, 427, "Task"], [428, 429, "Task"], [440, 443, "Method"], [444, 448, "Task"], [453, 455, "Method"], [464, 465, "Task"], [469, 471, "Task"], [472, 474, "Method"], [488, 489, "Method"], [492, 494, "Method"], [520, 523, "Method"], [526, 528, "Method"], [532, 534, "Method"], [537, 538, "Metric"], [541, 544, "Metric"], [558, 560, "Task"], [564, 567, "Task"], [571, 572, "Task"], [580, 584, "Method"], [586, 591, "Task"], [593, 594, "Task"], [601, 605, "Task"], [634, 636, "Method"], [637, 638, "Task"], [667, 669, "Method"], [671, 675, "Method"], [679, 681, "Method"], [683, 685, "Method"], [698, 700, "Method"], [702, 704, "Method"], [719, 721, "Method"], [726, 731, "Method"], [737, 738, "Method"], [795, 797, "Method"], [803, 805, "Method"], [813, 815, "Method"], [829, 831, "Method"], [835, 837, "Method"], [848, 850, "Method"], [870, 875, "Task"], [902, 904, "Task"], [929, 932, "Method"], [939, 942, "Method"], [964, 966, "Method"], [986, 988, "Task"], [988, 990, "Method"], [999, 1001, "Method"], [1009, 1011, "Method"], [1044, 1046, "Task"], [1061, 1062, "Task"], [1075, 1078, "Method"], [1086, 1090, "Method"], [1105, 1107, "Metric"], [1110, 1111, "Method"], [1143, 1146, "Metric"], [1165, 1167, "Method"], [1169, 1171, "Task"], [1204, 1207, "Metric"], [1225, 1229, "Method"], [1303, 1307, "Method"], [1309, 1311, "Method"], [1314, 1316, "Task"], [1317, 1318, "Task"], [1322, 1326, "Method"], [1332, 1335, "Method"], [1350, 1351, "Task"], [1354, 1359, "Method"], [1379, 1381, "Method"], [1383, 1385, "Method"], [1386, 1392, "Task"], [1399, 1400, "Method"], [1429, 1430, "Task"], [1437, 1442, "Task"], [1454, 1459, "Method"], [1459, 1464, "Method"], [1479, 1481, "Method"], [1500, 1501, "Task"], [1543, 1544, "Task"], [1548, 1552, "Method"], [1572, 1576, "Method"], [1578, 1582, "Method"], [1583, 1587, "Method"], [1599, 1604, "Method"], [1619, 1621, "Method"], [1624, 1626, "Method"], [1634, 1636, "Method"], [1725, 1727, "Method"], [1742, 1744, "Method"], [1760, 1762, "Method"], [1764, 1766, "Method"], [1777, 1779, "Task"], [1785, 1789, "Method"], [1802, 1805, "Method"], [1806, 1807, "Task"], [1848, 1850, "Material"], [1853, 1855, "Material"], [1864, 1869, "Method"], [1877, 1879, "Method"], [1884, 1886, "Method"], [1899, 1901, "Method"], [1902, 1905, "Method"], [1918, 1923, "Method"], [1945, 1949, "Method"], [1966, 1968, "Method"], [2009, 2011, "Method"], [2049, 2051, "Method"], [2110, 2114, "Method"], [2127, 2129, "Method"], [2133, 2135, "Task"], [2136, 2139, "Task"], [2146, 2148, "Task"], [2150, 2152, "Method"], [2167, 2169, "Method"], [2173, 2176, "Metric"], [2178, 2180, "Metric"], [2181, 2182, "Metric"], [2185, 2187, "Method"], [2195, 2197, "Method"], [2206, 2208, "Method"], [2225, 2228, "Task"], [2231, 2233, "Method"], [2322, 2325, "Method"], [2328, 2330, "Method"], [2361, 2363, "Method"], [2378, 2380, "Method"], [2444, 2446, "Material"], [2451, 2453, "Material"], [2456, 2460, "Material"], [2462, 2464, "Material"], [2505, 2507, "Method"], [2509, 2510, "Method"], [2519, 2521, "Method"], [2525, 2529, "Material"], [2531, 2533, "Material"], [2573, 2575, "Method"], [2587, 2589, "Method"], [2600, 2602, "Metric"], [2616, 2621, "Method"], [2622, 2625, "Method"], [2626, 2627, "Method"], [2662, 2667, "Method"], [2668, 2671, "Method"], [2672, 2673, "Method"], [2688, 2690, "Method"], [2699, 2701, "Method"], [2720, 2724, "Method"], [2725, 2728, "Method"], [2744, 2745, "Metric"], [2753, 2757, "Method"], [2763, 2765, "Method"], [2781, 2783, "Metric"], [2787, 2790, "Material"], [2850, 2853, "Method"], [2853, 2856, "Method"], [2873, 2875, "Method"], [2924, 2929, "Method"], [2930, 2933, "Method"], [2937, 2939, "Material"], [2943, 2945, "Material"], [2962, 2964, "Method"], [2989, 2992, "Method"], [3005, 3008, "Method"], [3020, 3024, "Method"], [3025, 3028, "Method"], [3050, 3052, "Method"], [3078, 3080, "Method"], [3082, 3086, "Method"], [3092, 3094, "Method"], [3104, 3105, "Task"], [3108, 3112, "Method"], [3116, 3121, "Method"], [3127, 3129, "Method"], [3193, 3195, "Method"], [3209, 3211, "Material"], [3248, 3250, "Method"], [3268, 3271, "Method"], [3283, 3286, "Method"], [3322, 3323, "Metric"], [3336, 3337, "Metric"], [3383, 3385, "Metric"], [3385, 3389, "Metric"], [3390, 3392, "Task"], [3403, 3408, "Method"], [3410, 3412, "Task"], [3435, 3439, "Method"], [3440, 3441, "Method"], [3466, 3470, "Method"], [3471, 3472, "Method"], [3486, 3488, "Method"], [3491, 3493, "Method"], [3495, 3497, "Method"], [3498, 3500, "Method"], [3515, 3517, "Method"], [3518, 3520, "Method"], [3531, 3533, "Method"], [3565, 3567, "Method"], [3589, 3592, "Metric"], [3594, 3597, "Method"], [3619, 3621, "Metric"], [3623, 3625, "Method"], [3627, 3629, "Method"], [3630, 3632, "Method"], [3633, 3634, "Task"], [3671, 3674, "Method"], [3674, 3677, "Method"], [3697, 3699, "Method"], [3706, 3708, "Metric"], [3720, 3722, "Metric"], [3751, 3753, "Method"], [3754, 3756, "Method"], [3765, 3767, "Method"], [3777, 3779, "Method"], [3784, 3785, "Metric"], [3798, 3799, "Metric"], [3815, 3817, "Method"], [3826, 3831, "Task"], [3837, 3839, "Method"], [3851, 3853, "Method"], [3874, 3878, "Method"], [3888, 3890, "Method"], [3911, 3913, "Method"], [3917, 3920, "Method"], [3936, 3940, "Method"], [3944, 3946, "Metric"], [3960, 3964, "Method"], [3972, 3974, "Method"], [3993, 3997, "Method"], [4004, 4008, "Method"], [4029, 4030, "Method"], [4031, 4034, "Task"], [4060, 4063, "Method"], [4066, 4068, "Method"], [4072, 4074, "Method"], [4081, 4085, "Method"], [4096, 4100, "Method"], [4113, 4115, "Method"], [4116, 4117, "Method"], [4128, 4130, "Method"], [4135, 4141, "Method"], [4145, 4146, "Method"], [4150, 4151, "Method"], [4154, 4155, "Method"], [4156, 4158, "Task"], [4162, 4164, "Task"], [4165, 4167, "Task"], [4171, 4172, "Method"], [4175, 4178, "Method"], [4182, 4183, "Task"], [4191, 4195, "Method"], [4196, 4199, "Method"], [4201, 4203, "Method"], [4210, 4215, "Method"], [4244, 4246, "Method"], [4247, 4251, "Method"], [4252, 4253, "Method"], [4254, 4255, "Method"], [4257, 4260, "Method"], [4271, 4274, "Method"], [4275, 4276, "Task"], [4288, 4292, "Method"], [4293, 4295, "Method"], [4301, 4306, "Method"], [4313, 4314, "Task"], [4323, 4326, "Method"], [4329, 4335, "Method"], [4346, 4347, "Task"], [4348, 4349, "Task"], [4350, 4351, "Task"], [4352, 4357, "Task"], [4358, 4360, "Task"], [4361, 4363, "Task"], [4365, 4367, "Task"], [4382, 4384, "Method"], [34, 35, "Task"], [235, 236, "Task"], [273, 274, "Task"], [924, 925, "Task"], [980, 982, "Material"], [1359, 1360, "Task"], [2217, 2218, "Metric"], [2438, 2439, "Task"], [2771, 2774, "Method"], [2792, 2795, "Method"], [2866, 2869, "Method"], [2881, 2884, "Method"], [2914, 2917, "Method"], [2949, 2952, "Method"], [2952, 2955, "Method"], [3037, 3040, "Method"], [3041, 3044, "Method"], [3064, 3067, "Method"], [3070, 3073, "Method"], [3176, 3179, "Method"], [3217, 3220, "Method"], [3251, 3254, "Method"], [3340, 3342, "Material"], [3350, 3353, "Method"], [3360, 3363, "Method"], [3371, 3372, "Metric"], [3377, 3378, "Metric"], [3420, 3421, "Task"], [3561, 3563, "Material"], [3651, 3652, "Task"], [3666, 3668, "Material"], [3700, 3703, "Method"], [3714, 3717, "Method"], [3947, 3948, "Task"]], "sections": [[0, 204], [204, 865], [865, 868], [868, 984], [984, 1312], [1312, 1352], [1352, 1452], [1452, 1943], [1943, 2423], [2423, 2614], [2614, 2660], [2660, 2718], [2718, 2889], [2889, 3381], [3381, 3513], [3513, 3818], [3818, 3956], [3956, 4261], [4261, 4388], [4388, 4391]], "sentences": [[0, 7], [7, 28], [28, 42], [42, 71], [71, 129], [129, 152], [152, 175], [175, 204], [204, 207], [207, 235], [235, 266], [266, 303], [303, 326], [326, 350], [350, 380], [380, 402], [402, 417], [417, 452], [452, 472], [472, 520], [520, 552], [552, 568], [568, 592], [592, 624], [624, 670], [670, 705], [705, 748], [748, 763], [763, 787], [787, 812], [812, 825], [825, 851], [851, 865], [865, 868], [868, 877], [877, 902], [902, 924], [924, 961], [961, 984], [984, 988], [988, 1023], [1023, 1044], [1044, 1057], [1057, 1060], [1060, 1079], [1079, 1103], [1103, 1135], [1135, 1168], [1168, 1189], [1189, 1223], [1223, 1243], [1243, 1273], [1273, 1312], [1312, 1318], [1318, 1336], [1336, 1352], [1352, 1359], [1359, 1374], [1374, 1396], [1396, 1412], [1412, 1425], [1425, 1452], [1452, 1459], [1459, 1472], [1472, 1493], [1493, 1513], [1513, 1534], [1534, 1563], [1563, 1593], [1593, 1605], [1605, 1627], [1627, 1673], [1673, 1688], [1688, 1709], [1709, 1718], [1718, 1749], [1749, 1767], [1767, 1794], [1794, 1825], [1825, 1861], [1861, 1910], [1910, 1933], [1933, 1943], [1943, 1949], [1949, 1997], [1997, 2031], [2031, 2087], [2087, 2103], [2103, 2122], [2122, 2150], [2150, 2184], [2184, 2209], [2209, 2219], [2219, 2259], [2259, 2315], [2315, 2382], [2382, 2401], [2401, 2423], [2423, 2427], [2427, 2455], [2455, 2465], [2465, 2488], [2488, 2504], [2504, 2524], [2524, 2534], [2534, 2569], [2569, 2591], [2591, 2597], [2597, 2614], [2614, 2626], [2626, 2652], [2652, 2660], [2660, 2672], [2672, 2702], [2702, 2718], [2718, 2729], [2729, 2750], [2750, 2786], [2786, 2809], [2809, 2822], [2822, 2889], [2889, 2894], [2894, 2904], [2904, 2946], [2946, 3020], [3020, 3068], [3068, 3075], [3075, 3113], [3113, 3162], [3162, 3205], [3205, 3242], [3242, 3264], [3264, 3283], [3283, 3305], [3305, 3335], [3335, 3381], [3381, 3385], [3385, 3398], [3398, 3426], [3426, 3463], [3463, 3479], [3479, 3513], [3513, 3517], [3517, 3556], [3556, 3580], [3580, 3612], [3612, 3630], [3630, 3662], [3662, 3693], [3693, 3724], [3724, 3735], [3735, 3743], [3743, 3759], [3759, 3786], [3786, 3818], [3818, 3822], [3822, 3839], [3839, 3853], [3853, 3879], [3879, 3898], [3898, 3932], [3932, 3956], [3956, 3960], [3960, 3972], [3972, 3987], [3987, 4011], [4011, 4017], [4017, 4023], [4023, 4060], [4060, 4086], [4086, 4118], [4118, 4159], [4159, 4160], [4160, 4179], [4179, 4204], [4204, 4236], [4236, 4261], [4261, 4264], [4264, 4307], [4307, 4368], [4368, 4388], [4388, 4391]], "words": ["document", ":", "Sequence", "-", "Level", "Knowledge", "Distillation", "Neural", "machine", "translation", "(", "NMT", ")", "offers", "a", "novel", "alternative", "formulation", "of", "translation", "that", "is", "potentially", "simpler", "than", "statistical", "approaches", ".", "However", "to", "reach", "competitive", "performance", ",", "NMT", "models", "need", "to", "be", "exceedingly", "large", ".", "In", "this", "paper", "we", "consider", "applying", "knowledge", "distillation", "approaches", "that", "have", "proven", "successful", "for", "reducing", "the", "size", "of", "neural", "models", "in", "other", "domains", "to", "the", "problem", "of", "NMT", ".", "We", "demonstrate", "that", "standard", "knowledge", "distillation", "applied", "to", "word", "-", "level", "prediction", "can", "be", "effective", "for", "NMT", ",", "and", "also", "introduce", "two", "novel", "sequence", "-", "level", "versions", "of", "knowledge", "distillation", "that", "further", "improve", "performance", ",", "and", "somewhat", "surprisingly", ",", "seem", "to", "eliminate", "the", "need", "for", "beam", "search", "(", "even", "when", "applied", "on", "the", "original", "teacher", "model", ")", ".", "Our", "best", "student", "model", "runs", "times", "faster", "than", "its", "state", "-", "of", "-", "the", "-", "art", "teacher", "with", "little", "loss", "in", "performance", ".", "It", "is", "also", "significantly", "better", "than", "a", "baseline", "model", "trained", "without", "knowledge", "distillation", ":", "by", "BLEU", "with", "greedy", "decoding", "/", "beam", "search", ".", "Applying", "weight", "pruning", "on", "top", "of", "knowledge", "distillation", "results", "in", "a", "student", "model", "that", "has", "fewer", "parameters", "than", "the", "original", "teacher", "model", ",", "with", "a", "decrease", "of", "BLEU", ".", "section", ":", "Introduction", "Neural", "machine", "translation", "(", "NMT", ")", "is", "a", "deep", "learning", "-", "based", "method", "for", "translation", "that", "has", "recently", "shown", "promising", "results", "as", "an", "alternative", "to", "statistical", "approaches", ".", "NMT", "systems", "directly", "model", "the", "probability", "of", "the", "next", "word", "in", "the", "target", "sentence", "simply", "by", "conditioning", "a", "recurrent", "neural", "network", "on", "the", "source", "sentence", "and", "previously", "generated", "target", "words", ".", "While", "both", "simple", "and", "surprisingly", "accurate", ",", "NMT", "systems", "typically", "need", "to", "have", "very", "high", "capacity", "in", "order", "to", "perform", "well", ":", "Sutskever2014", "used", "a", "-", "layer", "LSTM", "with", "hidden", "units", "per", "layer", "(", "herein", ")", "and", "Zhou2016", "obtained", "state", "-", "of", "-", "the", "-", "art", "results", "on", "English", "French", "with", "a", "-", "layer", "LSTM", "with", "units", "per", "layer", ".", "The", "sheer", "size", "of", "the", "models", "requires", "cutting", "-", "edge", "hardware", "for", "training", "and", "makes", "using", "the", "models", "on", "standard", "setups", "very", "challenging", ".", "This", "issue", "of", "excessively", "large", "networks", "has", "been", "observed", "in", "several", "other", "domains", ",", "with", "much", "focus", "on", "fully", "-", "connected", "and", "convolutional", "networks", "for", "multi", "-", "class", "classification", ".", "Researchers", "have", "particularly", "noted", "that", "large", "networks", "seem", "to", "be", "necessary", "for", "training", ",", "but", "learn", "redundant", "representations", "in", "the", "process", ".", "Therefore", "compressing", "deep", "models", "into", "smaller", "networks", "has", "been", "an", "active", "area", "of", "research", ".", "As", "deep", "learning", "systems", "obtain", "better", "results", "on", "NLP", "tasks", ",", "compression", "also", "becomes", "an", "important", "practical", "issue", "with", "applications", "such", "as", "running", "deep", "learning", "models", "for", "speech", "and", "translation", "locally", "on", "cell", "phones", ".", "Existing", "compression", "methods", "generally", "fall", "into", "two", "categories", ":", "(", "1", ")", "pruning", "and", "(", "2", ")", "knowledge", "distillation", ".", "Pruning", "methods", ",", "zero", "-", "out", "weights", "or", "entire", "neurons", "based", "on", "an", "importance", "criterion", ":", "LeCun1990", "use", "(", "a", "diagonal", "approximation", "to", ")", "the", "Hessian", "to", "identify", "weights", "whose", "removal", "minimally", "impacts", "the", "objective", "function", ",", "while", "Han2016", "remove", "weights", "based", "on", "thresholding", "their", "absolute", "values", ".", "Knowledge", "distillation", "approaches", "learn", "a", "smaller", "student", "network", "to", "mimic", "the", "original", "teacher", "network", "by", "minimizing", "the", "loss", "(", "typically", "or", "cross", "-", "entropy", ")", "between", "the", "student", "and", "teacher", "output", ".", "In", "this", "work", ",", "we", "investigate", "knowledge", "distillation", "in", "the", "context", "of", "neural", "machine", "translation", ".", "We", "note", "that", "NMT", "differs", "from", "previous", "work", "which", "has", "mainly", "explored", "non", "-", "recurrent", "models", "in", "the", "multi", "-", "class", "prediction", "setting", ".", "For", "NMT", ",", "while", "the", "model", "is", "trained", "on", "multi", "-", "class", "prediction", "at", "the", "word", "-", "level", ",", "it", "is", "tasked", "with", "predicting", "complete", "sequence", "outputs", "conditioned", "on", "previous", "decisions", ".", "With", "this", "difference", "in", "mind", ",", "we", "experiment", "with", "standard", "knowledge", "distillation", "for", "NMT", "and", "also", "propose", "two", "new", "versions", "of", "the", "approach", "that", "attempt", "to", "approximately", "match", "the", "sequence", "-", "level", "(", "as", "opposed", "to", "word", "-", "level", ")", "distribution", "of", "the", "teacher", "network", ".", "This", "sequence", "-", "level", "approximation", "leads", "to", "a", "simple", "training", "procedure", "wherein", "the", "student", "network", "is", "trained", "on", "a", "newly", "generated", "dataset", "that", "is", "the", "result", "of", "running", "beam", "search", "with", "the", "teacher", "network", ".", "We", "run", "experiments", "to", "compress", "a", "large", "state", "-", "of", "-", "the", "-", "art", "LSTM", "model", ",", "and", "find", "that", "with", "sequence", "-", "level", "knowledge", "distillation", "we", "are", "able", "to", "learn", "a", "LSTM", "that", "roughly", "matches", "the", "performance", "of", "the", "full", "system", ".", "We", "see", "similar", "results", "compressing", "a", "model", "down", "to", "on", "a", "smaller", "data", "set", ".", "Furthermore", ",", "we", "observe", "that", "our", "proposed", "approach", "has", "other", "benefits", ",", "such", "as", "not", "requiring", "any", "beam", "search", "at", "test", "-", "time", ".", "As", "a", "result", "we", "are", "able", "to", "perform", "greedy", "decoding", "on", "the", "model", "times", "faster", "than", "beam", "search", "on", "the", "model", "with", "comparable", "performance", ".", "Our", "student", "models", "can", "even", "be", "run", "efficiently", "on", "a", "standard", "smartphone", ".", "Finally", ",", "we", "apply", "weight", "pruning", "on", "top", "of", "the", "student", "network", "to", "obtain", "a", "model", "that", "has", "fewer", "parameters", "than", "the", "original", "teacher", "model", ".", "We", "have", "released", "all", "the", "code", "for", "the", "models", "described", "in", "this", "paper", ".", "section", ":", "Background", "subsection", ":", "Sequence", "-", "to", "-", "Sequence", "with", "Attention", "Let", "and", "be", "(", "random", "variable", "sequences", "representing", ")", "the", "source", "/", "target", "sentence", ",", "with", "and", "respectively", "being", "the", "source", "/", "target", "lengths", ".", "Machine", "translation", "involves", "finding", "the", "most", "probable", "target", "sentence", "given", "the", "source", ":", "where", "is", "the", "set", "of", "all", "possible", "sequences", ".", "NMT", "models", "parameterize", "with", "an", "encoder", "neural", "network", "which", "reads", "the", "source", "sentence", "and", "a", "decoder", "neural", "network", "which", "produces", "a", "distribution", "over", "the", "target", "sentence", "(", "one", "word", "at", "a", "time", ")", "given", "the", "source", ".", "We", "employ", "the", "attentional", "architecture", "from", "Luong2015", ",", "which", "achieved", "state", "-", "of", "-", "the", "-", "art", "results", "on", "English", "German", "translation", ".", "subsection", ":", "Knowledge", "Distillation", "Knowledge", "distillation", "describes", "a", "class", "of", "methods", "for", "training", "a", "smaller", "student", "network", "to", "perform", "better", "by", "learning", "from", "a", "larger", "teacher", "network", "(", "in", "addition", "to", "learning", "from", "the", "training", "data", "set", ")", ".", "We", "generally", "assume", "that", "the", "teacher", "has", "previously", "been", "trained", ",", "and", "that", "we", "are", "estimating", "parameters", "for", "the", "student", ".", "Knowledge", "distillation", "suggests", "training", "by", "matching", "the", "student", "\u2019s", "predictions", "to", "the", "teacher", "\u2019s", "predictions", ".", "For", "classification", "this", "usually", "means", "matching", "the", "probabilities", "either", "via", "on", "the", "scale", "or", "by", "cross", "-", "entropy", ".", "Concretely", ",", "assume", "we", "are", "learning", "a", "multi", "-", "class", "classifier", "over", "a", "data", "set", "of", "examples", "of", "the", "form", "with", "possible", "classes", ".", "The", "usual", "training", "criteria", "is", "to", "minimize", "NLL", "for", "each", "example", "from", "the", "training", "data", ",", "where", "is", "the", "indicator", "function", "and", "the", "distribution", "from", "our", "model", "(", "parameterized", "by", ")", ".", "This", "objective", "can", "be", "seen", "as", "minimizing", "the", "cross", "-", "entropy", "between", "the", "degenerate", "data", "distribution", "(", "which", "has", "all", "of", "its", "probability", "mass", "on", "one", "class", ")", "and", "the", "model", "distribution", ".", "In", "knowledge", "distillation", ",", "we", "assume", "access", "to", "a", "learned", "teacher", "distribution", ",", "possibly", "trained", "over", "the", "same", "data", "set", ".", "Instead", "of", "minimizing", "cross", "-", "entropy", "with", "the", "observed", "data", ",", "we", "instead", "minimize", "the", "cross", "-", "entropy", "with", "the", "teacher", "\u2019s", "probability", "distribution", ",", "where", "parameterizes", "the", "teacher", "distribution", "and", "remains", "fixed", ".", "Note", "the", "cross", "-", "entropy", "setup", "is", "identical", ",", "but", "the", "target", "distribution", "is", "no", "longer", "a", "sparse", "distribution", ".", "Training", "on", "is", "attractive", "since", "it", "gives", "more", "information", "about", "other", "classes", "for", "a", "given", "data", "point", "(", "e.g.", "similarity", "between", "classes", ")", "and", "has", "less", "variance", "in", "gradients", ".", "Since", "this", "new", "objective", "has", "no", "direct", "term", "for", "the", "training", "data", ",", "it", "is", "common", "practice", "to", "interpolate", "between", "the", "two", "losses", ",", "where", "is", "mixture", "parameter", "combining", "the", "one", "-", "hot", "distribution", "and", "the", "teacher", "distribution", ".", "section", ":", "Knowledge", "Distillation", "for", "NMT", "The", "large", "sizes", "of", "neural", "machine", "translation", "systems", "make", "them", "an", "ideal", "candidate", "for", "knowledge", "distillation", "approaches", ".", "In", "this", "section", "we", "explore", "three", "different", "ways", "this", "technique", "can", "be", "applied", "to", "NMT", ".", "subsection", ":", "Word", "-", "Level", "Knowledge", "Distillation", "NMT", "systems", "are", "trained", "directly", "to", "minimize", "word", "NLL", ",", ",", "at", "each", "position", ".", "Therefore", "if", "we", "have", "a", "teacher", "model", ",", "standard", "knowledge", "distillation", "for", "multi", "-", "class", "cross", "-", "entropy", "can", "be", "applied", ".", "We", "define", "this", "distillation", "for", "a", "sentence", "as", ",", "where", "is", "the", "target", "vocabulary", "set", ".", "The", "student", "can", "further", "be", "trained", "to", "optimize", "the", "mixture", "of", "and", ".", "In", "the", "context", "of", "NMT", ",", "we", "refer", "to", "this", "approach", "as", "word", "-", "level", "knowledge", "distillation", "and", "illustrate", "this", "in", "Figure", "1", "(", "left", ")", ".", "subsection", ":", "Sequence", "-", "Level", "Knowledge", "Distillation", "Word", "-", "level", "knowledge", "distillation", "allows", "transfer", "of", "these", "local", "word", "distributions", ".", "Ideally", "however", ",", "we", "would", "like", "the", "student", "model", "to", "mimic", "the", "teacher", "\u2019s", "actions", "at", "the", "sequence", "-", "level", ".", "The", "sequence", "distribution", "is", "particularly", "important", "for", "NMT", ",", "because", "wrong", "predictions", "can", "propagate", "forward", "at", "test", "-", "time", ".", "First", ",", "consider", "the", "sequence", "-", "level", "distribution", "specified", "by", "the", "model", "over", "all", "possible", "sequences", ",", "for", "any", "length", ".", "The", "sequence", "-", "level", "negative", "log", "-", "likelihood", "for", "NMT", "then", "involves", "matching", "the", "one", "-", "hot", "distribution", "over", "all", "complete", "sequences", ",", "where", "is", "the", "observed", "sequence", ".", "Of", "course", ",", "this", "just", "shows", "that", "from", "a", "negative", "log", "likelihood", "perspective", ",", "minimizing", "word", "-", "level", "NLL", "and", "sequence", "-", "level", "NLL", "are", "equivalent", "in", "this", "model", ".", "But", "now", "consider", "the", "case", "of", "sequence", "-", "level", "knowledge", "distillation", ".", "As", "before", ",", "we", "can", "simply", "replace", "the", "distribution", "from", "the", "data", "with", "a", "probability", "distribution", "derived", "from", "our", "teacher", "model", ".", "However", ",", "instead", "of", "using", "a", "single", "word", "prediction", ",", "we", "use", "to", "represent", "the", "teacher", "\u2019s", "sequence", "distribution", "over", "the", "sample", "space", "of", "all", "possible", "sequences", ",", "Note", "that", "is", "inherently", "different", "from", ",", "as", "the", "sum", "is", "over", "an", "exponential", "number", "of", "terms", ".", "Despite", "its", "intractability", ",", "we", "posit", "that", "this", "sequence", "-", "level", "objective", "is", "worthwhile", ".", "It", "gives", "the", "teacher", "the", "chance", "to", "assign", "probabilities", "to", "complete", "sequences", "and", "therefore", "transfer", "a", "broader", "range", "of", "knowledge", ".", "We", "thus", "consider", "an", "approximation", "of", "this", "objective", ".", "Our", "simplest", "approximation", "is", "to", "replace", "the", "teacher", "distribution", "with", "its", "mode", ",", "Observing", "that", "finding", "the", "mode", "is", "itself", "intractable", ",", "we", "use", "beam", "search", "to", "find", "an", "approximation", ".", "The", "loss", "is", "then", "where", "is", "now", "the", "output", "from", "running", "beam", "search", "with", "the", "teacher", "model", ".", "Using", "the", "mode", "seems", "like", "a", "poor", "approximation", "for", "the", "teacher", "distribution", ",", "as", "we", "are", "approximating", "an", "exponentially", "-", "sized", "distribution", "with", "a", "single", "sample", ".", "However", ",", "previous", "results", "showing", "the", "effectiveness", "of", "beam", "search", "decoding", "for", "NMT", "lead", "us", "to", "belief", "that", "a", "large", "portion", "of", "\u2019s", "mass", "lies", "in", "a", "single", "output", "sequence", ".", "In", "fact", ",", "in", "experiments", "we", "find", "that", "with", "beam", "of", "size", ",", "(", "on", "average", ")", "accounts", "for", "of", "the", "distribution", "for", "German", "English", ",", "and", "for", "Thai", "English", "(", "Table", "1", ":", ")", ".", "To", "summarize", ",", "sequence", "-", "level", "knowledge", "distillation", "suggests", "to", ":", "(", "1", ")", "train", "a", "teacher", "model", ",", "(", "2", ")", "run", "beam", "search", "over", "the", "training", "set", "with", "this", "model", ",", "(", "3", ")", "train", "the", "student", "network", "with", "cross", "-", "entropy", "on", "this", "new", "dataset", ".", "Step", "(", "3", ")", "is", "identical", "to", "the", "word", "-", "level", "NLL", "process", "except", "now", "on", "the", "newly", "-", "generated", "data", "set", ".", "This", "is", "shown", "in", "Figure", "1", "(", "center", ")", ".", "subsection", ":", "Sequence", "-", "Level", "Interpolation", "Next", "we", "consider", "integrating", "the", "training", "data", "back", "into", "the", "process", ",", "such", "that", "we", "train", "the", "student", "model", "as", "a", "mixture", "of", "our", "sequence", "-", "level", "teacher", "-", "generated", "data", "(", ")", "with", "the", "original", "training", "data", "(", ")", ",", "where", "is", "the", "gold", "target", "sequence", ".", "Since", "the", "second", "term", "is", "intractable", ",", "we", "could", "again", "apply", "the", "mode", "approximation", "from", "the", "previous", "section", ",", "and", "train", "on", "both", "observed", "(", ")", "and", "teacher", "-", "generated", "(", ")", "data", ".", "However", ",", "this", "process", "is", "non", "-", "ideal", "for", "two", "reasons", ":", "(", "1", ")", "unlike", "for", "standard", "knowledge", "distribution", ",", "it", "doubles", "the", "size", "of", "the", "training", "data", ",", "and", "(", "2", ")", "it", "requires", "training", "on", "both", "the", "teacher", "-", "generated", "sequence", "and", "the", "true", "sequence", ",", "conditioned", "on", "the", "same", "source", "input", ".", "The", "latter", "concern", "is", "particularly", "problematic", "since", "we", "observe", "that", "and", "are", "often", "quite", "different", ".", "As", "an", "alternative", ",", "we", "propose", "a", "single", "-", "sequence", "approximation", "that", "is", "more", "attractive", "in", "this", "setting", ".", "This", "approach", "is", "inspired", "by", "local", "updating", ",", "a", "method", "for", "discriminative", "training", "in", "statistical", "machine", "translation", "(", "although", "to", "our", "knowledge", "not", "for", "knowledge", "distillation", ")", ".", "Local", "updating", "suggests", "selecting", "a", "training", "sequence", "which", "is", "close", "to", "and", "has", "high", "probability", "under", "the", "teacher", "model", ",", "where", "is", "a", "function", "measuring", "closeness", "(", "e.g.", "Jaccard", "similarity", "or", "BLEU", ")", ".", "Following", "local", "updating", ",", "we", "can", "approximate", "this", "sequence", "by", "running", "beam", "search", "and", "choosing", "where", "is", "the", "-", "best", "list", "from", "beam", "search", ".", "We", "take", "to", "be", "smoothed", "sentence", "-", "level", "BLEU", ".", "We", "justify", "training", "on", "from", "a", "knowledge", "distillation", "perspective", "with", "the", "following", "generative", "process", ":", "suppose", "that", "there", "is", "a", "true", "target", "sequence", "(", "which", "we", "do", "not", "observe", ")", "that", "is", "first", "generated", "from", "the", "underlying", "data", "distribution", ".", "And", "further", "suppose", "that", "the", "target", "sequence", "that", "we", "observe", "(", ")", "is", "a", "noisy", "version", "of", "the", "unobserved", "true", "sequence", ":", "i.e.", "(", "i", ")", ",", "(", "ii", ")", ",", "where", "is", ",", "for", "example", ",", "a", "noise", "function", "that", "independently", "replaces", "each", "element", "in", "with", "a", "random", "element", "in", "with", "some", "small", "probability", ".", "In", "such", "a", "case", ",", "ideally", "the", "student", "\u2019s", "distribution", "should", "match", "the", "mixture", "distribution", ",", "In", "this", "setting", ",", "due", "to", "the", "noise", "assumption", ",", "now", "has", "significant", "probability", "mass", "around", "a", "neighborhood", "of", "(", "not", "just", "at", ")", ",", "and", "therefore", "the", "of", "the", "mixture", "distribution", "is", "likely", "something", "other", "than", "(", "the", "observed", "sequence", ")", "or", "(", "the", "output", "from", "beam", "search", ")", ".", "We", "can", "see", "that", "is", "a", "natural", "approximation", "to", "the", "of", "this", "mixture", "distribution", "between", "and", "for", "some", ".", "We", "illustrate", "this", "framework", "in", "Figure", "1", "(", "right", ")", "and", "visualize", "the", "distribution", "over", "a", "real", "example", "in", "Figure", "2", ".", "section", ":", "Experimental", "Setup", "To", "test", "out", "these", "approaches", ",", "we", "conduct", "two", "sets", "of", "NMT", "experiments", ":", "high", "resource", "(", "English", "German", ")", "and", "low", "resource", "(", "Thai", "English", ")", ".", "The", "English", "-", "German", "data", "comes", "from", "WMT", "2014", ".", "The", "training", "set", "has", "m", "sentences", "and", "we", "take", "newstest2012", "/", "newstest2013", "as", "the", "dev", "set", "and", "newstest2014", "as", "the", "test", "set", ".", "We", "keep", "the", "top", "k", "most", "frequent", "words", ",", "and", "replace", "the", "rest", "with", "UNK", ".", "The", "teacher", "model", "is", "a", "LSTM", "(", "as", "in", "Luong2015", ")", "and", "we", "train", "two", "student", "models", ":", "and", ".", "The", "Thai", "-", "English", "data", "comes", "from", "IWSLT", "2015", ".", "There", "are", "k", "sentences", "in", "the", "training", "set", "and", "we", "take", "2010", "/", "2011", "/", "2012", "data", "as", "the", "dev", "set", "and", "2012", "/", "2013", "as", "the", "test", "set", ",", "with", "a", "vocabulary", "size", "is", "k.", "Size", "of", "the", "teacher", "model", "is", "(", "which", "performed", "better", "than", ",", "models", ")", ",", "and", "the", "student", "model", "is", ".", "Other", "training", "details", "mirror", "Luong2015", ".", "We", "evaluate", "on", "tokenized", "BLEU", "with", "multi", "-", "bleu.perl", ",", "and", "experiment", "with", "the", "following", "variations", ":", "paragraph", ":", "Word", "-", "Level", "Knowledge", "Distillation", "(", "Word", "-", "KD", ")", "Student", "is", "trained", "on", "the", "original", "data", "and", "additionally", "trained", "to", "minimize", "the", "cross", "-", "entropy", "of", "the", "teacher", "distribution", "at", "the", "word", "-", "level", ".", "We", "tested", "and", "found", "to", "work", "better", ".", "paragraph", ":", "Sequence", "-", "Level", "Knowledge", "Distillation", "(", "Seq", "-", "KD", ")", "Student", "is", "trained", "on", "the", "teacher", "-", "generated", "data", ",", "which", "is", "the", "result", "of", "running", "beam", "search", "and", "taking", "the", "highest", "-", "scoring", "sequence", "with", "the", "teacher", "model", ".", "We", "use", "beam", "size", "(", "we", "did", "not", "see", "improvements", "with", "a", "larger", "beam", ")", ".", "paragraph", ":", "Sequence", "-", "Level", "Interpolation", "(", "Seq", "-", "Inter", ")", "Student", "is", "trained", "on", "the", "sequence", "on", "the", "teacher", "\u2019s", "beam", "that", "had", "the", "highest", "BLEU", "(", "beam", "size", ")", ".", "We", "adopt", "a", "fine", "-", "tuning", "approach", "where", "we", "begin", "training", "from", "a", "pretrained", "model", "(", "either", "on", "original", "data", "or", "Seq", "-", "KD", "data", ")", "and", "train", "with", "a", "smaller", "learning", "rate", "(", ")", ".", "For", "English", "-", "German", "we", "generate", "Seq", "-", "Inter", "data", "on", "a", "smaller", "portion", "of", "the", "training", "set", "(", ")", "for", "efficiency", ".", "The", "above", "methods", "are", "complementary", "and", "can", "be", "combined", "with", "each", "other", ".", "For", "example", ",", "we", "can", "train", "on", "teacher", "-", "generated", "data", "but", "still", "include", "a", "word", "-", "level", "cross", "-", "entropy", "term", "between", "the", "teacher", "/", "student", "(", "Seq", "-", "KD", "Word", "-", "KD", "in", "Table", "1", ")", ",", "or", "fine", "-", "tune", "towards", "Seq", "-", "Inter", "data", "starting", "from", "the", "baseline", "model", "trained", "on", "original", "data", "(", "Baseline", "Seq", "-", "Inter", "in", "Table", "1", ")", ".", "section", ":", "Results", "and", "Discussion", "Results", "of", "our", "experiments", "are", "shown", "in", "Table", "1", ".", "We", "find", "that", "while", "word", "-", "level", "knowledge", "distillation", "(", "Word", "-", "KD", ")", "does", "improve", "upon", "the", "baseline", ",", "sequence", "-", "level", "knowledge", "distillation", "(", "Seq", "-", "KD", ")", "does", "better", "on", "English", "German", "and", "performs", "similarly", "on", "Thai", "English", ".", "Combining", "them", "(", "Seq", "-", "KD", "Word", "-", "KD", ")", "results", "in", "further", "gains", "for", "the", "and", "models", "(", "although", "not", "for", "the", "model", ")", ",", "indicating", "that", "these", "methods", "provide", "orthogonal", "means", "of", "transferring", "knowledge", "from", "the", "teacher", "to", "the", "student", ":", "Word", "-", "KD", "is", "transferring", "knowledge", "at", "the", "the", "local", "(", "i.e.", "word", ")", "level", "while", "Seq", "-", "KD", "is", "transferring", "knowledge", "at", "the", "global", "(", "i.e.", "sequence", ")", "level", ".", "Sequence", "-", "level", "interpolation", "(", "Seq", "-", "Inter", ")", ",", "in", "addition", "to", "improving", "models", "trained", "via", "Word", "-", "KD", "and", "Seq", "-", "KD", ",", "also", "improves", "upon", "the", "original", "teacher", "model", "that", "was", "trained", "on", "the", "actual", "data", "but", "fine", "-", "tuned", "towards", "Seq", "-", "Inter", "data", "(", "Baseline", "Seq", "-", "Inter", ")", ".", "In", "fact", ",", "greedy", "decoding", "with", "this", "fine", "-", "tuned", "model", "has", "similar", "performance", "(", ")", "as", "beam", "search", "with", "the", "original", "model", "(", ")", ",", "allowing", "for", "faster", "decoding", "even", "with", "an", "identically", "-", "sized", "model", ".", "We", "hypothesize", "that", "sequence", "-", "level", "knowledge", "distillation", "is", "effective", "because", "it", "allows", "the", "student", "network", "to", "only", "model", "relevant", "parts", "of", "the", "teacher", "distribution", "(", "i.e.", "around", "the", "teacher", "\u2019s", "mode", ")", "instead", "of", "\u2018", "wasting", "\u2019", "parameters", "on", "trying", "to", "model", "the", "entire", "space", "of", "translations", ".", "Our", "results", "suggest", "that", "this", "is", "indeed", "the", "case", ":", "the", "probability", "mass", "that", "Seq", "-", "KD", "models", "assign", "to", "the", "approximate", "mode", "is", "much", "higher", "than", "is", "the", "case", "for", "baseline", "models", "trained", "on", "original", "data", "(", "Table", "1", ":", ")", ".", "For", "example", ",", "on", "English", "German", "the", "(", "approximate", ")", "for", "the", "Seq", "-", "KD", "model", "(", "on", "average", ")", "accounts", "for", "of", "the", "total", "probability", "mass", ",", "while", "the", "corresponding", "number", "is", "for", "the", "baseline", ".", "This", "also", "explains", "the", "success", "of", "greedy", "decoding", "for", "Seq", "-", "KD", "models", "\u2014", "since", "we", "are", "only", "modeling", "around", "the", "teacher", "\u2019s", "mode", ",", "the", "student", "\u2019s", "distribution", "is", "more", "peaked", "and", "therefore", "the", "is", "much", "easier", "to", "find", ".", "Seq", "-", "Inter", "offers", "a", "compromise", "between", "the", "two", ",", "with", "the", "greedily", "-", "decoded", "sequence", "accounting", "for", "of", "the", "distribution", ".", "Finally", ",", "although", "past", "work", "has", "shown", "that", "models", "with", "lower", "perplexity", "generally", "tend", "to", "have", "higher", "BLEU", ",", "our", "results", "indicate", "that", "this", "is", "not", "necessarily", "the", "case", ".", "The", "perplexity", "of", "the", "baseline", "English", "German", "model", "is", "while", "the", "perplexity", "of", "the", "corresponding", "Seq", "-", "KD", "model", "is", ",", "despite", "the", "fact", "that", "Seq", "-", "KD", "model", "does", "significantly", "better", "for", "both", "greedy", "(", "BLEU", ")", "and", "beam", "search", "(", "BLEU", ")", "decoding", ".", "subsection", ":", "Decoding", "Speed", "Run", "-", "time", "complexity", "for", "beam", "search", "grows", "linearly", "with", "beam", "size", ".", "Therefore", ",", "the", "fact", "that", "sequence", "-", "level", "knowledge", "distillation", "allows", "for", "greedy", "decoding", "is", "significant", ",", "with", "practical", "implications", "for", "running", "NMT", "systems", "across", "various", "devices", ".", "To", "test", "the", "speed", "gains", ",", "we", "run", "the", "teacher", "/", "student", "models", "on", "GPU", ",", "CPU", ",", "and", "smartphone", ",", "and", "check", "the", "average", "number", "of", "source", "words", "translated", "per", "second", "(", "Table", "2", ")", ".", "We", "use", "a", "GeForce", "GTX", "Titan", "X", "for", "GPU", "and", "a", "Samsung", "Galaxy", "6", "smartphone", ".", "We", "find", "that", "we", "can", "run", "the", "student", "model", "times", "faster", "with", "greedy", "decoding", "than", "the", "teacher", "model", "with", "beam", "search", "on", "GPU", "(", "vs", "words", "/", "sec", ")", ",", "with", "similar", "performance", ".", "subsection", ":", "Weight", "Pruning", "Although", "knowledge", "distillation", "enables", "training", "faster", "models", ",", "the", "number", "of", "parameters", "for", "the", "student", "models", "is", "still", "somewhat", "large", "(", "Table", "1", ":", "Params", ")", ",", "due", "to", "the", "word", "embeddings", "which", "dominate", "most", "of", "the", "parameters", ".", "For", "example", ",", "on", "the", "English", "German", "model", "the", "word", "embeddings", "account", "for", "approximately", "(", "m", "out", "of", "m", ")", "of", "the", "parameters", ".", "The", "size", "of", "word", "embeddings", "have", "little", "impact", "on", "run", "-", "time", "as", "the", "word", "embedding", "layer", "is", "a", "simple", "lookup", "table", "that", "only", "affects", "the", "first", "layer", "of", "the", "model", ".", "We", "therefore", "focus", "next", "on", "reducing", "the", "memory", "footprint", "of", "the", "student", "models", "further", "through", "weight", "pruning", ".", "Weight", "pruning", "for", "NMT", "was", "recently", "investigated", "by", "See2016", ",", "who", "found", "that", "up", "to", "of", "the", "parameters", "in", "a", "large", "NMT", "model", "can", "be", "pruned", "with", "little", "loss", "in", "performance", ".", "We", "take", "our", "best", "English", "German", "student", "model", "(", "Seq", "-", "KD", "Seq", "-", "Inter", ")", "and", "prune", "of", "the", "parameters", "by", "removing", "the", "weights", "with", "the", "lowest", "absolute", "values", ".", "We", "then", "retrain", "the", "pruned", "model", "on", "Seq", "-", "KD", "data", "with", "a", "learning", "rate", "of", "and", "fine", "-", "tune", "towards", "Seq", "-", "Inter", "data", "with", "a", "learning", "rate", "of", ".", "As", "observed", "by", "See2016", ",", "retraining", "proved", "to", "be", "crucial", ".", "The", "results", "are", "shown", "in", "Table", "3", ".", "Our", "findings", "suggest", "that", "compression", "benefits", "achieved", "through", "weight", "pruning", "and", "knowledge", "distillation", "are", "orthogonal", ".", "Pruning", "of", "the", "weight", "in", "the", "student", "model", "results", "in", "a", "model", "with", "fewer", "parameters", "than", "the", "original", "teacher", "model", "with", "only", "a", "decrease", "of", "BLEU", ".", "While", "pruning", "of", "the", "weights", "results", "in", "a", "more", "appreciable", "decrease", "of", "BLEU", ",", "the", "model", "is", "drastically", "smaller", "with", "m", "parameters", ",", "which", "is", "fewer", "than", "the", "original", "teacher", "model", ".", "subsection", ":", "Further", "Observations", "For", "models", "trained", "with", "word", "-", "level", "knowledge", "distillation", ",", "we", "also", "tried", "regressing", "the", "student", "network", "\u2019s", "top", "-", "most", "hidden", "layer", "at", "each", "time", "step", "to", "the", "teacher", "network", "\u2019s", "top", "-", "most", "hidden", "layer", "as", "a", "pretraining", "step", ",", "noting", "that", "Romero2015", "obtained", "improvements", "with", "a", "similar", "technique", "on", "feed", "-", "forward", "models", ".", "We", "found", "this", "to", "give", "comparable", "results", "to", "standard", "knowledge", "distillation", "and", "hence", "did", "not", "pursue", "this", "further", ".", "There", "have", "been", "promising", "recent", "results", "on", "eliminating", "word", "embeddings", "completely", "and", "obtaining", "word", "representations", "directly", "from", "characters", "with", "character", "composition", "models", ",", "which", "have", "many", "fewer", "parameters", "than", "word", "embedding", "lookup", "tables", ".", "Combining", "such", "methods", "with", "knowledge", "distillation", "/", "pruning", "to", "further", "reduce", "the", "memory", "footprint", "of", "NMT", "systems", "remains", "an", "avenue", "for", "future", "work", ".", "section", ":", "Related", "Work", "Compressing", "deep", "learning", "models", "is", "an", "active", "area", "of", "current", "research", ".", "Pruning", "methods", "involve", "pruning", "weights", "or", "entire", "neurons", "/", "nodes", "based", "on", "some", "criterion", ".", "LeCun1990", "prune", "weights", "based", "on", "an", "approximation", "of", "the", "Hessian", ",", "while", "Han2016", "show", "that", "a", "simple", "magnitude", "-", "based", "pruning", "works", "well", ".", "Prior", "work", "on", "removing", "neurons", "/", "nodes", "include", "Srinivas2015", "and", "Mariet2016", ".", "See2016", "were", "the", "first", "to", "apply", "pruning", "to", "Neural", "Machine", "Translation", ",", "observing", "that", "that", "different", "parts", "of", "the", "architecture", "(", "input", "word", "embeddings", ",", "LSTM", "matrices", ",", "etc", ".", ")", "admit", "different", "levels", "of", "pruning", ".", "Knowledge", "distillation", "approaches", "train", "a", "smaller", "student", "model", "to", "mimic", "a", "larger", "teacher", "model", ",", "by", "minimizing", "the", "loss", "between", "the", "teacher", "/", "student", "predictions", ".", "Romero2015", "additionally", "regress", "on", "the", "intermediate", "hidden", "layers", "of", "the", "student", "/", "teacher", "network", "as", "a", "pretraining", "step", ",", "while", "Mou2015", "obtain", "smaller", "word", "embeddings", "from", "a", "teacher", "model", "via", "regression", ".", "There", "has", "also", "been", "work", "on", "transferring", "knowledge", "across", "different", "network", "architectures", ":", "Chan2015b", "show", "that", "a", "deep", "non", "-", "recurrent", "neural", "network", "can", "learn", "from", "an", "RNN", ";", "Geras2016", "train", "a", "CNN", "to", "mimic", "an", "LSTM", "for", "speech", "recognition", ".", "Kuncoro2016", "recently", "investigated", "knowledge", "distillation", "for", "structured", "prediction", "by", "having", "a", "single", "parser", "learn", "from", "an", "ensemble", "of", "parsers", ".", "Other", "approaches", "for", "compression", "involve", "low", "rank", "factorizations", "of", "weight", "matrices", ",", "sparsity", "-", "inducing", "regularizers", ",", "binarization", "of", "weights", ",", "and", "weight", "sharing", ".", "Finally", ",", "although", "we", "have", "motivated", "sequence", "-", "level", "knowledge", "distillation", "in", "the", "context", "of", "training", "a", "smaller", "model", ",", "there", "are", "other", "techniques", "that", "train", "on", "a", "mixture", "of", "the", "model", "\u2019s", "predictions", "and", "the", "data", ",", "such", "as", "local", "updating", ",", "hope", "/", "fear", "training", ",", "SEARN", ",", "DAgger", ",", "and", "minimum", "risk", "training", ".", "section", ":", "Conclusion", "In", "this", "work", "we", "have", "investigated", "existing", "knowledge", "distillation", "methods", "for", "NMT", "(", "which", "work", "at", "the", "word", "-", "level", ")", "and", "introduced", "two", "sequence", "-", "level", "variants", "of", "knowledge", "distillation", ",", "which", "provide", "improvements", "over", "standard", "word", "-", "level", "knowledge", "distillation", ".", "We", "have", "chosen", "to", "focus", "on", "translation", "as", "this", "domain", "has", "generally", "required", "the", "largest", "capacity", "deep", "learning", "models", ",", "but", "the", "sequence", "-", "to", "-", "sequence", "framework", "has", "been", "successfully", "applied", "to", "a", "wide", "range", "of", "tasks", "including", "parsing", ",", "summarization", ",", "dialogue", ",", "NER", "/", "POS", "-", "tagging", ",", "image", "captioning", ",", "video", "generation", ",", "and", "speech", "recognition", ".", "We", "anticipate", "that", "methods", "described", "in", "this", "paper", "can", "be", "used", "to", "similarly", "train", "smaller", "models", "in", "other", "domains", ".", "bibliography", ":", "References"]}