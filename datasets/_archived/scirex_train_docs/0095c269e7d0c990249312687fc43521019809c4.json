{"coref": {"50D_stacked_TC-LSTMs": [[565, 568], [569, 572], [1145, 1149], [1406, 1410], [1411, 1414], [1497, 1502], [1600, 1603], [1659, 1662], [1684, 1688], [1709, 1712], [1751, 1754], [1803, 1806], [3120, 3123], [3213, 3216], [3292, 3295], [4095, 4098], [4133, 4136]], "Natural_Language_Inference": [[2, 7], [20, 24], [2705, 2708], [2958, 2961], [2961, 2964], [2965, 2966], [101, 105], [494, 498], [674, 678], [1060, 1064], [1312, 1316], [3022, 3023], [4119, 4120], [4308, 4312]], "Parameters": [], "SNLI": [[2982, 2987], [2988, 2989], [3011, 3012], [3031, 3032], [3060, 3061]], "__Test_Accuracy": [[3203, 3204]], "__Train_Accuracy": []}, "coref_non_salient": {"0": [[208, 211], [224, 227], [718, 720], [1919, 1921], [2398, 2401], [2491, 2494], [2548, 2550], [2698, 2701], [3792, 3794]], "1": [[269, 272], [453, 456]], "10": [[1507, 1509], [4465, 4467]], "11": [[306, 308], [1957, 1959], [2586, 2588], [3037, 3039]], "12": [[4433, 4435]], "13": [[95, 96], [773, 774], [806, 807], [909, 910], [1049, 1050], [1178, 1179], [1190, 1191], [1320, 1321], [1366, 1367], [1374, 1375], [1388, 1389], [1396, 1397], [1464, 1465], [1550, 1551], [1720, 1721], [1788, 1789], [1829, 1830], [2062, 2063], [2872, 2873], [2893, 2894], [4226, 4227], [4245, 4246], [4319, 4320], [10, 11], [80, 81], [401, 402], [459, 460], [506, 507], [512, 513], [517, 518], [534, 535], [554, 555], [577, 578], [592, 593], [605, 606], [681, 682], [709, 710], [781, 782], [826, 827], [833, 834], [855, 856], [894, 895], [996, 997], [1028, 1029], [1101, 1102], [1118, 1119], [1123, 1124], [1132, 1133], [1136, 1137], [1142, 1143], [1267, 1268], [1270, 1271], [1301, 1302], [1305, 1306], [1331, 1332], [1339, 1340], [1350, 1351], [1432, 1433], [1449, 1450], [1563, 1564], [1588, 1589], [1626, 1627], [1845, 1846], [1851, 1852], [1887, 1888], [2005, 2006], [2018, 2019], [2043, 2044], [2076, 2077], [2095, 2096], [2130, 2131], [2139, 2140], [2156, 2157], [2198, 2199], [2220, 2221], [2868, 2869], [2885, 2886], [2907, 2908], [2911, 2912], [2931, 2932], [2937, 2938], [3086, 3087], [3163, 3164], [3201, 3202], [3611, 3612], [4015, 4016], [4032, 4033], [4358, 4359]], "14": [[378, 381], [1071, 1073], [2940, 2947], [4322, 4324]], "15": [[2406, 2408], [2426, 2428], [2510, 2512], [2710, 2712]], "16": [[2840, 2841], [4029, 4030]], "17": [[114, 116], [613, 616], [2244, 2246]], "18": [[177, 179], [1087, 1089], [2411, 2414]], "19": [[2070, 2071], [2184, 2189]], "2": [[1170, 1172], [1950, 1952], [2009, 2011]], "20": [[3252, 3256]], "21": [[174, 176], [2417, 2419], [2453, 2455], [2573, 2575], [2702, 2704]], "22": [[3777, 3779], [3781, 3784]], "23": [[3445, 3447], [3565, 3566]], "24": [[71, 76], [1030, 1033]], "25": [[4159, 4162]], "26": [[3604, 3606]], "27": [[66, 68], [486, 490], [1928, 1935], [4391, 4398]], "28": [[2865, 2866], [2904, 2905]], "29": [[2172, 2177], [3182, 3186], [3986, 3990]], "3": [[2212, 2214], [2311, 2313], [2351, 2353], [3555, 3557]], "30": [[2831, 2833], [4059, 4061]], "31": [[4477, 4481]], "32": [[4494, 4499]], "33": [[1879, 1881]], "34": [[560, 563], [1419, 1422], [1604, 1607], [1663, 1666], [1713, 1716], [1776, 1779], [1814, 1817], [1835, 1838], [3116, 3119], [3220, 3223], [4089, 4092], [4127, 4130]], "35": [[4274, 4276]], "36": [[314, 316], [644, 646], [2433, 2436], [2524, 2526]], "37": [[4411, 4416]], "38": [[25, 28], [744, 747], [3104, 3106]], "39": [[3768, 3770]], "4": [[2713, 2718], [3997, 4001]], "40": [[1125, 1128], [1594, 1597], [2098, 2101], [3257, 3260], [3268, 3271], [4018, 4021], [4054, 4057], [4062, 4065], [4300, 4303], [4362, 4365]], "41": [[2505, 2509]], "42": [[2538, 2543]], "43": [[4107, 4110]], "44": [[4218, 4220]], "45": [[946, 948]], "46": [[2561, 2564]], "47": [[4205, 4207]], "48": [[3831, 3833]], "49": [[928, 930], [1534, 1536], [2442, 2444]], "5": [[341, 345], [4011, 4013], [4167, 4169]], "50": [[2622, 2624]], "51": [[2649, 2652]], "52": [[298, 305]], "53": [[2496, 2498]], "54": [[800, 805]], "55": [[791, 792]], "56": [[1986, 1990]], "57": [[3951, 3952], [4104, 4105]], "58": [[180, 182], [1084, 1086]], "59": [[1916, 1918]], "6": [[164, 171], [2402, 2403]], "60": [[2471, 2473]], "61": [[1103, 1106]], "62": [[2833, 2839]], "63": [[2666, 2668]], "64": [[4343, 4345]], "65": [[2654, 2658]], "66": [[368, 372]], "67": [[214, 218]], "68": [[1556, 1558]], "69": [[2797, 2799]], "7": [[2064, 2066], [2143, 2145], [2146, 2148], [2202, 2204], [3284, 3286]], "70": [[2552, 2556]], "71": [[2207, 2209]], "72": [[273, 274]], "73": [[2422, 2424]], "74": [[632, 635], [2343, 2347], [2357, 2360], [2447, 2451], [2476, 2480]], "75": [[2722, 2723]], "76": [[941, 944]], "77": [[664, 666]], "78": [[556, 559], [1344, 1347]], "79": [[351, 355]], "8": [[787, 790], [1093, 1099]], "80": [[288, 296]], "81": [[2568, 2572]], "82": [[366, 367]], "83": [[1965, 1971]], "84": [[1973, 1975]], "85": [[2365, 2367]], "86": [[1258, 1262]], "87": [[41, 42]], "88": [[408, 411]], "89": [[770, 772]], "9": [[255, 258], [432, 435], [4025, 4028]], "90": [[3785, 3786]], "91": [[398, 399]], "92": [[152, 156]], "93": [[639, 641]]}, "doc_id": "0095c269e7d0c990249312687fc43521019809c4", "method_subrelations": {"50D_stacked_TC-LSTMs": [[[0, 20], "50D_stacked_TC-LSTMs"]]}, "n_ary_relations": [{"Material": "SNLI", "Method": "50D_stacked_TC-LSTMs", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "85.1"}, {"Material": "SNLI", "Method": "50D_stacked_TC-LSTMs", "Metric": "__Train_Accuracy", "Task": "Natural_Language_Inference", "score": "86.7"}, {"Material": "SNLI", "Method": "50D_stacked_TC-LSTMs", "Metric": "Parameters", "Task": "Natural_Language_Inference", "score": "190k"}], "ner": [[2, 7, "Task"], [20, 24, "Task"], [25, 28, "Method"], [41, 42, "Method"], [66, 68, "Method"], [71, 76, "Task"], [95, 96, "Method"], [114, 116, "Method"], [152, 156, "Method"], [164, 171, "Task"], [174, 176, "Task"], [177, 179, "Task"], [180, 182, "Task"], [208, 211, "Task"], [214, 218, "Method"], [224, 227, "Task"], [255, 258, "Method"], [269, 272, "Method"], [273, 274, "Method"], [288, 296, "Method"], [298, 305, "Method"], [306, 308, "Method"], [314, 316, "Metric"], [341, 345, "Method"], [351, 355, "Method"], [366, 367, "Method"], [368, 372, "Method"], [378, 381, "Method"], [398, 399, "Method"], [408, 411, "Task"], [432, 435, "Method"], [453, 456, "Method"], [486, 490, "Method"], [556, 559, "Method"], [560, 563, "Method"], [565, 568, "Method"], [569, 572, "Method"], [613, 616, "Method"], [632, 635, "Method"], [639, 641, "Method"], [644, 646, "Metric"], [664, 666, "Method"], [718, 720, "Task"], [744, 747, "Method"], [770, 772, "Method"], [773, 774, "Method"], [787, 790, "Method"], [791, 792, "Method"], [800, 805, "Task"], [806, 807, "Method"], [909, 910, "Method"], [928, 930, "Method"], [941, 944, "Method"], [946, 948, "Method"], [1030, 1033, "Task"], [1049, 1050, "Method"], [1071, 1073, "Method"], [1084, 1086, "Task"], [1087, 1089, "Task"], [1093, 1099, "Method"], [1103, 1106, "Task"], [1125, 1128, "Method"], [1145, 1149, "Method"], [1170, 1172, "Method"], [1178, 1179, "Method"], [1190, 1191, "Method"], [1258, 1262, "Method"], [1320, 1321, "Method"], [1344, 1347, "Method"], [1366, 1367, "Method"], [1374, 1375, "Method"], [1388, 1389, "Method"], [1396, 1397, "Method"], [1406, 1410, "Method"], [1411, 1414, "Method"], [1419, 1422, "Method"], [1464, 1465, "Method"], [1497, 1502, "Method"], [1507, 1509, "Method"], [1534, 1536, "Method"], [1550, 1551, "Method"], [1556, 1558, "Method"], [1594, 1597, "Method"], [1600, 1603, "Method"], [1604, 1607, "Method"], [1659, 1662, "Method"], [1663, 1666, "Method"], [1684, 1688, "Method"], [1709, 1712, "Method"], [1713, 1716, "Method"], [1720, 1721, "Method"], [1751, 1754, "Method"], [1776, 1779, "Method"], [1788, 1789, "Method"], [1803, 1806, "Method"], [1814, 1817, "Method"], [1829, 1830, "Method"], [1835, 1838, "Method"], [1879, 1881, "Method"], [1916, 1918, "Method"], [1919, 1921, "Task"], [1928, 1935, "Method"], [1950, 1952, "Method"], [1957, 1959, "Method"], [1965, 1971, "Method"], [1973, 1975, "Method"], [1986, 1990, "Method"], [2009, 2011, "Method"], [2062, 2063, "Method"], [2064, 2066, "Method"], [2070, 2071, "Task"], [2098, 2101, "Method"], [2143, 2145, "Method"], [2146, 2148, "Method"], [2172, 2177, "Method"], [2184, 2189, "Task"], [2202, 2204, "Method"], [2207, 2209, "Method"], [2212, 2214, "Method"], [2244, 2246, "Method"], [2311, 2313, "Method"], [2343, 2347, "Method"], [2351, 2353, "Method"], [2357, 2360, "Method"], [2365, 2367, "Method"], [2398, 2401, "Task"], [2402, 2403, "Task"], [2406, 2408, "Task"], [2411, 2414, "Task"], [2417, 2419, "Task"], [2422, 2424, "Task"], [2426, 2428, "Task"], [2433, 2436, "Metric"], [2442, 2444, "Method"], [2447, 2451, "Method"], [2453, 2455, "Task"], [2471, 2473, "Method"], [2476, 2480, "Method"], [2491, 2494, "Task"], [2496, 2498, "Method"], [2505, 2509, "Metric"], [2510, 2512, "Task"], [2524, 2526, "Metric"], [2538, 2543, "Method"], [2548, 2550, "Task"], [2552, 2556, "Metric"], [2561, 2564, "Metric"], [2568, 2572, "Metric"], [2573, 2575, "Task"], [2586, 2588, "Method"], [2622, 2624, "Method"], [2649, 2652, "Method"], [2654, 2658, "Method"], [2666, 2668, "Method"], [2698, 2701, "Task"], [2702, 2704, "Task"], [2705, 2708, "Task"], [2710, 2712, "Task"], [2713, 2718, "Task"], [2722, 2723, "Method"], [2797, 2799, "Metric"], [2831, 2833, "Method"], [2833, 2839, "Task"], [2840, 2841, "Method"], [2865, 2866, "Method"], [2872, 2873, "Method"], [2893, 2894, "Method"], [2904, 2905, "Method"], [2940, 2947, "Method"], [2958, 2961, "Task"], [2961, 2964, "Task"], [2965, 2966, "Task"], [2982, 2987, "Material"], [2988, 2989, "Material"], [3011, 3012, "Material"], [3031, 3032, "Material"], [3037, 3039, "Method"], [3060, 3061, "Material"], [3104, 3106, "Method"], [3116, 3119, "Method"], [3120, 3123, "Method"], [3182, 3186, "Method"], [3203, 3204, "Metric"], [3213, 3216, "Method"], [3220, 3223, "Method"], [3252, 3256, "Task"], [3257, 3260, "Method"], [3268, 3271, "Method"], [3284, 3286, "Method"], [3292, 3295, "Method"], [3445, 3447, "Task"], [3555, 3557, "Method"], [3565, 3566, "Task"], [3604, 3606, "Method"], [3768, 3770, "Method"], [3777, 3779, "Task"], [3781, 3784, "Task"], [3785, 3786, "Task"], [3792, 3794, "Task"], [3831, 3833, "Task"], [3951, 3952, "Method"], [3986, 3990, "Method"], [3997, 4001, "Task"], [4011, 4013, "Method"], [4018, 4021, "Method"], [4025, 4028, "Method"], [4029, 4030, "Method"], [4054, 4057, "Method"], [4059, 4061, "Method"], [4062, 4065, "Method"], [4089, 4092, "Method"], [4095, 4098, "Method"], [4104, 4105, "Method"], [4107, 4110, "Task"], [4127, 4130, "Method"], [4133, 4136, "Method"], [4159, 4162, "Task"], [4167, 4169, "Method"], [4205, 4207, "Task"], [4218, 4220, "Method"], [4226, 4227, "Method"], [4245, 4246, "Method"], [4274, 4276, "Metric"], [4300, 4303, "Method"], [4319, 4320, "Method"], [4322, 4324, "Method"], [4343, 4345, "Method"], [4362, 4365, "Method"], [4391, 4398, "Method"], [4411, 4416, "Task"], [4433, 4435, "Task"], [4465, 4467, "Method"], [4477, 4481, "Method"], [4494, 4499, "Method"], [10, 11, "Method"], [80, 81, "Method"], [101, 105, "Task"], [401, 402, "Method"], [459, 460, "Method"], [494, 498, "Task"], [506, 507, "Method"], [512, 513, "Method"], [517, 518, "Method"], [534, 535, "Method"], [554, 555, "Method"], [577, 578, "Method"], [592, 593, "Method"], [605, 606, "Method"], [674, 678, "Task"], [681, 682, "Method"], [709, 710, "Method"], [781, 782, "Method"], [826, 827, "Method"], [833, 834, "Method"], [855, 856, "Method"], [894, 895, "Method"], [996, 997, "Method"], [1028, 1029, "Method"], [1060, 1064, "Task"], [1101, 1102, "Method"], [1118, 1119, "Method"], [1123, 1124, "Method"], [1132, 1133, "Method"], [1136, 1137, "Method"], [1142, 1143, "Method"], [1267, 1268, "Method"], [1270, 1271, "Method"], [1301, 1302, "Method"], [1305, 1306, "Method"], [1312, 1316, "Task"], [1331, 1332, "Method"], [1339, 1340, "Method"], [1350, 1351, "Method"], [1432, 1433, "Method"], [1449, 1450, "Method"], [1563, 1564, "Method"], [1588, 1589, "Method"], [1626, 1627, "Method"], [1845, 1846, "Method"], [1851, 1852, "Method"], [1887, 1888, "Method"], [2005, 2006, "Method"], [2018, 2019, "Method"], [2043, 2044, "Method"], [2076, 2077, "Method"], [2095, 2096, "Method"], [2130, 2131, "Method"], [2139, 2140, "Method"], [2156, 2157, "Method"], [2198, 2199, "Method"], [2220, 2221, "Method"], [2868, 2869, "Method"], [2885, 2886, "Method"], [2907, 2908, "Method"], [2911, 2912, "Method"], [2931, 2932, "Method"], [2937, 2938, "Method"], [3022, 3023, "Task"], [3086, 3087, "Method"], [3163, 3164, "Method"], [3201, 3202, "Method"], [3611, 3612, "Method"], [4015, 4016, "Method"], [4032, 4033, "Method"], [4119, 4120, "Task"], [4308, 4312, "Task"], [4358, 4359, "Method"]], "sections": [[0, 149], [149, 253], [253, 339], [339, 430], [430, 768], [768, 1024], [1024, 1296], [1296, 1404], [1404, 1576], [1576, 1677], [1677, 1744], [1744, 1831], [1831, 1910], [1910, 1948], [1948, 2000], [2000, 2089], [2089, 2141], [2141, 2170], [2170, 2210], [2210, 2341], [2341, 2368], [2368, 2481], [2481, 2503], [2503, 2566], [2566, 2679], [2679, 2720], [2720, 2829], [2829, 2952], [2952, 3048], [3048, 3250], [3250, 3602], [3602, 3771], [3771, 3946], [3946, 4152], [4152, 4378], [4378, 4508]], "sentences": [[0, 11], [11, 29], [29, 59], [59, 82], [82, 106], [106, 123], [123, 149], [149, 152], [152, 186], [186, 212], [212, 234], [234, 253], [253, 258], [258, 278], [278, 325], [325, 339], [339, 345], [345, 373], [373, 403], [403, 430], [430, 435], [435, 453], [453, 461], [461, 478], [478, 499], [499, 529], [529, 543], [543, 574], [574, 594], [594, 625], [625, 647], [647, 658], [658, 695], [695, 712], [712, 732], [732, 748], [748, 768], [768, 774], [774, 806], [806, 822], [822, 852], [852, 889], [889, 897], [897, 908], [908, 916], [916, 939], [939, 949], [949, 992], [992, 1014], [1014, 1024], [1024, 1033], [1033, 1051], [1051, 1065], [1065, 1090], [1090, 1130], [1130, 1134], [1134, 1144], [1144, 1150], [1150, 1161], [1161, 1176], [1176, 1184], [1184, 1198], [1198, 1211], [1211, 1234], [1234, 1238], [1238, 1254], [1254, 1287], [1287, 1296], [1296, 1307], [1307, 1328], [1328, 1352], [1352, 1378], [1378, 1404], [1404, 1415], [1415, 1440], [1440, 1466], [1466, 1494], [1494, 1505], [1505, 1532], [1532, 1545], [1545, 1576], [1576, 1583], [1583, 1608], [1608, 1656], [1656, 1677], [1677, 1683], [1683, 1706], [1706, 1744], [1744, 1750], [1750, 1773], [1773, 1795], [1795, 1831], [1831, 1846], [1846, 1882], [1882, 1910], [1910, 1921], [1921, 1948], [1948, 1952], [1952, 1976], [1976, 2000], [2000, 2007], [2007, 2028], [2028, 2036], [2036, 2054], [2054, 2067], [2067, 2089], [2089, 2097], [2097, 2125], [2125, 2141], [2141, 2145], [2145, 2161], [2161, 2170], [2170, 2177], [2177, 2210], [2210, 2214], [2214, 2242], [2242, 2258], [2258, 2278], [2278, 2285], [2285, 2295], [2295, 2326], [2326, 2341], [2341, 2347], [2347, 2368], [2368, 2372], [2372, 2392], [2392, 2404], [2404, 2415], [2415, 2425], [2425, 2452], [2452, 2481], [2481, 2484], [2484, 2495], [2495, 2503], [2503, 2512], [2512, 2523], [2523, 2531], [2531, 2551], [2551, 2566], [2566, 2575], [2575, 2583], [2583, 2596], [2596, 2617], [2617, 2642], [2642, 2659], [2659, 2679], [2679, 2682], [2682, 2720], [2720, 2725], [2725, 2757], [2757, 2770], [2770, 2816], [2816, 2829], [2829, 2833], [2833, 2843], [2843, 2867], [2867, 2870], [2870, 2884], [2884, 2887], [2887, 2906], [2906, 2925], [2925, 2952], [2952, 2961], [2961, 2979], [2979, 2991], [2991, 3011], [3011, 3025], [3025, 3048], [3048, 3051], [3051, 3062], [3062, 3081], [3081, 3110], [3110, 3140], [3140, 3160], [3160, 3181], [3181, 3208], [3208, 3242], [3242, 3246], [3246, 3250], [3250, 3260], [3260, 3296], [3296, 3307], [3307, 3324], [3324, 3345], [3345, 3384], [3384, 3392], [3392, 3415], [3415, 3439], [3439, 3458], [3458, 3471], [3471, 3472], [3472, 3486], [3486, 3514], [3514, 3537], [3537, 3548], [3548, 3567], [3567, 3588], [3588, 3602], [3602, 3606], [3606, 3636], [3636, 3654], [3654, 3655], [3655, 3667], [3667, 3674], [3674, 3675], [3675, 3711], [3711, 3729], [3729, 3745], [3745, 3771], [3771, 3781], [3781, 3795], [3795, 3810], [3810, 3822], [3822, 3831], [3831, 3842], [3842, 3872], [3872, 3912], [3912, 3927], [3927, 3946], [3946, 3949], [3949, 3961], [3961, 3991], [3991, 4051], [4051, 4058], [4058, 4087], [4087, 4099], [4099, 4122], [4122, 4152], [4152, 4156], [4156, 4178], [4178, 4196], [4196, 4208], [4208, 4221], [4221, 4242], [4242, 4255], [4255, 4277], [4277, 4291], [4291, 4313], [4313, 4332], [4332, 4354], [4354, 4378], [4378, 4384], [4384, 4408], [4408, 4430], [4430, 4455], [4455, 4500], [4500, 4505], [4505, 4508]], "words": ["document", ":", "Modelling", "Interaction", "of", "Sentence", "Pair", "with", "Coupled", "-", "LSTMs", "Recently", ",", "there", "is", "rising", "interest", "in", "modelling", "the", "interactions", "of", "two", "sentences", "with", "deep", "neural", "networks", ".", "However", ",", "most", "of", "the", "existing", "methods", "encode", "two", "sequences", "with", "separate", "encoders", ",", "in", "which", "a", "sentence", "is", "encoded", "with", "little", "or", "no", "information", "from", "the", "other", "sentence", ".", "In", "this", "paper", ",", "we", "propose", "a", "deep", "architecture", "to", "model", "the", "strong", "interaction", "of", "sentence", "pair", "with", "two", "coupled", "-", "LSTMs", ".", "Specifically", ",", "we", "introduce", "two", "coupled", "ways", "to", "model", "the", "interdependences", "of", "two", "LSTMs", ",", "coupling", "the", "local", "contextualized", "interactions", "of", "two", "sentences", ".", "We", "then", "aggregate", "these", "interactions", "and", "use", "a", "dynamic", "pooling", "to", "select", "the", "most", "informative", "features", ".", "Experiments", "on", "two", "very", "large", "datasets", "demonstrate", "the", "efficacy", "of", "our", "proposed", "architecture", "and", "its", "superiority", "to", "state", "-", "of", "-", "the", "-", "art", "methods", ".", "section", ":", "Introduction", "Distributed", "representations", "of", "words", "or", "sentences", "have", "been", "widely", "used", "in", "many", "natural", "language", "processing", "(", "NLP", ")", "tasks", ",", "such", "as", "text", "classification", ",", "question", "answering", "and", "machine", "translation", "and", "so", "on", ".", "Among", "these", "tasks", ",", "a", "common", "problem", "is", "modelling", "the", "relevance", "/", "similarity", "of", "the", "sentence", "pair", ",", "which", "is", "also", "called", "text", "semantic", "matching", ".", "Recently", ",", "deep", "learning", "based", "models", "is", "rising", "a", "substantial", "interest", "in", "text", "semantic", "matching", "and", "have", "achieved", "some", "great", "progresses", ".", "According", "to", "the", "phases", "of", "interaction", "between", "two", "sentences", ",", "previous", "models", "can", "be", "classified", "into", "three", "categories", ".", "paragraph", ":", "Weak", "interaction", "Models", "Some", "early", "works", "focus", "on", "sentence", "level", "interactions", ",", "such", "as", "ARC", "-", "I", ",", "CNTN", "and", "so", "on", ".", "These", "models", "first", "encode", "two", "sequences", "with", "some", "basic", "(", "Neural", "Bag", "-", "of", "-", "words", ",", "BOW", ")", "or", "advanced", "(", "RNN", ",", "CNN", ")", "components", "of", "neural", "networks", "separately", ",", "and", "then", "compute", "the", "matching", "score", "based", "on", "the", "distributed", "vectors", "of", "two", "sentences", ".", "In", "this", "paradigm", ",", "two", "sentences", "have", "no", "interaction", "until", "arriving", "final", "phase", ".", "paragraph", ":", "Semi", "-", "interaction", "Models", "Some", "improved", "methods", "focus", "on", "utilizing", "multi", "-", "granularity", "representation", "(", "word", ",", "phrase", "and", "sentence", "level", ")", ",", "such", "as", "MultiGranCNN", "and", "Multi", "-", "Perspective", "CNN", ".", "Another", "kind", "of", "models", "use", "soft", "attention", "mechanism", "to", "obtain", "the", "representation", "of", "one", "sentence", "by", "depending", "on", "representation", "of", "another", "sentence", ",", "such", "as", "ABCNN", ",", "Attention", "LSTM", ".", "These", "models", "can", "alleviate", "the", "weak", "interaction", "problem", ",", "but", "are", "still", "insufficient", "to", "model", "the", "contextualized", "interaction", "on", "the", "word", "as", "well", "as", "phrase", "level", ".", "paragraph", ":", "Strong", "Interaction", "Models", "These", "models", "directly", "build", "an", "interaction", "space", "between", "two", "sentences", "and", "model", "the", "interaction", "at", "different", "positions", ".", "ARC", "-", "II", "and", "MV", "-", "LSTM", ".", "These", "models", "enable", "the", "model", "to", "easily", "capture", "the", "difference", "between", "semantic", "capacity", "of", "two", "sentences", ".", "In", "this", "paper", ",", "we", "propose", "a", "new", "deep", "neural", "network", "architecture", "to", "model", "the", "strong", "interactions", "of", "two", "sentences", ".", "Different", "with", "modelling", "two", "sentences", "with", "separated", "LSTMs", ",", "we", "utilize", "two", "interdependent", "LSTMs", ",", "called", "coupled", "-", "LSTMs", ",", "to", "fully", "affect", "each", "other", "at", "different", "time", "steps", ".", "The", "output", "of", "coupled", "-", "LSTMs", "at", "each", "step", "depends", "on", "both", "sentences", ".", "Specifically", ",", "we", "propose", "two", "interdependent", "ways", "for", "the", "coupled", "-", "LSTMs", ":", "loosely", "coupled", "model", "(", "LC", "-", "LSTMs", ")", "and", "tightly", "coupled", "model", "(", "TC", "-", "LSTMs", ")", ".", "Similar", "to", "bidirectional", "LSTM", "for", "single", "sentence", ",", "there", "are", "four", "directions", "can", "be", "used", "in", "coupled", "-", "LSTMs", ".", "To", "utilize", "all", "the", "information", "of", "four", "directions", "of", "coupled", "-", "LSTMs", ",", "we", "aggregate", "them", "and", "adopt", "a", "dynamic", "pooling", "strategy", "to", "automatically", "select", "the", "most", "informative", "interaction", "signals", ".", "Finally", ",", "we", "feed", "them", "into", "a", "fully", "connected", "layer", ",", "followed", "by", "an", "output", "layer", "to", "compute", "the", "matching", "score", ".", "The", "contributions", "of", "this", "paper", "can", "be", "summarized", "as", "follows", ".", "Different", "with", "the", "architectures", "of", "using", "similarity", "matrix", ",", "our", "proposed", "architecture", "directly", "model", "the", "strong", "interactions", "of", "two", "sentences", "with", "coupled", "-", "LSTMs", ",", "which", "can", "capture", "the", "useful", "local", "semantic", "relevances", "of", "two", "sentences", ".", "Our", "architecture", "can", "also", "capture", "the", "multiple", "granular", "interactions", "by", "several", "stacked", "coupled", "-", "LSTMs", "layers", ".", "Compared", "to", "the", "previous", "works", "on", "text", "matching", ",", "we", "perform", "extensive", "empirical", "studies", "on", "two", "very", "large", "datasets", ".", "The", "massive", "scale", "of", "the", "datasets", "allows", "us", "to", "train", "a", "very", "deep", "neural", "networks", ".", "Experiment", "results", "demonstrate", "that", "our", "proposed", "architecture", "is", "more", "effective", "than", "state", "-", "of", "-", "the", "-", "art", "methods", ".", "section", ":", "Sentence", "Modelling", "with", "LSTM", "Long", "short", "-", "term", "memory", "network", "(", "LSTM", ")", "is", "a", "type", "of", "recurrent", "neural", "network", "(", "RNN", ")", ",", "and", "specifically", "addresses", "the", "issue", "of", "learning", "long", "-", "term", "dependencies", ".", "LSTM", "maintains", "a", "memory", "cell", "that", "updates", "and", "exposes", "its", "content", "only", "when", "deemed", "necessary", ".", "While", "there", "are", "numerous", "LSTM", "variants", ",", "here", "we", "use", "the", "LSTM", "architecture", "used", "by", ",", "which", "is", "similar", "to", "the", "architecture", "of", "but", "without", "peep", "-", "hole", "connections", ".", "We", "define", "the", "LSTM", "units", "at", "each", "time", "step", "to", "be", "a", "collection", "of", "vectors", "in", ":", "an", "input", "gate", ",", "a", "forget", "gate", ",", "an", "output", "gate", ",", "a", "memory", "cell", "and", "a", "hidden", "state", ".", "is", "the", "number", "of", "the", "LSTM", "units", ".", "The", "elements", "of", "the", "gating", "vectors", ",", "and", "are", "in", ".", "The", "LSTM", "is", "precisely", "specified", "as", "follows", ".", "where", "is", "the", "input", "at", "the", "current", "time", "step", ";", "is", "an", "affine", "transformation", "which", "depends", "on", "parameters", "of", "the", "network", "and", ".", "denotes", "the", "logistic", "sigmoid", "function", "and", "denotes", "elementwise", "multiplication", ".", "Intuitively", ",", "the", "forget", "gate", "controls", "the", "amount", "of", "which", "each", "unit", "of", "the", "memory", "cell", "is", "erased", ",", "the", "input", "gate", "controls", "how", "much", "each", "unit", "is", "updated", ",", "and", "the", "output", "gate", "controls", "the", "exposure", "of", "the", "internal", "memory", "state", ".", "The", "update", "of", "each", "LSTM", "unit", "can", "be", "written", "precisely", "as", "follows", "Here", ",", "the", "function", "is", "a", "shorthand", "for", "Eq", ".", "(", "[", "reference", "]", "-", "[", "reference", "]", ")", ".", "section", ":", "Coupled", "-", "LSTMs", "for", "Strong", "Sentence", "Interaction", "To", "deal", "with", "two", "sentences", ",", "one", "straightforward", "method", "is", "to", "model", "them", "with", "two", "separate", "LSTMs", ".", "However", ",", "this", "method", "is", "difficult", "to", "model", "local", "interactions", "of", "two", "sentences", ".", "An", "improved", "way", "is", "to", "introduce", "attention", "mechanism", ",", "which", "has", "been", "used", "in", "many", "tasks", ",", "such", "as", "machine", "translation", "and", "question", "answering", ".", "Inspired", "by", "the", "multi", "-", "dimensional", "recurrent", "neural", "network", "and", "grid", "LSTM", "in", "computer", "vision", "community", ",", "we", "propose", "two", "models", "to", "capture", "the", "interdependences", "between", "two", "parallel", "LSTMs", ",", "called", "coupled", "-", "LSTMs", "(", "C", "-", "LSTMs", ")", ".", "[", "Parallel", "LSTMs", "]", "[", "Attention", "LSTMs", "]", "[", "Loosely", "coupled", "-", "LSTMs", "]", "[", "Tightly", "coupled", "-", "LSTMs", "]", "To", "facilitate", "our", "models", ",", "we", "firstly", "give", "some", "definitions", ".", "Given", "two", "sequences", "and", ",", "we", "let", "denote", "the", "embedded", "representation", "of", "the", "word", ".", "The", "standard", "LSTM", "have", "one", "temporal", "dimension", ".", "When", "dealing", "with", "a", "sentence", ",", "LSTM", "regards", "the", "position", "as", "time", "step", ".", "At", "position", "of", "sentence", ",", "the", "output", "reflects", "the", "meaning", "of", "subsequence", ".", "To", "model", "the", "interaction", "of", "two", "sentences", "as", "early", "as", "possible", ",", "we", "define", "to", "represent", "the", "interaction", "of", "the", "subsequences", "and", ".", "Figure", "[", "reference", "]", "(", "c", ")", "and", "[", "reference", "]", "(", "d", ")", "illustrate", "our", "two", "propose", "models", ".", "For", "intuitive", "comparison", "of", "weak", "interaction", "parallel", "LSTMs", ",", "we", "also", "give", "parallel", "LSTMs", "and", "attention", "LSTMs", "in", "Figure", "[", "reference", "]", "(", "a", ")", "and", "[", "reference", "]", "(", "b", ")", ".", "We", "describe", "our", "two", "proposed", "models", "as", "follows", ".", "subsection", ":", "Loosely", "Coupled", "-", "LSTMs", "(", "LC", "-", "LSTMs", ")", "To", "model", "the", "local", "contextual", "interactions", "of", "two", "sentences", ",", "we", "enable", "two", "LSTMs", "to", "be", "interdependent", "at", "different", "positions", ".", "Inspired", "by", "Grid", "LSTM", "and", "word", "-", "by", "-", "word", "attention", "LSTMs", ",", "we", "propose", "a", "loosely", "coupling", "model", "for", "two", "interdependent", "LSTMs", ".", "More", "concretely", ",", "we", "refer", "to", "as", "the", "encoding", "of", "subsequence", "in", "the", "first", "LSTM", "influenced", "by", "the", "output", "of", "the", "second", "LSTM", "on", "subsequence", ".", "Meanwhile", ",", "is", "the", "encoding", "of", "subsequence", "in", "the", "second", "LSTM", "influenced", "by", "the", "output", "of", "the", "first", "LSTM", "on", "subsequence", "and", "are", "computed", "as", "where", "subsection", ":", "Tightly", "Coupled", "-", "LSTMs", "(", "TC", "-", "LSTMs", ")", "The", "hidden", "states", "of", "LC", "-", "LSTMs", "are", "the", "combination", "of", "the", "hidden", "states", "of", "two", "interdependent", "LSTMs", ",", "whose", "memory", "cells", "are", "separated", ".", "Inspired", "by", "the", "configuration", "of", "the", "multi", "-", "dimensional", "LSTM", ",", "we", "further", "conflate", "both", "the", "hidden", "states", "and", "the", "memory", "cells", "of", "two", "LSTMs", ".", "We", "assume", "that", "directly", "model", "the", "interaction", "of", "the", "subsequences", "and", ",", "which", "depends", "on", "two", "previous", "interaction", "and", ",", "where", "are", "the", "positions", "in", "sentence", "and", ".", "We", "define", "a", "tightly", "coupled", "-", "LSTMs", "units", "as", "follows", ".", "where", "the", "gating", "units", "and", "determine", "which", "memory", "units", "are", "affected", "by", "the", "inputs", "through", ",", "and", "which", "memory", "cells", "are", "written", "to", "the", "hidden", "units", ".", "is", "an", "affine", "transformation", "which", "depends", "on", "parameters", "of", "the", "network", "and", ".", "In", "contrast", "to", "the", "standard", "LSTM", "defined", "over", "time", ",", "each", "memory", "unit", "of", "a", "tightly", "coupled", "-", "LSTMs", "has", "two", "preceding", "states", "and", "and", "two", "corresponding", "forget", "gates", "and", ".", "subsection", ":", "Analysis", "of", "Two", "Proposed", "Models", "Our", "two", "proposed", "coupled", "-", "LSTMs", "can", "be", "formulated", "as", "where", "C", "-", "LSTMs", "can", "be", "either", "TC", "-", "LSTMs", "or", "LC", "-", "LSTMs", ".", "The", "input", "consisted", "of", "two", "type", "of", "information", "at", "step", "(", "i", ",", "j", ")", "in", "coupled", "-", "LSTMs", ":", "temporal", "dimension", "h", "-", "i1", ",", "j", ",", "hi", ",-", "j1", ",", "c", "-", "i1", ",", "j", ",", "ci", ",-", "j1", "and", "depth", "dimension", "xi", ",", "yj", ".", "The", "difference", "between", "TC", "-", "LSTMs", "and", "LC", "-", "LSTMs", "is", "the", "dependence", "of", "information", "from", "temporal", "and", "depth", "dimension", ".", "paragraph", ":", "Interaction", "Between", "Temporal", "Dimensions", "The", "TC", "-", "LSTMs", "model", "the", "interactions", "at", "position", "by", "merging", "the", "internal", "memory", "and", "hidden", "state", "along", "row", "and", "column", "dimensions", ".", "In", "contrast", "with", "TC", "-", "LSTMs", ",", "LC", "-", "LSTMs", "firstly", "use", "two", "standard", "LSTMs", "in", "parallel", ",", "producing", "hidden", "states", "and", "along", "row", "and", "column", "dimensions", "respectively", ",", "which", "are", "then", "merged", "together", "flowing", "next", "step", ".", "paragraph", ":", "Interaction", "Between", "Depth", "Dimension", "In", "TC", "-", "LSTMs", ",", "each", "hidden", "state", "at", "higher", "layer", "receives", "a", "fusion", "of", "information", "and", ",", "flowed", "from", "lower", "layer", ".", "However", ",", "in", "LC", "-", "LSTMs", ",", "the", "information", "and", "are", "accepted", "by", "two", "corresponding", "LSTMs", "at", "the", "higher", "layer", "separately", ".", "The", "two", "architectures", "have", "their", "own", "characteristics", ",", "TC", "-", "LSTMs", "give", "more", "strong", "interactions", "among", "different", "dimensions", "while", "LC", "-", "LSTMs", "ensures", "the", "two", "sequences", "interact", "closely", "without", "being", "conflated", "using", "two", "separated", "LSTMs", ".", "subsubsection", ":", "Comparison", "of", "LC", "-", "LSTMs", "and", "word", "-", "by", "-", "word", "Attention", "LSTMs", "The", "main", "idea", "of", "attention", "LSTMs", "is", "that", "the", "representation", "of", "sentence", "X", "is", "obtained", "dynamically", "based", "on", "the", "alignment", "degree", "between", "the", "words", "in", "sentence", "X", "and", "Y", ",", "which", "is", "asymmetric", "unidirectional", "encoding", ".", "Nevertheless", ",", "in", "LC", "-", "LSTM", ",", "each", "hidden", "state", "of", "each", "step", "is", "obtained", "with", "the", "consideration", "of", "interaction", "between", "two", "sequences", "with", "symmetrical", "encoding", "fashion", ".", "section", ":", "End", "-", "to", "-", "End", "Architecture", "for", "Sentence", "Matching", "In", "this", "section", ",", "we", "present", "an", "end", "-", "to", "-", "end", "deep", "architecture", "for", "matching", "two", "sentences", ",", "as", "shown", "in", "Figure", "[", "reference", "]", ".", "subsection", ":", "Embedding", "Layer", "To", "model", "the", "sentences", "with", "neural", "model", ",", "we", "firstly", "need", "transform", "the", "one", "-", "hot", "representation", "of", "word", "into", "the", "distributed", "representation", ".", "All", "words", "of", "two", "sequences", "and", "will", "be", "mapped", "into", "low", "dimensional", "vector", "representations", ",", "which", "are", "taken", "as", "input", "of", "the", "network", ".", "subsection", ":", "Stacked", "Coupled", "-", "LSTMs", "Layers", "After", "the", "embedding", "layer", ",", "we", "use", "our", "proposed", "coupled", "-", "LSTMs", "to", "capture", "the", "strong", "interactions", "between", "two", "sentences", ".", "A", "basic", "block", "consists", "of", "five", "layers", ".", "We", "firstly", "use", "four", "directional", "coupled", "-", "LSTMs", "to", "model", "the", "local", "interactions", "with", "different", "information", "flows", ".", "And", "then", "we", "sum", "the", "outputs", "of", "these", "LSTMs", "by", "aggregation", "layer", ".", "To", "increase", "the", "learning", "capabilities", "of", "the", "coupled", "-", "LSTMs", ",", "we", "stack", "the", "basic", "block", "on", "top", "of", "each", "other", ".", "subsubsection", ":", "Four", "Directional", "Coupled", "-", "LSTMs", "Layers", "The", "C", "-", "LSTMs", "is", "defined", "along", "a", "certain", "pre", "-", "defined", "direction", ",", "we", "can", "extend", "them", "to", "access", "to", "the", "surrounding", "context", "in", "all", "directions", ".", "Similar", "to", "bi", "-", "directional", "LSTM", ",", "there", "are", "four", "directions", "in", "coupled", "-", "LSTMs", ".", "subsubsection", ":", "Aggregation", "Layer", "The", "aggregation", "layer", "sums", "the", "outputs", "of", "four", "directional", "coupled", "-", "LSTMs", "into", "a", "vector", ".", "where", "the", "superscript", "of", "denotes", "the", "different", "directions", ".", "subsubsection", ":", "Stacking", "C", "-", "LSTMs", "Blocks", "To", "increase", "the", "capabilities", "of", "network", "of", "learning", "multiple", "granularities", "of", "interactions", ",", "we", "stack", "several", "blocks", "(", "four", "C", "-", "LSTMs", "layers", "and", "one", "aggregation", "layer", ")", "to", "form", "deep", "architectures", ".", "subsection", ":", "Pooling", "Layer", "The", "output", "of", "stacked", "coupled", "-", "LSTMs", "layers", "is", "a", "tensor", ",", "where", "and", "are", "the", "lengths", "of", "sentences", ",", "and", "is", "the", "number", "of", "hidden", "neurons", ".", "We", "apply", "dynamic", "pooling", "to", "automatically", "extract", "subsampling", "matrix", "in", "each", "slice", ",", "similar", "to", ".", "More", "formally", ",", "for", "each", "slice", "matrix", ",", "we", "partition", "the", "rows", "and", "columns", "of", "into", "roughly", "equal", "grids", ".", "These", "grid", "are", "non", "-", "overlapping", ".", "Then", "we", "select", "the", "maximum", "value", "within", "each", "grid", ".", "Since", "each", "slice", "consists", "of", "the", "hidden", "states", "of", "one", "neuron", "at", "different", "positions", ",", "the", "pooling", "operation", "can", "be", "regarded", "as", "the", "most", "informative", "interactions", "captured", "by", "the", "neuron", ".", "Thus", ",", "we", "get", "a", "tensor", ",", "which", "is", "further", "reshaped", "into", "a", "vector", ".", "subsection", ":", "Fully", "-", "Connected", "Layer", "The", "vector", "obtained", "by", "pooling", "layer", "is", "fed", "into", "a", "full", "connection", "layer", "to", "obtain", "a", "final", "more", "abstractive", "representation", ".", "subsection", ":", "Output", "Layer", "The", "output", "layer", "depends", "on", "the", "types", "of", "the", "tasks", ",", "we", "choose", "the", "corresponding", "form", "of", "output", "layer", ".", "There", "are", "two", "popular", "types", "of", "text", "matching", "tasks", "in", "NLP", ".", "One", "is", "ranking", "task", ",", "such", "as", "community", "question", "answering", ".", "Another", "is", "classification", "task", ",", "such", "as", "textual", "entailment", ".", "For", "ranking", "task", ",", "the", "output", "is", "a", "scalar", "matching", "score", ",", "which", "is", "obtained", "by", "a", "linear", "transformation", "after", "the", "last", "fully", "-", "connected", "layer", ".", "For", "classification", "task", ",", "the", "outputs", "are", "the", "probabilities", "of", "the", "different", "classes", ",", "which", "is", "computed", "by", "a", "softmax", "function", "after", "the", "last", "fully", "-", "connected", "layer", ".", "section", ":", "Training", "Our", "proposed", "architecture", "can", "deal", "with", "different", "sentence", "matching", "tasks", ".", "The", "loss", "functions", "varies", "with", "different", "tasks", ".", "paragraph", ":", "Max", "-", "Margin", "Loss", "for", "Ranking", "Task", "Given", "a", "positive", "sentence", "pair", "and", "its", "corresponding", "negative", "pair", ".", "The", "matching", "score", "should", "be", "larger", "than", ".", "For", "this", "task", ",", "we", "use", "the", "contrastive", "max", "-", "margin", "criterion", "to", "train", "our", "models", "on", "matching", "task", ".", "The", "ranking", "-", "based", "loss", "is", "defined", "as", "where", "is", "predicted", "matching", "score", "for", ".", "paragraph", ":", "Cross", "-", "entropy", "Loss", "for", "Classification", "Task", "Given", "a", "sentence", "pair", "and", "its", "label", ".", "The", "output", "of", "neural", "network", "is", "the", "probabilities", "of", "the", "different", "classes", ".", "The", "parameters", "of", "the", "network", "are", "trained", "to", "minimise", "the", "cross", "-", "entropy", "of", "the", "predicted", "and", "true", "label", "distributions", ".", "where", "l", "is", "one", "-", "hot", "representation", "of", "the", "ground", "-", "truth", "label", ";", "is", "predicted", "probabilities", "of", "labels", ";", "is", "the", "class", "number", ".", "To", "minimize", "the", "objective", ",", "we", "use", "stochastic", "gradient", "descent", "with", "the", "diagonal", "variant", "of", "AdaGrad", ".", "To", "prevent", "exploding", "gradients", ",", "we", "perform", "gradient", "clipping", "by", "scaling", "the", "gradient", "when", "the", "norm", "exceeds", "a", "threshold", ".", "section", ":", "Experiment", "In", "this", "section", ",", "we", "investigate", "the", "empirical", "performances", "of", "our", "proposed", "model", "on", "two", "different", "text", "matching", "tasks", ":", "classification", "task", "(", "recognizing", "textual", "entailment", ")", "and", "ranking", "task", "(", "matching", "of", "question", "and", "answer", ")", ".", "subsection", ":", "Hyperparameters", "and", "Training", "The", "word", "embeddings", "for", "all", "of", "the", "models", "are", "initialized", "with", "the", "100d", "GloVe", "vectors", "(", "840B", "token", "version", ",", ")", "and", "fine", "-", "tuned", "during", "training", "to", "improve", "the", "performance", ".", "The", "other", "parameters", "are", "initialized", "by", "randomly", "sampling", "from", "uniform", "distribution", "in", ".", "For", "each", "task", ",", "we", "take", "the", "hyperparameters", "which", "achieve", "the", "best", "performance", "on", "the", "development", "set", "via", "an", "small", "grid", "search", "over", "combinations", "of", "the", "initial", "learning", "rate", ",", "regularization", "and", "the", "threshold", "value", "of", "gradient", "norm", "[", "5", ",", "10", ",", "100", "]", ".", "The", "final", "hyper", "-", "parameters", "are", "set", "as", "Table", "[", "reference", "]", ".", "subsection", ":", "Competitor", "Methods", "Neural", "bag", "-", "of", "-", "words", "(", "NBOW", ")", ":", "Each", "sequence", "as", "the", "sum", "of", "the", "embeddings", "of", "the", "words", "it", "contains", ",", "then", "they", "are", "concatenated", "and", "fed", "to", "a", "MLP", ".", "Single", "LSTM", ":", "A", "single", "LSTM", "to", "encode", "the", "two", "sequences", ",", "which", "is", "used", "in", ".", "Parallel", "LSTMs", ":", "Two", "sequences", "are", "encoded", "by", "two", "LSTMs", "separately", ",", "then", "they", "are", "concatenated", "and", "fed", "to", "a", "MLP", ".", "Attention", "LSTMs", ":", "An", "attentive", "LSTM", "to", "encode", "two", "sentences", "into", "a", "semantic", "space", ",", "which", "used", "in", ".", "Word", "-", "by", "-", "word", "Attention", "LSTMs", ":", "An", "improvement", "of", "attention", "LSTM", "by", "introducing", "word", "-", "by", "-", "word", "attention", "mechanism", ",", "which", "used", "in", ".", "subsection", ":", "Experiment", "-", "I", ":", "Recognizing", "Textual", "Entailment", "Recognizing", "textual", "entailment", "(", "RTE", ")", "is", "a", "task", "to", "determine", "the", "semantic", "relationship", "between", "two", "sentences", ".", "We", "use", "the", "Stanford", "Natural", "Language", "Inference", "Corpus", "(", "SNLI", ")", ".", "This", "corpus", "contains", "570", "K", "sentence", "pairs", ",", "and", "all", "of", "the", "sentences", "and", "labels", "stem", "from", "human", "annotators", ".", "SNLI", "is", "two", "orders", "of", "magnitude", "larger", "than", "all", "other", "existing", "RTE", "corpora", ".", "Therefore", ",", "the", "massive", "scale", "of", "SNLI", "allows", "us", "to", "train", "powerful", "neural", "networks", "such", "as", "our", "proposed", "architecture", "in", "this", "paper", ".", "subsubsection", ":", "Results", "Table", "[", "reference", "]", "shows", "the", "evaluation", "results", "on", "SNLI", ".", "The", "rd", "column", "of", "the", "table", "gives", "the", "number", "of", "parameters", "of", "different", "models", "without", "the", "word", "embeddings", ".", "Our", "proposed", "two", "C", "-", "LSTMs", "models", "with", "four", "stacked", "blocks", "outperform", "all", "the", "competitor", "models", ",", "which", "indicates", "that", "our", "thinner", "and", "deeper", "network", "does", "work", "effectively", ".", "Besides", ",", "we", "can", "see", "both", "LC", "-", "LSTMs", "and", "TC", "-", "LSTMs", "benefit", "from", "multi", "-", "directional", "layer", ",", "while", "the", "latter", "obtains", "more", "gains", "than", "the", "former", ".", "We", "attribute", "this", "discrepancy", "between", "two", "models", "to", "their", "different", "mechanisms", "of", "controlling", "the", "information", "flow", "from", "depth", "dimension", ".", "Compared", "with", "attention", "LSTMs", ",", "our", "two", "models", "achieve", "comparable", "results", "to", "them", "using", "much", "fewer", "parameters", "(", "nearly", ")", ".", "By", "stacking", "C", "-", "LSTMs", ",", "the", "performance", "of", "them", "are", "improved", "significantly", ",", "and", "the", "four", "stacked", "TC", "-", "LSTMs", "achieve", "accuracy", "on", "this", "dataset", ".", "Moreover", ",", "we", "can", "see", "TC", "-", "LSTMs", "achieve", "better", "performance", "than", "LC", "-", "LSTMs", "on", "this", "task", ",", "which", "need", "fine", "-", "grained", "reasoning", "over", "pairs", "of", "words", "as", "well", "as", "phrases", ".", "[", "3rd", "neuron", "]", "[", "17th", "neuron", "]", "subsubsection", ":", "Understanding", "Behaviors", "of", "Neurons", "in", "C", "-", "LSTMs", "To", "get", "an", "intuitive", "understanding", "of", "how", "the", "C", "-", "LSTMs", "work", "on", "this", "problem", ",", "we", "examined", "the", "neuron", "activations", "in", "the", "last", "aggregation", "layer", "while", "evaluating", "the", "test", "set", "using", "TC", "-", "LSTMs", ".", "We", "find", "that", "some", "cells", "are", "bound", "to", "certain", "roles", ".", "Let", "denotes", "the", "activation", "of", "the", "-", "th", "neuron", "at", "the", "position", "of", ",", "where", "and", ".", "By", "visualizing", "the", "hidden", "state", "and", "analyzing", "the", "maximum", "activation", ",", "we", "can", "find", "that", "there", "exist", "multiple", "interpretable", "neurons", ".", "For", "example", ",", "when", "some", "contextualized", "local", "perspectives", "are", "semantically", "related", "at", "point", "of", "the", "sentence", "pair", ",", "the", "activation", "value", "of", "hidden", "neuron", "tend", "to", "be", "maximum", ",", "meaning", "that", "the", "model", "could", "capture", "some", "reasoning", "patterns", ".", "Figure", "[", "reference", "]", "illustrates", "this", "phenomenon", ".", "In", "Figure", "[", "reference", "]", "(", "a", ")", ",", "a", "neuron", "shows", "its", "ability", "to", "monitor", "the", "local", "contextual", "interactions", "about", "color", ".", "The", "activation", "in", "the", "patch", ",", "including", "the", "word", "pair", "\u201c", "(", "red", ",", "green", ")", "\u201d", ",", "is", "much", "higher", "than", "others", ".", "This", "is", "informative", "pattern", "for", "the", "relation", "prediction", "of", "these", "two", "sentences", ",", "whose", "ground", "truth", "is", "contradiction", ".", "An", "interesting", "thing", "is", "there", "are", "two", "words", "describing", "color", "in", "the", "sentence", "\u201c", "A", "person", "in", "a", "red", "shirt", "and", "black", "pants", "hunched", "over", ".", "\u201d", ".", "Our", "model", "ignores", "the", "useless", "word", "\u201c", "black", "\u201d", ",", "which", "indicates", "that", "this", "neuron", "selectively", "captures", "pattern", "by", "contextual", "understanding", ",", "not", "just", "word", "level", "interaction", ".", "In", "Figure", "[", "reference", "]", "(", "b", ")", ",", "another", "neuron", "shows", "that", "it", "can", "capture", "the", "local", "contextual", "interactions", ",", "such", "as", "\u201c", "(", "walking", "down", "the", "street", ",", "outside", ")", "\u201d", ".", "These", "patterns", "can", "be", "easily", "captured", "by", "pooling", "layer", "and", "provide", "a", "strong", "support", "for", "the", "final", "prediction", ".", "Table", "[", "reference", "]", "illustrates", "multiple", "interpretable", "neurons", "and", "some", "representative", "word", "or", "phrase", "pairs", "which", "can", "activate", "these", "neurons", ".", "These", "cases", "show", "that", "our", "models", "can", "capture", "contextual", "interactions", "beyond", "word", "level", ".", "subsubsection", ":", "Error", "Analysis", "Although", "our", "models", "C", "-", "LSTMs", "are", "more", "sensitive", "to", "the", "discrepancy", "of", "the", "semantic", "capacity", "between", "two", "sentences", ",", "some", "semantic", "mistakes", "at", "the", "phrasal", "level", "still", "exist", ".", "For", "example", ",", "our", "models", "failed", "to", "capture", "the", "key", "informative", "pattern", "when", "predicting", "the", "entailment", "sentence", "pair", "\u201c", "A", "girl", "takes", "off", "her", "shoes", "and", "eats", "blue", "cotton", "candy", "/", "The", "girl", "is", "eating", "while", "barefoot", ".", "\u201d", "Besides", ",", "despite", "the", "large", "size", "of", "the", "training", "corpus", ",", "it", "\u2019s", "still", "very", "different", "to", "solve", "some", "cases", ",", "which", "depend", "on", "the", "combination", "of", "the", "world", "knowledge", "and", "context", "-", "sensitive", "inferences", ".", "For", "example", ",", "given", "an", "entailment", "pair", "\u201c", "a", "man", "grabs", "his", "crotch", "during", "a", "political", "demonstration", "/", "The", "man", "is", "making", "a", "crude", "gesture", "\u201d", ",", "all", "models", "predict", "\u201c", "neutral", "\u201d", ".", "This", "analysis", "suggests", "that", "some", "architectural", "improvements", "or", "external", "world", "knowledge", "are", "necessary", "to", "eliminate", "all", "errors", "instead", "of", "simply", "scaling", "up", "the", "basic", "model", ".", "subsection", ":", "Experiment", "-", "II", ":", "Matching", "Question", "and", "Answer", "Matching", "question", "answering", "(", "MQA", ")", "is", "a", "typical", "task", "for", "semantic", "matching", ".", "Given", "a", "question", ",", "we", "need", "select", "a", "correct", "answer", "from", "some", "candidate", "answers", ".", "In", "this", "paper", ",", "we", "use", "the", "dataset", "collected", "from", "Yahoo", "!", "Answers", "with", "the", "getByCategory", "function", "provided", "in", "Yahoo", "!", "Answers", "API", ",", "which", "produces", "questions", "and", "corresponding", "best", "answers", ".", "We", "then", "select", "the", "pairs", "in", "which", "the", "length", "of", "questions", "and", "answers", "are", "both", "in", "the", "interval", ",", "thus", "obtaining", "question", "answer", "pairs", "to", "form", "the", "positive", "pairs", ".", "For", "negative", "pairs", ",", "we", "first", "use", "each", "question", "\u2019s", "best", "answer", "as", "a", "query", "to", "retrieval", "top", "results", "from", "the", "whole", "answer", "set", "with", "Lucene", ",", "where", "or", "answers", "will", "be", "selected", "randomly", "to", "construct", "the", "negative", "pairs", ".", "The", "whole", "dataset", "is", "divided", "into", "training", ",", "validation", "and", "testing", "data", "with", "proportion", ".", "Moreover", ",", "we", "give", "two", "test", "settings", ":", "selecting", "the", "best", "answer", "from", "5", "and", "10", "candidates", "respectively", ".", "subsubsection", ":", "Results", "Results", "of", "MQA", "are", "shown", "in", "the", "Table", "[", "reference", "]", ".", "For", "our", "models", ",", "due", "to", "stacking", "block", "more", "than", "three", "layers", "can", "not", "make", "significant", "improvements", "on", "this", "task", ",", "we", "just", "use", "three", "stacked", "C", "-", "LSTMs", ".", "By", "analyzing", "the", "evaluation", "results", "of", "question", "-", "answer", "matching", "in", "table", "[", "reference", "]", ",", "we", "can", "see", "strong", "interaction", "models", "(", "attention", "LSTMs", ",", "our", "C", "-", "LSTMs", ")", "consistently", "outperform", "the", "weak", "interaction", "models", "(", "NBOW", ",", "parallel", "LSTMs", ")", "with", "a", "large", "margin", ",", "which", "suggests", "the", "importance", "of", "modelling", "strong", "interaction", "of", "two", "sentences", ".", "Our", "proposed", "two", "C", "-", "LSTMs", "surpass", "the", "competitor", "methods", "and", "C", "-", "LSTMs", "augmented", "with", "multi", "-", "directions", "layers", "and", "multiple", "stacked", "blocks", "fully", "utilize", "multiple", "levels", "of", "abstraction", "to", "directly", "boost", "the", "performance", ".", "Additionally", ",", "LC", "-", "LSTMs", "is", "superior", "to", "TC", "-", "LSTMs", ".", "The", "reason", "may", "be", "that", "MQA", "is", "a", "relative", "simple", "task", ",", "which", "requires", "less", "reasoning", "abilities", ",", "compared", "with", "RTE", "task", ".", "Moreover", ",", "the", "parameters", "of", "LC", "-", "LSTMs", "are", "less", "than", "TC", "-", "LSTMs", ",", "which", "ensures", "the", "former", "can", "avoid", "suffering", "from", "overfitting", "on", "a", "relatively", "smaller", "corpus", ".", "section", ":", "Related", "Work", "Our", "architecture", "for", "sentence", "pair", "encoding", "can", "be", "regarded", "as", "strong", "interaction", "models", ",", "which", "have", "been", "explored", "in", "previous", "models", ".", "An", "intuitive", "paradigm", "is", "to", "compute", "similarities", "between", "all", "the", "words", "or", "phrases", "of", "the", "two", "sentences", ".", "socher2011dynamic", "[", "socher2011dynamic", "]", "firstly", "used", "this", "paradigm", "for", "paraphrase", "detection", ".", "The", "representations", "of", "words", "or", "phrases", "are", "learned", "based", "on", "recursive", "autoencoders", ".", "wan2015deep", "[", "wan2015deep", "]", "used", "LSTM", "to", "enhance", "the", "positional", "contextual", "interactions", "of", "the", "words", "or", "phrases", "between", "two", "sentences", ".", "The", "input", "of", "LSTM", "for", "one", "sentence", "does", "not", "involve", "another", "sentence", ".", "A", "major", "limitation", "of", "this", "paradigm", "is", "the", "interaction", "of", "two", "sentence", "is", "captured", "by", "a", "pre", "-", "defined", "similarity", "measure", ".", "Thus", ",", "it", "is", "not", "easy", "to", "increase", "the", "depth", "of", "the", "network", ".", "Compared", "with", "this", "paradigm", ",", "we", "can", "stack", "our", "C", "-", "LSTMs", "to", "model", "multiple", "-", "granularity", "interactions", "of", "two", "sentences", ".", "rocktaschel2015reasoning", "[", "rocktaschel2015reasoning", "]", "used", "two", "LSTMs", "equipped", "with", "attention", "mechanism", "to", "capture", "the", "iteration", "between", "two", "sentences", ".", "This", "architecture", "is", "asymmetrical", "for", "two", "sentences", ",", "where", "the", "obtained", "final", "representation", "is", "sensitive", "to", "the", "two", "sentences", "\u2019", "order", ".", "Compared", "with", "the", "attentive", "LSTM", ",", "our", "proposed", "C", "-", "LSTMs", "are", "symmetrical", "and", "model", "the", "local", "contextual", "interaction", "of", "two", "sequences", "directly", ".", "section", ":", "Conclusion", "and", "Future", "Work", "In", "this", "paper", ",", "we", "propose", "an", "end", "-", "to", "-", "end", "deep", "architecture", "to", "capture", "the", "strong", "interaction", "information", "of", "sentence", "pair", ".", "Experiments", "on", "two", "large", "scale", "text", "matching", "tasks", "demonstrate", "the", "efficacy", "of", "our", "proposed", "model", "and", "its", "superiority", "to", "competitor", "models", ".", "Besides", ",", "our", "visualization", "analysis", "revealed", "that", "multiple", "interpretable", "neurons", "in", "our", "proposed", "models", "can", "capture", "the", "contextual", "interactions", "of", "the", "words", "or", "phrases", ".", "In", "future", "work", ",", "we", "would", "like", "to", "incorporate", "some", "gating", "strategies", "into", "the", "depth", "dimension", "of", "our", "proposed", "models", ",", "like", "highway", "or", "residual", "network", ",", "to", "enhance", "the", "interactions", "between", "depth", "and", "other", "dimensions", "thus", "training", "more", "deep", "and", "powerful", "neural", "networks", ".", ".", "/", "nlp", ",", "..", "/", "ours", "."]}