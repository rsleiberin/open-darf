{"coref": {"BC5CDR": [[2966, 2967], [3159, 3162], [3163, 3164], [3190, 3193], [3194, 3197], [3210, 3213], [3214, 3217], [3698, 3699], [3710, 3713], [3714, 3717], [4242, 4245], [4246, 4249], [3148, 3149], [3155, 3156]], "CollaboNet": [[2, 3], [129, 130], [140, 141], [199, 200], [218, 219], [291, 292], [1110, 1111], [1132, 1133], [1149, 1150], [1444, 1445], [1519, 1520], [1552, 1553], [1639, 1640], [2532, 2533], [2533, 2534], [2572, 2573], [2624, 2625], [2690, 2691], [3483, 3484], [3630, 3631], [3690, 3691], [3909, 3910], [3921, 3922], [3939, 3940], [3947, 3948], [3989, 3990], [4019, 4020], [4123, 4124], [4235, 4236], [4457, 4458], [4528, 4529], [4546, 4547], [4573, 4574], [4591, 4592], [4614, 4615], [4682, 4683], [4784, 4785], [4856, 4857], [4877, 4878], [4940, 4941], [4966, 4967], [5250, 5251], [5282, 5283], [5301, 5302], [5337, 5338], [5406, 5407], [5422, 5423], [5434, 5435], [5453, 5454], [5676, 5677], [5419, 5420], [5466, 5467]], "F1": [[235, 237], [3291, 3293], [3305, 3307], [3852, 3854], [3926, 3928], [5290, 5292], [5373, 5375]], "JNLPBA": [[956, 958], [2968, 2969], [3038, 3039], [3086, 3087], [3218, 3219], [4250, 4251], [4309, 4310], [5009, 5011], [3064, 3065], [3115, 3116]], "Named_Entity_Recognition__NER_": [[109, 112], [368, 369], [369, 376], [463, 466], [467, 468], [556, 557], [756, 757], [884, 885], [1260, 1261], [1664, 1667], [1765, 1768], [5533, 5534], [5535, 5538], [11, 14], [43, 46], [136, 137], [500, 503], [1099, 1100], [1611, 1614], [2537, 2538], [3231, 3234], [3866, 3867], [4006, 4009], [5013, 5014], [5263, 5266], [5309, 5310], [5483, 5486]]}, "coref_non_salient": {"0": [[538, 542], [771, 778]], "1": [[33, 38], [57, 60], [737, 741]], "10": [[530, 531], [874, 875], [1789, 1791], [4054, 4056], [5219, 5221]], "100": [[297, 302], [513, 517]], "101": [[5185, 5187]], "102": [[2358, 2362]], "103": [[626, 629]], "104": [[2160, 2162]], "105": [[3398, 3402]], "106": [[4535, 4541]], "107": [[572, 577]], "108": [[600, 602]], "109": [[2454, 2456]], "11": [[794, 798], [869, 873], [1929, 1933], [2094, 2098], [3453, 3457], [3812, 3820]], "110": [[1470, 1473]], "111": [[460, 462]], "112": [[439, 444]], "113": [[1299, 1301]], "114": [[2381, 2384]], "115": [[3478, 3479]], "12": [[1477, 1481], [4688, 4690], [4731, 4733], [4950, 4954]], "13": [[1727, 1729], [1732, 1734], [1887, 1891], [2100, 2102], [5489, 5491], [5494, 5498]], "14": [[987, 991], [992, 993]], "15": [[1760, 1764], [2152, 2156], [5539, 5544]], "16": [[2563, 2567], [2666, 2670], [3571, 3575], [3655, 3659], [3767, 3771], [3951, 3955], [5296, 5300], [5332, 5336], [5394, 5398], [5528, 5532], [5552, 5556]], "17": [[209, 211], [1340, 1343]], "18": [[1010, 1011], [1057, 1059], [1076, 1078], [1122, 1124], [1178, 1181], [1192, 1195], [1231, 1233], [5519, 5520]], "19": [[2191, 2193], [2211, 2212], [2501, 2502]], "2": [[4619, 4621], [4642, 4643]], "20": [[3680, 3685], [3977, 3981], [5521, 5525]], "21": [[47, 48], [248, 249], [504, 506], [911, 913], [1997, 1999]], "22": [[5674, 5675], [5678, 5679], [5704, 5705]], "23": [[3792, 3794]], "24": [[1484, 1486], [1493, 1495], [4701, 4705], [4737, 4741], [4761, 4763], [4853, 4855], [4934, 4938]], "25": [[1778, 1780], [1834, 1836], [1873, 1875], [1882, 1884], [1982, 1984], [3394, 3396], [5565, 5567]], "26": [[2117, 2124], [2166, 2174], [5511, 5518]], "27": [[2732, 2734], [3549, 3551]], "28": [[3930, 3932], [4318, 4320], [4801, 4803]], "29": [[2568, 2569], [2575, 2576], [2592, 2593], [2641, 2642], [2693, 2694], [2763, 2764], [2814, 2815], [3660, 3661], [3744, 3745], [3780, 3781], [3798, 3799], [3807, 3808], [3822, 3823], [3839, 3840], [3844, 3845], [3888, 3889], [3898, 3899], [4121, 4122], [4230, 4231], [4274, 4275], [4533, 4534], [4617, 4618], [4667, 4668], [4916, 4917], [5312, 5313]], "3": [[2243, 2245], [2260, 2262], [2279, 2281], [2283, 2285], [2330, 2334], [3471, 3475]], "30": [[231, 232], [233, 234], [658, 659], [1174, 1175], [1183, 1184], [1222, 1223], [1256, 1257], [3278, 3279], [3301, 3302], [3303, 3304], [3848, 3849], [3850, 3851], [3924, 3925], [3943, 3944], [3945, 3946], [4022, 4023], [4034, 4035], [4039, 4040], [4046, 4047], [4971, 4972], [5376, 5377], [5378, 5379], [5425, 5426]], "31": [[1497, 1499], [1508, 1510], [4781, 4783]], "32": [[162, 164], [188, 190], [1449, 1451], [2789, 2791], [2808, 2810], [2880, 2882], [4697, 4699], [4963, 4965]], "33": [[2054, 2056]], "34": [[304, 309], [519, 524], [4432, 4437]], "35": [[3726, 3728]], "36": [[4512, 4518], [4880, 4885]], "37": [[4255, 4257], [4270, 4272], [4314, 4316]], "38": [[3686, 3687], [3956, 3957], [5526, 5527]], "39": [[1414, 1415], [1487, 1488]], "4": [[27, 30], [445, 447], [558, 561], [4425, 4429], [5437, 5441]], "40": [[3530, 3532]], "41": [[3994, 3996], [4460, 4462], [4486, 4488], [4494, 4496], [5412, 5414]], "42": [[2840, 2842], [2847, 2850]], "43": [[2843, 2844]], "44": [[295, 296], [1580, 1581]], "45": [[1723, 1725], [2204, 2206]], "46": [[786, 787], [5505, 5506], [813, 814], [1349, 1350], [1607, 1608], [1622, 1623], [1650, 1651], [2353, 2354], [2392, 2393], [2450, 2451], [2527, 2528], [2546, 2547], [2560, 2561], [2727, 2728], [2928, 2929], [4282, 4283], [5258, 5259]], "47": [[3591, 3592]], "48": [[3599, 3601]], "49": [[4127, 4131], [5171, 5173]], "5": [[893, 895], [1265, 1267], [4419, 4421]], "50": [[5735, 5738]], "51": [[3420, 3422]], "52": [[4903, 4904]], "53": [[1892, 1893], [1934, 1935], [3487, 3488], [5492, 5493]], "54": [[1938, 1941], [3824, 3827]], "55": [[2306, 2307]], "56": [[5696, 5697]], "57": [[4216, 4219], [4974, 4977]], "58": [[2512, 2514]], "59": [[5624, 5629]], "6": [[4578, 4584], [5487, 5488]], "60": [[5473, 5479]], "61": [[2836, 2838]], "62": [[3403, 3404]], "63": [[1739, 1741]], "64": [[2427, 2430]], "65": [[3144, 3146]], "66": [[2063, 2065]], "67": [[453, 457]], "68": [[568, 570]], "69": [[753, 754], [2144, 2145], [5557, 5558], [2130, 2131]], "7": [[779, 780], [2292, 2299], [2300, 2301], [2356, 2357], [2400, 2401], [3492, 3493], [3809, 3810], [5471, 5472]], "70": [[1969, 1973]], "71": [[2852, 2854]], "72": [[3264, 3268]], "73": [[3536, 3539]], "74": [[1942, 1943], [2002, 2003], [3828, 3829], [5499, 5504]], "75": [[682, 688], [691, 697]], "76": [[2163, 2165]], "77": [[2466, 2469]], "78": [[578, 581]], "79": [[2157, 2159]], "8": [[2066, 2067], [3358, 3359]], "80": [[3353, 3357]], "81": [[649, 655]], "82": [[122, 126]], "83": [[474, 478]], "84": [[3832, 3834], [3869, 3873], [3900, 3904]], "85": [[525, 529]], "86": [[4905, 4906]], "87": [[1436, 1439]], "88": [[6, 9]], "89": [[749, 752], [2126, 2129], [2183, 2186], [5559, 5562]], "9": [[1693, 1695], [3254, 3256]], "90": [[4221, 4223]], "91": [[782, 785], [5507, 5510], [2347, 2350], [2388, 2391]], "92": [[565, 567]], "93": [[471, 473]], "94": [[2134, 2136]], "95": [[15, 19]], "96": [[3425, 3427]], "97": [[1129, 1131]], "98": [[2313, 2316]], "99": [[245, 247]]}, "doc_id": "14ad9d060c1e8f0449e697ee189ac346353fbfbc", "method_subrelations": {"CollaboNet": [[[0, 10], "CollaboNet"]]}, "n_ary_relations": [{"Material": "BC5CDR", "Method": "CollaboNet", "Metric": "F1", "Task": "Named_Entity_Recognition__NER_", "score": "87.12"}, {"Material": "JNLPBA", "Method": "CollaboNet", "Metric": "F1", "Task": "Named_Entity_Recognition__NER_", "score": "78.58"}], "ner": [[2, 3, "Method"], [6, 9, "Method"], [15, 19, "Task"], [27, 30, "Task"], [33, 38, "Method"], [47, 48, "Task"], [57, 60, "Method"], [109, 112, "Task"], [122, 126, "Task"], [129, 130, "Method"], [140, 141, "Method"], [162, 164, "Method"], [188, 190, "Method"], [199, 200, "Method"], [209, 211, "Metric"], [218, 219, "Method"], [231, 232, "Metric"], [233, 234, "Metric"], [235, 237, "Metric"], [245, 247, "Method"], [248, 249, "Task"], [291, 292, "Method"], [295, 296, "Metric"], [297, 302, "Task"], [304, 309, "Task"], [368, 369, "Task"], [369, 376, "Task"], [439, 444, "Task"], [445, 447, "Task"], [453, 457, "Task"], [460, 462, "Task"], [463, 466, "Task"], [467, 468, "Task"], [471, 473, "Task"], [474, 478, "Task"], [504, 506, "Task"], [513, 517, "Task"], [519, 524, "Task"], [525, 529, "Task"], [530, 531, "Method"], [538, 542, "Method"], [556, 557, "Task"], [558, 561, "Task"], [565, 567, "Method"], [568, 570, "Method"], [572, 577, "Method"], [578, 581, "Method"], [600, 602, "Metric"], [626, 629, "Method"], [649, 655, "Method"], [658, 659, "Metric"], [682, 688, "Task"], [691, 697, "Task"], [737, 741, "Method"], [749, 752, "Method"], [753, 754, "Method"], [756, 757, "Task"], [771, 778, "Method"], [779, 780, "Method"], [782, 785, "Method"], [786, 787, "Method"], [794, 798, "Method"], [869, 873, "Method"], [874, 875, "Method"], [884, 885, "Task"], [893, 895, "Task"], [911, 913, "Task"], [956, 958, "Material"], [987, 991, "Task"], [992, 993, "Task"], [1010, 1011, "Method"], [1057, 1059, "Method"], [1076, 1078, "Method"], [1110, 1111, "Method"], [1122, 1124, "Method"], [1129, 1131, "Method"], [1132, 1133, "Method"], [1149, 1150, "Method"], [1174, 1175, "Metric"], [1178, 1181, "Method"], [1183, 1184, "Metric"], [1192, 1195, "Method"], [1222, 1223, "Metric"], [1231, 1233, "Method"], [1256, 1257, "Metric"], [1260, 1261, "Task"], [1265, 1267, "Task"], [1299, 1301, "Task"], [1340, 1343, "Metric"], [1414, 1415, "Method"], [1436, 1439, "Task"], [1444, 1445, "Method"], [1449, 1451, "Method"], [1470, 1473, "Task"], [1477, 1481, "Method"], [1484, 1486, "Method"], [1487, 1488, "Method"], [1493, 1495, "Method"], [1497, 1499, "Method"], [1508, 1510, "Method"], [1519, 1520, "Method"], [1552, 1553, "Method"], [1580, 1581, "Metric"], [1639, 1640, "Method"], [1664, 1667, "Task"], [1693, 1695, "Method"], [1723, 1725, "Method"], [1727, 1729, "Method"], [1732, 1734, "Method"], [1739, 1741, "Task"], [1760, 1764, "Task"], [1765, 1768, "Task"], [1778, 1780, "Method"], [1789, 1791, "Method"], [1834, 1836, "Method"], [1873, 1875, "Method"], [1882, 1884, "Method"], [1887, 1891, "Method"], [1892, 1893, "Method"], [1929, 1933, "Method"], [1934, 1935, "Method"], [1938, 1941, "Method"], [1942, 1943, "Method"], [1969, 1973, "Method"], [1982, 1984, "Method"], [1997, 1999, "Task"], [2002, 2003, "Method"], [2054, 2056, "Method"], [2063, 2065, "Method"], [2066, 2067, "Method"], [2094, 2098, "Method"], [2100, 2102, "Method"], [2117, 2124, "Method"], [2126, 2129, "Method"], [2134, 2136, "Method"], [2144, 2145, "Method"], [2152, 2156, "Task"], [2157, 2159, "Task"], [2160, 2162, "Task"], [2163, 2165, "Task"], [2166, 2174, "Method"], [2183, 2186, "Method"], [2191, 2193, "Method"], [2204, 2206, "Method"], [2211, 2212, "Method"], [2243, 2245, "Method"], [2260, 2262, "Method"], [2279, 2281, "Method"], [2283, 2285, "Method"], [2292, 2299, "Method"], [2300, 2301, "Method"], [2306, 2307, "Method"], [2313, 2316, "Task"], [2330, 2334, "Method"], [2356, 2357, "Method"], [2358, 2362, "Task"], [2381, 2384, "Method"], [2400, 2401, "Method"], [2427, 2430, "Method"], [2454, 2456, "Metric"], [2466, 2469, "Metric"], [2501, 2502, "Method"], [2512, 2514, "Method"], [2532, 2533, "Method"], [2533, 2534, "Method"], [2563, 2567, "Method"], [2568, 2569, "Method"], [2572, 2573, "Method"], [2575, 2576, "Method"], [2592, 2593, "Method"], [2624, 2625, "Method"], [2641, 2642, "Method"], [2666, 2670, "Method"], [2690, 2691, "Method"], [2693, 2694, "Method"], [2732, 2734, "Task"], [2763, 2764, "Method"], [2789, 2791, "Method"], [2808, 2810, "Method"], [2814, 2815, "Method"], [2836, 2838, "Method"], [2840, 2842, "Method"], [2843, 2844, "Method"], [2847, 2850, "Method"], [2852, 2854, "Task"], [2880, 2882, "Method"], [2966, 2967, "Material"], [2968, 2969, "Material"], [3038, 3039, "Material"], [3086, 3087, "Material"], [3144, 3146, "Task"], [3159, 3162, "Material"], [3163, 3164, "Material"], [3190, 3193, "Material"], [3194, 3197, "Material"], [3210, 3213, "Material"], [3214, 3217, "Material"], [3218, 3219, "Material"], [3254, 3256, "Method"], [3264, 3268, "Method"], [3278, 3279, "Metric"], [3291, 3293, "Metric"], [3301, 3302, "Metric"], [3303, 3304, "Metric"], [3305, 3307, "Metric"], [3353, 3357, "Method"], [3358, 3359, "Method"], [3394, 3396, "Method"], [3398, 3402, "Task"], [3403, 3404, "Task"], [3420, 3422, "Method"], [3425, 3427, "Metric"], [3453, 3457, "Method"], [3471, 3475, "Method"], [3478, 3479, "Method"], [3483, 3484, "Method"], [3487, 3488, "Method"], [3492, 3493, "Method"], [3530, 3532, "Metric"], [3536, 3539, "Method"], [3549, 3551, "Task"], [3571, 3575, "Method"], [3591, 3592, "Method"], [3599, 3601, "Metric"], [3630, 3631, "Method"], [3655, 3659, "Method"], [3660, 3661, "Method"], [3680, 3685, "Method"], [3686, 3687, "Method"], [3690, 3691, "Method"], [3698, 3699, "Material"], [3710, 3713, "Material"], [3714, 3717, "Material"], [3726, 3728, "Metric"], [3744, 3745, "Method"], [3767, 3771, "Method"], [3780, 3781, "Method"], [3792, 3794, "Method"], [3798, 3799, "Method"], [3807, 3808, "Method"], [3809, 3810, "Method"], [3812, 3820, "Method"], [3822, 3823, "Method"], [3824, 3827, "Method"], [3828, 3829, "Method"], [3832, 3834, "Method"], [3839, 3840, "Method"], [3844, 3845, "Method"], [3848, 3849, "Metric"], [3850, 3851, "Metric"], [3852, 3854, "Metric"], [3869, 3873, "Method"], [3888, 3889, "Method"], [3898, 3899, "Method"], [3900, 3904, "Method"], [3909, 3910, "Method"], [3921, 3922, "Method"], [3924, 3925, "Metric"], [3926, 3928, "Metric"], [3930, 3932, "Method"], [3939, 3940, "Method"], [3943, 3944, "Metric"], [3945, 3946, "Metric"], [3947, 3948, "Method"], [3951, 3955, "Method"], [3956, 3957, "Method"], [3977, 3981, "Method"], [3989, 3990, "Method"], [3994, 3996, "Method"], [4019, 4020, "Method"], [4022, 4023, "Metric"], [4034, 4035, "Metric"], [4039, 4040, "Metric"], [4046, 4047, "Metric"], [4054, 4056, "Method"], [4121, 4122, "Method"], [4123, 4124, "Method"], [4127, 4131, "Metric"], [4216, 4219, "Method"], [4221, 4223, "Task"], [4230, 4231, "Method"], [4235, 4236, "Method"], [4242, 4245, "Material"], [4246, 4249, "Material"], [4250, 4251, "Material"], [4255, 4257, "Method"], [4270, 4272, "Method"], [4274, 4275, "Method"], [4309, 4310, "Material"], [4314, 4316, "Method"], [4318, 4320, "Method"], [4419, 4421, "Task"], [4425, 4429, "Task"], [4432, 4437, "Task"], [4457, 4458, "Method"], [4460, 4462, "Method"], [4486, 4488, "Method"], [4494, 4496, "Method"], [4512, 4518, "Task"], [4528, 4529, "Method"], [4533, 4534, "Method"], [4535, 4541, "Task"], [4546, 4547, "Method"], [4573, 4574, "Method"], [4578, 4584, "Method"], [4591, 4592, "Method"], [4614, 4615, "Method"], [4617, 4618, "Method"], [4619, 4621, "Method"], [4642, 4643, "Method"], [4667, 4668, "Method"], [4682, 4683, "Method"], [4688, 4690, "Method"], [4697, 4699, "Method"], [4701, 4705, "Method"], [4731, 4733, "Method"], [4737, 4741, "Method"], [4761, 4763, "Method"], [4781, 4783, "Method"], [4784, 4785, "Method"], [4801, 4803, "Method"], [4853, 4855, "Method"], [4856, 4857, "Method"], [4877, 4878, "Method"], [4880, 4885, "Task"], [4903, 4904, "Method"], [4905, 4906, "Method"], [4916, 4917, "Method"], [4934, 4938, "Method"], [4940, 4941, "Method"], [4950, 4954, "Method"], [4963, 4965, "Method"], [4966, 4967, "Method"], [4971, 4972, "Metric"], [4974, 4977, "Method"], [5009, 5011, "Material"], [5171, 5173, "Metric"], [5185, 5187, "Task"], [5219, 5221, "Method"], [5250, 5251, "Method"], [5282, 5283, "Method"], [5290, 5292, "Metric"], [5296, 5300, "Method"], [5301, 5302, "Method"], [5312, 5313, "Method"], [5332, 5336, "Method"], [5337, 5338, "Method"], [5373, 5375, "Metric"], [5376, 5377, "Metric"], [5378, 5379, "Metric"], [5394, 5398, "Method"], [5406, 5407, "Method"], [5412, 5414, "Method"], [5422, 5423, "Method"], [5425, 5426, "Metric"], [5434, 5435, "Method"], [5437, 5441, "Task"], [5453, 5454, "Method"], [5471, 5472, "Method"], [5473, 5479, "Task"], [5487, 5488, "Method"], [5489, 5491, "Method"], [5492, 5493, "Method"], [5494, 5498, "Method"], [5499, 5504, "Method"], [5505, 5506, "Method"], [5507, 5510, "Method"], [5511, 5518, "Method"], [5519, 5520, "Method"], [5521, 5525, "Method"], [5526, 5527, "Method"], [5528, 5532, "Method"], [5533, 5534, "Task"], [5535, 5538, "Task"], [5539, 5544, "Task"], [5552, 5556, "Method"], [5557, 5558, "Method"], [5559, 5562, "Method"], [5565, 5567, "Method"], [5624, 5629, "Task"], [5674, 5675, "Method"], [5676, 5677, "Method"], [5678, 5679, "Method"], [5696, 5697, "Method"], [5704, 5705, "Method"], [5735, 5738, "Task"], [11, 14, "Task"], [43, 46, "Task"], [136, 137, "Task"], [500, 503, "Task"], [813, 814, "Method"], [1099, 1100, "Task"], [1349, 1350, "Method"], [1607, 1608, "Method"], [1611, 1614, "Task"], [1622, 1623, "Method"], [1650, 1651, "Method"], [2130, 2131, "Method"], [2347, 2350, "Method"], [2353, 2354, "Method"], [2388, 2391, "Method"], [2392, 2393, "Method"], [2450, 2451, "Method"], [2527, 2528, "Method"], [2537, 2538, "Task"], [2546, 2547, "Method"], [2560, 2561, "Method"], [2727, 2728, "Method"], [2928, 2929, "Method"], [3064, 3065, "Material"], [3115, 3116, "Material"], [3148, 3149, "Material"], [3155, 3156, "Material"], [3231, 3234, "Task"], [3866, 3867, "Task"], [4006, 4009, "Task"], [4282, 4283, "Method"], [5013, 5014, "Task"], [5258, 5259, "Method"], [5263, 5266, "Task"], [5309, 5310, "Task"], [5419, 5420, "Method"], [5466, 5467, "Method"], [5483, 5486, "Task"]], "sections": [[0, 376], [376, 1593], [1593, 1660], [1660, 1721], [1721, 1725], [1725, 1885], [1885, 2115], [2115, 2342], [2342, 2530], [2530, 2951], [2951, 2954], [2954, 3223], [3223, 3345], [3345, 3619], [3619, 3763], [3763, 3905], [3905, 4011], [4011, 4564], [4564, 5241], [5241, 5442], [5442, 5468], [5468, 5567], [5567, 5635], [5635, 5649], [5649, 5723], [5723, 5748], [5748, 5825]], "sentences": [[0, 14], [14, 31], [31, 54], [54, 76], [76, 93], [93, 113], [113, 114], [114, 139], [139, 169], [169, 194], [194, 218], [218, 238], [238, 250], [250, 274], [274, 310], [310, 313], [313, 315], [315, 319], [319, 321], [321, 324], [324, 326], [326, 334], [334, 337], [337, 339], [339, 347], [347, 353], [353, 357], [357, 360], [360, 376], [376, 379], [379, 389], [389, 405], [405, 432], [432, 445], [445, 463], [463, 482], [482, 499], [499, 530], [530, 556], [556, 578], [578, 603], [603, 625], [625, 648], [648, 690], [690, 729], [729, 742], [742, 761], [761, 789], [789, 805], [805, 809], [809, 821], [821, 831], [831, 835], [835, 876], [876, 900], [900, 914], [914, 927], [927, 950], [950, 966], [966, 987], [987, 1010], [1010, 1024], [1024, 1051], [1051, 1075], [1075, 1102], [1102, 1119], [1119, 1146], [1146, 1171], [1171, 1191], [1191, 1224], [1224, 1258], [1258, 1284], [1284, 1321], [1321, 1333], [1333, 1344], [1344, 1389], [1389, 1433], [1433, 1464], [1464, 1482], [1482, 1518], [1518, 1549], [1549, 1565], [1565, 1593], [1593, 1596], [1596, 1615], [1615, 1632], [1632, 1660], [1660, 1664], [1664, 1677], [1677, 1690], [1690, 1721], [1721, 1725], [1725, 1732], [1732, 1742], [1742, 1769], [1769, 1792], [1792, 1819], [1819, 1845], [1845, 1859], [1859, 1885], [1885, 1894], [1894, 1927], [1927, 1954], [1954, 1978], [1978, 2000], [2000, 2024], [2024, 2070], [2070, 2091], [2091, 2115], [2115, 2125], [2125, 2144], [2144, 2166], [2166, 2187], [2187, 2199], [2199, 2240], [2240, 2271], [2271, 2300], [2300, 2317], [2317, 2342], [2342, 2355], [2355, 2385], [2385, 2406], [2406, 2444], [2444, 2483], [2483, 2506], [2506, 2530], [2530, 2533], [2533, 2571], [2571, 2604], [2604, 2623], [2623, 2652], [2652, 2683], [2683, 2709], [2709, 2730], [2730, 2753], [2753, 2772], [2772, 2792], [2792, 2811], [2811, 2845], [2845, 2855], [2855, 2875], [2875, 2894], [2894, 2903], [2903, 2927], [2927, 2938], [2938, 2951], [2951, 2954], [2954, 2957], [2957, 2984], [2984, 3007], [3007, 3028], [3028, 3044], [3044, 3062], [3062, 3085], [3085, 3109], [3109, 3129], [3129, 3147], [3147, 3185], [3185, 3198], [3198, 3223], [3223, 3226], [3226, 3257], [3257, 3274], [3274, 3301], [3301, 3314], [3314, 3325], [3325, 3337], [3337, 3345], [3345, 3350], [3350, 3388], [3388, 3397], [3397, 3418], [3418, 3439], [3439, 3464], [3464, 3476], [3476, 3497], [3497, 3508], [3508, 3523], [3523, 3540], [3540, 3548], [3548, 3576], [3576, 3588], [3588, 3619], [3619, 3622], [3622, 3646], [3646, 3692], [3692, 3725], [3725, 3733], [3733, 3746], [3746, 3763], [3763, 3771], [3771, 3786], [3786, 3788], [3788, 3791], [3791, 3804], [3804, 3835], [3835, 3855], [3855, 3881], [3881, 3905], [3905, 3910], [3910, 3920], [3920, 3936], [3936, 3947], [3947, 3963], [3963, 3976], [3976, 4011], [4011, 4014], [4014, 4026], [4026, 4057], [4057, 4070], [4070, 4093], [4093, 4108], [4108, 4125], [4125, 4143], [4143, 4170], [4170, 4220], [4220, 4255], [4255, 4269], [4269, 4311], [4311, 4341], [4341, 4387], [4387, 4422], [4422, 4456], [4456, 4489], [4489, 4521], [4521, 4542], [4542, 4564], [4564, 4568], [4568, 4598], [4598, 4616], [4616, 4626], [4626, 4648], [4648, 4664], [4664, 4676], [4676, 4717], [4717, 4742], [4742, 4759], [4759, 4807], [4807, 4820], [4820, 4846], [4846, 4866], [4866, 4886], [4886, 4903], [4903, 4928], [4928, 4957], [4957, 4978], [4978, 4997], [4997, 5016], [5016, 5026], [5026, 5062], [5062, 5075], [5075, 5114], [5114, 5137], [5137, 5162], [5162, 5174], [5174, 5202], [5202, 5222], [5222, 5241], [5241, 5244], [5244, 5267], [5267, 5293], [5293, 5325], [5325, 5351], [5351, 5380], [5380, 5421], [5421, 5442], [5442, 5449], [5449, 5468], [5468, 5471], [5471, 5482], [5482, 5487], [5487, 5552], [5552, 5559], [5559, 5567], [5567, 5570], [5570, 5614], [5614, 5620], [5620, 5630], [5630, 5635], [5635, 5639], [5639, 5649], [5649, 5654], [5654, 5665], [5665, 5672], [5672, 5678], [5678, 5687], [5687, 5696], [5696, 5714], [5714, 5723], [5723, 5726], [5726, 5739], [5739, 5748], [5748, 5751], [5751, 5778], [5778, 5788], [5788, 5815], [5815, 5825]], "words": ["document", ":", "CollaboNet", ":", "collaboration", "of", "deep", "neural", "networks", "for", "biomedical", "named", "entity", "recognition", "Background", "Finding", "biomedical", "named", "entities", "is", "one", "of", "the", "most", "essential", "tasks", "in", "biomedical", "text", "mining", ".", "Recently", ",", "deep", "learning", "-", "based", "approaches", "have", "been", "applied", "to", "biomedical", "named", "entity", "recognition", "(", "BioNER", ")", "and", "showed", "promising", "results", ".", "However", ",", "as", "deep", "learning", "approaches", "need", "an", "abundant", "amount", "of", "training", "data", ",", "a", "lack", "of", "data", "can", "hinder", "performance", ".", "BioNER", "datasets", "are", "scarce", "resources", "and", "each", "dataset", "covers", "only", "a", "small", "subset", "of", "entity", "types", ".", "Furthermore", ",", "many", "bio", "entities", "are", "polysemous", ",", "which", "is", "one", "of", "the", "major", "obstacles", "in", "named", "entity", "recognition", ".", "Results", "To", "address", "the", "lack", "of", "data", "and", "the", "entity", "type", "misclassification", "problem", ",", "we", "propose", "CollaboNet", "which", "utilizes", "a", "combination", "of", "multiple", "NER", "models", ".", "In", "CollaboNet", ",", "models", "trained", "on", "a", "different", "dataset", "are", "connected", "to", "each", "other", "so", "that", "a", "target", "model", "obtains", "information", "from", "other", "collaborator", "models", "to", "reduce", "false", "positives", ".", "Every", "model", "is", "an", "expert", "on", "their", "target", "entity", "type", "and", "takes", "turns", "serving", "as", "a", "target", "and", "a", "collaborator", "model", "during", "training", "time", ".", "The", "experimental", "results", "show", "that", "CollaboNet", "can", "be", "used", "to", "greatly", "reduce", "the", "number", "of", "false", "positives", "and", "misclassified", "entities", "including", "polysemous", "words", ".", "CollaboNet", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "in", "terms", "of", "precision", ",", "recall", "and", "F1", "score", ".", "Conclusions", "We", "demonstrated", "the", "benefits", "of", "combining", "multiple", "models", "for", "BioNER", ".", "Our", "model", "has", "successfully", "reduced", "the", "number", "of", "misclassified", "entities", "and", "improved", "the", "performance", "by", "leveraging", "multiple", "datasets", "annotated", "for", "different", "entity", "types", ".", "Given", "the", "state", "-", "of", "-", "the", "-", "art", "performance", "of", "our", "model", ",", "we", "believe", "that", "CollaboNet", "can", "improve", "the", "accuracy", "of", "downstream", "biomedical", "text", "mining", "applications", "such", "as", "bio", "-", "entity", "relation", "extraction", ".", "Research", "addressref", "=", "aff1", ",", "noteref", "=", "n1", ",", "email=wonjin.info@gmail.com", "]", "WY", "Wonjin", "Yoon", "addressref", "=", "aff2", ",", "noteref", "=", "n1", ",", "email=chanhoso@korea.ac.kr", "]", "CHS", "Chan", "Ho", "So", "addressref", "=", "aff1", ",", "email=jinhyuk_lee@korea.ac.kr", "]", "JL", "Jinhyuk", "Lee", "addressref", "=", "aff1", ",", "corref", "=", "aff1", ",", "email=kangj@korea.ac.kr", "]", "JK", "Jaewoo", "Kang", "[", "i", "d", "=", "n1", "]", "Equal", "contributor", "NER", "Deep", "Learning", "Named", "Entity", "Recognition", "Text", "Mining", "section", ":", "Background", "The", "amount", "of", "biomedical", "text", "continues", "to", "increase", "rapidly", ".", "There", "were", "4.7", "million", "full", "-", "text", "online", "accessible", "articles", "in", "PubMed", "Central", "in", "2017", ".", "One", "of", "the", "obstacles", "in", "utilizing", "biomedical", "text", "data", "is", "that", "it", "is", "too", "large", "for", "a", "human", "to", "read", "or", "even", "search", "for", "needed", "information", ".", "This", "has", "led", "to", "the", "demand", "for", "automated", "extraction", "of", "valuable", "information", ".", "Text", "mining", "can", "be", "used", "to", "turn", "the", "time", "-", "consuming", "task", "into", "a", "fully", "automated", "job", ".", "Named", "Entity", "Recognition", "(", "NER", ")", "is", "the", "computerized", "procedure", "of", "recognizing", "and", "labeling", "entities", "in", "given", "texts", ".", "In", "the", "biomedical", "domain", ",", "typical", "entity", "types", "include", "disease", ",", "chemical", ",", "gene", "and", "protein", ".", "Biomedical", "named", "entity", "recognition", "(", "BioNER", ")", "is", "an", "essential", "building", "block", "of", "many", "downstream", "text", "mining", "applications", "such", "as", "extracting", "drug", "-", "drug", "interactions", "and", "disease", "-", "treatment", "relations", ".", "BioNER", "is", "also", "used", "when", "building", "a", "sophisticated", "biomedical", "entity", "search", "tool", "that", "enables", "users", "to", "pose", "complex", "queries", "to", "search", "for", "bio", "-", "entities", ".", "NER", "in", "biomedical", "text", "mining", "is", "focused", "mainly", "on", "dictionary", "-", ",", "rule", "-", ",", "and", "machined", "learning", "-", "based", "approaches", ".", "Dictionary", "based", "systems", "have", "a", "simple", "and", "intuitive", "structure", "but", "they", "can", "not", "handle", "unseen", "entities", "or", "polysemous", "words", ",", "resulting", "in", "low", "recall", ".", "Moreover", ",", "building", "and", "maintaining", "a", "comprehensive", "and", "up", "-", "to", "-", "date", "dictionary", "involves", "a", "considerable", "amount", "of", "manual", "work", ".", "The", "rule", "based", "approach", "is", "more", "scalable", ",", "but", "it", "needs", "hand", "crafted", "feature", "sets", "to", "fit", "a", "model", "to", "a", "dataset", ".", "These", "rule", "and", "dictionary", "-", "based", "approaches", "can", "achieve", "high", "precision", "but", "can", "produce", "incorrect", "predictions", "when", "a", "new", "word", ",", "which", "is", "not", "in", "the", "training", "data", ",", "appears", "in", "a", "sentence", "(", "out", "-", "of", "-", "vocabulary", "problem", ")", ".", "This", "out", "-", "of", "-", "vocabulary", "problem", "occurs", "frequently", "especially", "in", "the", "biomedical", "domain", ",", "as", "it", "is", "common", "for", "a", "new", "biomedical", "term", ",", "such", "as", "a", "new", "drug", "name", ",", "to", "be", "registered", "in", "this", "domain", ".", "Recently", ",", "studies", "have", "demonstrated", "the", "effectiveness", "of", "deep", "learning", "based", "methods", ".", "Sahu", "and", "Anand", "demonstrated", "the", "efficiency", "of", "Recurrent", "Neural", "Network", "(", "RNN", ")", "for", "NER", "in", "biomedical", "text", ".", "The", "model", "by", "Sahu", "and", "Anand", "is", "composed", "of", "a", "bidirectional", "Long", "Short", "-", "Term", "Memory", "Network", "(", "BiLSTM", ")", "and", "Conditional", "Random", "Field", "(", "CRF", ")", ".", "Sahu", "and", "Anand", "also", "used", "character", "level", "word", "embeddings", "but", "could", "not", "demonstrate", "their", "benefits", ".", "Habibi", "et", "al", ".", "combined", "the", "BiLSTM", "-", "CRF", "model", "implementation", "of", "Lample", "et", "al", ".", "and", "the", "word", "embeddings", "of", "Pyysalo", "et", "al", ".", ".", "Habibi", "et", "al", ".", "utilized", "character", "level", "word", "embeddings", "to", "capture", "characteristics", ",", "such", "as", "orthographic", "features", ",", "of", "bio", "-", "medical", "entities", "and", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", ",", "demonstrating", "the", "effectiveness", "of", "character", "level", "word", "embeddings", "in", "BioNER", ".", "Although", "these", "models", "showed", "some", "promising", "results", ",", "NER", "is", "still", "a", "very", "challenging", "task", "in", "the", "biomedical", "domain", "for", "the", "following", "reasons", ".", "First", ",", "a", "limited", "amount", "of", "training", "data", "is", "available", "for", "BioNER", "tasks", ".", "Gold", "-", "standard", "datasets", "contain", "annotations", "of", "one", "or", "two", "entity", "types", ".", "For", "example", ",", "the", "NCBI", "corpus", "includes", "annotations", "of", "diseases", "but", "not", "of", "other", "types", "of", "entities", "such", "as", "genes", "and", "proteins", ".", "On", "the", "other", "hand", ",", "the", "JNLPBA", "corpus", "contains", "annotations", "of", "only", "genes", "and", "proteins", ".", "Therefore", ",", "the", "data", "for", "each", "entity", "type", "comprises", "only", "a", "small", "portion", "of", "the", "total", "amount", "of", "annotated", "data", ".", "Multi", "-", "task", "learning", "(", "MTL", ")", "is", "a", "method", "for", "training", "a", "single", "model", "for", "multiple", "tasks", "at", "the", "same", "time", ".", "MTL", "can", "leverage", "different", "datasets", "that", "are", "collected", "for", "different", "but", "related", "tasks", ".", "Although", "extracting", "genes", "is", "different", "from", "extracting", "chemicals", ",", "both", "tasks", "require", "learning", "some", "common", "features", "that", "can", "help", "understand", "the", "linguistic", "expressions", "of", "biomedical", "texts", ".", "Crichton", "et", "al", ".", "developed", "an", "MTL", "model", "that", "was", "trained", "on", "various", "source", "datasets", "containing", "annotations", "of", "different", "subsets", "of", "entity", "types", ".", "An", "MTL", "model", "by", "Wang", "et", "al", ".", "achieved", "performance", "comparable", "to", "that", "of", "the", "state", "-", "of", "-", "the", "-", "art", "single", "task", "NER", "models", ".", "Inspired", "by", "the", "previous", "studies", ",", "we", "propose", "CollaboNet", "which", "uses", "the", "collaboration", "of", "multiple", "models", ".", "Unlike", "the", "conventional", "MTL", "methods", "which", "use", "only", "a", "single", "static", "model", ",", "CollaboNet", "is", "composed", "of", "multiple", "models", "trained", "on", "different", "datasets", "for", "different", "tasks", ".", "Each", "model", "in", "CollaboNet", "is", "trained", "on", "dataset", "annotated", "on", "a", "specific", "type", "of", "entity", "and", "becomes", "an", "expert", "on", "their", "own", "entity", "type", ".", "Despite", "the", "high", "recall", "obtained", "by", "the", "MTL", "based", "models", ",", "the", "precision", "of", "these", "models", "is", "relatively", "low", ".", "Since", "MTL", "based", "models", "are", "trained", "on", "multiple", "types", "of", "entities", "and", "larger", "training", "data", ",", "they", "have", "a", "broader", "coverage", "of", "various", "biomedical", "entities", ",", "which", "naturally", "results", "in", "high", "recall", ".", "On", "the", "other", "hand", ",", "as", "the", "MTL", "models", "are", "trained", "on", "combinations", "of", "different", "entity", "types", ",", "they", "tend", "to", "have", "difficulty", "in", "differentiating", "among", "entity", "types", ",", "resulting", "in", "lower", "precision", ".", "Another", "reason", "NER", "is", "difficult", "in", "the", "biomedical", "domain", "is", "that", "an", "entity", "could", "be", "labeled", "as", "different", "entity", "types", "depending", "on", "its", "textual", "context", ".", "In", "our", "experiments", ",", "we", "observed", "that", "many", "incorrect", "predictions", "were", "a", "result", "of", "the", "polysemy", "problem", ",", "in", "which", "a", "word", ",", "for", "example", ",", "can", "be", "used", "as", "both", "a", "gene", "and", "disease", "name", ".", "Models", "designed", "to", "predict", "disease", "entities", "misidentify", "some", "genes", "as", "diseases", ".", "This", "misidentification", "of", "entity", "types", "increases", "the", "false", "positive", "rate", ".", "For", "instance", ",", "BiLSTM", "-", "CRF", "based", "models", "for", "disease", "entities", "mistakenly", "label", "the", "gene", "name", "\u201c", "BRCA1", "\u201d", "as", "a", "disease", "entity", "because", "there", "are", "disease", "names", "such", "as", "\u201c", "BRCA1", "abnormalities", "\u201d", "or", "\u201c", "Brca1", "-", "deficient", "\u201d", "in", "the", "training", "set", ".", "Besides", ",", "the", "training", "set", "that", "annotates", "\u201c", "VHL", "\u201d", "(", "Von", "Hippel", "-", "Lindau", "disease", ")", "as", "a", "disease", "entity", "confuses", "the", "models", "because", "VHL", "is", "also", "used", "as", "a", "gene", "name", ",", "since", "the", "mutation", "of", "this", "gene", "causes", "VHL", "disease", ".", "To", "solve", "the", "false", "positive", "problems", "due", "to", "polysemous", "words", ",", "CollaboNet", "aggregates", "the", "results", "of", "collaborator", "models", ",", "and", "uses", "them", "as", "an", "additional", "input", "to", "the", "target", "model", ".", "Consider", "the", "case", "of", "predicting", "the", "disease", "entity", "VHL", "utilizing", "the", "outputs", "of", "gene", "and", "chemical", "models", ".", "Once", "a", "gene", "model", "predicts", "VHL", "as", "a", "gene", ",", "the", "gene", "model", "informs", "a", "disease", "model", "that", "VHL", "is", "a", "gene", "entity", "so", "that", "the", "disease", "model", "will", "not", "predict", "VHL", "as", "a", "disease", ".", "In", "CollaboNet", ",", "each", "model", "is", "individually", "trained", "on", "an", "entity", "type", "and", "then", "further", "trained", "on", "the", "outputs", "of", "other", "models", "that", "are", "trained", "on", "the", "other", "entity", "types", ".", "The", "models", "in", "CollaboNet", "take", "turns", "in", "being", "the", "target", "and", "collaborator", "models", "during", "training", ".", "Consequently", ",", "each", "model", "is", "an", "expert", "in", "its", "own", "domain", "and", "helps", "improve", "the", "accuracy", "by", "leveraging", "the", "multi", "-", "domain", "information", "from", "the", "other", "models", ".", "section", ":", "Methods", "In", "the", "following", "section", ",", "we", "first", "discuss", "a", "BiLSTM", "-", "CRF", "model", "for", "biomedical", "named", "entity", "recognition", ".", "The", "overall", "structure", "of", "the", "BiLSTM", "-", "CRF", "model", "is", "illustrated", "in", "Figure", "[", "reference", "]", ".", "Next", ",", "we", "introduce", "the", "structure", "of", "CollaboNet", ",", "which", "is", "comprised", "of", "a", "set", "of", "BiLSTM", "-", "CRF", "models", "as", "shown", "in", "Figure", "[", "reference", "]", ".", "subsection", ":", "Problem", "Definition", "Named", "entity", "recognition", "involves", "annotating", "words", "in", "a", "sentence", "as", "named", "entities", ".", "More", "formally", ",", "given", "an", "input", "sequence", ",", "we", "predict", "corresponding", "labels", ".", "We", "use", "the", "BIOES", "scheme", "for", "representing", ",", "where", "B", "stands", "for", "Beginning", ",", "I", "for", "Inside", ",", "O", "for", "Out", ",", "E", "for", "End", ",", "and", "S", "for", "Single", ".", "subsection", ":", "Embedding", "Layer", "subsubsection", ":", "Word", "Embedding", "(", "WE", ")", "Word", "embedding", "is", "an", "effective", "way", "of", "representing", "words", ".", "As", "word", "embeddings", "capture", "semantic", "and", "syntactic", "meanings", "of", "words", ",", "they", "have", "been", "widely", "used", "in", "various", "natural", "language", "processing", "tasks", "including", "named", "entity", "recognition", ".", "The", "experiment", "of", "Habibi", "et", "al", ".", "showed", "that", "word", "embeddings", "trained", "on", "biomedical", "corpora", "notably", "improved", "the", "performance", "of", "BioNER", "models", ".", "Pyysalo", "et", "al", ".", "were", "the", "first", "to", "suggest", "training", "word", "embeddings", "on", "biomedical", "corpora", "from", "PubMed", ",", "PubMed", "Central", "(", "PMC", ")", ",", "and", "Wikipedia", ".", "The", "results", "of", "Pyysalo", "et", "al", ".", "and", "Habibi", "et", "al", ".", "suggest", "that", "using", "word", "embeddings", "trained", "on", "biomedical", "corpora", "is", "essential", "for", "BioNER", ".", "We", "also", "use", "the", "trained", "word", "embeddings", "provided", "by", "Pyysalo", "et", "al", ".", ".", "For", "each", "word", "in", "a", "sequence", ",", "we", "denote", "a", "word", "represented", "by", "a", "word", "embedding", "as", "where", "is", "a", "dimension", "of", "the", "word", "embedding", ".", "subsubsection", ":", "Character", "Level", "Word", "Embedding", "(", "CLWE", ")", "To", "give", "our", "model", "character", "level", "morphological", "information", "(", "e.g.", ",", "\u2018", "-", "ase", "\u2019", "is", "common", "in", "protein", "entities", ")", ",", "we", "also", "leverage", "the", "character", "level", "information", "of", "each", "word", ".", "We", "build", "character", "level", "word", "embeddings", "(", "CLWEs", ")", "using", "a", "convolution", "neural", "network", "(", "CNN", ")", ",", "similar", "to", "the", "work", "of", "Santos", "and", "Zadrozny", ".", "Given", "a", "word", ",", "composed", "of", "number", "of", "characters", ",", "we", "represent", "where", "is", "a", "randomly", "initialized", "character", "embedding", "for", "each", "unique", "character", ".", "Note", "that", "unlike", "the", "word", "embeddings", "trained", "on", "separate", "biomedical", "corpora", ",", "character", "embeddings", "are", "learned", "from", "only", "the", "BioNER", "task", ".", "For", "the", "CNN", ",", "padding", "of", "the", "proper", "size", "(", ")", "according", "to", "window", "size", "should", "be", "attached", "before", "and", "after", "each", "word", ".", "We", "obtain", "a", "window", "vector", "by", "simply", "concatenating", "the", "character", "embeddings", "of", "with", "the", "character", "embeddings", "of", "characters", "on", "both", "sides", ":", "From", "the", "window", "vector", ",", "we", "perform", "a", "convolution", "operation", "as", "follows", ":", "where", "and", "denote", "a", "trainable", "filter", "and", "bias", ",", "respectively", ".", "We", "obtain", "the", "element", "-", "wise", "maximum", "values", ",", "and", "the", "output", "is", "a", "character", "level", "word", "embedding", "denoted", "as", ".", "We", "concatenate", "the", "character", "level", "word", "embedding", "with", "the", "word", "embedding", "trained", "on", "biomedical", "corpora", "as", "to", "utilize", "both", "representations", "in", "our", "model", ".", "subsection", ":", "Long", "Short", "-", "Term", "Memory", "(", "LSTM", ")", "A", "Recurrent", "Neural", "Network", "(", "RNN", ")", "is", "a", "neural", "network", "that", "effectively", "handles", "variable", "-", "length", "inputs", ".", "RNNs", "have", "proven", "to", "be", "useful", "in", "various", "natural", "language", "processing", "tasks", "including", "language", "modeling", ",", "speech", "recognition", "and", "machine", "translation", ".", "Long", "Short", "-", "Term", "Memory", "(", "LSTM", ")", "is", "one", "of", "the", "most", "frequently", "used", "variants", "of", "recurrent", "neural", "networks", ".", "Our", "model", "uses", "the", "LSTM", "architecture", "from", "Graves", "et", "al", ".", ".", "Given", "the", "outputs", "of", "an", "embedding", "layer", ",", "the", "hidden", "states", "of", "LSTM", "are", "calculated", "as", "follows", ":", "where", "and", "denote", "a", "logistic", "sigmoid", "function", "and", "a", "hyperbolic", "tangent", "function", ",", "respectively", ",", "and", "is", "an", "element", "-", "wise", "product", ".", "We", "use", "a", "forward", "LSTM", "that", "extracts", "the", "representations", "of", "inputs", "in", "the", "forward", "direction", ",", "and", "we", "use", "a", "backward", "LSTM", "that", "represents", "the", "inputs", "in", "the", "backward", "direction", ".", "We", "concatenate", "the", "two", "states", "coming", "from", "the", "forward", "LSTM", "and", "the", "backward", "LSTM", "to", "form", "the", "hidden", "states", "of", "the", "bi", "-", "directional", "LSTM", "(", "BiLSTM", ")", ".", "BiLSTM", ",", "proposed", "by", "Schuster", "and", "Paliwal", ",", "was", "extensively", "used", "in", "various", "sequence", "encoding", "tasks", ".", "We", "obtain", "a", "set", "of", "hidden", "states", "where", "and", "are", "hidden", "states", "of", "forward", "and", "backward", "LSTMs", ",", "respectively", ",", "at", "a", "time", "step", ".", "subsection", ":", "Bidirectional", "LSTM", "with", "Conditional", "Random", "Field", "(", "BiLSTM", "-", "CRF", ")", "While", "BiLSTM", "handles", "long", "term", "dependency", "problems", "as", "well", "as", "backward", "dependency", "issues", ",", "modeling", "dependencies", "among", "adjacent", "output", "tags", "helps", "improve", "the", "performance", "of", "the", "sequence", "labeling", "models", ".", "We", "applied", "a", "Conditional", "Random", "Field", "(", "CRF", ")", "to", "the", "output", "layer", "of", "the", "BiLSTM", "to", "capture", "these", "dependencies", ".", "First", ",", "we", "compute", "the", "probability", "of", "each", "label", "given", "the", "sequence", "as", "follows", ":", "where", "and", "are", "parameters", "of", "the", "fully", "connected", "layer", "for", "BIOES", "tags", ",", "and", "the", "function", "computes", "the", "probability", "of", "each", "tag", ".", "Based", "on", "the", "probability", "and", "the", "CRF", "layer", ",", "our", "training", "objective", "to", "minimize", "is", "defined", "as", "follows", ":", "where", "is", "the", "cross", "entropy", "loss", "for", "the", "label", ",", "and", "is", "the", "negative", "sentence", "-", "level", "log", "likelihood", ".", "The", "score", "of", "a", "tag", "is", "the", "summation", "of", "the", "transition", "score", "and", "the", "emission", "score", "from", "our", "LSTM", "at", "time", "step", ".", "At", "test", "time", ",", "we", "use", "Viterbi", "decoding", "to", "find", "the", "most", "probable", "sequence", "given", "the", "outputs", "of", "the", "BiLSTM", "-", "CRF", "model", ".", "subsection", ":", "CollaboNet", "CollaboNet", ",", "our", "novel", "NER", "model", ",", "is", "composed", "of", "multiple", "BiLSTM", "-", "CRF", "models", ",", "and", "following", "the", "terminology", "of", ",", "we", "call", "each", "BiLSTM", "-", "CRF", "model", "a", "single", "-", "task", "model", "(", "STM", ")", ".", "In", "CollaboNet", ",", "each", "STM", "is", "trained", "on", "a", "specific", "dataset", "as", "illustrated", "in", "Figure", "[", "reference", "]", ",", "and", "each", "STM", "is", "regarded", "as", "an", "expert", "on", "a", "particular", "entity", "type", ".", "These", "experts", "help", "each", "other", "since", "the", "knowledge", "of", "each", "expert", "is", "transferred", "to", "all", "the", "other", "experts", ".", "Training", "CollaboNet", "consists", "of", "phases", "and", "in", "each", "phase", ",", "except", "for", "the", "first", "preparation", "phase", ",", "every", "STM", "is", "trained", "on", "a", "single", "dataset", "for", "one", "epoch", ".", "More", "formally", ",", "let", "us", "denote", "a", "set", "of", "datasets", "as", ",", "and", "a", "single", "-", "task", "model", "as", ",", "which", "is", "trained", "on", "the", "-", "th", "dataset", "in", "phase", ".", "In", "the", "preparation", "phase", "(", ")", "of", "CollaboNet", ",", "each", "STM", "is", "trained", "independently", "on", "a", "corresponding", "dataset", "until", "the", "performance", "of", "each", "model", "converges", ".", "Note", "that", "an", "STM", "in", "the", "preparation", "phase", "(", ")", "is", "the", "same", "as", "a", "single", "BiLSTM", "-", "CRF", "model", ".", "In", "the", "preparation", "phase", ",", "we", "assume", "that", "each", "model", "has", "obtained", "the", "maximum", "amount", "of", "knowledge", "about", "the", "-", "th", "dataset", ".", "In", "the", "subsequent", "phases", ",", "where", ",", "we", "select", "an", "STM", "which", "is", "an", "expert", "on", "the", "dataset", ".", "We", "refer", "to", "the", "target", "STM", "as", "the", "target", "model", ",", "and", "the", "remaining", "STMs", "as", "the", "collaborator", "models", ".", "To", "train", "the", "target", "model", ",", "we", "use", "inputs", "from", "the", "target", "dataset", "and", "outputs", "from", "collaborator", "models", ".", "We", "train", "each", "STM", "on", "its", "dataset", "for", "one", "epoch", ",", "and", "change", "the", "target", "STM", "as", "follows", ":", "where", "denotes", "concatenation", "and", "denotes", "an", "aggregation", "operation", "such", "as", "max", "pooling", "or", "concatenation", ".", "We", "used", "weighted", "max", "pooling", "for", "the", "aggregation", "operation", ".", "is", "the", "input", "sequences", "of", "-", "th", "dataset", ",", "and", "is", "output", ",", "defined", "by", "Equation", "[", "reference", "]", ".", "When", "aggregating", "the", "results", "of", "collaborator", "models", ",", "we", "multiply", "each", "of", "the", "results", "by", "a", "weighting", "factor", ".", "The", "results", "are", "used", "to", "train", "the", "model", ".", "Using", "the", "outputs", "obtained", "by", "Equation", "[", "reference", "]", ",", "we", "train", "for", "one", "epoch", ",", "and", "it", "becomes", "in", "the", "next", "phase", ".", "The", "CRF", "layer", "is", "attached", "to", "the", "final", "output", "of", ".", "Once", "we", "iterate", "all", "the", "target", "datasets", ",", "the", "next", "phase", "begins", ".", "section", ":", "Experiments", "subsection", ":", "Datasets", "We", "used", "5", "datasets", "(", "BC2GM", ",", "BC4CHEMD", ",", "BC5CDR", ",", "JNLPBA", ",", "NCBI", ")", ",", "all", "of", "which", "were", "collected", "by", "Crichton", "et", "al", ".", ".", "Each", "of", "the", "5", "datasets", "were", "constructed", "from", "MEDLINE", "abstracts", ",", "and", "we", "used", "the", "BIOES", "notation", "format", "for", "named", "entity", "labels", ".", "Each", "dataset", "focuses", "on", "one", "of", "the", "three", "biomedical", "entity", "types", ":", "disease", ",", "chemical", ",", "and", "gene", "/", "protein", ".", "We", "did", "not", "use", "cell", "-", "type", "entity", "tags", "from", "JNLPBA", "for", "the", "entity", "types", ".", "All", "the", "datasets", "are", "comprised", "of", "pairs", "of", "input", "sentences", "and", "biomedical", "entity", "labels", "for", "the", "sentences", ".", "While", "the", "JNLPBA", "dataset", "has", "only", "training", "and", "test", "sets", ",", "the", "other", "four", "datasets", "contain", "training", ",", "development", "and", "test", "sets", ".", "For", "JNLPBA", ",", "we", "used", "part", "of", "its", "training", "set", "as", "its", "development", "set", "which", "is", "the", "same", "size", "as", "its", "test", "set", ".", "Also", ",", "we", "found", "that", "the", "JNLPBA", "dataset", "from", "Crichton", "et", "al", ".", "contained", "sentences", "that", "were", "incorrectly", "split", ".", "So", "we", "preprocessed", "the", "original", "dataset", "by", "Kim", "et", "al", ".", "with", "a", "more", "accurate", "sentence", "separation", ".", "The", "BC5CDR", "dataset", "has", "the", "sub", "-", "datasets", "BC5CDR", "-", "chem", ",", "BC5CDR", "-", "disease", "and", "BC5CDR", "-", "both", ",", "and", "they", "contain", "chemical", "entity", "types", ",", "disease", "entity", "types", ",", "and", "both", "entity", "types", ",", "respectively", ".", "We", "reported", "the", "performance", "on", "BC5CDR", "-", "chem", "and", "BC5CDR", "-", "disease", ".", "We", "have", "a", "total", "of", "six", "datasets", ":", "BC2GM", ",", "BC4CHEMD", ",", "BC5CDR", "-", "chem", ",", "BC5CDR", "-", "disease", ",", "JNLPBA", ",", "and", "NCBI", ".", "subsection", ":", "Metric", "For", "the", "evaluation", "of", "the", "named", "entity", "recognition", "task", ",", "true", "positives", "are", "counted", "from", "exact", "matches", "between", "predicted", "entity", "spans", "and", "ground", "truth", "spans", "based", "on", "the", "BIOES", "notation", ".", "We", "also", "designed", "and", "applied", "a", "simple", "post", "-", "processing", "step", "that", "corrects", "invalid", "BIOES", "sequences", ".", "This", "simple", "step", "improved", "precision", "by", "about", "0.1", "%", "to", "0.5", "%", ",", "and", "thus", "boosted", "the", "F1", "score", "by", "about", "0.04", "%", "to", "0.3", "%", ".", "Precision", ",", "recall", "and", "F1", "scores", "were", "used", "to", "evaluate", "the", "models", ".", "M", "=", "total", "number", "of", "predicted", "entities", "in", "the", "sequence", ".", "N", "=", "total", "number", "of", "ground", "truth", "entities", "in", "the", "sequence", ".", "C", "=", "total", "number", "of", "correct", "entities", ".", "subsection", ":", "Settings", "and", "hyperparameters", "We", "used", "the", "200", "dimensional", "word", "embedding", "(", "WE", ")", "by", "Pyysalo", "et", "al", ".", "which", "was", "trained", "on", "PubMed", ",", "PubMed", "Central", "(", "PMC", ")", "and", "Wikipedia", "text", ",", "and", "it", "contains", "about", "5", "million", "words", ".", "Word2vec", "was", "used", "to", "train", "the", "word", "embedding", ".", "For", "character", "level", "word", "embedding", "(", "CLWE", ")", ",", "we", "used", "window", "sizes", "of", "3", ",", "5", ",", "and", "7", ".", "We", "used", "AdaGrad", "optimizer", "with", "an", "initial", "learning", "rate", "of", "0.01", "which", "was", "exponentially", "decayed", "for", "each", "epoch", "by", "0.95", ".", "The", "dimension", "of", "the", "character", "embedding", "(", ")", "was", "30", "and", "dimension", "of", "the", "character", "level", "word", "embedding", "(", ")", "was", "200", "*", "3", ".", "We", "used", "300", "hidden", "units", "for", "both", "forward", "and", "backward", "LSTMs", ".", "We", "applied", "dropout", "to", "two", "parts", "of", "CollaboNet", ":", "outputs", "of", "CLWE", "(", "0.5", ")", "and", "BiLSTM", "(", "0.3", ")", ".", "The", "mini", "-", "batch", "size", "for", "our", "experiment", "was", "10", ".", "Most", "of", "our", "hyperparameter", "settings", "are", "similar", "to", "those", "of", "Wang", "et", "al", ".", ".", "Only", "a", "few", "settings", "such", "as", "the", "dropout", "rates", "were", "different", "from", "the", "hyperparameters", "of", "Wang", ".", "We", "tuned", "these", "hyperparameters", "using", "validation", "sets", ".", "The", "preparation", "phase", "for", "6", "datasets", "takes", "approximately", "900", "minutes", ",", "which", "is", "the", "same", "amount", "of", "time", "it", "takes", "to", "train", "6", "single", "-", "task", "models", ".", "The", "rest", "of", "the", "phases", "require", "3000", "minutes", "for", "complete", "training", ".", "If", "we", "exclude", "BC4GM", ",", "the", "largest", "dataset", ",", "then", "the", "training", "time", "for", "is", "reduced", "to", "1500", "minutes", ",", "which", "is", "half", "the", "time", "required", "for", "the", "remainder", "phases", ".", "section", ":", "Results", "The", "experimental", "results", "of", "the", "baseline", "models", "and", "CollaboNet", "are", "provided", "in", "Table", "[", "reference", "]", "and", "Table", "[", "reference", "]", ",", "respectively", ".", "Table", "[", "reference", "]", "shows", "the", "results", "of", "the", "single", "-", "task", "models", "(", "STMs", ")", "where", "Table", "[", "reference", "]", "shows", "the", "comparison", "between", "the", "existing", "state", "-", "of", "-", "the", "-", "art", "multi", "-", "task", "learning", "model", "(", "MTM", ")", "and", "our", "CollaboNet", ".", "Since", "Wang", "et", "al", ".", "used", "BC5CDR", "-", "both", "for", "their", "experiments", ",", "we", "reran", "their", "models", "on", "BC5CDR", "-", "chem", "and", "BC5CDR", "-", "disease", "for", "a", "fair", "comparison", "with", "other", "models", ".", "The", "rerun", "scores", "are", "denoted", "with", "asterisks", ".", "We", "conducted", "10", "experiments", "with", "10", "different", "random", "initializations", "on", "our", "STM", ".", "We", "take", "arithmetic", "mean", "over", "the", "6", "datasets", "to", "compare", "the", "overall", "performance", "of", "each", "model", ".", "subsection", ":", "Performance", "of", "Single", "-", "Task", "Models", "Table", "[", "reference", "]", "shows", "the", "results", "of", "the", "STMs", "of", "Habibi", "et", "al", ".", "and", "Wang", "et", "al", ".", "(", "baseline", "STMs", ")", ",", "and", "our", "STM", "on", "the", "6", "datasets", ".", "While", "the", "baseline", "STMs", "applied", "BiLSTM", "for", "the", "Character", "Level", "Word", "Embedding", "(", "CLWE", ")", "layer", ",", "our", "STM", "used", "Convolution", "Neural", "Network", "(", "CNN", ")", "for", "the", "CLWE", "layer", ".", "On", "average", ",", "our", "STM", "significantly", "outperforms", "the", "baseline", "STMs", "in", "terms", "of", "precision", ",", "recall", "and", "F1", "score", ".", "Although", ",", "Sahu", "and", "Anand", "tried", "to", "improve", "the", "performance", "of", "NER", "models", "with", "CNN", "based", "CLWE", "layer", ",", "they", "have", "failed", "to", "do", "so", ".", "In", "our", "experiments", ",", "however", ",", "our", "STM", "outperforms", "other", "baseline", "STMs", ",", "demonstrating", "the", "effectiveness", "of", "STM", "with", "CNN", "based", "CLWE", "layer", ".", "subsection", ":", "Performance", "of", "CollaboNet", "Comparing", "Table", "[", "reference", "]", "and", "Table", "[", "reference", "]", ",", "CollaboNet", "achieves", "higher", "precision", "and", "F1", "score", "than", "most", "STM", "models", "on", "all", "datasets", ".", "On", "average", ",", "CollaboNet", "has", "improved", "both", "precision", "and", "recall", ".", "CollaboNet", "also", "outperforms", "the", "multi", "-", "task", "model", "(", "MTM", ")", "from", "Wang", "et", "al", ".", "on", "4", "out", "of", "6", "datasets", "(", "Table", "[", "reference", "]", ")", ".", "While", "multi", "-", "task", "learning", "has", "improved", "performance", "in", "previous", "studies", ",", "using", "CollaboNet", ",", "which", "consists", "of", "expert", "models", "trained", "for", "each", "entity", "type", ",", "could", "further", "improve", "biomedical", "named", "entity", "recognition", "performance", ".", "section", ":", "Discussion", "Compared", "to", "baseline", "models", ",", "CollaboNet", "achieves", "higher", "precision", "on", "average", ".", "Even", "though", "we", "observe", "a", "slight", "increase", "in", "recall", ",", "the", "increase", "in", "precision", "is", "more", "valuable", "than", "that", "in", "recall", "when", "considering", "the", "practical", "use", "of", "the", "bioNER", "systems", ".", "Important", "information", "tends", "to", "be", "repeated", "in", "a", "large", "size", "text", "corpus", ".", "Therefore", ",", "missing", "a", "few", "entities", "may", "not", "hinder", "the", "performance", "of", "an", "entire", "system", ",", "as", "this", "can", "be", "compensated", "elsewhere", ".", "However", ",", "incorrect", "information", "and", "the", "propagation", "of", "errors", "can", "effect", "the", "entire", "system", ".", "In", "Table", "[", "reference", "]", ",", "we", "report", "the", "error", "types", "of", "our", "STM", "and", "CollaboNet", ".", "We", "define", "bio", "-", "entity", "error", "as", "recognizing", "different", "types", "of", "biomedical", "entities", "as", "target", "entity", "types", ".", "For", "instance", ",", "recognizing", "\u2018", "VHL", "\u2019", "as", "a", "gene", "when", "it", "was", "used", "as", "a", "disease", "in", "a", "sentence", "is", "a", "bio", "-", "entity", "error", ".", "Note", "that", "a", "bio", "-", "entity", "error", "could", "occur", "when", "an", "entity", "is", "a", "polysemous", "word", "(", "e.g.", "VHL", ")", ",", "or", "comprised", "of", "multiple", "words", "(", "e.g.", "BRCA1", "deficient", ")", ",", "and", "thus", "correcting", "bio", "-", "entity", "errors", "requires", "contextual", "information", "or", "supervision", "of", "other", "entity", "type", "models", ".", "The", "error", "analysis", "was", "conducted", "on", "4334", "errors", "of", "our", "STM", "and", "3966", "errors", "of", "CollaboNet", "on", "5", "datasets", "(", "BC2GM", ",", "BC5CDR", "-", "chem", ",", "BC5CDR", "-", "disease", ",", "JNLPBA", ",", "NCBI", ")", ".", "Error", "analysis", "was", "conducted", "on", "models", "which", "showed", "best", "performance", "in", "our", "experiments", ".", "The", "error", "analysis", "of", "our", "STM", ",", "which", "is", "a", "single", "BiLSTM", "-", "CRF", "model", ",", "shows", "that", "the", "majority", "of", "errors", "are", "classified", "as", "bio", "-", "entity", "errors", "which", "comprise", "up", "to", "49.3", "%", "of", "the", "total", "errors", "in", "JNLPBA", ".", "According", "to", "the", "error", "analysis", "of", "our", "STM", "model", ",", "bio", "-", "entity", "errors", "constitute", "1333", "errors", "out", "of", "4334", "errors", ",", "comprising", "30.8", "%", "of", "all", "the", "errors", ".", "Although", "bio", "-", "entity", "error", "was", "not", "the", "most", "common", "error", "type", ",", "the", "importance", "of", "bio", "-", "entity", "error", "is", "much", "greater", "that", "of", "other", "errors", "such", "as", "span", "error", "which", "was", "the", "most", "common", "error", "type", ",", "constituting", "38", "%", "of", "incorrect", "errors", ".", "While", "most", "span", "errors", "tend", "to", "come", "from", "subjective", "annotations", ",", "or", "can", "be", "easily", "fixed", "by", "non", "-", "experts", ",", "bio", "-", "entity", "errors", "are", "difficult", "to", "detect", ",", "even", "for", "biomedical", "researchers", ".", "Also", ",", "for", "biomedical", "text", "mining", "methods", ",", "such", "as", "drug", "-", "drug", "interaction", "extraction", ",", "span", "errors", "can", "cause", "minor", "errors", "but", "bio", "-", "entity", "errors", "could", "lead", "to", "completely", "different", "results", ".", "In", "CollaboNet", ",", "each", "expert", "model", "is", "trained", "on", "a", "single", "entity", "type", "dataset", ",", "and", "their", "training", "inputs", "are", "a", "concatenation", "of", "word", "embeddings", "and", "outputs", "of", "the", "other", "expert", "models", ".", "We", "expect", "that", "the", "other", "expert", "models", "will", "transfer", "knowledge", "on", "their", "respective", "entity", "to", "the", "target", "model", ",", "and", "thus", "improve", "the", "bio", "-", "entity", "type", "error", "problem", "by", "collaboration", ".", "As", "Table", "[", "reference", "]", "shows", ",", "CollaboNet", "performs", "better", "than", "our", "STM", "in", "detecting", "polysemy", "and", "other", "entity", "types", ".", "Among", "3966", "errors", "from", "CollaboNet", ",", "736", "errors", "are", "bio", "-", "entity", "errors", ",", "comprising", "18.6", "%", "of", "all", "the", "errors", ".", "subsection", ":", "Case", "study", "We", "sampled", "the", "predictions", "of", "CollaboNet", "and", "those", "of", "our", "STM", "(", "single", "-", "task", "model", ")", "to", "further", "understand", "the", "strengths", "of", "CollaboNet", "in", "Table", "[", "reference", "]", ".", "The", "first", "example", "from", "chemical", "dataset", "in", "Table", "[", "reference", "]", "shows", "our", "expected", "result", "from", "CollaboNet", ".", "Our", "STM", "annotates", "antilymphocyte", "globulin", "as", "a", "chemical", "entity", ".", "However", ",", "it", "is", "clear", "that", "the", "entity", "is", "not", "a", "chemical", "but", "a", "type", "of", "globulin", "which", "is", "a", "protein", ".", "The", "second", "example", "sentence", "from", "the", "chemical", "dataset", "is", "about", "an", "ACE", "/", "ARB", "entity", ".", "Again", ",", "our", "STM", "misidentifies", "the", "entity", "as", "a", "chemical", "entity", ".", "On", "the", "other", "hand", ",", "in", "CollaboNet", ",", "the", "target", "model", "(", "chemical", "model", ")", "obtains", "knowledge", "from", "one", "of", "the", "collaborator", "models", "(", "the", "gene", "/", "protein", "model", ")", "to", "avoid", "mistakenly", "recognizing", "the", "entity", "as", "a", "chemical", "entity", ".", "As", "globulin", "or", "ACE", "entities", "appear", "in", "the", "gene", "/", "protein", "dataset", ",", "the", "chemical", "model", "obtains", "information", "from", "the", "gene", "/", "protein", "model", ".", "In", "the", "disease", "dataset", ",", "the", "first", "example", "shows", "a", "multi", "-", "word", "entity", "in", "parentheses", ".", "As", "a", "gene", "model", "can", "pass", "syntactic", "and", "semantic", "information", "about", "a", "word", "e.g.", ",", "mutated", "and", "its", "surrounding", "words", "to", "a", "disease", "model", ",", "CollaboNet", "can", "abstain", "from", "predicting", "A", "-", "T", ",", "mutated", "as", "the", "disease", "entity", ",", "which", "our", "STM", "model", "failed", "to", "do", ".", "The", "second", "example", "in", "the", "disease", "dataset", "is", "on", "cardiac", "troponin", "T", ".", "Since", "cardiac", "+", "noun", "in", "biomedical", "text", "can", "be", "easily", "considered", "as", "a", "disease", "name", ",", "our", "STM", "misidentified", "this", "word", "as", "a", "disease", "entity", ".", "However", ",", "with", "the", "help", "of", "a", "gene", "model", ",", "CollaboNet", "did", "not", "mark", "it", "as", "a", "disease", "entity", ".", "The", "gene", "/", "protein", "entity", "type", "further", "demonstrates", "the", "effectiveness", "of", "CollaboNet", "in", "reducing", "bio", "-", "entity", "type", "errors", ".", "Two", "example", "sentences", "contain", "abbreviations", ",", "which", "are", "one", "of", "the", "distinct", "characteristics", "of", "gene", "entities", ".", "LMB", "and", "cHD", "are", "incorrectly", "predicted", "as", "gene", "/", "protein", "entities", "by", "our", "STM", ",", "since", "lots", "of", "gene", "/", "protein", "entities", "are", "abbreviations", ".", "However", ",", "the", "target", "model", "(", "gene", "/", "protein", "model", ")", "in", "CollaboNet", "can", "obtain", "information", "on", "leptomycin", "and", "disease", "from", "the", "chemical", "and", "disease", "models", ",", "respectively", ".", "With", "the", "help", "of", "information", "from", "collaborator", "models", ",", "CollaboNet", "can", "effectively", "increase", "the", "precision", "of", "other", "entity", "type", "models", ".", "In", "addition", ",", "we", "found", "some", "labels", "in", "the", "ground", "truth", "set", ",", "which", "we", "believe", "are", "incorrect", ".", "Tsai", "et", "al", ".", "also", "reported", "that", "the", "inconsistent", "annotations", "in", "the", "JNLPBA", "corpus", "limit", "the", "NER", "system", ".", "We", "report", "our", "findings", "in", "Table", "[", "reference", "]", ".", "In", "the", "first", "row", "of", "Table", "[", "reference", "]", ",", "the", "gene", "/", "protein", "entity", "osteopontin", "was", "not", "marked", "in", "the", "ground", "truth", "labels", ",", "whereas", "our", "network", "correctly", "predicted", "it", "as", "a", "gene", "entity", ".", "The", "second", "row", "also", "displays", "questionable", "results", "of", "the", "ground", "truth", "labels", ".", "Although", "lg", "and", "bcl", "-", "6", ",", "which", "are", "abbreviations", "of", "Immunoglobulin", "and", "B", "-", "cell", "lymphoma", "6", ",", "where", "not", "labeled", "in", "the", "ground", "truth", "labels", ",", "our", "model", "detected", "them", "as", "a", "gene", "/", "protein", "entity", ".", "The", "example", "sentences", "of", "gene", "/", "protein", "annotations", "in", "Table", "[", "reference", "]", "were", "reviewed", "by", "several", "domain", "experts", "and", "medical", "doctors", ".", "As", "shown", "in", "the", "third", "row", ",", "beta", "-", "muricholate", "is", "a", "chemical", "entity", "but", "it", "was", "not", "annotated", "in", "the", "ground", "truth", "labels", ".", "However", ",", "the", "last", "row", "shows", "another", "type", "of", "annotation", "error", ".", "Contrast", "media", "is", "a", "general", "term", "for", "a", "medium", "used", "in", "medical", "imaging", "and", "since", "is", "not", "a", "proper", "noun", ",", "it", "is", "not", "a", "named", "entity", ".", "These", "examples", "shows", "the", "presence", "of", "incorrect", "ground", "truth", "labels", ",", "which", "can", "harm", "the", "performance", "of", "bioNER", "models", ".", "However", ",", "we", "believe", "that", "these", "missed", "or", "misidentified", "ground", "truth", "labels", "can", "be", "corrected", "by", "our", "system", ".", "section", ":", "Conclusion", "In", "this", "paper", ",", "we", "introduced", "CollaboNet", ",", "which", "consists", "of", "multiple", "BiLSTM", "-", "CRF", "models", ",", "for", "biomedical", "named", "entity", "recognition", ".", "While", "existing", "models", "were", "only", "able", "to", "handle", "datasets", "with", "a", "single", "entity", "type", ",", "CollaboNet", "leverages", "multiple", "datasets", "and", "achieves", "the", "highest", "F1", "scores", ".", "Unlike", "recently", "proposed", "multi", "-", "task", "models", ",", "CollaboNet", "is", "built", "upon", "multiple", "single", "-", "task", "NER", "models", "(", "STMs", ")", "that", "send", "information", "to", "each", "other", "for", "more", "accurate", "predictions", ".", "In", "addition", "to", "the", "performance", "improvement", "over", "multi", "-", "task", "models", ",", "CollaboNet", "differentiates", "between", "biomedical", "entities", "that", "are", "polysemous", "or", "have", "similar", "orthographic", "features", ".", "As", "a", "result", ",", "our", "model", "achieved", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "four", "bioNER", "datasets", "in", "terms", "of", "F1", "score", ",", "precision", "and", "recall", ".", "Although", "our", "model", "requires", "a", "large", "amount", "of", "memory", "and", "time", ",", "which", "existing", "multi", "-", "task", "models", "require", "as", "well", ",", "the", "simple", "structure", "of", "CollaboNet", "allows", "researchers", "to", "build", "another", "expert", "model", "for", "different", "entity", "types", "in", "CollaboNet", ".", "As", "CollaboNet", "obtains", "higher", "precision", "than", "other", "models", ",", "we", "plan", "to", "apply", "CollaboNet", "in", "a", "biomedical", "text", "mining", "system", ".", "section", ":", "Availability", "of", "data", "and", "materials", "The", "source", "code", "of", "CollaboNet", "and", "the", "datasets", "are", "available", "at", "https:", "//", "github.com", "/", "wonjininfo", "/", "CollaboNet", ".", "section", ":", "Abbreviations", "BiLSTM", ":", "Bidirectional", "long", "short", "-", "term", "memory", ";", "BioNER", ":", "Biomedical", "named", "entity", "recognition", ";", "CE", ":", "Character", "embedding", ";", "CLWE", ":", "Character", "level", "word", "embedding", ";", "CNN", ":", "convolution", "neural", "network", ";", "CRF", ":", "Conditional", "random", "field", ";", "LSTM", ":", "long", "short", "-", "term", "memory", ";", "MTL", ":", "Multi", "-", "task", "learning", ";", "MTM", ":", "Multi", "-", "task", "model", ";", "NER", ":", "Named", "entity", "recognition", ";", "NLP", ":", "Natural", "language", "processing", ";", "PMC", ":", "PubMed", "Central", ";", "STM", ":", "Single", "-", "task", "model", ";", "RNN", ":", "Recurrent", "neural", "network", ";", "WE", ":", "Word", "embedding", "section", ":", "Funding", "This", "work", "was", "supported", "by", "the", "National", "Research", "Foundation", "of", "Korea", "(", "NRF", "-", "2016M3A9A7916996", ",", "NRF", "-", "2017M3C4A7065887", ")", "and", "National", "IT", "Industry", "Promotion", "Agency", "grant", "funded", "by", "the", "Ministry", "of", "Science", "and", "ICT", "and", "Ministry", "of", "Health", "and", "Welfare", "(", "NO", ".", "C1202", "-", "18", "-", "1001", ",", "Development", "Project", "of", "The", "Precision", "Medicine", "Hospital", "Information", "System", "(", "P", "-", "HIS", ")", ")", "section", ":", "Competing", "interests", "The", "authors", "declare", "that", "they", "have", "no", "competing", "interests", ".", "section", ":", "Author", "\u2019s", "contributions", "WY", ",", "CHS", ",", "JL", "and", "JK", "conceived", "the", "idea", ".", "WY", "and", "JL", "designed", "the", "model", ".", "WY", "and", "CHS", "developed", "CollaboNet", ".", "CHS", "experimented", "and", "collected", "analysis", "examples", "and", "results", ".", "WY", ",", "JL", "and", "JK", "wrote", "the", "manuscript", ".", "JK", ",", "as", "the", "supervisor", "of", "WY", ",", "CHS", "and", "JL", ",", "provided", "guidance", "on", "the", "experiment", ".", "All", "authors", "read", "and", "approved", "the", "final", "manuscript", ".", "section", ":", "Acknowledgements", "We", "are", "sincerely", "grateful", "to", "Inah", "Chang", "for", "conducting", "manual", "error", "counting", ".", "We", "appreciate", "Susan", "Kim", "for", "editing", "the", "manuscript", ".", "bibliography", ":", "References", "Scores", "in", "the", "asterisked", "(", "*", ")", "cells", "are", "obtained", "in", "the", "experiments", "that", "we", "conducted", ";", "these", "scores", "are", "not", "reported", "in", "the", "original", "papers", ".", "The", "best", "scores", "from", "these", "experiments", "are", "in", "bold", ".", "Scores", "in", "the", "asterisked", "(", "*", ")", "cells", "are", "obtained", "in", "the", "experiments", "that", "we", "conducted", ";", "these", "scores", "are", "not", "reported", "in", "the", "original", "papers", ".", "The", "best", "scores", "from", "these", "experiments", "are", "in", "bold", "."]}