{"coref": {"AWD-LSTM-MoS": [], "AWD-LSTM-MoS___Partial_Shuffle": [], "Language_Modelling": [[91, 96], [156, 161], [25, 30]], "Number_of_params": [], "Params": [], "Partial_Shuffle": [[2, 4], [750, 753], [838, 841], [1121, 1123]], "Penn_Treebank__Word_Level_": [[99, 101], [1077, 1079], [1172, 1174]], "Test_perplexity": [], "Validation_perplexity": [], "WikiText-2": [[102, 105], [1080, 1083]]}, "coref_non_salient": {"0": [[9, 11], [111, 113], [210, 212], [765, 767], [819, 821]], "1": [[12, 13], [754, 755]], "10": [[1073, 1074]], "11": [[456, 457]], "12": [[1059, 1061]], "13": [[124, 127]], "2": [[653, 654], [730, 731]], "3": [[1125, 1127]], "4": [[1114, 1116]], "5": [[1062, 1063]], "6": [[997, 1000]], "7": [[733, 735]], "8": [[193, 195]], "9": [[445, 446]]}, "doc_id": "121e30c48546e671dc5e16c694c5e69b392cf8fb", "method_subrelations": {"AWD-LSTM-MoS___Partial_Shuffle": [[[0, 12], "AWD-LSTM-MoS"], [[15, 30], "Partial_Shuffle"]]}, "n_ary_relations": [{"Material": "Penn_Treebank__Word_Level_", "Method": "AWD-LSTM-MoS___Partial_Shuffle", "Metric": "Params", "Task": "Language_Modelling", "score": "22M"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "AWD-LSTM-MoS___Partial_Shuffle", "Metric": "Test_perplexity", "Task": "Language_Modelling", "score": "53.92"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "AWD-LSTM-MoS___Partial_Shuffle", "Metric": "Validation_perplexity", "Task": "Language_Modelling", "score": "55.89"}, {"Material": "WikiText-2", "Method": "AWD-LSTM-MoS___Partial_Shuffle", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "35M"}, {"Material": "WikiText-2", "Method": "AWD-LSTM-MoS___Partial_Shuffle", "Metric": "Test_perplexity", "Task": "Language_Modelling", "score": "59.98"}, {"Material": "WikiText-2", "Method": "AWD-LSTM-MoS___Partial_Shuffle", "Metric": "Validation_perplexity", "Task": "Language_Modelling", "score": "62.38"}], "ner": [[2, 4, "Method"], [9, 11, "Method"], [12, 13, "Method"], [91, 96, "Task"], [99, 101, "Material"], [102, 105, "Material"], [111, 113, "Method"], [124, 127, "Method"], [156, 161, "Task"], [193, 195, "Method"], [210, 212, "Method"], [445, 446, "Method"], [456, 457, "Task"], [653, 654, "Method"], [730, 731, "Method"], [733, 735, "Metric"], [750, 753, "Method"], [754, 755, "Method"], [765, 767, "Method"], [819, 821, "Method"], [838, 841, "Method"], [997, 1000, "Method"], [1059, 1061, "Method"], [1062, 1063, "Method"], [1073, 1074, "Method"], [1077, 1079, "Material"], [1080, 1083, "Material"], [1114, 1116, "Method"], [1121, 1123, "Method"], [1125, 1127, "Method"], [25, 30, "Task"], [1172, 1174, "Material"]], "sections": [[0, 107], [107, 747], [747, 1046], [1046, 1176], [1176, 1201], [1201, 1204]], "sentences": [[0, 11], [11, 34], [34, 54], [54, 68], [68, 82], [82, 107], [107, 110], [110, 123], [123, 152], [152, 169], [169, 177], [177, 192], [192, 204], [204, 244], [244, 257], [257, 285], [285, 315], [315, 348], [348, 388], [388, 393], [393, 398], [398, 423], [423, 435], [435, 451], [451, 464], [464, 486], [486, 499], [499, 519], [519, 527], [527, 543], [543, 548], [548, 553], [553, 558], [558, 563], [563, 582], [582, 600], [600, 605], [605, 609], [609, 628], [628, 652], [652, 691], [691, 723], [723, 747], [747, 753], [753, 778], [778, 795], [795, 816], [816, 821], [821, 834], [834, 850], [850, 863], [863, 878], [878, 886], [886, 894], [894, 913], [913, 934], [934, 966], [966, 974], [974, 980], [980, 1004], [1004, 1011], [1011, 1016], [1016, 1021], [1021, 1026], [1026, 1031], [1031, 1046], [1046, 1049], [1049, 1087], [1087, 1107], [1107, 1124], [1124, 1146], [1146, 1176], [1176, 1179], [1179, 1201], [1201, 1204]], "words": ["document", ":", "Partially", "Shuffling", "the", "Training", "Data", "to", "Improve", "Language", "Models", "Although", "SGD", "requires", "shuffling", "the", "training", "data", "between", "epochs", ",", "currently", "none", "of", "the", "word", "-", "level", "language", "modeling", "systems", "do", "this", ".", "Naively", "shuffling", "all", "sentences", "in", "the", "training", "data", "would", "not", "permit", "the", "model", "to", "learn", "inter", "-", "sentence", "dependencies", ".", "Here", "we", "present", "a", "method", "that", "partially", "shuffles", "the", "training", "data", "between", "epochs", ".", "This", "method", "makes", "each", "batch", "random", ",", "while", "keeping", "most", "sentence", "ordering", "intact", ".", "It", "achieves", "new", "state", "of", "the", "art", "results", "on", "word", "-", "level", "language", "modeling", "on", "both", "the", "Penn", "Treebank", "and", "WikiText", "-", "2", "datasets", ".", "section", ":", "Background", "A", "language", "model", "is", "trained", "to", "predict", "word", "given", "all", "previous", "words", ".", "A", "recurrent", "language", "model", "receives", "at", "timestep", "the", "th", "word", "and", "the", "previous", "hidden", "state", "and", "outputs", "a", "prediction", "of", "the", "next", "word", "and", "the", "next", "hidden", "state", ".", "The", "training", "data", "for", "word", "-", "level", "language", "modeling", "consists", "of", "a", "series", "of", "concatenated", "documents", ".", "The", "sentences", "from", "these", "documents", "are", "unshuffled", ".", "This", "lets", "the", "model", "learn", "long", "term", ",", "multi", "-", "sentence", "dependencies", "between", "words", ".", "The", "concatenation", "operation", "results", "in", "a", "single", "long", "sequence", "of", "words", ".", "The", "naive", "way", "to", "train", "a", "language", "model", "would", "be", "to", ",", "at", "every", "epoch", ",", "use", "the", "entire", "training", "sequence", "as", "the", "input", ",", "and", "use", "the", "same", "sequence", "shifted", "one", "word", "to", "the", "left", "as", "target", "output", ".", "Since", "the", "training", "sequence", "is", "too", "long", ",", "this", "solution", "is", "infeasible", ".", "To", "solve", "this", ",", "we", "set", "a", "back", "propagation", "through", "-", "time", "length", "(", ")", ",", "and", "split", "the", "training", "sequence", "into", "sub", "-", "sequences", "of", "length", ".", "In", "this", "case", ",", "in", "each", "epoch", "the", "model", "is", "first", "trained", "on", "the", "first", "sub", "-", "sequence", ",", "and", "then", "on", "the", "second", "one", ",", "and", "so", "on", ".", "While", "gradients", "are", "not", "passed", "between", "different", "sub", "-", "sequences", ",", "the", "last", "hidden", "state", "from", "sub", "-", "sequence", "becomes", "the", "initial", "hidden", "state", "while", "training", "the", "model", "with", "sub", "-", "sequence", ".", "For", "example", ",", "if", "the", "training", "sequence", "of", "words", "is", ":", "[", "A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L", "]", "for", ",", "the", "resulting", "four", "sub", "-", "sequences", "are", ":", "[", "A", "B", "C", "]", "[", "D", "E", "F", "]", "[", "G", "H", "I", "]", "[", "J", "K", "L", "]", "Note", "that", "we", "only", "present", "the", "input", "sub", "-", "sequences", ",", "as", "the", "target", "output", "sub", "-", "sequences", "are", "simply", "the", "input", "sub", "-", "sequences", "shifted", "one", "word", "to", "the", "left", ".", "This", "method", "works", ",", "but", "it", "does", "not", "utilize", "current", "GPUs", "to", "their", "full", "potential", ".", "In", "order", "to", "speed", "up", "training", ",", "we", "batch", "our", "training", "data", ".", "We", "set", "a", "batch", "size", ",", "and", "at", "every", "training", "step", "we", "train", "the", "model", "on", "sub", "-", "sequences", "in", "parallel", ".", "To", "do", "this", ",", "we", "first", "split", "the", "training", "sequence", "into", "parts", ".", "Continuing", "the", "example", "from", "above", ",", "for", ",", "this", "results", "in", ":", "[", "A", "B", "C", "D", "E", "F", "]", "[", "G", "H", "I", "J", "K", "L", "]", "Then", ",", "as", "before", ",", "we", "split", "each", "part", "into", "sub", "-", "sequences", "of", "length", ":", "[", "A", "B", "C", "]", "[", "D", "E", "F", "]", "[", "G", "H", "I", "]", "[", "J", "K", "L", "]", "Then", ",", "during", "the", "first", "training", "step", "in", "each", "epoch", "we", "train", "on", ":", "[", "A", "B", "C", "]", "[", "G", "H", "I", "]", "and", "during", "the", "second", "training", "step", "in", "each", "epoch", "we", "train", "on", ":", "[", "D", "E", "F", "]", "[", "J", "K", "L", "]", "Note", "that", "at", "every", "step", ",", "all", "sub", "-", "sequences", "in", "the", "batch", "are", "processed", "in", "parallel", ".", "Before", "we", "introduced", "batching", ",", "in", "each", "epoch", "the", "output", "for", "each", "word", "in", "the", "training", "sequence", "was", "dependant", "on", "all", "previous", "words", ".", "With", "batching", ",", "the", "output", "of", "the", "model", "for", "each", "word", "is", "only", "dependant", "on", "the", "previous", "words", "in", "that", "batch", "element", "(", "or", "equivalently", ",", "row", "in", "our", "example", ")", ",", "and", "the", "other", "words", "are", "ignored", ".", "In", "our", "example", ",", "the", "hidden", "state", "that", "is", "given", "when", "inputting", "G", "is", "the", "default", "initial", "hidden", "state", ",", "and", "not", "the", "one", "that", "resulted", "after", "the", "input", "of", "F", ".", "This", "is", "not", "optimal", ",", "but", "since", "batching", "reduces", "the", "training", "time", "by", "a", "significant", "amount", ",", "all", "current", "models", "use", "this", "method", ".", "section", ":", "The", "Partial", "Shuffle", "Method", "While", "SGD", "calls", "for", "random", "batches", "in", "each", "epoch", ",", "in", "existing", "language", "models", ",", "the", "data", "is", "not", "shuffled", "between", "epochs", "during", "training", ".", "This", "means", "that", "batch", "in", "every", "epoch", "is", "made", "up", "of", "the", "same", "sub", "-", "sequences", ".", "The", "straightforward", "way", "to", "shuffle", "the", "data", "would", "be", "to", "shuffle", "all", "sentences", "in", "the", "training", "sequence", "between", "each", "epoch", ".", "This", "hurts", "the", "language", "model", "\u2019s", "performance", ",", "since", "it", "does", "not", "learn", "inter", "-", "sentence", "dependencies", ".", "Here", "we", "present", "the", "Partial", "Shuffle", "method", ",", "which", "improves", "the", "performance", "of", "the", "model", ".", "Like", "before", ",", "we", "first", "separate", "the", "sequence", "of", "words", "into", "rows", ".", "Using", "the", "example", "sequence", "from", "above", ",", "this", "would", "result", "in", "(", "for", ")", ":", "[", "A", "B", "C", "D", "E", "F", "]", "[", "G", "H", "I", "J", "K", "L", "]", "Then", ",", "for", "each", "row", ",", "we", "pick", "a", "random", "index", "between", "zero", "and", "the", "length", "of", "the", "row", "and", "we", "take", "the", "words", "that", "are", "located", "before", "this", "index", "and", "move", "them", "to", "the", "end", "of", "the", "row", ".", "So", "in", "our", "example", ",", "if", "the", "random", "index", "for", "row", "one", "was", "and", "for", "row", "two", "was", "this", "would", "result", "in", "(", "red", "marks", "the", "words", "which", "were", "moved", ")", ":", "[", "C", "D", "E", "F", "A", "B", "]", "[", "L", "H", "J", "K", "]", "Finally", ",", "as", "before", ",", "each", "row", "(", "or", "equivalently", ",", "batch", "element", ")", "is", "divided", "into", "back", "-", "propagation", "through", "time", "segments", ".", "For", ",", "this", "will", "result", "in", ":", "[", "C", "D", "E", "]", "[", "F", "A", "B", "]", "[", "L", "G", "H", "]", "[", "I", "J", "K", "]", "This", "method", "randomizes", "the", "batches", "while", "still", "keeping", "most", "of", "the", "word", "ordering", "intact", ".", "section", ":", "Results", "We", "evaluate", "our", "method", "on", "the", "current", "state", "of", "the", "art", "model", ",", "DOC", ",", "and", "the", "previous", "state", "of", "the", "art", "model", ",", "MoS", ",", "on", "the", "Penn", "Treebank", "and", "WikiText", "-", "2", "language", "modeling", "datasets", ".", "For", "each", "model", ",", "the", "hyper", "-", "parameters", "(", "including", "and", ")", "are", "not", "modified", "from", "their", "original", "values", ".", "In", "addition", ",", "we", "present", "results", "for", "finetuned", "models", ",", "with", "and", "without", "the", "Partial", "Shuffle", ".", "Our", "shuffling", "method", "improves", "the", "performance", "of", "all", "models", ",", "and", "achieves", "new", "state", "of", "the", "art", "results", "on", "both", "datasets", ".", "Our", "method", "does", "not", "require", "any", "additional", "parameters", "or", "hyper", "-", "parameters", ",", "and", "runs", "in", "less", "than", "th", "of", "a", "second", "per", "epoch", "on", "the", "Penn", "Treebank", "dataset", ".", "section", ":", "Acknowledgements", "This", "note", "benefited", "from", "feedback", "from", "Judit", "Acs", ",", "Shimi", "Salant", "and", "Noah", "A.", "Smith", ",", "which", "is", "acknowledged", "with", "gratitude", ".", "bibliography", ":", "References"]}