{"coref": {"CIFAR-10": [[1481, 1484], [4770, 4773], [4939, 4942], [5077, 5080], [5164, 5167], [6501, 6504], [6586, 6589], [6592, 6597], [6717, 6722], [4823, 4826], [4880, 4883], [4900, 4903]], "Image_Classification": [[1387, 1388]], "Improving_neural_networks_by_preventing_co-adaptation_of_feature_detectors": [[2, 13], [2335, 2337]], "Percentage_correct": []}, "coref_non_salient": {"0": [[2247, 2249], [2252, 2257]], "1": [[2786, 2788], [4656, 4658], [4745, 4746]], "10": [[5666, 5669], [5685, 5687], [5701, 5703], [5705, 5707], [5728, 5730], [5750, 5752], [5769, 5771], [5822, 5824], [5865, 5867], [6605, 6607], [6614, 6616], [6627, 6629], [6643, 6645], [6657, 6659], [6669, 6671], [6759, 6761], [6919, 6921], [6940, 6942]], "11": [[902, 906], [1001, 1005], [1029, 1032], [3672, 3676], [6122, 6126]], "12": [[3300, 3303], [3324, 3326], [3587, 3588]], "13": [[660, 662], [735, 737], [772, 774], [814, 816], [3047, 3052], [6249, 6254]], "14": [[810, 812], [824, 826], [1285, 1289], [1575, 1577], [1594, 1596], [1660, 1662], [1729, 1731], [1763, 1764], [1996, 1997], [3975, 3978], [3991, 3993], [4324, 4327], [4361, 4362], [4404, 4405], [6106, 6108]], "15": [[492, 496], [2924, 2927], [3274, 3276], [3455, 3458], [6421, 6424]], "16": [[1096, 1098], [3729, 3731]], "17": [[1262, 1266], [3352, 3354], [4714, 4722], [6089, 6092]], "18": [[1188, 1191], [1207, 1209]], "19": [[3506, 3509], [4236, 4239], [4633, 4636]], "2": [[3358, 3365], [5158, 5161], [5604, 5609]], "20": [[434, 435], [436, 437]], "21": [[5208, 5210], [5255, 5257], [5335, 5336], [5426, 5427], [6072, 6076], [6984, 6985], [7150, 7152]], "22": [[720, 724], [6677, 6680], [6814, 6816]], "23": [[5917, 5920], [5924, 5927], [5998, 6001], [6650, 6653], [6931, 6935]], "24": [[3745, 3746], [4751, 4752], [5840, 5841], [5880, 5881], [6877, 6878]], "25": [[624, 625], [2722, 2724], [3063, 3064], [3261, 3262], [3649, 3651], [4077, 4078], [4091, 4092]], "26": [[5507, 5509], [5529, 5530], [5574, 5576]], "27": [[1606, 1609], [1771, 1774], [5566, 5568], [5655, 5657], [5679, 5681], [5694, 5696], [6602, 6604], [6633, 6635], [6690, 6692], [6771, 6772], [6777, 6779], [6890, 6891], [6913, 6915], [6945, 6947], [6977, 6979], [7010, 7013], [7041, 7043], [7121, 7123], [7155, 7157], [7190, 7192], [7197, 7199], [7463, 7468]], "28": [[1192, 1195], [1196, 1197], [1228, 1231]], "29": [[1056, 1059], [1115, 1116], [1992, 1993], [3160, 3161], [3375, 3377], [3466, 3468], [3610, 3611], [3716, 3717], [4305, 4306], [4348, 4349], [4641, 4642]], "3": [[3281, 3283], [3917, 3921], [4214, 4216]], "30": [[803, 804], [6203, 6207]], "31": [[1613, 1618], [1777, 1782], [5757, 5765], [6636, 6639], [6901, 6905]], "32": [[6748, 6751], [6763, 6765], [6821, 6824], [7230, 7232]], "33": [[4335, 4339], [6099, 6101]], "34": [[114, 117], [305, 307], [360, 362], [438, 440], [705, 707], [759, 761], [797, 799], [828, 830], [837, 838], [956, 957], [995, 996], [1170, 1171], [1377, 1378], [1450, 1451], [1459, 1460], [1652, 1653], [1815, 1816], [1903, 1904], [1913, 1914], [2012, 2013], [2052, 2053], [2214, 2215], [2268, 2269], [2326, 2328], [2417, 2418], [2436, 2437], [2501, 2502], [2847, 2849], [2909, 2910], [2917, 2918], [3294, 3295], [3311, 3312], [3381, 3383], [3473, 3474], [3584, 3585], [3605, 3606], [3701, 3702], [3725, 3726], [3986, 3987], [4345, 4346], [4357, 4358], [4726, 4727], [5649, 5650], [6517, 6518], [6727, 6728], [6811, 6812], [7251, 7252], [7364, 7365], [7420, 7421], [7479, 7480], [7485, 7486]], "35": [[1393, 1395], [3925, 3927], [4351, 4353], [7392, 7394]], "36": [[5179, 5180], [5281, 5282], [5296, 5297], [5333, 5334], [5504, 5505], [5518, 5519], [5661, 5662], [6599, 6600], [6838, 6839]], "37": [[2550, 2552], [6042, 6048], [6280, 6286], [7098, 7104]], "38": [[3874, 3878], [6694, 6696], [6949, 6951], [6981, 6983], [7159, 7161], [7202, 7204]], "39": [[4995, 5003]], "4": [[839, 840], [1172, 1173], [1268, 1269], [1666, 1667], [1921, 1923], [2737, 2738], [2781, 2782], [3751, 3752], [3784, 3786], [4006, 4007], [4427, 4431], [4767, 4769], [4774, 4777], [4798, 4800], [4832, 4835], [4889, 4892], [4967, 4968], [4968, 4969], [5031, 5035], [5041, 5042], [5168, 5169], [6511, 6512], [6829, 6830], [6833, 6836], [1296, 1297], [2789, 2790], [3753, 3754], [4280, 4281], [4663, 4664], [5109, 5110], [5116, 5117], [7343, 7344]], "40": [[5826, 5828]], "41": [[1791, 1796], [7268, 7272]], "42": [[2934, 2939], [4328, 4333], [4363, 4366], [6220, 6223]], "43": [[1040, 1043], [3327, 3330], [3339, 3342], [3568, 3571], [4015, 4018]], "44": [[4992, 4994]], "45": [[370, 372], [2221, 2224], [2356, 2359]], "46": [[168, 170], [1656, 1658], [1819, 1821]], "47": [[6116, 6119]], "48": [[3057, 3058], [4085, 4086]], "49": [[4354, 4356]], "5": [[619, 621], [649, 651], [1014, 1016], [2904, 2906], [2943, 2945], [2966, 2968], [3096, 3098], [3152, 3155], [3166, 3168], [3196, 3198], [3220, 3222], [3315, 3317], [3386, 3388], [3408, 3410], [4108, 4110], [4156, 4158], [4309, 4311], [4417, 4419], [6456, 6458], [6525, 6527], [6531, 6533], [6569, 6571]], "50": [[298, 299]], "51": [[132, 134], [1489, 1491], [7451, 7453], [1671, 1673], [1708, 1710], [1847, 1849], [5023, 5025]], "52": [[130, 131], [1182, 1183], [1840, 1841], [3769, 3770], [3807, 3808], [3816, 3817], [3851, 3852], [3885, 3886]], "53": [[1425, 1426]], "54": [[3028, 3030]], "55": [[1089, 1092], [3481, 3484], [3489, 3493]], "56": [[4432, 4435]], "57": [[6031, 6033]], "58": [[7052, 7054]], "59": [[2361, 2363], [2390, 2391], [2445, 2446]], "6": [[3846, 3850], [6238, 6240]], "60": [[567, 570], [604, 607], [3134, 3136]], "61": [[51, 53], [67, 69], [79, 81], [172, 174], [278, 280], [1024, 1026]], "62": [[6438, 6440]], "63": [[6481, 6485]], "64": [[2504, 2507]], "65": [[846, 849]], "66": [[4395, 4397]], "67": [[2033, 2035]], "68": [[6862, 6864]], "69": [[5499, 5502], [5522, 5525]], "7": [[3514, 3522], [6646, 6649]], "70": [[6197, 6199], [6553, 6555]], "71": [[2399, 2401]], "72": [[3843, 3844]], "73": [[2484, 2485]], "74": [[2239, 2241]], "75": [[2588, 2589]], "76": [[3544, 3545]], "77": [[373, 375], [1321, 1323], [1342, 1344], [1415, 1417], [1602, 1604], [1767, 1769], [2827, 2829], [3287, 3289], [3334, 3336], [3668, 3670], [3945, 3947], [4011, 4013], [4227, 4229], [4630, 4632], [5621, 5623], [7430, 7432], [17, 19], [139, 141], [500, 502], [897, 899], [934, 936], [1241, 1243], [1979, 1981], [2244, 2246], [2427, 2429], [5176, 5178], [5185, 5187], [5285, 5287]], "78": [[1275, 1278]], "79": [[2764, 2765]], "8": [[1346, 1351], [1637, 1641], [1785, 1788], [1983, 1986], [7260, 7264]], "80": [[2766, 2767]], "81": [[3268, 3270]], "82": [[4794, 4797]], "83": [[61, 64]], "84": [[1437, 1439]], "85": [[3111, 3113]], "86": [[5141, 5142]], "87": [[2928, 2932]], "88": [[1406, 1409], [1453, 1455]], "9": [[4036, 4038], [4152, 4154], [4201, 4203], [4218, 4219]]}, "doc_id": "2116b2eaaece4af9c28c32af2728f3d49b792cf9", "method_subrelations": {"Improving_neural_networks_by_preventing_co-adaptation_of_feature_detectors": [[[0, 74], "Improving_neural_networks_by_preventing_co-adaptation_of_feature_detectors"]]}, "n_ary_relations": [{"Material": "CIFAR-10", "Method": "Improving_neural_networks_by_preventing_co-adaptation_of_feature_detectors", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "84.4"}], "ner": [[2, 13, "Method"], [51, 53, "Method"], [61, 64, "Task"], [67, 69, "Method"], [79, 81, "Method"], [114, 117, "Method"], [130, 131, "Task"], [132, 134, "Task"], [168, 170, "Method"], [172, 174, "Method"], [278, 280, "Method"], [298, 299, "Method"], [305, 307, "Method"], [360, 362, "Method"], [370, 372, "Method"], [373, 375, "Method"], [434, 435, "Task"], [436, 437, "Task"], [438, 440, "Method"], [492, 496, "Method"], [567, 570, "Method"], [604, 607, "Method"], [619, 621, "Metric"], [624, 625, "Task"], [649, 651, "Metric"], [660, 662, "Method"], [705, 707, "Method"], [720, 724, "Method"], [735, 737, "Method"], [759, 761, "Method"], [772, 774, "Method"], [797, 799, "Method"], [803, 804, "Task"], [810, 812, "Metric"], [814, 816, "Method"], [824, 826, "Metric"], [828, 830, "Method"], [837, 838, "Method"], [839, 840, "Material"], [846, 849, "Method"], [902, 906, "Method"], [956, 957, "Method"], [995, 996, "Method"], [1001, 1005, "Method"], [1014, 1016, "Metric"], [1029, 1032, "Method"], [1040, 1043, "Method"], [1056, 1059, "Method"], [1089, 1092, "Method"], [1096, 1098, "Method"], [1115, 1116, "Method"], [1170, 1171, "Method"], [1172, 1173, "Material"], [1188, 1191, "Method"], [1192, 1195, "Method"], [1196, 1197, "Method"], [1207, 1209, "Method"], [1228, 1231, "Method"], [1262, 1266, "Method"], [1268, 1269, "Material"], [1275, 1278, "Task"], [1285, 1289, "Metric"], [1321, 1323, "Method"], [1342, 1344, "Method"], [1346, 1351, "Method"], [1377, 1378, "Method"], [1387, 1388, "Task"], [1393, 1395, "Method"], [1406, 1409, "Metric"], [1415, 1417, "Method"], [1425, 1426, "Method"], [1437, 1439, "Method"], [1450, 1451, "Method"], [1453, 1455, "Metric"], [1459, 1460, "Method"], [1481, 1484, "Material"], [1489, 1491, "Task"], [1575, 1577, "Metric"], [1594, 1596, "Metric"], [1602, 1604, "Method"], [1606, 1609, "Method"], [1613, 1618, "Method"], [1637, 1641, "Method"], [1652, 1653, "Method"], [1656, 1658, "Method"], [1660, 1662, "Metric"], [1666, 1667, "Material"], [1729, 1731, "Metric"], [1763, 1764, "Metric"], [1767, 1769, "Method"], [1771, 1774, "Method"], [1777, 1782, "Method"], [1785, 1788, "Method"], [1791, 1796, "Method"], [1815, 1816, "Method"], [1819, 1821, "Method"], [1903, 1904, "Method"], [1913, 1914, "Method"], [1921, 1923, "Material"], [1983, 1986, "Method"], [1992, 1993, "Method"], [1996, 1997, "Metric"], [2012, 2013, "Method"], [2033, 2035, "Metric"], [2052, 2053, "Method"], [2214, 2215, "Method"], [2221, 2224, "Method"], [2239, 2241, "Task"], [2247, 2249, "Method"], [2252, 2257, "Method"], [2268, 2269, "Method"], [2326, 2328, "Method"], [2335, 2337, "Method"], [2356, 2359, "Method"], [2361, 2363, "Method"], [2390, 2391, "Method"], [2399, 2401, "Method"], [2417, 2418, "Method"], [2436, 2437, "Method"], [2445, 2446, "Method"], [2484, 2485, "Method"], [2501, 2502, "Method"], [2504, 2507, "Method"], [2550, 2552, "Method"], [2588, 2589, "Task"], [2722, 2724, "Task"], [2737, 2738, "Material"], [2764, 2765, "Method"], [2766, 2767, "Method"], [2781, 2782, "Material"], [2786, 2788, "Method"], [2827, 2829, "Method"], [2847, 2849, "Method"], [2904, 2906, "Metric"], [2909, 2910, "Method"], [2917, 2918, "Method"], [2924, 2927, "Method"], [2928, 2932, "Method"], [2934, 2939, "Metric"], [2943, 2945, "Metric"], [2966, 2968, "Metric"], [3028, 3030, "Method"], [3047, 3052, "Method"], [3057, 3058, "Method"], [3063, 3064, "Task"], [3096, 3098, "Metric"], [3111, 3113, "Method"], [3134, 3136, "Method"], [3152, 3155, "Metric"], [3160, 3161, "Method"], [3166, 3168, "Metric"], [3196, 3198, "Metric"], [3220, 3222, "Metric"], [3261, 3262, "Task"], [3268, 3270, "Task"], [3274, 3276, "Method"], [3281, 3283, "Task"], [3287, 3289, "Method"], [3294, 3295, "Method"], [3300, 3303, "Method"], [3311, 3312, "Method"], [3315, 3317, "Metric"], [3324, 3326, "Method"], [3327, 3330, "Method"], [3334, 3336, "Method"], [3339, 3342, "Method"], [3352, 3354, "Method"], [3358, 3365, "Method"], [3375, 3377, "Method"], [3381, 3383, "Method"], [3386, 3388, "Metric"], [3408, 3410, "Metric"], [3455, 3458, "Method"], [3466, 3468, "Method"], [3473, 3474, "Method"], [3481, 3484, "Method"], [3489, 3493, "Method"], [3506, 3509, "Method"], [3514, 3522, "Method"], [3544, 3545, "Method"], [3568, 3571, "Method"], [3584, 3585, "Method"], [3587, 3588, "Method"], [3605, 3606, "Method"], [3610, 3611, "Method"], [3649, 3651, "Task"], [3668, 3670, "Method"], [3672, 3676, "Method"], [3701, 3702, "Method"], [3716, 3717, "Method"], [3725, 3726, "Method"], [3729, 3731, "Method"], [3745, 3746, "Task"], [3751, 3752, "Material"], [3784, 3786, "Material"], [3843, 3844, "Method"], [3846, 3850, "Method"], [3874, 3878, "Method"], [3917, 3921, "Task"], [3925, 3927, "Method"], [3945, 3947, "Method"], [3975, 3978, "Metric"], [3986, 3987, "Method"], [3991, 3993, "Metric"], [4006, 4007, "Material"], [4011, 4013, "Method"], [4015, 4018, "Method"], [4036, 4038, "Method"], [4077, 4078, "Task"], [4085, 4086, "Method"], [4091, 4092, "Task"], [4108, 4110, "Metric"], [4152, 4154, "Method"], [4156, 4158, "Metric"], [4201, 4203, "Method"], [4214, 4216, "Task"], [4218, 4219, "Method"], [4227, 4229, "Method"], [4236, 4239, "Method"], [4305, 4306, "Method"], [4309, 4311, "Metric"], [4324, 4327, "Metric"], [4328, 4333, "Metric"], [4335, 4339, "Metric"], [4345, 4346, "Method"], [4348, 4349, "Method"], [4351, 4353, "Method"], [4354, 4356, "Method"], [4357, 4358, "Method"], [4361, 4362, "Metric"], [4363, 4366, "Metric"], [4395, 4397, "Task"], [4404, 4405, "Metric"], [4417, 4419, "Metric"], [4427, 4431, "Material"], [4432, 4435, "Material"], [4630, 4632, "Method"], [4633, 4636, "Method"], [4641, 4642, "Method"], [4656, 4658, "Method"], [4714, 4722, "Method"], [4726, 4727, "Method"], [4745, 4746, "Method"], [4751, 4752, "Task"], [4767, 4769, "Material"], [4770, 4773, "Material"], [4774, 4777, "Material"], [4794, 4797, "Method"], [4798, 4800, "Material"], [4832, 4835, "Material"], [4889, 4892, "Material"], [4939, 4942, "Material"], [4967, 4968, "Material"], [4968, 4969, "Material"], [4992, 4994, "Method"], [4995, 5003, "Method"], [5031, 5035, "Material"], [5041, 5042, "Material"], [5077, 5080, "Material"], [5141, 5142, "Metric"], [5158, 5161, "Method"], [5164, 5167, "Material"], [5168, 5169, "Material"], [5179, 5180, "Method"], [5208, 5210, "Method"], [5255, 5257, "Method"], [5281, 5282, "Method"], [5296, 5297, "Method"], [5333, 5334, "Method"], [5335, 5336, "Method"], [5426, 5427, "Method"], [5499, 5502, "Method"], [5504, 5505, "Method"], [5507, 5509, "Method"], [5518, 5519, "Method"], [5522, 5525, "Method"], [5529, 5530, "Method"], [5566, 5568, "Method"], [5574, 5576, "Method"], [5604, 5609, "Method"], [5621, 5623, "Method"], [5649, 5650, "Method"], [5655, 5657, "Method"], [5661, 5662, "Method"], [5666, 5669, "Method"], [5679, 5681, "Method"], [5685, 5687, "Method"], [5694, 5696, "Method"], [5701, 5703, "Method"], [5705, 5707, "Method"], [5728, 5730, "Method"], [5750, 5752, "Method"], [5757, 5765, "Method"], [5769, 5771, "Method"], [5822, 5824, "Method"], [5826, 5828, "Method"], [5840, 5841, "Task"], [5865, 5867, "Method"], [5880, 5881, "Task"], [5917, 5920, "Method"], [5924, 5927, "Method"], [5998, 6001, "Method"], [6031, 6033, "Method"], [6042, 6048, "Method"], [6072, 6076, "Method"], [6089, 6092, "Method"], [6099, 6101, "Metric"], [6106, 6108, "Metric"], [6116, 6119, "Task"], [6122, 6126, "Method"], [6197, 6199, "Metric"], [6203, 6207, "Task"], [6220, 6223, "Metric"], [6238, 6240, "Method"], [6249, 6254, "Method"], [6280, 6286, "Method"], [6421, 6424, "Method"], [6438, 6440, "Method"], [6456, 6458, "Metric"], [6481, 6485, "Method"], [6501, 6504, "Material"], [6511, 6512, "Material"], [6517, 6518, "Method"], [6525, 6527, "Metric"], [6531, 6533, "Metric"], [6553, 6555, "Metric"], [6569, 6571, "Metric"], [6586, 6589, "Material"], [6592, 6597, "Material"], [6599, 6600, "Method"], [6602, 6604, "Method"], [6605, 6607, "Method"], [6614, 6616, "Method"], [6627, 6629, "Method"], [6633, 6635, "Method"], [6636, 6639, "Method"], [6643, 6645, "Method"], [6646, 6649, "Method"], [6650, 6653, "Method"], [6657, 6659, "Method"], [6669, 6671, "Method"], [6677, 6680, "Method"], [6690, 6692, "Method"], [6694, 6696, "Method"], [6717, 6722, "Material"], [6727, 6728, "Method"], [6748, 6751, "Method"], [6759, 6761, "Method"], [6763, 6765, "Method"], [6771, 6772, "Method"], [6777, 6779, "Method"], [6811, 6812, "Method"], [6814, 6816, "Method"], [6821, 6824, "Method"], [6829, 6830, "Material"], [6833, 6836, "Material"], [6838, 6839, "Method"], [6862, 6864, "Task"], [6877, 6878, "Task"], [6890, 6891, "Method"], [6901, 6905, "Method"], [6913, 6915, "Method"], [6919, 6921, "Method"], [6931, 6935, "Method"], [6940, 6942, "Method"], [6945, 6947, "Method"], [6949, 6951, "Method"], [6977, 6979, "Method"], [6981, 6983, "Method"], [6984, 6985, "Method"], [7010, 7013, "Method"], [7041, 7043, "Method"], [7052, 7054, "Method"], [7098, 7104, "Method"], [7121, 7123, "Method"], [7150, 7152, "Method"], [7155, 7157, "Method"], [7159, 7161, "Method"], [7190, 7192, "Method"], [7197, 7199, "Method"], [7202, 7204, "Method"], [7230, 7232, "Method"], [7251, 7252, "Method"], [7260, 7264, "Method"], [7268, 7272, "Method"], [7364, 7365, "Method"], [7392, 7394, "Method"], [7420, 7421, "Method"], [7430, 7432, "Method"], [7451, 7453, "Task"], [7463, 7468, "Method"], [7479, 7480, "Method"], [7485, 7486, "Method"], [17, 19, "Method"], [139, 141, "Method"], [500, 502, "Method"], [897, 899, "Method"], [934, 936, "Method"], [1024, 1026, "Method"], [1182, 1183, "Task"], [1241, 1243, "Method"], [1296, 1297, "Material"], [1671, 1673, "Task"], [1708, 1710, "Task"], [1840, 1841, "Task"], [1847, 1849, "Task"], [1979, 1981, "Method"], [2244, 2246, "Method"], [2427, 2429, "Method"], [2789, 2790, "Material"], [3753, 3754, "Material"], [3769, 3770, "Task"], [3807, 3808, "Task"], [3816, 3817, "Task"], [3851, 3852, "Task"], [3885, 3886, "Task"], [4280, 4281, "Material"], [4663, 4664, "Material"], [4823, 4826, "Material"], [4880, 4883, "Material"], [4900, 4903, "Material"], [5023, 5025, "Task"], [5109, 5110, "Material"], [5116, 5117, "Material"], [5176, 5178, "Method"], [5185, 5187, "Method"], [5285, 5287, "Method"], [7343, 7344, "Material"]], "sections": [[0, 2725], [2725, 2777], [2777, 2782], [2782, 3277], [3277, 3597], [3597, 3747], [3747, 3998], [3998, 4212], [4212, 4422], [4422, 4765], [4765, 4965], [4965, 5156], [5156, 5658], [5658, 5915], [5915, 6029], [6029, 6195], [6195, 6236], [6236, 6413], [6413, 6523], [6523, 6582], [6582, 6825], [6825, 7487]], "sentences": [[0, 13], [13, 38], [38, 58], [58, 82], [82, 114], [114, 135], [135, 158], [158, 188], [188, 244], [244, 298], [298, 318], [318, 355], [355, 376], [376, 402], [402, 438], [438, 456], [456, 487], [487, 529], [529, 565], [565, 585], [585, 609], [609, 652], [652, 690], [690, 708], [708, 757], [757, 800], [800, 831], [831, 850], [850, 870], [870, 919], [919, 944], [944, 995], [995, 1033], [1033, 1075], [1075, 1137], [1137, 1167], [1167, 1188], [1188, 1232], [1232, 1279], [1279, 1324], [1324, 1341], [1341, 1377], [1377, 1403], [1403, 1449], [1449, 1481], [1481, 1492], [1492, 1529], [1529, 1572], [1572, 1591], [1591, 1630], [1630, 1651], [1651, 1666], [1666, 1689], [1689, 1739], [1739, 1756], [1756, 1797], [1797, 1812], [1812, 1838], [1838, 1868], [1868, 1920], [1920, 1935], [1935, 1953], [1953, 1977], [1977, 2002], [2002, 2020], [2020, 2039], [2039, 2078], [2078, 2102], [2102, 2137], [2137, 2145], [2145, 2214], [2214, 2237], [2237, 2265], [2265, 2299], [2299, 2338], [2338, 2352], [2352, 2390], [2390, 2417], [2417, 2436], [2436, 2479], [2479, 2495], [2495, 2536], [2536, 2569], [2569, 2590], [2590, 2663], [2663, 2691], [2691, 2725], [2725, 2730], [2730, 2764], [2764, 2777], [2777, 2782], [2782, 2788], [2788, 2810], [2810, 2824], [2824, 2853], [2853, 2895], [2895, 2922], [2922, 2940], [2940, 2965], [2965, 2978], [2978, 2997], [2997, 3027], [3027, 3037], [3037, 3057], [3057, 3065], [3065, 3093], [3093, 3110], [3110, 3116], [3116, 3126], [3126, 3133], [3133, 3149], [3149, 3178], [3178, 3199], [3199, 3218], [3218, 3246], [3246, 3277], [3277, 3283], [3283, 3304], [3304, 3327], [3327, 3330], [3330, 3343], [3343, 3366], [3366, 3386], [3386, 3405], [3405, 3415], [3415, 3427], [3427, 3433], [3433, 3447], [3447, 3464], [3464, 3481], [3481, 3510], [3510, 3551], [3551, 3572], [3572, 3593], [3593, 3597], [3597, 3602], [3602, 3636], [3636, 3677], [3677, 3687], [3687, 3698], [3698, 3722], [3722, 3747], [3747, 3752], [3752, 3773], [3773, 3794], [3794, 3809], [3809, 3825], [3825, 3841], [3841, 3868], [3868, 3879], [3879, 3893], [3893, 3909], [3909, 3922], [3922, 3969], [3969, 3985], [3985, 3994], [3994, 3998], [3998, 4001], [4001, 4019], [4019, 4039], [4039, 4063], [4063, 4077], [4077, 4085], [4085, 4093], [4093, 4107], [4107, 4129], [4129, 4138], [4138, 4146], [4146, 4155], [4155, 4163], [4163, 4184], [4184, 4204], [4204, 4212], [4212, 4216], [4216, 4230], [4230, 4240], [4240, 4252], [4252, 4272], [4272, 4284], [4284, 4297], [4297, 4340], [4340, 4357], [4357, 4367], [4367, 4382], [4382, 4398], [4398, 4422], [4422, 4427], [4427, 4454], [4454, 4474], [4474, 4504], [4504, 4517], [4517, 4543], [4543, 4563], [4563, 4581], [4581, 4593], [4593, 4607], [4607, 4623], [4623, 4643], [4643, 4655], [4655, 4673], [4673, 4680], [4680, 4695], [4695, 4728], [4728, 4744], [4744, 4765], [4765, 4773], [4773, 4787], [4787, 4822], [4822, 4844], [4844, 4855], [4855, 4879], [4879, 4899], [4899, 4922], [4922, 4965], [4965, 4968], [4968, 4982], [4982, 5004], [5004, 5036], [5036, 5049], [5049, 5069], [5069, 5088], [5088, 5104], [5104, 5129], [5129, 5146], [5146, 5156], [5156, 5161], [5161, 5182], [5182, 5221], [5221, 5254], [5254, 5281], [5281, 5291], [5291, 5314], [5314, 5328], [5328, 5355], [5355, 5386], [5386, 5416], [5416, 5444], [5444, 5459], [5459, 5494], [5494, 5513], [5513, 5535], [5535, 5548], [5548, 5579], [5579, 5587], [5587, 5599], [5599, 5631], [5631, 5658], [5658, 5661], [5661, 5682], [5682, 5700], [5700, 5727], [5727, 5743], [5743, 5750], [5750, 5768], [5768, 5799], [5799, 5818], [5818, 5845], [5845, 5865], [5865, 5882], [5882, 5903], [5903, 5915], [5915, 5920], [5920, 5928], [5928, 5944], [5944, 5983], [5983, 5998], [5998, 6012], [6012, 6029], [6029, 6033], [6033, 6049], [6049, 6082], [6082, 6109], [6109, 6122], [6122, 6149], [6149, 6178], [6178, 6195], [6195, 6199], [6199, 6236], [6236, 6240], [6240, 6271], [6271, 6287], [6287, 6323], [6323, 6353], [6353, 6369], [6369, 6377], [6377, 6413], [6413, 6416], [6416, 6436], [6436, 6476], [6476, 6499], [6499, 6509], [6509, 6523], [6523, 6527], [6527, 6556], [6556, 6566], [6566, 6582], [6582, 6589], [6589, 6605], [6605, 6611], [6611, 6626], [6626, 6650], [6650, 6665], [6665, 6689], [6689, 6714], [6714, 6744], [6744, 6762], [6762, 6773], [6773, 6791], [6791, 6801], [6801, 6813], [6813, 6825], [6825, 6830], [6830, 6857], [6857, 6868], [6868, 6879], [6879, 6886], [6886, 6901], [6901, 6916], [6916, 6931], [6931, 6943], [6943, 6975], [6975, 6986], [6986, 6992], [6992, 7014], [7014, 7044], [7044, 7074], [7074, 7114], [7114, 7153], [7153, 7193], [7193, 7227], [7227, 7242], [7242, 7253], [7253, 7282], [7282, 7315], [7315, 7340], [7340, 7366], [7366, 7397], [7397, 7413], [7413, 7454], [7454, 7487]], "words": ["document", ":", "Improving", "neural", "networks", "by", "preventing", "co", "-", "adaptation", "of", "feature", "detectors", "When", "a", "large", "feedforward", "neural", "network", "is", "trained", "on", "a", "small", "training", "set", ",", "it", "typically", "performs", "poorly", "on", "held", "-", "out", "test", "data", ".", "This", "\u201c", "overfitting", "\u201d", "is", "greatly", "reduced", "by", "randomly", "omitting", "half", "of", "the", "feature", "detectors", "on", "each", "training", "case", ".", "This", "prevents", "complex", "co", "-", "adaptations", "in", "which", "a", "feature", "detector", "is", "only", "helpful", "in", "the", "context", "of", "several", "other", "specific", "feature", "detectors", ".", "Instead", ",", "each", "neuron", "learns", "to", "detect", "a", "feature", "that", "is", "generally", "helpful", "for", "producing", "the", "correct", "answer", "given", "the", "combinatorially", "large", "variety", "of", "internal", "contexts", "in", "which", "it", "must", "operate", ".", "Random", "\u201c", "dropout", "\u201d", "gives", "big", "improvements", "on", "many", "benchmark", "tasks", "and", "sets", "new", "records", "for", "speech", "and", "object", "recognition", ".", "A", "feedforward", ",", "artificial", "neural", "network", "uses", "layers", "of", "non", "-", "linear", "\u201c", "hidden", "\u201d", "units", "between", "its", "inputs", "and", "its", "outputs", ".", "By", "adapting", "the", "weights", "on", "the", "incoming", "connections", "of", "these", "hidden", "units", "it", "learns", "feature", "detectors", "that", "enable", "it", "to", "predict", "the", "correct", "output", "when", "given", "an", "input", "vector", ".", "If", "the", "relationship", "between", "the", "input", "and", "the", "correct", "output", "is", "complicated", "and", "the", "network", "has", "enough", "hidden", "units", "to", "model", "it", "accurately", ",", "there", "will", "typically", "be", "many", "different", "settings", "of", "the", "weights", "that", "can", "model", "the", "training", "set", "almost", "perfectly", ",", "especially", "if", "there", "is", "only", "a", "limited", "amount", "of", "labeled", "training", "data", ".", "Each", "of", "these", "weight", "vectors", "will", "make", "different", "predictions", "on", "held", "-", "out", "test", "data", "and", "almost", "all", "of", "them", "will", "do", "worse", "on", "the", "test", "data", "than", "on", "the", "training", "data", "because", "the", "feature", "detectors", "have", "been", "tuned", "to", "work", "well", "together", "on", "the", "training", "data", "but", "not", "on", "the", "test", "data", ".", "Overfitting", "can", "be", "reduced", "by", "using", "\u201c", "dropout", "\u201d", "to", "prevent", "complex", "co", "-", "adaptations", "on", "the", "training", "data", ".", "On", "each", "presentation", "of", "each", "training", "case", ",", "each", "hidden", "unit", "is", "randomly", "omitted", "from", "the", "network", "with", "a", "probability", "of", "0.5", ",", "so", "a", "hidden", "unit", "can", "not", "rely", "on", "other", "hidden", "units", "being", "present", ".", "Another", "way", "to", "view", "the", "dropout", "procedure", "is", "as", "a", "very", "efficient", "way", "of", "performing", "model", "averaging", "with", "neural", "networks", ".", "A", "good", "way", "to", "reduce", "the", "error", "on", "the", "test", "set", "is", "to", "average", "the", "predictions", "produced", "by", "a", "very", "large", "number", "of", "different", "networks", ".", "The", "standard", "way", "to", "do", "this", "is", "to", "train", "many", "separate", "networks", "and", "then", "to", "apply", "each", "of", "these", "networks", "to", "the", "test", "data", ",", "but", "this", "is", "computationally", "expensive", "during", "both", "training", "and", "testing", ".", "Random", "dropout", "makes", "it", "possible", "to", "train", "a", "huge", "number", "of", "different", "networks", "in", "a", "reasonable", "time", ".", "There", "is", "almost", "certainly", "a", "different", "network", "for", "each", "presentation", "of", "each", "training", "case", "but", "all", "of", "these", "networks", "share", "the", "same", "weights", "for", "the", "hidden", "units", "that", "are", "present", ".", "We", "use", "the", "standard", ",", "stochastic", "gradient", "descent", "procedure", "for", "training", "the", "dropout", "neural", "networks", "on", "mini", "-", "batches", "of", "training", "cases", ",", "but", "we", "modify", "the", "penalty", "term", "that", "is", "normally", "used", "to", "prevent", "the", "weights", "from", "growing", "too", "large", ".", "Instead", "of", "penalizing", "the", "squared", "length", "(", "L2", "norm", ")", "of", "the", "whole", "weight", "vector", ",", "we", "set", "an", "upper", "bound", "on", "the", "L2", "norm", "of", "the", "incoming", "weight", "vector", "for", "each", "individual", "hidden", "unit", ".", "If", "a", "weight", "-", "update", "violates", "this", "constraint", ",", "we", "renormalize", "the", "weights", "of", "the", "hidden", "unit", "by", "division", ".", "Using", "a", "constraint", "rather", "than", "a", "penalty", "prevents", "weights", "from", "growing", "very", "large", "no", "matter", "how", "large", "the", "proposed", "weight", "-", "update", "is", ".", "This", "makes", "it", "possible", "to", "start", "with", "a", "very", "large", "learning", "rate", "which", "decays", "during", "learning", ",", "thus", "allowing", "a", "far", "more", "thorough", "search", "of", "the", "weight", "-", "space", "than", "methods", "that", "start", "with", "small", "weights", "and", "use", "a", "small", "learning", "rate", ".", "At", "test", "time", ",", "we", "use", "the", "\u201c", "mean", "network", "\u201d", "that", "contains", "all", "of", "the", "hidden", "units", "but", "with", "their", "outgoing", "weights", "halved", "to", "compensate", "for", "the", "fact", "that", "twice", "as", "many", "of", "them", "are", "active", ".", "In", "practice", ",", "this", "gives", "very", "similar", "performance", "to", "averaging", "over", "a", "large", "number", "of", "dropout", "networks", ".", "In", "networks", "with", "a", "single", "hidden", "layer", "of", "units", "and", "a", "\u201c", "softmax", "\u201d", "output", "layer", "for", "computing", "the", "probabilities", "of", "the", "class", "labels", ",", "using", "the", "mean", "network", "is", "exactly", "equivalent", "to", "taking", "the", "geometric", "mean", "of", "the", "probability", "distributions", "over", "labels", "predicted", "by", "all", "possible", "networks", ".", "Assuming", "the", "dropout", "networks", "do", "not", "all", "make", "identical", "predictions", ",", "the", "prediction", "of", "the", "mean", "network", "is", "guaranteed", "to", "assign", "a", "higher", "log", "probability", "to", "the", "correct", "answer", "than", "the", "mean", "of", "the", "log", "probabilities", "assigned", "by", "the", "individual", "dropout", "networks", ".", "Similarly", ",", "for", "regression", "with", "linear", "output", "units", ",", "the", "squared", "error", "of", "the", "mean", "network", "is", "always", "better", "than", "the", "average", "of", "the", "squared", "errors", "of", "the", "dropout", "networks", ".", "We", "initially", "explored", "the", "effectiveness", "of", "dropout", "using", "MNIST", ",", "a", "widely", "used", "benchmark", "for", "machine", "learning", "algorithms", ".", "It", "contains", "60", ",", "000", "28x28", "training", "images", "of", "individual", "hand", "written", "digits", "and", "10", ",", "000", "test", "images", ".", "Performance", "on", "the", "test", "set", "can", "be", "greatly", "improved", "by", "enhancing", "the", "training", "data", "with", "transformed", "images", "or", "by", "wiring", "knowledge", "about", "spatial", "transformations", "into", "a", "convolutional", "neural", "network", "or", "by", "using", "generative", "pre", "-", "training", "to", "extract", "useful", "features", "from", "the", "training", "images", "without", "using", "the", "labels", ".", "Without", "using", "any", "of", "these", "tricks", ",", "the", "best", "published", "result", "for", "a", "standard", "feedforward", "neural", "network", "is", "160", "errors", "on", "the", "test", "set", ".", "This", "can", "be", "reduced", "to", "about", "130", "errors", "by", "using", "50", "%", "dropout", "with", "separate", "L2", "constraints", "on", "the", "incoming", "weights", "of", "each", "hidden", "unit", "and", "further", "reduced", "to", "about", "110", "errors", "by", "also", "dropping", "out", "a", "random", "20", "%", "of", "the", "pixels", "(", "see", "figure", "[", "reference", "]", ")", ".", "Dropout", "can", "also", "be", "combined", "with", "generative", "pre", "-", "training", ",", "but", "in", "this", "case", "we", "use", "a", "small", "learning", "rate", "and", "no", "weight", "constraints", "to", "avoid", "losing", "the", "feature", "detectors", "discovered", "by", "the", "pre", "-", "training", ".", "The", "publically", "available", ",", "pre", "-", "trained", "deep", "belief", "net", "described", "in", "got", "118", "errors", "when", "it", "was", "fine", "-", "tuned", "using", "standard", "back", "-", "propagation", "and", "92", "errors", "when", "fine", "-", "tuned", "using", "50", "%", "dropout", "of", "the", "hidden", "units", ".", "When", "the", "publically", "available", "code", "at", "URL", "was", "used", "to", "pre", "-", "train", "a", "deep", "Boltzmann", "machine", "five", "times", ",", "the", "unrolled", "network", "got", "103", ",", "97", ",", "94", ",", "93", "and", "88", "errors", "when", "fine", "-", "tuned", "using", "standard", "backpropagation", "and", "83", ",", "79", ",", "78", ",", "78", "and", "77", "errors", "when", "using", "50", "%", "dropout", "of", "the", "hidden", "units", ".", "The", "mean", "of", "79", "errors", "is", "a", "record", "for", "methods", "that", "do", "not", "use", "prior", "knowledge", "or", "enhanced", "training", "sets", "(", "For", "details", "see", "Appendix", "[", "reference", "]", ")", ".", "We", "then", "applied", "dropout", "to", "TIMIT", ",", "a", "widely", "used", "benchmark", "for", "recognition", "of", "clean", "speech", "with", "a", "small", "vocabulary", ".", "Speech", "recognition", "systems", "use", "hidden", "Markov", "models", "(", "HMMs", ")", "to", "deal", "with", "temporal", "variability", "and", "they", "need", "an", "acoustic", "model", "that", "determines", "how", "well", "a", "frame", "of", "coefficients", "extracted", "from", "the", "acoustic", "input", "fits", "each", "possible", "state", "of", "each", "hidden", "Markov", "model", ".", "Recently", ",", "deep", ",", "pre", "-", "trained", ",", "feedforward", "neural", "networks", "that", "map", "a", "short", "sequence", "of", "frames", "into", "a", "probability", "distribution", "over", "HMM", "states", "have", "been", "shown", "to", "outperform", "tradional", "Gaussian", "mixture", "models", "on", "both", "TIMIT", "and", "a", "variety", "of", "more", "realistic", "large", "vocabulary", "tasks", ".", "Figure", "[", "reference", "]", "shows", "the", "frame", "classification", "error", "rate", "on", "the", "core", "test", "set", "of", "the", "TIMIT", "benchmark", "when", "the", "central", "frame", "of", "a", "window", "is", "classified", "as", "belonging", "to", "the", "HMM", "state", "that", "is", "given", "the", "highest", "probability", "by", "the", "neural", "net", ".", "The", "input", "to", "the", "net", "is", "21", "adjacent", "frames", "with", "an", "advance", "of", "10ms", "per", "frame", ".", "The", "neural", "net", "has", "4", "fully", "-", "connected", "hidden", "layers", "of", "4000", "units", "per", "layer", "and", "185", "\u201c", "softmax", "\u201d", "output", "units", "that", "are", "subsequently", "merged", "into", "the", "39", "distinct", "classes", "used", "for", "the", "benchmark", ".", "Dropout", "of", "50", "%", "of", "the", "hidden", "units", "significantly", "improves", "classification", "for", "a", "variety", "of", "different", "network", "architectures", "(", "see", "figure", "[", "reference", "]", ")", ".", "To", "get", "the", "frame", "recognition", "rate", ",", "the", "class", "probabilities", "that", "the", "neural", "network", "outputs", "for", "each", "frame", "are", "given", "to", "a", "decoder", "which", "knows", "about", "transition", "probabilities", "between", "HMM", "states", "and", "runs", "the", "Viterbi", "algorithm", "to", "infer", "the", "single", "best", "sequence", "of", "HMM", "states", ".", "Without", "dropout", ",", "the", "recognition", "rate", "is", "%", "and", "with", "dropout", "this", "improves", "to", "%", ",", "which", "is", "a", "record", "for", "methods", "that", "do", "not", "use", "any", "information", "about", "speaker", "identity", ".", "CIFAR", "-", "10", "is", "a", "benchmark", "task", "for", "object", "recognition", ".", "It", "uses", "32x32", "downsampled", "color", "images", "of", "10", "different", "object", "classes", "that", "were", "found", "by", "searching", "the", "web", "for", "the", "names", "of", "the", "class", "(", "e.g.", "dog", ")", "or", "its", "subclasses", "(", "e.g.", "Golden", "Retriever", ")", ".", "These", "images", "were", "labeled", "by", "hand", "to", "produce", "50", ",", "000", "training", "images", "and", "10", ",", "000", "test", "images", "in", "which", "there", "is", "a", "single", "dominant", "object", "that", "could", "plausibly", "be", "given", "the", "class", "name", "(", "see", "figure", "[", "reference", "]", ")", ".", "The", "best", "published", "error", "rate", "on", "the", "test", "set", ",", "without", "using", "transformed", "data", ",", "is", "18.5", "%", ".", "We", "achieved", "an", "error", "rate", "of", "16.6", "%", "by", "using", "a", "neural", "network", "with", "three", "convolutional", "hidden", "layers", "interleaved", "with", "three", "\u201c", "max", "-", "pooling", "\u201d", "layers", "that", "report", "the", "maximum", "activity", "in", "local", "pools", "of", "convolutional", "units", ".", "These", "six", "layers", "were", "followed", "by", "one", "locally", "-", "connected", "layer", "(", "For", "details", "see", "Appendix", "[", "reference", "]", ")", ".", "Using", "dropout", "in", "the", "last", "hidden", "layer", "gives", "an", "error", "rate", "of", "15.6", "%", ".", "ImageNet", "is", "an", "extremely", "challenging", "object", "recognition", "dataset", "consisting", "of", "thousands", "of", "high", "-", "resolution", "images", "of", "thousands", "of", "classes", "of", "object", ".", "In", "2010", ",", "a", "subset", "of", "1000", "classes", "with", "roughly", "1000", "examples", "per", "class", "was", "the", "basis", "of", "an", "object", "recognition", "competition", "in", "which", "the", "winning", "entry", ",", "which", "was", "actually", "an", "average", "of", "six", "separate", "models", ",", "achieved", "an", "error", "rate", "of", "47.2", "%", "on", "the", "test", "set", ".", "The", "current", "state", "-", "of", "-", "the", "-", "art", "result", "on", "this", "dataset", "is", "45.7", "%", ".", "We", "achieved", "comparable", "performance", "of", "48.6", "%", "error", "using", "a", "single", "neural", "network", "with", "five", "convolutional", "hidden", "layers", "interleaved", "with", "\u201c", "max", "-", "pooling", "\u201d", "layer", "followed", "by", "two", "globally", "connected", "layers", "and", "a", "final", "1000", "-", "way", "softmax", "layer", ".", "All", "layers", "had", "L2", "weight", "constraints", "on", "the", "incoming", "weights", "of", "each", "hidden", "unit", ".", "Using", "50", "%", "dropout", "in", "the", "sixth", "hidden", "layer", "reduces", "this", "to", "a", "record", "42.4", "%", "(", "For", "details", "see", "Appendix", "[", "reference", "]", ")", ".", "For", "the", "speech", "recognition", "dataset", "and", "both", "of", "the", "object", "recognition", "datasets", "it", "is", "necessary", "to", "make", "a", "large", "number", "of", "decisions", "in", "designing", "the", "architecture", "of", "the", "net", ".", "We", "made", "these", "decisions", "by", "holding", "out", "a", "separate", "validation", "set", "that", "was", "used", "to", "evaluate", "the", "performance", "of", "a", "large", "number", "of", "different", "architectures", "and", "we", "then", "used", "the", "architecture", "that", "performed", "best", "with", "dropout", "on", "the", "validation", "set", "to", "assess", "the", "performance", "of", "dropout", "on", "the", "real", "test", "set", ".", "The", "Reuters", "dataset", "contains", "documents", "that", "have", "been", "labeled", "with", "a", "hierarchy", "of", "classes", ".", "We", "created", "training", "and", "test", "sets", "each", "containing", "201", ",", "369", "documents", "from", "50", "mutually", "exclusive", "classes", ".", "Each", "document", "was", "represented", "by", "a", "vector", "of", "counts", "for", "2000", "common", "non", "-", "stop", "words", ",", "with", "each", "count", "being", "transformed", "to", ".", "A", "feedforward", "neural", "network", "with", "2", "fully", "connected", "layers", "of", "2000", "hidden", "units", "trained", "with", "backpropagation", "gets", "31.05", "%", "error", "on", "the", "test", "set", ".", "This", "is", "reduced", "to", "29.62", "%", "by", "using", "50", "%", "dropout", "(", "Appendix", "[", "reference", "]", ")", ".", "We", "have", "tried", "various", "dropout", "probabilities", "and", "almost", "all", "of", "them", "improve", "the", "generalization", "performance", "of", "the", "network", ".", "For", "fully", "connected", "layers", ",", "dropout", "in", "all", "hidden", "layers", "works", "better", "than", "dropout", "in", "only", "one", "hidden", "layer", "and", "more", "extreme", "probabilities", "tend", "to", "be", "worse", ",", "which", "is", "why", "we", "have", "used", "0.5", "throughout", "this", "paper", ".", "For", "the", "inputs", ",", "dropout", "can", "also", "help", ",", "though", "it", "it", "often", "better", "to", "retain", "more", "than", "50", "%", "of", "the", "inputs", ".", "It", "is", "also", "possible", "to", "adapt", "the", "individual", "dropout", "probability", "of", "each", "hidden", "or", "input", "unit", "by", "comparing", "the", "average", "performance", "on", "a", "validation", "set", "with", "the", "average", "performance", "when", "the", "unit", "is", "present", ".", "This", "makes", "the", "method", "work", "slightly", "better", ".", "For", "datasets", "in", "which", "the", "required", "input", "-", "output", "mapping", "has", "a", "number", "of", "fairly", "different", "regimes", ",", "performance", "can", "probably", "be", "further", "improved", "by", "making", "the", "dropout", "probabilities", "be", "a", "learned", "function", "of", "the", "input", ",", "thus", "creating", "a", "statistically", "efficient", "\u201c", "mixture", "of", "experts", "\u201d", "in", "which", "there", "are", "combinatorially", "many", "experts", ",", "but", "each", "parameter", "gets", "adapted", "on", "a", "large", "fraction", "of", "the", "training", "data", ".", "Dropout", "is", "considerably", "simpler", "to", "implement", "than", "Bayesian", "model", "averaging", "which", "weights", "each", "model", "by", "its", "posterior", "probability", "given", "the", "training", "data", ".", "For", "complicated", "model", "classes", ",", "like", "feedforward", "neural", "networks", ",", "Bayesian", "methods", "typically", "use", "a", "Markov", "chain", "Monte", "Carlo", "method", "to", "sample", "models", "from", "the", "posterior", "distribution", ".", "By", "contrast", ",", "dropout", "with", "a", "probability", "of", "assumes", "that", "all", "the", "models", "will", "eventually", "be", "given", "equal", "importance", "in", "the", "combination", "but", "the", "learning", "of", "the", "shared", "weights", "takes", "this", "into", "account", ".", "At", "test", "time", ",", "the", "fact", "that", "the", "dropout", "decisions", "are", "independent", "for", "each", "unit", "makes", "it", "very", "easy", "to", "approximate", "the", "combined", "opinions", "of", "exponentially", "many", "dropout", "nets", "by", "using", "a", "single", "pass", "through", "the", "mean", "net", ".", "This", "is", "far", "more", "efficient", "than", "averaging", "the", "predictions", "of", "many", "separate", "models", ".", "A", "popular", "alternative", "to", "Bayesian", "model", "averaging", "is", "\u201c", "bagging", "\u201d", "in", "which", "different", "models", "are", "trained", "on", "different", "random", "selections", "of", "cases", "from", "the", "training", "set", "and", "all", "models", "are", "given", "equal", "weight", "in", "the", "combination", ".", "Bagging", "is", "most", "often", "used", "with", "models", "such", "as", "decision", "trees", "because", "these", "are", "very", "quick", "to", "fit", "to", "data", "and", "very", "quick", "at", "test", "time", ".", "Dropout", "allows", "a", "similar", "approach", "to", "be", "applied", "to", "feedforward", "neural", "networks", "which", "are", "much", "more", "powerful", "models", ".", "Dropout", "can", "be", "seen", "as", "an", "extreme", "form", "of", "bagging", "in", "which", "each", "model", "is", "trained", "on", "a", "single", "case", "and", "each", "parameter", "of", "the", "model", "is", "very", "strongly", "regularized", "by", "sharing", "it", "with", "the", "corresponding", "parameter", "in", "all", "the", "other", "models", ".", "This", "is", "a", "much", "better", "regularizer", "than", "the", "standard", "method", "of", "shrinking", "parameters", "towards", "zero", ".", "A", "familiar", "and", "extreme", "case", "of", "dropout", "is", "\u201c", "naive", "bayes", "\u201d", "in", "which", "each", "input", "feature", "is", "trained", "separately", "to", "predict", "the", "class", "label", "and", "then", "the", "predictive", "distributions", "of", "all", "the", "features", "are", "multiplied", "together", "at", "test", "time", ".", "When", "there", "is", "very", "little", "training", "data", ",", "this", "often", "works", "much", "better", "than", "logistic", "classification", "which", "trains", "each", "input", "feature", "to", "work", "well", "in", "the", "context", "of", "all", "the", "other", "features", ".", "Finally", ",", "there", "is", "an", "intriguing", "similarity", "between", "dropout", "and", "a", "recent", "theory", "of", "the", "role", "of", "sex", "in", "evolution", ".", "One", "possible", "interpretation", "of", "the", "theory", "of", "mixability", "articulated", "in", "is", "that", "sex", "breaks", "up", "sets", "of", "co", "-", "adapted", "genes", "and", "this", "means", "that", "achieving", "a", "function", "by", "using", "a", "large", "set", "of", "co", "-", "adapted", "genes", "is", "not", "nearly", "as", "robust", "as", "achieving", "the", "same", "function", ",", "perhaps", "less", "than", "optimally", ",", "in", "multiple", "alternative", "ways", ",", "each", "of", "which", "only", "uses", "a", "small", "number", "of", "co", "-", "adapted", "genes", ".", "This", "allows", "evolution", "to", "avoid", "dead", "-", "ends", "in", "which", "improvements", "in", "fitness", "require", "co", "-", "ordinated", "changes", "to", "a", "large", "number", "of", "co", "-", "adapted", "genes", ".", "It", "also", "reduces", "the", "probability", "that", "small", "changes", "in", "the", "environment", "will", "cause", "large", "decreases", "in", "fitness", "\u00e2\u0080\u0093", "a", "phenomenon", "which", "is", "known", "as", "\u201c", "overfitting", "\u201d", "in", "the", "field", "of", "machine", "learning", ".", "bibliography", ":", "References", "and", "Notes", "We", "thank", "N.", "Jaitly", "for", "help", "with", "TIMIT", ",", "H.", "Larochelle", ",", "R.", "Neal", ",", "K.", "Swersky", "and", "C.K.I.", "Williams", "for", "helpful", "discussions", ",", "and", "NSERC", ",", "Google", "and", "Microsoft", "Research", "for", "funding", ".", "GEH", "and", "RRS", "are", "members", "of", "the", "Canadian", "Institute", "for", "Advanced", "Research", ".", "appendix", ":", "Experiments", "on", "MNIST", "subsection", ":", "Details", "for", "dropout", "training", "The", "MNIST", "dataset", "consists", "of", "28", "28", "digit", "images", "-", "60", ",", "000", "for", "training", "and", "10", ",", "000", "for", "testing", ".", "The", "objective", "is", "to", "classify", "the", "digit", "images", "into", "their", "correct", "digit", "class", ".", "We", "experimented", "with", "neural", "nets", "of", "different", "architectures", "(", "different", "number", "of", "hidden", "units", "and", "layers", ")", "to", "evaluate", "the", "sensitivity", "of", "the", "dropout", "method", "to", "these", "choices", ".", "We", "show", "results", "for", "4", "nets", "(", "784", "-", "800", "-", "800", "-", "10", ",", "784", "-", "1200", "-", "1200", "-", "10", ",", "784", "-", "2000", "-", "2000", "-", "10", ",", "784", "-", "1200", "-", "1200", "-", "1200", "-", "10", ")", ".", "For", "each", "of", "these", "architectures", "we", "use", "the", "same", "dropout", "rates", "-", "50", "%", "dropout", "for", "all", "hidden", "units", "and", "20", "%", "dropout", "for", "visible", "units", ".", "We", "use", "stochastic", "gradient", "descent", "with", "100", "-", "sized", "minibatches", "and", "a", "cross", "-", "entropy", "objective", "function", ".", "An", "exponentially", "decaying", "learning", "rate", "is", "used", "that", "starts", "at", "the", "value", "of", "10.0", "(", "applied", "to", "the", "average", "gradient", "in", "each", "minibatch", ")", ".", "The", "learning", "rate", "is", "multiplied", "by", "0.998", "after", "each", "epoch", "of", "training", ".", "The", "incoming", "weight", "vector", "corresponding", "to", "each", "hidden", "unit", "is", "constrained", "to", "have", "a", "maximum", "squared", "length", "of", ".", "If", ",", "as", "a", "result", "of", "an", "update", ",", "the", "squared", "length", "exceeds", ",", "the", "vector", "is", "scaled", "down", "so", "as", "to", "make", "it", "have", "a", "squared", "length", "of", ".", "Using", "cross", "validation", "we", "found", "that", "gave", "best", "results", ".", "Weights", "are", "initialzed", "to", "small", "random", "values", "drawn", "from", "a", "zero", "-", "mean", "normal", "distribution", "with", "standard", "deviation", "0.01", ".", "Momentum", "is", "used", "to", "speed", "up", "learning", ".", "The", "momentum", "starts", "off", "at", "a", "value", "of", "0.5", "and", "is", "increased", "linearly", "to", "0.99", "over", "the", "first", "500", "epochs", ",", "after", "which", "it", "stays", "at", "0.99", ".", "Also", ",", "the", "learning", "rate", "is", "multiplied", "by", "a", "factor", "of", "(", "1", "-", "momentum", ")", ".", "No", "weight", "decay", "is", "used", ".", "Weights", "were", "updated", "at", "the", "end", "of", "each", "minibatch", ".", "Training", "was", "done", "for", "3000", "epochs", ".", "The", "weight", "update", "takes", "the", "following", "form", ":", "where", ",", "with", ",", ",", ",", ",", ".", "While", "using", "a", "constant", "learning", "rate", "also", "gives", "improvements", "over", "standard", "backpropagation", ",", "starting", "with", "a", "high", "learning", "rate", "and", "decaying", "it", "provided", "a", "significant", "boost", "in", "performance", ".", "Constraining", "input", "vectors", "to", "have", "a", "fixed", "length", "prevents", "weights", "from", "increasing", "arbitrarily", "in", "magnitude", "irrespective", "of", "the", "learning", "rate", ".", "This", "gives", "the", "network", "a", "lot", "of", "opportunity", "to", "search", "for", "a", "good", "configuration", "in", "the", "weight", "space", ".", "As", "the", "learning", "rate", "decays", ",", "the", "algorithm", "is", "able", "to", "take", "smaller", "steps", "and", "finds", "the", "right", "step", "size", "at", "which", "it", "can", "make", "learning", "progress", ".", "Using", "a", "high", "final", "momentum", "distributes", "gradient", "information", "over", "a", "large", "number", "of", "updates", "making", "learning", "stable", "in", "this", "scenario", "where", "each", "gradient", "computation", "is", "for", "a", "different", "stochastic", "network", ".", "subsection", ":", "Details", "for", "dropout", "finetuning", "Apart", "from", "training", "a", "neural", "network", "starting", "from", "random", "weights", ",", "dropout", "can", "also", "be", "used", "to", "finetune", "pretrained", "models", ".", "We", "found", "that", "finetuning", "a", "model", "using", "dropout", "with", "a", "small", "learning", "rate", "can", "give", "much", "better", "performace", "than", "standard", "backpropagation", "finetuning", ".", "Deep", "Belief", "Nets", "-", "We", "took", "a", "neural", "network", "pretrained", "using", "a", "Deep", "Belief", "Network", ".", "It", "had", "a", "784", "-", "500", "-", "500", "-", "2000", "architecture", "and", "was", "trained", "using", "greedy", "layer", "-", "wise", "Contrastive", "Divergence", "learning", ".", "Instead", "of", "fine", "-", "tuning", "it", "with", "the", "usual", "backpropagation", "algorithm", ",", "we", "used", "the", "dropout", "version", "of", "it", ".", "Dropout", "rate", "was", "same", "as", "before", ":", "50", "%", "for", "hidden", "units", "and", "20", "%", "for", "visible", "units", ".", "A", "constant", "small", "learning", "rate", "of", "1.0", "was", "used", ".", "No", "constraint", "was", "imposed", "on", "the", "length", "of", "incoming", "weight", "vectors", ".", "No", "weight", "decay", "was", "used", ".", "All", "other", "hyper", "-", "parameters", "were", "set", "to", "be", "the", "same", "as", "before", ".", "The", "model", "was", "trained", "for", "1000", "epochs", "with", "stochstic", "gradient", "descent", "using", "minibatches", "of", "size", "100", ".", "While", "standard", "back", "propagation", "gave", "about", "118", "errors", ",", "dropout", "decreased", "the", "errors", "to", "about", "92", ".", "Deep", "Boltzmann", "Machines", "-", "We", "also", "took", "a", "pretrained", "Deep", "Boltzmann", "Machine", "(", "784", "-", "500", "-", "1000", "-", "10", ")", "and", "finetuned", "it", "using", "dropout", "-", "backpropagation", ".", "The", "model", "uses", "a", "1784", "-", "500", "-", "1000", "-", "10", "architecture", "(", "The", "extra", "1000", "input", "units", "come", "from", "the", "mean", "-", "field", "activations", "of", "the", "second", "layer", "of", "hidden", "units", "in", "the", "DBM", ",", "See", "for", "details", ")", ".", "All", "finetuning", "hyper", "-", "parameters", "were", "set", "to", "be", "the", "same", "as", "the", "ones", "used", "for", "a", "Deep", "Belief", "Network", ".", "We", "were", "able", "to", "get", "a", "mean", "of", "about", "79", "errors", "with", "dropout", "whereas", "usual", "finetuning", "gives", "about", "94", "errors", ".", "[", "]", "[", "]", "subsection", ":", "Effect", "on", "features", "One", "reason", "why", "dropout", "gives", "major", "improvements", "over", "backpropagation", "is", "that", "it", "encourages", "each", "individual", "hidden", "unit", "to", "learn", "a", "useful", "feature", "without", "relying", "on", "specific", "other", "hidden", "units", "to", "correct", "its", "mistakes", ".", "In", "order", "to", "verify", "this", "and", "better", "understand", "the", "effect", "of", "dropout", "on", "feature", "learning", ",", "we", "look", "at", "the", "first", "level", "of", "features", "learned", "by", "a", "784", "-", "500", "-", "500", "neural", "network", "without", "any", "generative", "pre", "-", "training", ".", "The", "features", "are", "shown", "in", "Figure", "[", "reference", "]", ".", "Each", "panel", "shows", "100", "random", "features", "learned", "by", "each", "network", ".", "The", "features", "that", "dropout", "learns", "are", "simpler", "and", "look", "like", "strokes", ",", "whereas", "the", "ones", "learned", "by", "standard", "backpropagation", "are", "difficult", "to", "interpret", ".", "This", "confirms", "that", "dropout", "indeed", "forces", "the", "discriminative", "model", "to", "learn", "good", "features", "which", "are", "less", "co", "-", "adapted", "and", "leads", "to", "better", "generalization", ".", "appendix", ":", "Experiments", "on", "TIMIT", "The", "TIMIT", "Acoustic", "-", "Phonetic", "Continuous", "Speech", "Corpus", "is", "a", "standard", "dataset", "used", "for", "evaluation", "of", "automatic", "speech", "recognition", "systems", ".", "It", "consists", "of", "recordings", "of", "630", "speakers", "of", "8", "dialects", "of", "American", "English", "each", "reading", "10", "phonetically", "-", "rich", "sentences", ".", "It", "also", "comes", "with", "the", "word", "and", "phone", "-", "level", "transcriptions", "of", "the", "speech", ".", "The", "objective", "is", "to", "convert", "a", "given", "speech", "signal", "into", "a", "transcription", "sequence", "of", "phones", ".", "This", "data", "needs", "to", "be", "pre", "-", "processed", "to", "extract", "input", "features", "and", "output", "targets", ".", "We", "used", "Kaldi", ",", "an", "open", "source", "code", "library", "for", "speech", ",", "to", "pre", "-", "process", "the", "dataset", "so", "that", "our", "results", "can", "be", "reproduced", "exactly", ".", "The", "inputs", "to", "our", "networks", "are", "log", "filter", "bank", "responses", ".", "They", "are", "extracted", "for", "25", "ms", "speech", "windows", "with", "strides", "of", "10", "ms", ".", "Each", "dimension", "of", "the", "input", "representation", "was", "normalized", "to", "have", "mean", "0", "and", "variance", "1", ".", "Minibatches", "of", "size", "100", "were", "used", "for", "both", "pretraining", "and", "dropout", "finetuning", ".", "We", "tried", "several", "network", "architectures", "by", "varying", "the", "number", "of", "input", "frames", "(", "15", "and", "31", ")", ",", "number", "of", "layers", "in", "the", "neural", "network", "(", "3", ",", "4", "and", "5", ")", "and", "the", "number", "of", "hidden", "units", "in", "each", "layer", "(", "2000", "and", "4000", ")", ".", "Figure", "[", "reference", "]", "shows", "the", "validation", "error", "curves", "for", "a", "number", "of", "these", "combinations", ".", "Using", "dropout", "consistently", "leads", "to", "lower", "error", "rates", ".", "[", "]", "[", "]", "subsection", ":", "Pretraining", "For", "all", "our", "experiments", "on", "TIMIT", ",", "we", "pretrain", "the", "neural", "network", "with", "a", "Deep", "Belief", "Network", ".", "Since", "the", "inputs", "are", "real", "-", "valued", ",", "the", "first", "layer", "was", "pre", "-", "trained", "as", "a", "Gaussian", "RBM", ".", "Visible", "biases", "were", "initialized", "to", "zero", "and", "weights", "to", "random", "numbers", "sampled", "from", "a", "zero", "-", "mean", "normal", "distribution", "with", "standard", "deviation", "0.01", ".", "The", "variance", "of", "each", "visible", "unit", "was", "set", "to", "1.0", "and", "not", "learned", ".", "Learning", "was", "done", "by", "minimizing", "Contrastive", "Divergence", ".", "Momentum", "was", "used", "to", "speed", "up", "learning", ".", "Momentum", "started", "at", "0.5", "and", "was", "increased", "linearly", "to", "0.9", "over", "20", "epochs", ".", "A", "learning", "rate", "of", "0.001", "on", "the", "average", "gradient", "was", "used", "(", "which", "was", "then", "multiplied", "by", "1", "-", "momentum", ")", ".", "An", "L2", "weight", "decay", "of", "0.001", "was", "used", ".", "The", "model", "was", "trained", "for", "100", "epochs", ".", "All", "subsequent", "layers", "were", "trained", "as", "binary", "RBMs", ".", "A", "learning", "rate", "of", "0.01", "was", "used", ".", "The", "visible", "bias", "of", "each", "unit", "was", "initialized", "to", "where", "was", "the", "mean", "activation", "of", "that", "unit", "in", "the", "dataset", ".", "All", "other", "hyper", "-", "parameters", "were", "set", "to", "be", "the", "same", "as", "those", "we", "used", "for", "the", "Gaussian", "RBM", ".", "Each", "layer", "was", "trained", "for", "50", "epochs", ".", "subsection", ":", "Dropout", "Finetuning", "The", "pretrained", "RBMs", "were", "used", "to", "initialize", "the", "weights", "in", "a", "neural", "network", ".", "The", "network", "was", "then", "finetuned", "with", "dropout", "-", "backpropagation", ".", "Momentum", "was", "increased", "from", "0.5", "to", "0.9", "linearly", "over", "10", "epochs", ".", "A", "small", "constant", "learning", "rate", "of", "1.0", "was", "used", "(", "applied", "to", "the", "average", "gradient", "on", "a", "minibatch", ")", ".", "All", "other", "hyperparameters", "are", "the", "same", "as", "for", "MNIST", "dropout", "finetuning", ".", "The", "model", "needs", "to", "be", "run", "for", "about", "200", "epochs", "to", "converge", ".", "The", "same", "network", "was", "also", "finetuned", "with", "standard", "backpropagation", "using", "a", "smaller", "learning", "rate", "of", "0.1", ",", "keeping", "all", "other", "hyperparameters", "Figure", "[", "reference", "]", "shows", "the", "frame", "classification", "error", "and", "cross", "-", "entropy", "objective", "value", "on", "the", "training", "and", "validation", "sets", ".", "We", "compare", "the", "performance", "of", "dropout", "and", "standard", "backpropagation", "on", "several", "network", "architectures", "and", "input", "representations", ".", "Dropout", "consistently", "achieves", "lower", "error", "and", "cross", "-", "entropy", ".", "It", "significantly", "controls", "overfitting", ",", "making", "the", "method", "robust", "to", "choices", "of", "network", "architecture", ".", "It", "allows", "much", "larger", "nets", "to", "be", "trained", "and", "removes", "the", "need", "for", "early", "stopping", ".", "We", "also", "observed", "that", "the", "final", "error", "obtained", "by", "the", "model", "is", "not", "very", "sensitive", "to", "the", "choice", "of", "learning", "rate", "and", "momentum", ".", "appendix", ":", "Experiments", "on", "Reuters", "Reuters", "Corpus", "Volume", "I", "(", "RCV1", "-", "v2", ")", "is", "an", "archive", "of", "804", ",", "414", "newswire", "stories", "that", "have", "been", "manually", "categorized", "into", "103", "topics", ".", "The", "corpus", "covers", "four", "major", "groups", ":", "corporate", "/", "industrial", ",", "economics", ",", "government", "/", "social", ",", "and", "markets", ".", "Sample", "topics", "include", "Energy", "Markets", ",", "Accounts", "/", "Earnings", ",", "Government", "Borrowings", ",", "Disasters", "and", "Accidents", ",", "Interbank", "Markets", ",", "Legal", "/", "Judicial", ",", "Production", "/", "Services", ",", "etc", ".", "The", "topic", "classes", "form", "a", "tree", "which", "is", "typically", "of", "depth", "three", ".", "We", "took", "the", "dataset", "and", "split", "it", "into", "63", "classes", "based", "on", "the", "the", "63", "categories", "at", "the", "second", "-", "level", "of", "the", "category", "tree", ".", "We", "removed", "11", "categories", "that", "did", "not", "have", "any", "data", "and", "one", "category", "that", "had", "only", "4", "training", "examples", ".", "We", "also", "removed", "one", "category", "that", "covered", "a", "huge", "chunk", "(", "25", "%", ")", "of", "the", "examples", ".", "This", "left", "us", "with", "50", "classes", "and", "402", ",", "738", "documents", ".", "We", "divided", "the", "documents", "into", "equal", "-", "sized", "training", "and", "test", "sets", "randomly", ".", "Each", "document", "was", "represented", "using", "the", "2000", "most", "frequent", "non", "-", "stopwords", "in", "the", "dataset", ".", "[", "]", "[", "]", "We", "trained", "a", "neural", "network", "using", "dropout", "-", "backpropagation", "and", "compared", "it", "with", "standard", "backpropagation", ".", "We", "used", "a", "2000", "-", "2000", "-", "1000", "-", "50", "architecture", ".", "The", "training", "hyperparameters", "are", "same", "as", "that", "in", "MNIST", "dropout", "training", "(", "Appendix", "[", "reference", "]", ")", ".", "Training", "was", "done", "for", "500", "epochs", ".", "Figure", "[", "reference", "]", "shows", "the", "training", "and", "test", "set", "errors", "as", "learning", "progresses", ".", "We", "show", "two", "nets", "-", "one", "with", "a", "2000", "-", "2000", "-", "1000", "-", "50", "and", "another", "with", "a", "2000", "-", "1000", "-", "1000", "-", "50", "architecture", "trained", "with", "and", "without", "dropout", ".", "As", "in", "all", "previous", "datasets", "discussed", "so", "far", ",", "we", "obtain", "significant", "improvements", "here", "too", ".", "The", "learning", "not", "only", "results", "in", "better", "generalization", ",", "but", "also", "proceeds", "smoothly", ",", "without", "the", "need", "for", "early", "stopping", ".", "appendix", ":", "Tiny", "Images", "and", "CIFAR", "-", "10", "The", "Tiny", "Images", "dataset", "contains", "80", "million", "color", "images", "collected", "from", "the", "web", ".", "The", "images", "were", "found", "by", "searching", "various", "image", "search", "engines", "for", "English", "nouns", ",", "so", "each", "image", "comes", "with", "a", "very", "unreliable", "label", ",", "which", "is", "the", "noun", "that", "was", "used", "to", "find", "it", ".", "The", "CIFAR", "-", "10", "dataset", "is", "a", "subset", "of", "the", "Tiny", "Images", "dataset", "which", "contains", "60000", "images", "divided", "among", "ten", "classes", ".", "Each", "class", "contains", "5000", "training", "images", "and", "1000", "testing", "images", ".", "The", "classes", "are", "airplane", ",", "automobile", ",", "bird", ",", "cat", ",", "deer", ",", "dog", ",", "frog", ",", "horse", ",", "ship", ",", "and", "truck", ".", "The", "CIFAR", "-", "10", "dataset", "was", "obtained", "by", "filtering", "the", "Tiny", "Images", "dataset", "to", "remove", "images", "with", "incorrect", "labels", ".", "The", "CIFAR", "-", "10", "images", "are", "highly", "varied", ",", "and", "there", "is", "no", "canonical", "viewpoint", "or", "scale", "at", "which", "the", "objects", "appear", ".", "The", "only", "criteria", "for", "including", "an", "image", "were", "that", "the", "image", "contain", "one", "dominant", "instance", "of", "a", "CIFAR", "-", "10", "class", ",", "and", "that", "the", "object", "in", "the", "image", "be", "easily", "identifiable", "as", "belonging", "to", "the", "class", "indicated", "by", "the", "image", "label", ".", "appendix", ":", "ImageNet", "ImageNet", "is", "a", "dataset", "of", "millions", "of", "labeled", "images", "in", "thousands", "of", "categories", ".", "The", "images", "were", "collected", "from", "the", "web", "and", "labelled", "by", "human", "labellers", "using", "Amazon", "\u2019s", "Mechanical", "Turk", "crowd", "-", "sourcing", "tool", ".", "In", "2010", ",", "a", "subset", "of", "roughly", "1000", "images", "in", "each", "of", "1000", "classes", "was", "the", "basis", "of", "an", "object", "recognition", "competition", ",", "a", "part", "of", "the", "Pascal", "Visual", "Object", "Challenge", ".", "This", "is", "the", "version", "of", "ImageNet", "on", "which", "we", "performed", "our", "experiments", ".", "In", "all", ",", "there", "are", "roughly", "1.3", "million", "training", "images", ",", "50000", "validation", "images", ",", "and", "150000", "testing", "images", ".", "This", "dataset", "is", "similar", "in", "spirit", "to", "the", "CIFAR", "-", "10", ",", "but", "on", "a", "much", "bigger", "scale", ".", "The", "images", "are", "full", "-", "resolution", ",", "and", "there", "are", "1000", "categories", "instead", "of", "ten", ".", "Another", "difference", "is", "that", "the", "ImageNet", "images", "often", "contain", "multiple", "instances", "of", "ImageNet", "objects", ",", "simply", "due", "to", "the", "sheer", "number", "of", "object", "classes", ".", "For", "this", "reason", ",", "even", "a", "human", "would", "have", "difficulty", "approaching", "perfect", "accuracy", "on", "this", "dataset", ".", "For", "our", "experiments", "we", "resized", "all", "images", "to", "pixels", ".", "appendix", ":", "Convolutional", "Neural", "Networks", "Our", "models", "for", "CIFAR", "-", "10", "and", "ImageNet", "are", "deep", ",", "feed", "-", "forward", "convolutional", "neural", "networks", "(", "CNNs", ")", ".", "Feed", "-", "forward", "neural", "networks", "are", "models", "which", "consist", "of", "several", "layers", "of", "\u201c", "neurons", "\u201d", ",", "where", "each", "neuron", "in", "a", "given", "layer", "applies", "a", "linear", "filter", "to", "the", "outputs", "of", "the", "neurons", "in", "the", "previous", "layer", ".", "Typically", ",", "a", "scalar", "bias", "is", "added", "to", "the", "filter", "output", "and", "a", "nonlinear", "activation", "function", "is", "applied", "to", "the", "result", "before", "the", "neuron", "\u2019s", "output", "is", "passed", "to", "the", "next", "layer", ".", "The", "linear", "filters", "and", "biases", "are", "referred", "to", "as", "weights", ",", "and", "these", "are", "the", "parameters", "of", "the", "network", "that", "are", "learned", "from", "the", "training", "data", ".", "CNNs", "differ", "from", "ordinary", "neural", "networks", "in", "several", "ways", ".", "First", ",", "neurons", "in", "a", "CNN", "are", "organized", "topographically", "into", "a", "bank", "that", "reflects", "the", "organization", "of", "dimensions", "in", "the", "input", "data", ".", "So", "for", "images", ",", "the", "neurons", "are", "laid", "out", "on", "a", "2D", "grid", ".", "Second", ",", "neurons", "in", "a", "CNN", "apply", "filters", "which", "are", "local", "in", "extent", "and", "which", "are", "centered", "at", "the", "neuron", "\u2019s", "location", "in", "the", "topographic", "organization", ".", "This", "is", "reasonable", "for", "datasets", "where", "we", "expect", "the", "dependence", "of", "input", "dimensions", "to", "be", "a", "decreasing", "function", "of", "distance", ",", "which", "is", "the", "case", "for", "pixels", "in", "natural", "images", ".", "In", "particular", ",", "we", "expect", "that", "useful", "clues", "to", "the", "identity", "of", "the", "object", "in", "an", "input", "image", "can", "be", "found", "by", "examining", "small", "local", "neighborhoods", "of", "the", "image", ".", "Third", ",", "all", "neurons", "in", "a", "bank", "apply", "the", "same", "filter", ",", "but", "as", "just", "mentioned", ",", "they", "apply", "it", "at", "different", "locations", "in", "the", "input", "image", ".", "This", "is", "reasonable", "for", "datasets", "with", "roughly", "stationary", "statistics", ",", "such", "as", "natural", "images", ".", "We", "expect", "that", "the", "same", "kinds", "of", "structures", "can", "appear", "at", "all", "positions", "in", "an", "input", "image", ",", "so", "it", "is", "reasonable", "to", "treat", "all", "positions", "equally", "by", "filtering", "them", "in", "the", "same", "way", ".", "In", "this", "way", ",", "a", "bank", "of", "neurons", "in", "a", "CNN", "applies", "a", "convolution", "operation", "to", "its", "input", ".", "A", "single", "layer", "in", "a", "CNN", "typically", "has", "multiple", "banks", "of", "neurons", ",", "each", "performing", "a", "convolution", "with", "a", "different", "filter", ".", "These", "banks", "of", "neurons", "become", "distinct", "input", "channels", "into", "the", "next", "layer", ".", "The", "distance", ",", "in", "pixels", ",", "between", "the", "boundaries", "of", "the", "receptive", "fields", "of", "neighboring", "neurons", "in", "a", "convolutional", "bank", "determines", "the", "stride", "with", "which", "the", "convolution", "operation", "is", "applied", ".", "Larger", "strides", "imply", "fewer", "neurons", "per", "bank", ".", "Our", "models", "use", "a", "stride", "of", "one", "pixel", "unless", "otherwise", "noted", ".", "One", "important", "consequence", "of", "this", "convolutional", "shared", "-", "filter", "architecture", "is", "a", "drastic", "reduction", "in", "the", "number", "of", "parameters", "relative", "to", "a", "neural", "net", "in", "which", "all", "neurons", "apply", "different", "filters", ".", "This", "reduces", "the", "net", "\u2019s", "representational", "capacity", ",", "but", "it", "also", "reduces", "its", "capacity", "to", "overfit", ",", "so", "dropout", "is", "far", "less", "advantageous", "in", "convolutional", "layers", ".", "subsection", ":", "Pooling", "CNNs", "typically", "also", "feature", "\u201c", "pooling", "\u201d", "layers", "which", "summarize", "the", "activities", "of", "local", "patches", "of", "neurons", "in", "convolutional", "layers", ".", "Essentially", ",", "a", "pooling", "layer", "takes", "as", "input", "the", "output", "of", "a", "convolutional", "layer", "and", "subsamples", "it", ".", "A", "pooling", "layer", "consists", "of", "pooling", "units", "which", "are", "laid", "out", "topographically", "and", "connected", "to", "a", "local", "neighborhood", "of", "convolutional", "unit", "outputs", "from", "the", "same", "bank", ".", "Each", "pooling", "unit", "then", "computes", "some", "function", "of", "the", "bank", "\u2019s", "output", "in", "that", "neighborhood", ".", "Typical", "functions", "are", "maximum", "and", "average", ".", "Pooling", "layers", "with", "such", "units", "are", "called", "max", "-", "pooling", "and", "average", "-", "pooling", "layers", ",", "respectively", ".", "The", "pooling", "units", "are", "usually", "spaced", "at", "least", "several", "pixels", "apart", ",", "so", "that", "there", "are", "fewer", "total", "pooling", "units", "than", "there", "are", "convolutional", "unit", "outputs", "in", "the", "previous", "layer", ".", "Making", "this", "spacing", "smaller", "than", "the", "size", "of", "the", "neighborhood", "that", "the", "pooling", "units", "summarize", "produces", "overlapping", "pooling", ".", "This", "variant", "makes", "the", "pooling", "layer", "produce", "a", "coarse", "coding", "of", "the", "convolutional", "unit", "outputs", ",", "which", "we", "have", "found", "to", "aid", "generalization", "in", "our", "experiments", ".", "We", "refer", "to", "this", "spacing", "as", "the", "stride", "between", "pooling", "units", ",", "analogously", "to", "the", "stride", "between", "convolutional", "units", ".", "Pooling", "layers", "introduce", "a", "level", "of", "local", "translation", "invariance", "to", "the", "network", ",", "which", "improves", "generalization", ".", "They", "are", "the", "analogues", "of", "complex", "cells", "in", "the", "mammalian", "visual", "cortex", ",", "which", "pool", "activities", "of", "multiple", "simple", "cells", ".", "These", "cells", "are", "known", "to", "exhibit", "similar", "phase", "-", "invariance", "properties", ".", "subsection", ":", "Local", "response", "normalization", "Our", "networks", "also", "include", "response", "normalization", "layers", ".", "This", "type", "of", "layer", "encourages", "competition", "for", "large", "activations", "among", "neurons", "belonging", "to", "different", "banks", ".", "In", "particular", ",", "the", "activity", "of", "a", "neuron", "in", "bank", "at", "position", "in", "the", "topographic", "organization", "is", "divided", "by", "where", "the", "sum", "runs", "over", "\u201c", "adjacent", "\u201d", "banks", "of", "neurons", "at", "the", "same", "position", "in", "the", "topographic", "organization", ".", "The", "ordering", "of", "the", "banks", "is", "of", "course", "arbitrary", "and", "determined", "before", "training", "begins", ".", "Response", "normalization", "layers", "implement", "a", "form", "of", "lateral", "inhibition", "found", "in", "real", "neurons", ".", "The", "constants", ",", "and", "are", "hyper", "-", "parameters", "whose", "values", "are", "determined", "using", "a", "validation", "set", ".", "subsection", ":", "Neuron", "nonlinearities", "All", "of", "the", "neurons", "in", "our", "networks", "utilize", "the", "max", "-", "with", "-", "zero", "nonlinearity", ".", "That", "is", ",", "their", "output", "is", "computed", "as", "where", "is", "the", "total", "input", "to", "the", "neuron", "(", "equivalently", ",", "the", "output", "of", "the", "neuron", "\u2019s", "linear", "filter", "added", "to", "the", "bias", ")", ".", "This", "nonlinearity", "has", "several", "advantages", "over", "traditional", "saturating", "neuron", "models", ",", "including", "a", "significant", "reduction", "in", "the", "training", "time", "required", "to", "reach", "a", "given", "error", "rate", ".", "This", "nonlinearity", "also", "reduces", "the", "need", "for", "contrast", "-", "normalization", "and", "similar", "data", "pre", "-", "processing", "schemes", ",", "because", "neurons", "with", "this", "nonlinearity", "do", "not", "saturate", "\u2013", "their", "activities", "simply", "scale", "up", "when", "presented", "with", "unusually", "large", "input", "values", ".", "Consequently", ",", "the", "only", "data", "pre", "-", "processing", "step", "which", "we", "take", "is", "to", "subtract", "the", "mean", "activity", "from", "each", "pixel", ",", "so", "that", "the", "data", "is", "centered", ".", "So", "we", "train", "our", "networks", "on", "the", "(", "centered", ")", "raw", "RGB", "values", "of", "the", "pixels", ".", "subsection", ":", "Objective", "function", "Our", "networks", "maximize", "the", "multinomial", "logistic", "regression", "objective", ",", "which", "is", "equivalent", "to", "minimizing", "the", "average", "across", "training", "cases", "of", "the", "cross", "-", "entropy", "between", "the", "true", "label", "distribution", "and", "the", "model", "\u2019s", "predicted", "label", "distribution", ".", "subsection", ":", "Weight", "initialization", "We", "initialize", "the", "weights", "in", "our", "model", "from", "a", "zero", "-", "mean", "normal", "distribution", "with", "a", "variance", "set", "high", "enough", "to", "produce", "positive", "inputs", "into", "the", "neurons", "in", "each", "layer", ".", "This", "is", "a", "slightly", "tricky", "point", "when", "using", "the", "max", "-", "with", "-", "zero", "nonlinearity", ".", "If", "the", "input", "to", "a", "neuron", "is", "always", "negative", ",", "no", "learning", "will", "take", "place", "because", "its", "output", "will", "be", "uniformly", "zero", ",", "as", "will", "the", "derivative", "of", "its", "output", "with", "respect", "to", "its", "input", ".", "Therefore", "it", "\u2019s", "important", "to", "initialize", "the", "weights", "from", "a", "distribution", "with", "a", "sufficiently", "large", "variance", "such", "that", "all", "neurons", "are", "likely", "to", "get", "positive", "inputs", "at", "least", "occasionally", ".", "In", "practice", ",", "we", "simply", "try", "different", "variances", "until", "we", "find", "an", "initialization", "that", "works", ".", "It", "usually", "only", "takes", "a", "few", "attempts", ".", "We", "also", "find", "that", "initializing", "the", "biases", "of", "the", "neurons", "in", "the", "hidden", "layers", "with", "some", "positive", "constant", "(", "1", "in", "our", "case", ")", "helps", "get", "learning", "off", "the", "ground", ",", "for", "the", "same", "reason", ".", "subsection", ":", "Training", "We", "train", "our", "models", "using", "stochastic", "gradient", "descent", "with", "a", "batch", "size", "of", "128", "examples", "and", "momentum", "of", "0.9", ".", "Therefore", "the", "update", "rule", "for", "weight", "is", "where", "is", "the", "iteration", "index", ",", "is", "a", "momentum", "variable", ",", "is", "the", "learning", "rate", ",", "and", "is", "the", "average", "over", "the", "batch", "of", "the", "derivative", "of", "the", "objective", "with", "respect", "to", ".", "We", "use", "the", "publicly", "available", "cuda", "-", "convnet", "package", "to", "train", "all", "of", "our", "models", "on", "a", "single", "NVIDIA", "GTX", "580", "GPU", ".", "Training", "on", "CIFAR", "-", "10", "takes", "roughly", "90", "minutes", ".", "Training", "on", "ImageNet", "takes", "roughly", "four", "days", "with", "dropout", "and", "two", "days", "without", ".", "subsection", ":", "Learning", "rates", "We", "use", "an", "equal", "learning", "rate", "for", "each", "layer", ",", "whose", "value", "we", "determine", "heuristically", "as", "the", "largest", "power", "of", "ten", "that", "produces", "reductions", "in", "the", "objective", "function", ".", "In", "practice", "it", "is", "typically", "of", "the", "order", "or", ".", "We", "reduce", "the", "learning", "rate", "twice", "by", "a", "factor", "of", "ten", "shortly", "before", "terminating", "training", ".", "appendix", ":", "Models", "for", "CIFAR", "-", "10", "Our", "model", "for", "CIFAR", "-", "10", "without", "dropout", "is", "a", "CNN", "with", "three", "convolutional", "layers", ".", "Pooling", "layers", "follow", "all", "three", ".", "All", "of", "the", "pooling", "layers", "summarize", "a", "neighborhood", "and", "use", "a", "stride", "of", "2", ".", "The", "pooling", "layer", "which", "follows", "the", "first", "convolutional", "layer", "performs", "max", "-", "pooling", ",", "while", "the", "remaining", "pooling", "layers", "perform", "average", "-", "pooling", ".", "Response", "normalization", "layers", "follow", "the", "first", "two", "pooling", "layers", ",", "with", ",", ",", "and", ".", "The", "upper", "-", "most", "pooling", "layer", "is", "connected", "to", "a", "ten", "-", "unit", "softmax", "layer", "which", "outputs", "a", "probability", "distribution", "over", "class", "labels", ".", "All", "convolutional", "layers", "have", "64", "filter", "banks", "and", "use", "a", "filter", "size", "of", "(", "times", "the", "number", "of", "channels", "in", "the", "preceding", "layer", ")", ".", "Our", "model", "for", "CIFAR", "-", "10", "with", "dropout", "is", "similar", ",", "but", "because", "dropout", "imposes", "a", "strong", "regularization", "on", "the", "network", ",", "we", "are", "able", "to", "use", "more", "parameters", ".", "Therefore", "we", "add", "a", "fourth", "weight", "layer", ",", "which", "takes", "its", "input", "from", "the", "third", "pooling", "layer", ".", "This", "weight", "layer", "is", "locally", "-", "connected", "but", "not", "convolutional", ".", "It", "is", "like", "a", "convolutional", "layer", "in", "which", "filters", "in", "the", "same", "bank", "do", "not", "share", "weights", ".", "This", "layer", "contains", "16", "banks", "of", "filters", "of", "size", ".", "This", "is", "the", "layer", "in", "which", "we", "use", "50", "%", "dropout", ".", "The", "softmax", "layer", "takes", "its", "input", "from", "this", "fourth", "weight", "layer", ".", "appendix", ":", "Models", "for", "ImageNet", "Our", "model", "for", "ImageNet", "with", "dropout", "is", "a", "CNN", "which", "is", "trained", "on", "patches", "randomly", "extracted", "from", "the", "images", ",", "as", "well", "as", "their", "horizontal", "reflections", ".", "This", "is", "a", "form", "of", "data", "augmentation", "that", "reduces", "the", "network", "\u2019s", "capacity", "to", "overfit", "the", "training", "data", "and", "helps", "generalization", ".", "The", "network", "contains", "seven", "weight", "layers", ".", "The", "first", "five", "are", "convolutional", ",", "while", "the", "last", "two", "are", "globally", "-", "connected", ".", "Max", "-", "pooling", "layers", "follow", "the", "first", ",", "second", ",", "and", "fifth", "convolutional", "layers", ".", "All", "of", "the", "pooling", "layers", "summarize", "a", "neighborhood", "and", "use", "a", "stride", "of", "2", ".", "Response", "-", "normalization", "layers", "follow", "the", "first", "and", "second", "pooling", "layers", ".", "The", "first", "convolutional", "layer", "has", "64", "filter", "banks", "with", "filters", "which", "it", "applies", "with", "a", "stride", "of", "4", "pixels", "(", "this", "is", "the", "distance", "between", "neighboring", "neurons", "in", "a", "bank", ")", ".", "The", "second", "convolutional", "layer", "has", "256", "filter", "banks", "with", "filters", ".", "This", "layer", "takes", "two", "inputs", ".", "The", "first", "input", "to", "this", "layer", "is", "the", "(", "pooled", "and", "response", "-", "normalized", ")", "output", "of", "the", "first", "convolutional", "layer", ".", "The", "256", "banks", "in", "this", "layer", "are", "divided", "arbitrarily", "into", "groups", "of", "64", ",", "and", "each", "group", "connects", "to", "a", "unique", "random", "16", "channels", "from", "the", "first", "convolutional", "layer", ".", "The", "second", "input", "to", "this", "layer", "is", "a", "subsampled", "version", "of", "the", "original", "image", "(", ")", ",", "which", "is", "filtered", "by", "this", "layer", "with", "a", "stride", "of", "2", "pixels", ".", "The", "two", "maps", "resulting", "from", "filtering", "the", "two", "inputs", "are", "summed", "element", "-", "wise", "(", "they", "have", "exactly", "the", "same", "dimensions", ")", "and", "a", "max", "-", "with", "-", "zero", "nonlinearity", "is", "applied", "to", "the", "sum", "in", "the", "usual", "way", ".", "The", "third", ",", "fourth", ",", "and", "fifth", "convolutional", "layers", "are", "connected", "to", "one", "another", "without", "any", "intervening", "pooling", "or", "normalization", "layers", ",", "but", "the", "max", "-", "with", "-", "zero", "nonlinearity", "is", "applied", "at", "each", "layer", "after", "linear", "filtering", ".", "The", "third", "convolutional", "layer", "has", "512", "filter", "banks", "divided", "into", "groups", "of", "32", ",", "each", "group", "connecting", "to", "a", "unique", "random", "subset", "of", "16", "channels", "produced", "by", "the", "(", "pooled", ",", "normalized", ")", "outputs", "of", "the", "second", "convolutional", "layer", ".", "The", "fourth", "and", "fifth", "convolutional", "layers", "similarly", "have", "512", "filter", "banks", "divided", "into", "groups", "of", "32", ",", "each", "group", "connecting", "to", "a", "unique", "random", "subset", "of", "32", "channels", "produced", "by", "the", "layer", "below", ".", "The", "next", "two", "weight", "layers", "are", "globally", "-", "connected", ",", "with", "4096", "neurons", "each", ".", "In", "these", "last", "two", "layers", "we", "use", "50", "%", "dropout", ".", "Finally", ",", "the", "output", "of", "the", "last", "globally", "-", "connected", "layer", "is", "fed", "to", "a", "1000", "-", "way", "softmax", "which", "produces", "a", "distribution", "over", "the", "1000", "class", "labels", ".", "We", "test", "our", "model", "by", "averaging", "the", "prediction", "of", "the", "net", "on", "ten", "patches", "of", "the", "input", "image", ":", "the", "center", "patch", ",", "the", "four", "corner", "patches", ",", "and", "their", "horizontal", "reflections", ".", "Even", "though", "we", "make", "ten", "passes", "of", "each", "image", "at", "test", "time", ",", "we", "are", "able", "to", "run", "our", "system", "in", "real", "-", "time", ".", "Our", "model", "for", "ImageNet", "without", "dropout", "is", "similar", ",", "but", "without", "the", "two", "globally", "-", "connected", "layers", "which", "create", "serious", "overfitting", "when", "used", "without", "dropout", ".", "In", "order", "to", "achieve", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "the", "validation", "set", ",", "we", "found", "it", "necessary", "to", "use", "the", "very", "complicated", "network", "architecture", "described", "above", ".", "Fortunately", ",", "the", "complexity", "of", "this", "architecture", "is", "not", "the", "main", "point", "of", "our", "paper", ".", "What", "we", "wanted", "to", "demonstrate", "is", "that", "dropout", "is", "a", "significant", "help", "even", "for", "the", "very", "complex", "neural", "nets", "that", "have", "been", "developed", "by", "the", "joint", "efforts", "of", "many", "groups", "over", "many", "years", "to", "be", "really", "good", "at", "object", "recognition", ".", "This", "is", "clearly", "demonstrated", "by", "the", "fact", "that", "using", "non", "-", "convolutional", "higher", "layers", "with", "a", "lot", "of", "parameters", "leads", "to", "a", "big", "improvement", "with", "dropout", "but", "makes", "things", "worse", "without", "dropout", "."]}