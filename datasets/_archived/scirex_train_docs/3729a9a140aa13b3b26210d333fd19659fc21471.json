{"coref": {"Chunking": [[338, 339], [497, 498], [520, 521], [935, 936], [936, 937], [984, 985], [1121, 1123], [2457, 2458], [2517, 2518], [2884, 2885], [2887, 2888], [3157, 3158], [3771, 3772], [3796, 3797], [3807, 3808], [4678, 4679], [5772, 5773], [6165, 6166], [6203, 6204], [6414, 6415], [524, 525], [948, 949], [1232, 1233], [2116, 2117], [2241, 2242], [3338, 3339], [3762, 3763], [3907, 3908], [4372, 4373], [4696, 4697], [5255, 5256], [6442, 6443], [7880, 7881]], "F1_score": [[2945, 2947]], "JMT": [[3, 8], [67, 72], [290, 294], [295, 296], [451, 456], [3300, 3301], [3440, 3442], [3466, 3468], [3538, 3539], [3542, 3544], [3993, 3995], [4251, 4253], [4741, 4742], [4788, 4789], [5696, 5701], [324, 325], [1832, 1833], [2687, 2688], [3307, 3308], [3358, 3359], [3365, 3366], [3379, 3380], [3519, 3520], [3689, 3690], [3732, 3733], [3775, 3776], [3976, 3977], [4060, 4061], [4109, 4110], [4220, 4221], [4411, 4412], [4615, 4616], [4854, 4855], [4998, 4999], [5072, 5073], [5274, 5275], [5478, 5479], [5601, 5602], [5662, 5663], [6627, 6628], [7501, 7502], [7581, 7582], [7611, 7612], [8010, 8011]], "Penn_Treebank": [[2838, 2840]]}, "coref_non_salient": {"0": [[1296, 1300], [2609, 2616]], "1": [[616, 618], [630, 632], [7708, 7714]], "10": [[157, 158], [340, 342], [499, 501], [529, 531], [1163, 1165], [1165, 1168], [2537, 2539], [2953, 2955], [2963, 2965], [3159, 3161], [3328, 3330], [3547, 3549], [3567, 3569], [3837, 3839], [3890, 3892], [4714, 4716], [5083, 5085], [5305, 5307], [5365, 5367], [5444, 5446], [5774, 5776], [6102, 6104], [6167, 6169], [6213, 6215], [6416, 6418], [6814, 6816], [6914, 6916], [6957, 6958], [7013, 7014], [5346, 5348], [5679, 5681]], "100": [[5411, 5415]], "101": [[6207, 6209]], "102": [[3529, 3533]], "103": [[2920, 2924]], "104": [[3083, 3085]], "105": [[2936, 2939]], "106": [[2445, 2451]], "107": [[208, 210], [212, 213]], "108": [[3954, 3956]], "109": [[2554, 2557], [5113, 5115]], "11": [[1536, 1540], [1565, 1569], [2475, 2479]], "110": [[14, 17], [190, 191], [310, 312], [2361, 2363], [2403, 2406], [2586, 2588], [2755, 2757], [4325, 4327], [5704, 5706], [5753, 5755]], "111": [[5716, 5718]], "112": [[247, 250]], "113": [[319, 321]], "114": [[155, 156]], "115": [[5529, 5531]], "116": [[3171, 3177], [6179, 6185]], "117": [[2349, 2352]], "118": [[5978, 5982]], "119": [[3073, 3076]], "12": [[2744, 2745], [2807, 2809], [2879, 2883], [3116, 3117], [3645, 3646], [3902, 3903], [4676, 4677], [5303, 5304], [5442, 5443], [6798, 6799]], "120": [[1668, 1670]], "121": [[2249, 2251]], "122": [[1648, 1650]], "123": [[2387, 2391]], "13": [[940, 945], [1583, 1586]], "14": [[5876, 5880], [5883, 5887]], "15": [[2541, 2543], [3927, 3930]], "16": [[5221, 5224], [5239, 5242], [6469, 6473]], "17": [[621, 624], [1904, 1907], [642, 645], [1884, 1887], [5851, 5854], [6518, 6521], [6649, 6652]], "18": [[186, 189], [224, 227]], "19": [[2044, 2047], [2049, 2051], [2792, 2794], [3229, 3231], [4638, 4640], [4683, 4685], [4724, 4726], [5746, 5748]], "2": [[7675, 7677], [7822, 7824]], "20": [[217, 221], [3817, 3821], [4706, 4710], [6348, 6352], [7597, 7601]], "21": [[676, 680], [1899, 1903], [1922, 1927], [3750, 3754], [5130, 5134], [5155, 5159], [5226, 5230], [5563, 5569], [5895, 5899], [5915, 5919], [6008, 6012], [6460, 6464], [6475, 6479], [6508, 6512], [6737, 6741], [6781, 6787], [6900, 6904]], "22": [[3827, 3829], [3858, 3861], [6917, 6919], [7141, 7142]], "23": [[7773, 7777], [8024, 8026]], "24": [[347, 349], [506, 508], [1473, 1475], [1665, 1667], [3086, 3088], [3090, 3092], [3166, 3168], [4104, 4106], [5092, 5094], [5781, 5783], [6174, 6176], [6420, 6421]], "25": [[1575, 1579], [1675, 1679], [4034, 4038], [4153, 4157]], "26": [[2597, 2600], [4539, 4545]], "27": [[627, 629], [1880, 1882], [1915, 1917], [5832, 5834], [5986, 5988], [7460, 7462], [7569, 7571]], "28": [[3018, 3019], [3651, 3652]], "29": [[2178, 2180], [4081, 4083]], "3": [[133, 139], [816, 821], [2669, 2673]], "30": [[11, 13], [2413, 2416]], "31": [[6810, 6813]], "32": [[614, 615], [668, 670], [750, 752], [6597, 6598], [6605, 6607]], "33": [[6191, 6195]], "34": [[1425, 1427], [1662, 1664], [3554, 3556], [4296, 4298], [4932, 4934], [5334, 5336], [5373, 5375], [5435, 5437], [7319, 7321], [7329, 7331], [7590, 7592], [7978, 7980], [8044, 8046], [8067, 8069]], "35": [[1143, 1145], [7857, 7859]], "36": [[2119, 2121], [2181, 2183], [2255, 2257], [2305, 2307], [6673, 6675]], "37": [[1037, 1040], [1070, 1072], [4353, 4355]], "38": [[3242, 3243], [6370, 6371], [6374, 6375], [6424, 6425]], "39": [[2548, 2550], [2561, 2563], [5501, 5503]], "4": [[3719, 3723], [3726, 3730]], "40": [[2834, 2835], [2893, 2894], [2960, 2961], [3843, 3844]], "41": [[3573, 3576], [4459, 4462], [6973, 6976], [7334, 7337]], "42": [[5922, 5926], [6495, 6498], [6639, 6643]], "43": [[1942, 1944], [4170, 4172]], "44": [[1151, 1153], [1642, 1644]], "45": [[911, 912], [1371, 1372], [1638, 1639], [1749, 1750], [1806, 1808], [1826, 1827], [1987, 1988], [4402, 4403], [6334, 6335], [6408, 6409], [6450, 6451]], "46": [[3081, 3082], [1086, 1087], [2265, 2266], [7124, 7125], [7405, 7406]], "47": [[3026, 3027], [3658, 3659], [6845, 6846], [7968, 7969]], "48": [[162, 164], [592, 594], [1517, 1519], [7350, 7352], [7523, 7525]], "49": [[1112, 1114], [1160, 1162]], "5": [[795, 799], [822, 823], [1209, 1210], [6087, 6088], [7723, 7724], [894, 895], [992, 993], [1006, 1007], [1193, 1194], [1511, 1512], [1984, 1985], [3213, 3214], [3413, 3414], [3483, 3484], [4232, 4233], [4315, 4316], [4773, 4774], [4845, 4846], [6247, 6248], [6324, 6325], [7661, 7662], [7688, 7689]], "50": [[1889, 1891], [6523, 6525], [5865, 5867]], "51": [[5398, 5400], [6261, 6263], [6276, 6278], [6286, 6288]], "52": [[6499, 6503]], "53": [[3185, 3188], [6219, 6222]], "54": [[2407, 2412], [2630, 2635], [4573, 4577]], "55": [[2520, 2522], [5509, 5511], [6891, 6893], [5537, 5539]], "56": [[5668, 5674]], "57": [[3014, 3017], [3022, 3025]], "58": [[7301, 7306]], "59": [[3870, 3872]], "6": [[5842, 5846], [6543, 6549]], "60": [[1406, 1412], [3639, 3642]], "61": [[2830, 2833]], "62": [[3937, 3939], [3950, 3952], [4024, 4026], [4136, 4138]], "63": [[6754, 6757]], "64": [[2682, 2684]], "65": [[229, 231], [5686, 5688]], "66": [[1030, 1031], [202, 203], [335, 336], [494, 495], [515, 516], [785, 786], [809, 810], [873, 874], [925, 926], [998, 999], [1049, 1050], [1060, 1061], [1080, 1081], [1087, 1088], [1101, 1102], [1130, 1131], [1240, 1241], [1956, 1957], [1968, 1969], [2077, 2078], [2132, 2133], [2156, 2157], [2166, 2167], [2454, 2455], [2514, 2515], [2534, 2535], [2817, 2818], [2823, 2824], [3154, 3155], [3336, 3337], [3403, 3404], [3674, 3675], [3684, 3685], [3793, 3794], [3905, 3906], [4370, 4371], [4711, 4712], [5244, 5245], [6162, 6163], [6200, 6201], [6411, 6412], [6440, 6441], [6758, 6759], [7818, 7819], [7844, 7845]], "67": [[3077, 3078]], "68": [[2605, 2607]], "69": [[17, 18]], "7": [[19, 23], [2571, 2575], [2675, 2679], [2758, 2762], [5588, 5597]], "70": [[5825, 5827]], "71": [[3237, 3241]], "72": [[6051, 6053]], "73": [[1155, 1157]], "74": [[1374, 1376]], "75": [[4142, 4146]], "76": [[4405, 4407]], "77": [[7478, 7484]], "78": [[4189, 4191]], "79": [[780, 784], [930, 934]], "8": [[1620, 1624], [1628, 1632]], "80": [[3006, 3008]], "81": [[7730, 7734]], "82": [[460, 462]], "83": [[4937, 4939]], "84": [[597, 599], [847, 849], [1214, 1216], [1874, 1876], [4224, 4226], [5731, 5733], [6395, 6397], [6432, 6434], [8038, 8040]], "85": [[7464, 7469]], "86": [[2302, 2304], [6403, 6405]], "87": [[6683, 6686]], "88": [[2041, 2043], [2081, 2082]], "89": [[3940, 3942]], "9": [[3135, 3138], [3289, 3295], [3450, 3453], [3881, 3884], [4750, 4756], [4989, 4994], [5033, 5039], [6061, 6064], [6386, 6392]], "90": [[2950, 2952]], "91": [[1848, 1849], [6149, 6150]], "92": [[358, 363]], "93": [[2558, 2560], [5498, 5500]], "94": [[3049, 3051], [3097, 3099]], "95": [[7982, 7984]], "96": [[1529, 1533], [1550, 1554]], "97": [[159, 160], [1515, 1516], [344, 345], [503, 504], [540, 541], [544, 545], [558, 559], [587, 588], [1429, 1430], [1449, 1450], [1461, 1462], [1592, 1593], [1607, 1608], [1683, 1684], [1757, 1758], [1768, 1769], [1783, 1784], [1811, 1812], [2270, 2271], [2340, 2341], [3038, 3039], [3043, 3044], [3108, 3109], [3163, 3164], [3960, 3961], [3971, 3972], [4375, 4376], [5778, 5779], [6171, 6172], [6453, 6454]], "98": [[2875, 2877], [2941, 2943], [3010, 3012], [3069, 3071], [3112, 3114]], "99": [[5929, 5931]]}, "doc_id": "3729a9a140aa13b3b26210d333fd19659fc21471", "method_subrelations": {"JMT": [[[0, 3], "JMT"]]}, "n_ary_relations": [{"Material": "Penn_Treebank", "Method": "JMT", "Metric": "F1_score", "Task": "Chunking", "score": "95.77"}], "ner": [[3, 8, "Method"], [11, 13, "Method"], [14, 17, "Task"], [17, 18, "Task"], [19, 23, "Task"], [67, 72, "Method"], [133, 139, "Method"], [155, 156, "Task"], [157, 158, "Task"], [159, 160, "Task"], [162, 164, "Task"], [186, 189, "Task"], [190, 191, "Task"], [208, 210, "Method"], [212, 213, "Method"], [217, 221, "Task"], [224, 227, "Task"], [229, 231, "Task"], [247, 250, "Method"], [290, 294, "Method"], [295, 296, "Method"], [310, 312, "Task"], [319, 321, "Method"], [338, 339, "Task"], [340, 342, "Task"], [347, 349, "Task"], [358, 363, "Method"], [451, 456, "Method"], [460, 462, "Method"], [497, 498, "Task"], [499, 501, "Task"], [506, 508, "Task"], [520, 521, "Task"], [529, 531, "Task"], [592, 594, "Task"], [597, 599, "Method"], [614, 615, "Method"], [616, 618, "Task"], [621, 624, "Method"], [627, 629, "Method"], [630, 632, "Task"], [668, 670, "Method"], [676, 680, "Method"], [750, 752, "Method"], [780, 784, "Task"], [795, 799, "Method"], [816, 821, "Method"], [822, 823, "Method"], [847, 849, "Method"], [911, 912, "Method"], [930, 934, "Task"], [935, 936, "Task"], [936, 937, "Task"], [940, 945, "Task"], [984, 985, "Task"], [1030, 1031, "Method"], [1037, 1040, "Method"], [1070, 1072, "Method"], [1112, 1114, "Task"], [1121, 1123, "Task"], [1143, 1145, "Task"], [1151, 1153, "Method"], [1155, 1157, "Method"], [1160, 1162, "Task"], [1163, 1165, "Task"], [1165, 1168, "Task"], [1209, 1210, "Method"], [1214, 1216, "Method"], [1296, 1300, "Method"], [1371, 1372, "Method"], [1374, 1376, "Method"], [1406, 1412, "Method"], [1425, 1427, "Task"], [1473, 1475, "Task"], [1515, 1516, "Task"], [1517, 1519, "Task"], [1529, 1533, "Method"], [1536, 1540, "Method"], [1550, 1554, "Method"], [1565, 1569, "Method"], [1575, 1579, "Method"], [1583, 1586, "Task"], [1620, 1624, "Method"], [1628, 1632, "Method"], [1638, 1639, "Method"], [1642, 1644, "Method"], [1648, 1650, "Metric"], [1662, 1664, "Task"], [1665, 1667, "Task"], [1668, 1670, "Task"], [1675, 1679, "Method"], [1749, 1750, "Method"], [1806, 1808, "Method"], [1826, 1827, "Method"], [1848, 1849, "Task"], [1874, 1876, "Method"], [1880, 1882, "Method"], [1889, 1891, "Method"], [1899, 1903, "Method"], [1904, 1907, "Method"], [1915, 1917, "Method"], [1922, 1927, "Method"], [1942, 1944, "Method"], [1987, 1988, "Method"], [2041, 2043, "Method"], [2044, 2047, "Method"], [2049, 2051, "Method"], [2081, 2082, "Method"], [2119, 2121, "Metric"], [2178, 2180, "Method"], [2181, 2183, "Metric"], [2249, 2251, "Method"], [2255, 2257, "Metric"], [2302, 2304, "Method"], [2305, 2307, "Metric"], [2349, 2352, "Method"], [2361, 2363, "Task"], [2387, 2391, "Method"], [2403, 2406, "Task"], [2407, 2412, "Method"], [2413, 2416, "Method"], [2445, 2451, "Task"], [2457, 2458, "Task"], [2475, 2479, "Method"], [2517, 2518, "Task"], [2520, 2522, "Method"], [2537, 2539, "Task"], [2541, 2543, "Method"], [2548, 2550, "Task"], [2554, 2557, "Method"], [2558, 2560, "Task"], [2561, 2563, "Task"], [2571, 2575, "Task"], [2586, 2588, "Task"], [2597, 2600, "Method"], [2605, 2607, "Task"], [2609, 2616, "Method"], [2630, 2635, "Method"], [2669, 2673, "Method"], [2675, 2679, "Task"], [2682, 2684, "Task"], [2744, 2745, "Metric"], [2755, 2757, "Task"], [2758, 2762, "Task"], [2792, 2794, "Method"], [2807, 2809, "Metric"], [2830, 2833, "Material"], [2834, 2835, "Material"], [2838, 2840, "Material"], [2875, 2877, "Metric"], [2879, 2883, "Metric"], [2884, 2885, "Task"], [2887, 2888, "Task"], [2920, 2924, "Material"], [2936, 2939, "Method"], [2941, 2943, "Metric"], [2945, 2947, "Metric"], [2950, 2952, "Task"], [2953, 2955, "Task"], [2963, 2965, "Task"], [3006, 3008, "Method"], [3010, 3012, "Metric"], [3014, 3017, "Metric"], [3018, 3019, "Metric"], [3022, 3025, "Metric"], [3026, 3027, "Metric"], [3049, 3051, "Material"], [3069, 3071, "Metric"], [3073, 3076, "Metric"], [3077, 3078, "Metric"], [3081, 3082, "Metric"], [3083, 3085, "Metric"], [3086, 3088, "Task"], [3090, 3092, "Task"], [3097, 3099, "Material"], [3112, 3114, "Metric"], [3116, 3117, "Metric"], [3135, 3138, "Method"], [3157, 3158, "Task"], [3159, 3161, "Task"], [3166, 3168, "Task"], [3171, 3177, "Method"], [3185, 3188, "Method"], [3229, 3231, "Method"], [3237, 3241, "Method"], [3242, 3243, "Method"], [3289, 3295, "Method"], [3300, 3301, "Method"], [3328, 3330, "Task"], [3440, 3442, "Method"], [3450, 3453, "Method"], [3466, 3468, "Method"], [3529, 3533, "Metric"], [3538, 3539, "Method"], [3542, 3544, "Method"], [3547, 3549, "Task"], [3554, 3556, "Task"], [3567, 3569, "Task"], [3573, 3576, "Method"], [3639, 3642, "Method"], [3645, 3646, "Metric"], [3651, 3652, "Metric"], [3658, 3659, "Metric"], [3719, 3723, "Method"], [3726, 3730, "Method"], [3750, 3754, "Method"], [3771, 3772, "Task"], [3796, 3797, "Task"], [3807, 3808, "Task"], [3817, 3821, "Task"], [3827, 3829, "Method"], [3837, 3839, "Task"], [3858, 3861, "Method"], [3870, 3872, "Method"], [3881, 3884, "Method"], [3890, 3892, "Task"], [3902, 3903, "Metric"], [3927, 3930, "Method"], [3937, 3939, "Method"], [3940, 3942, "Method"], [3950, 3952, "Method"], [3954, 3956, "Method"], [3993, 3995, "Method"], [4024, 4026, "Method"], [4034, 4038, "Method"], [4081, 4083, "Method"], [4104, 4106, "Task"], [4136, 4138, "Method"], [4142, 4146, "Method"], [4153, 4157, "Method"], [4170, 4172, "Method"], [4189, 4191, "Method"], [4224, 4226, "Method"], [4251, 4253, "Method"], [4296, 4298, "Task"], [4325, 4327, "Task"], [4353, 4355, "Method"], [4402, 4403, "Method"], [4405, 4407, "Method"], [4459, 4462, "Method"], [4539, 4545, "Method"], [4573, 4577, "Method"], [4638, 4640, "Method"], [4676, 4677, "Metric"], [4678, 4679, "Task"], [4683, 4685, "Method"], [4706, 4710, "Task"], [4714, 4716, "Task"], [4724, 4726, "Method"], [4741, 4742, "Method"], [4750, 4756, "Method"], [4788, 4789, "Method"], [4932, 4934, "Task"], [4937, 4939, "Method"], [4989, 4994, "Method"], [5033, 5039, "Method"], [5083, 5085, "Task"], [5092, 5094, "Task"], [5113, 5115, "Method"], [5130, 5134, "Method"], [5155, 5159, "Method"], [5221, 5224, "Method"], [5226, 5230, "Method"], [5239, 5242, "Method"], [5303, 5304, "Metric"], [5305, 5307, "Task"], [5334, 5336, "Task"], [5365, 5367, "Task"], [5373, 5375, "Task"], [5398, 5400, "Metric"], [5411, 5415, "Method"], [5435, 5437, "Task"], [5442, 5443, "Metric"], [5444, 5446, "Task"], [5498, 5500, "Task"], [5501, 5503, "Task"], [5509, 5511, "Method"], [5529, 5531, "Task"], [5563, 5569, "Method"], [5588, 5597, "Task"], [5668, 5674, "Task"], [5696, 5701, "Method"], [5704, 5706, "Task"], [5716, 5718, "Method"], [5731, 5733, "Method"], [5746, 5748, "Method"], [5753, 5755, "Task"], [5772, 5773, "Task"], [5774, 5776, "Task"], [5781, 5783, "Task"], [5825, 5827, "Method"], [5832, 5834, "Method"], [5842, 5846, "Material"], [5876, 5880, "Method"], [5883, 5887, "Method"], [5895, 5899, "Method"], [5915, 5919, "Method"], [5922, 5926, "Task"], [5929, 5931, "Task"], [5978, 5982, "Method"], [5986, 5988, "Method"], [6008, 6012, "Method"], [6051, 6053, "Method"], [6061, 6064, "Method"], [6087, 6088, "Method"], [6102, 6104, "Task"], [6149, 6150, "Task"], [6165, 6166, "Task"], [6167, 6169, "Task"], [6174, 6176, "Task"], [6179, 6185, "Method"], [6191, 6195, "Metric"], [6203, 6204, "Task"], [6207, 6209, "Task"], [6213, 6215, "Task"], [6219, 6222, "Method"], [6261, 6263, "Metric"], [6276, 6278, "Metric"], [6286, 6288, "Metric"], [6334, 6335, "Method"], [6348, 6352, "Task"], [6370, 6371, "Method"], [6386, 6392, "Method"], [6395, 6397, "Method"], [6403, 6405, "Method"], [6408, 6409, "Method"], [6414, 6415, "Task"], [6416, 6418, "Task"], [6420, 6421, "Task"], [6432, 6434, "Method"], [6450, 6451, "Method"], [6460, 6464, "Method"], [6469, 6473, "Method"], [6475, 6479, "Method"], [6495, 6498, "Task"], [6499, 6503, "Task"], [6508, 6512, "Method"], [6523, 6525, "Method"], [6543, 6549, "Material"], [6597, 6598, "Method"], [6605, 6607, "Method"], [6639, 6643, "Task"], [6673, 6675, "Metric"], [6683, 6686, "Method"], [6737, 6741, "Method"], [6754, 6757, "Task"], [6781, 6787, "Method"], [6798, 6799, "Metric"], [6810, 6813, "Method"], [6814, 6816, "Task"], [6891, 6893, "Method"], [6900, 6904, "Method"], [6914, 6916, "Task"], [6917, 6919, "Method"], [6957, 6958, "Task"], [6973, 6976, "Method"], [7013, 7014, "Task"], [7141, 7142, "Method"], [7301, 7306, "Method"], [7319, 7321, "Task"], [7329, 7331, "Task"], [7334, 7337, "Method"], [7460, 7462, "Method"], [7464, 7469, "Method"], [7478, 7484, "Method"], [7569, 7571, "Method"], [7590, 7592, "Task"], [7597, 7601, "Task"], [7675, 7677, "Metric"], [7708, 7714, "Task"], [7723, 7724, "Method"], [7730, 7734, "Method"], [7773, 7777, "Method"], [7822, 7824, "Metric"], [7857, 7859, "Task"], [7978, 7980, "Task"], [7982, 7984, "Method"], [8024, 8026, "Method"], [8038, 8040, "Method"], [8044, 8046, "Task"], [8067, 8069, "Task"], [202, 203, "Method"], [324, 325, "Method"], [335, 336, "Method"], [344, 345, "Task"], [494, 495, "Method"], [503, 504, "Task"], [515, 516, "Method"], [524, 525, "Task"], [540, 541, "Task"], [544, 545, "Task"], [558, 559, "Task"], [587, 588, "Task"], [642, 645, "Method"], [785, 786, "Method"], [809, 810, "Method"], [873, 874, "Method"], [894, 895, "Method"], [925, 926, "Method"], [948, 949, "Task"], [992, 993, "Method"], [998, 999, "Method"], [1006, 1007, "Method"], [1049, 1050, "Method"], [1060, 1061, "Method"], [1080, 1081, "Method"], [1086, 1087, "Metric"], [1087, 1088, "Method"], [1101, 1102, "Method"], [1130, 1131, "Method"], [1193, 1194, "Method"], [1232, 1233, "Task"], [1240, 1241, "Method"], [1429, 1430, "Task"], [1449, 1450, "Task"], [1461, 1462, "Task"], [1511, 1512, "Method"], [1592, 1593, "Task"], [1607, 1608, "Task"], [1683, 1684, "Task"], [1757, 1758, "Task"], [1768, 1769, "Task"], [1783, 1784, "Task"], [1811, 1812, "Task"], [1832, 1833, "Method"], [1884, 1887, "Method"], [1956, 1957, "Method"], [1968, 1969, "Method"], [1984, 1985, "Method"], [2077, 2078, "Method"], [2116, 2117, "Task"], [2132, 2133, "Method"], [2156, 2157, "Method"], [2166, 2167, "Method"], [2241, 2242, "Task"], [2265, 2266, "Metric"], [2270, 2271, "Task"], [2340, 2341, "Task"], [2454, 2455, "Method"], [2514, 2515, "Method"], [2534, 2535, "Method"], [2687, 2688, "Method"], [2817, 2818, "Method"], [2823, 2824, "Method"], [2893, 2894, "Material"], [2960, 2961, "Material"], [3038, 3039, "Task"], [3043, 3044, "Task"], [3108, 3109, "Task"], [3154, 3155, "Method"], [3163, 3164, "Task"], [3213, 3214, "Method"], [3307, 3308, "Method"], [3336, 3337, "Method"], [3338, 3339, "Task"], [3358, 3359, "Method"], [3365, 3366, "Method"], [3379, 3380, "Method"], [3403, 3404, "Method"], [3413, 3414, "Method"], [3483, 3484, "Method"], [3519, 3520, "Method"], [3674, 3675, "Method"], [3684, 3685, "Method"], [3689, 3690, "Method"], [3732, 3733, "Method"], [3762, 3763, "Task"], [3775, 3776, "Method"], [3793, 3794, "Method"], [3843, 3844, "Material"], [3905, 3906, "Method"], [3907, 3908, "Task"], [3960, 3961, "Task"], [3971, 3972, "Task"], [3976, 3977, "Method"], [4060, 4061, "Method"], [4109, 4110, "Method"], [4220, 4221, "Method"], [4232, 4233, "Method"], [4315, 4316, "Method"], [4370, 4371, "Method"], [4372, 4373, "Task"], [4375, 4376, "Task"], [4411, 4412, "Method"], [4615, 4616, "Method"], [4696, 4697, "Task"], [4711, 4712, "Method"], [4773, 4774, "Method"], [4845, 4846, "Method"], [4854, 4855, "Method"], [4998, 4999, "Method"], [5072, 5073, "Method"], [5244, 5245, "Method"], [5255, 5256, "Task"], [5274, 5275, "Method"], [5346, 5348, "Task"], [5478, 5479, "Method"], [5537, 5539, "Method"], [5601, 5602, "Method"], [5662, 5663, "Method"], [5679, 5681, "Task"], [5686, 5688, "Task"], [5778, 5779, "Task"], [5851, 5854, "Method"], [5865, 5867, "Method"], [6162, 6163, "Method"], [6171, 6172, "Task"], [6200, 6201, "Method"], [6247, 6248, "Method"], [6324, 6325, "Method"], [6374, 6375, "Method"], [6411, 6412, "Method"], [6424, 6425, "Method"], [6440, 6441, "Method"], [6442, 6443, "Task"], [6453, 6454, "Task"], [6518, 6521, "Method"], [6627, 6628, "Method"], [6649, 6652, "Method"], [6758, 6759, "Method"], [6845, 6846, "Metric"], [7124, 7125, "Metric"], [7350, 7352, "Task"], [7405, 7406, "Metric"], [7501, 7502, "Method"], [7523, 7525, "Task"], [7581, 7582, "Method"], [7611, 7612, "Method"], [7661, 7662, "Method"], [7688, 7689, "Method"], [7818, 7819, "Method"], [7844, 7845, "Method"], [7880, 7881, "Task"], [7968, 7969, "Metric"], [8010, 8011, "Method"]], "sections": [[0, 165], [165, 448], [448, 595], [595, 778], [778, 928], [928, 1158], [1158, 1423], [1423, 1660], [1660, 1828], [1828, 1869], [1869, 1952], [1952, 2112], [2112, 2174], [2174, 2245], [2245, 2298], [2298, 2344], [2344, 2810], [2810, 2814], [2814, 3118], [3118, 3254], [3254, 3666], [3666, 3672], [3672, 3760], [3760, 3825], [3825, 3957], [3957, 4092], [4092, 4184], [4184, 4215], [4215, 4350], [4350, 4442], [4442, 4636], [4636, 4734], [4734, 4848], [4848, 4972], [4972, 5128], [5128, 5265], [5265, 5268], [5268, 5473], [5473, 5586], [5586, 5690], [5690, 5784], [5784, 5805], [5805, 5808], [5808, 5812], [5812, 5816], [5816, 5927], [5927, 6049], [6049, 6147], [6147, 6313], [6313, 6456], [6456, 6493], [6493, 6724], [6724, 6910], [6910, 7315], [7315, 7602], [7602, 8077]], "sentences": [[0, 17], [17, 41], [41, 64], [64, 87], [87, 103], [103, 131], [131, 165], [165, 168], [168, 193], [193, 211], [211, 233], [233, 247], [247, 267], [267, 287], [287, 317], [317, 355], [355, 371], [371, 385], [385, 413], [413, 448], [448, 456], [456, 514], [514, 533], [533, 543], [543, 555], [555, 574], [574, 595], [595, 599], [599, 616], [616, 618], [618, 630], [630, 632], [632, 647], [647, 666], [666, 682], [682, 694], [694, 748], [748, 757], [757, 778], [778, 787], [787, 812], [812, 851], [851, 870], [870, 904], [904, 928], [928, 936], [936, 966], [966, 984], [984, 1001], [1001, 1013], [1013, 1034], [1034, 1073], [1073, 1092], [1092, 1118], [1118, 1146], [1146, 1158], [1158, 1165], [1165, 1187], [1187, 1204], [1204, 1245], [1245, 1251], [1251, 1263], [1263, 1276], [1276, 1301], [1301, 1329], [1329, 1340], [1340, 1377], [1377, 1391], [1391, 1423], [1423, 1430], [1430, 1443], [1443, 1454], [1454, 1469], [1469, 1490], [1490, 1503], [1503, 1522], [1522, 1547], [1547, 1588], [1588, 1600], [1600, 1613], [1613, 1633], [1633, 1660], [1660, 1667], [1667, 1686], [1686, 1709], [1709, 1744], [1744, 1751], [1751, 1771], [1771, 1789], [1789, 1795], [1795, 1819], [1819, 1828], [1828, 1834], [1834, 1843], [1843, 1869], [1869, 1876], [1876, 1893], [1893, 1908], [1908, 1934], [1934, 1945], [1945, 1952], [1952, 1958], [1958, 1998], [1998, 2008], [2008, 2037], [2037, 2048], [2048, 2073], [2073, 2108], [2108, 2112], [2112, 2118], [2118, 2160], [2160, 2174], [2174, 2180], [2180, 2245], [2245, 2251], [2251, 2298], [2298, 2304], [2304, 2344], [2344, 2348], [2348, 2371], [2371, 2401], [2401, 2459], [2459, 2501], [2501, 2544], [2544, 2564], [2564, 2601], [2601, 2624], [2624, 2640], [2640, 2663], [2663, 2685], [2685, 2709], [2709, 2742], [2742, 2754], [2754, 2781], [2781, 2810], [2810, 2814], [2814, 2817], [2817, 2874], [2874, 2884], [2884, 2886], [2886, 2925], [2925, 2940], [2940, 2953], [2953, 2995], [2995, 3009], [3009, 3037], [3037, 3068], [3068, 3086], [3086, 3111], [3111, 3118], [3118, 3122], [3122, 3141], [3141, 3169], [3169, 3226], [3226, 3245], [3245, 3254], [3254, 3259], [3259, 3275], [3275, 3310], [3310, 3323], [3323, 3344], [3344, 3378], [3378, 3393], [3393, 3416], [3416, 3432], [3432, 3461], [3461, 3494], [3494, 3534], [3534, 3557], [3557, 3596], [3596, 3627], [3627, 3666], [3666, 3672], [3672, 3676], [3676, 3706], [3706, 3724], [3724, 3760], [3760, 3763], [3763, 3788], [3788, 3809], [3809, 3825], [3825, 3829], [3829, 3852], [3852, 3876], [3876, 3893], [3893, 3910], [3910, 3943], [3943, 3957], [3957, 3961], [3961, 3989], [3989, 4010], [4010, 4027], [4027, 4057], [4057, 4092], [4092, 4096], [4096, 4122], [4122, 4149], [4149, 4173], [4173, 4184], [4184, 4191], [4191, 4201], [4201, 4215], [4215, 4219], [4219, 4242], [4242, 4260], [4260, 4279], [4279, 4309], [4309, 4332], [4332, 4350], [4350, 4355], [4355, 4389], [4389, 4414], [4414, 4442], [4442, 4449], [4449, 4491], [4491, 4562], [4562, 4597], [4597, 4636], [4636, 4640], [4640, 4671], [4671, 4695], [4695, 4717], [4717, 4734], [4734, 4738], [4738, 4757], [4757, 4781], [4781, 4797], [4797, 4816], [4816, 4848], [4848, 4853], [4853, 4870], [4870, 4895], [4895, 4925], [4925, 4940], [4940, 4972], [4972, 4975], [4975, 5011], [5011, 5059], [5059, 5095], [5095, 5128], [5128, 5134], [5134, 5160], [5160, 5185], [5185, 5196], [5196, 5220], [5220, 5265], [5265, 5268], [5268, 5272], [5272, 5298], [5298, 5315], [5315, 5360], [5360, 5392], [5392, 5426], [5426, 5451], [5451, 5473], [5473, 5477], [5477, 5513], [5513, 5533], [5533, 5549], [5549, 5570], [5570, 5586], [5586, 5597], [5597, 5610], [5610, 5651], [5651, 5690], [5690, 5693], [5693, 5719], [5719, 5749], [5749, 5784], [5784, 5787], [5787, 5805], [5805, 5808], [5808, 5812], [5812, 5816], [5816, 5822], [5822, 5835], [5835, 5889], [5889, 5912], [5912, 5927], [5927, 5931], [5931, 5961], [5961, 5993], [5993, 6021], [6021, 6049], [6049, 6053], [6053, 6069], [6069, 6110], [6110, 6120], [6120, 6147], [6147, 6150], [6150, 6177], [6177, 6190], [6190, 6216], [6216, 6260], [6260, 6289], [6289, 6297], [6297, 6313], [6313, 6316], [6316, 6355], [6355, 6367], [6367, 6373], [6373, 6422], [6422, 6456], [6456, 6464], [6464, 6493], [6493, 6503], [6503, 6527], [6527, 6550], [6550, 6570], [6570, 6590], [6590, 6634], [6634, 6654], [6654, 6680], [6680, 6702], [6702, 6724], [6724, 6730], [6730, 6748], [6748, 6770], [6770, 6803], [6803, 6822], [6822, 6850], [6850, 6875], [6875, 6910], [6910, 6916], [6916, 6949], [6949, 6977], [6977, 7016], [7016, 7022], [7022, 7033], [7033, 7061], [7061, 7062], [7062, 7082], [7082, 7127], [7127, 7156], [7156, 7190], [7190, 7227], [7227, 7252], [7252, 7271], [7271, 7315], [7315, 7321], [7321, 7338], [7338, 7353], [7353, 7368], [7368, 7370], [7370, 7371], [7371, 7387], [7387, 7388], [7388, 7397], [7397, 7410], [7410, 7432], [7432, 7452], [7452, 7493], [7493, 7515], [7515, 7550], [7550, 7602], [7602, 7609], [7609, 7632], [7632, 7664], [7664, 7691], [7691, 7703], [7703, 7725], [7725, 7735], [7735, 7749], [7749, 7778], [7778, 7798], [7798, 7829], [7829, 7855], [7855, 7887], [7887, 7919], [7919, 7933], [7933, 7974], [7974, 7994], [7994, 8027], [8027, 8061], [8061, 8077]], "words": ["document", ":", "A", "Joint", "Many", "-", "Task", "Model", ":", "Growing", "a", "Neural", "Network", "for", "Multiple", "NLP", "Tasks", "Transfer", "and", "multi", "-", "task", "learning", "have", "traditionally", "focused", "on", "either", "a", "single", "source", "-", "target", "pair", "or", "very", "few", ",", "similar", "tasks", ".", "Ideally", ",", "the", "linguistic", "levels", "of", "morphology", ",", "syntax", "and", "semantics", "would", "benefit", "each", "other", "by", "being", "trained", "in", "a", "single", "model", ".", "We", "introduce", "a", "joint", "many", "-", "task", "model", "together", "with", "a", "strategy", "for", "successively", "growing", "its", "depth", "to", "solve", "increasingly", "complex", "tasks", ".", "Higher", "layers", "include", "shortcut", "connections", "to", "lower", "-", "level", "task", "predictions", "to", "reflect", "linguistic", "hierarchies", ".", "We", "use", "a", "simple", "regularization", "term", "to", "allow", "for", "optimizing", "all", "model", "weights", "to", "improve", "one", "task", "\u2019s", "loss", "without", "exhibiting", "catastrophic", "interference", "of", "the", "other", "tasks", ".", "Our", "single", "end", "-", "to", "-", "end", "model", "obtains", "state", "-", "of", "-", "the", "-", "art", "or", "competitive", "results", "on", "five", "different", "tasks", "from", "tagging", ",", "parsing", ",", "relatedness", ",", "and", "entailment", "tasks", ".", "section", ":", "Introduction", "The", "potential", "for", "leveraging", "multiple", "levels", "of", "representation", "has", "been", "demonstrated", "in", "various", "ways", "in", "the", "field", "of", "Natural", "Language", "Processing", "(", "NLP", ")", ".", "For", "example", ",", "Part", "-", "Of", "-", "Speech", "(", "POS", ")", "tags", "are", "used", "for", "syntactic", "parsers", ".", "The", "parsers", "are", "used", "to", "improve", "higher", "-", "level", "tasks", ",", "such", "as", "natural", "language", "inference", "chen2016snli", "and", "machine", "translation", "eriguchi2016", ".", "These", "systems", "are", "often", "pipelines", "and", "not", "trained", "end", "-", "to", "-", "end", ".", "Deep", "NLP", "models", "have", "yet", "shown", "benefits", "from", "predicting", "many", "increasingly", "complex", "tasks", "each", "at", "a", "successively", "deeper", "layer", ".", "Existing", "models", "often", "ignore", "linguistic", "hierarchies", "by", "predicting", "different", "tasks", "either", "entirely", "separately", "or", "at", "the", "same", "depth", "collobert2011senna", ".", "We", "introduce", "a", "Joint", "Many", "-", "Task", "(", "JMT", ")", "model", ",", "outlined", "in", "Figure", "[", "reference", "]", ",", "which", "predicts", "increasingly", "complex", "NLP", "tasks", "at", "successively", "deeper", "layers", ".", "Unlike", "traditional", "pipeline", "systems", ",", "our", "single", "JMT", "model", "can", "be", "trained", "end", "-", "to", "-", "end", "for", "POS", "tagging", ",", "chunking", ",", "dependency", "parsing", ",", "semantic", "relatedness", ",", "and", "textual", "entailment", ",", "by", "considering", "linguistic", "hierarchies", ".", "We", "propose", "an", "adaptive", "training", "and", "regularization", "strategy", "to", "grow", "this", "model", "in", "its", "depth", ".", "With", "the", "help", "of", "this", "strategy", "we", "avoid", "catastrophic", "interference", "between", "the", "tasks", ".", "Our", "model", "is", "motivated", "by", "sogaard2016", "who", "showed", "that", "predicting", "two", "different", "tasks", "is", "more", "accurate", "when", "performed", "in", "different", "layers", "than", "in", "the", "same", "layer", "collobert2011senna", ".", "Experimental", "results", "show", "that", "our", "single", "model", "achieves", "competitive", "results", "for", "all", "of", "the", "five", "different", "tasks", ",", "demonstrating", "that", "using", "linguistic", "hierarchies", "is", "more", "important", "than", "handling", "different", "tasks", "in", "the", "same", "layer", ".", "section", ":", "The", "Joint", "Many", "-", "Task", "Model", "This", "section", "describes", "the", "inference", "procedure", "of", "our", "model", ",", "beginning", "at", "the", "lowest", "level", "and", "working", "our", "way", "to", "higher", "layers", "and", "more", "complex", "tasks", ";", "our", "model", "handles", "the", "five", "different", "tasks", "in", "the", "order", "of", "POS", "tagging", ",", "chunking", ",", "dependency", "parsing", ",", "semantic", "relatedness", ",", "and", "textual", "entailment", ",", "by", "considering", "linguistic", "hierarchies", ".", "The", "POS", "tags", "are", "used", "for", "chunking", ",", "and", "the", "chunking", "tags", "are", "used", "for", "dependency", "parsing", "Attardi2008", ".", "tai2015treelstm", "have", "shown", "that", "dependencies", "improve", "the", "relatedness", "task", ".", "The", "relatedness", "and", "entailment", "tasks", "are", "closely", "related", "to", "each", "other", ".", "If", "the", "semantic", "relatedness", "between", "two", "sentences", "is", "very", "low", ",", "they", "are", "unlikely", "to", "entail", "each", "other", ".", "Based", "on", "this", "observation", ",", "we", "make", "use", "of", "the", "information", "from", "the", "relatedness", "task", "for", "improving", "the", "entailment", "task", ".", "subsection", ":", "Word", "Representations", "For", "each", "word", "in", "the", "input", "sentence", "of", "length", ",", "we", "use", "two", "types", "of", "embeddings", ".", "Word", "embeddings", ":", "We", "use", "Skip", "-", "gram", "mikolov2013word2vec", "to", "train", "word", "embeddings", ".", "Character", "embeddings", ":", "Character", "-", "gram", "embeddings", "are", "trained", "by", "the", "same", "Skip", "-", "gram", "objective", ".", "We", "construct", "the", "character", "-", "gram", "vocabulary", "in", "the", "training", "data", "and", "assign", "an", "embedding", "for", "each", "entry", ".", "The", "final", "character", "embedding", "is", "the", "average", "of", "the", "unique", "character", "-", "gram", "embeddings", "of", ".", "For", "example", ",", "the", "character", "-", "grams", "(", ")", "of", "the", "word", "\u201c", "Cat", "\u201d", "are", "{", "C", ",", "a", ",", "t", ",", "#", "B#C", ",", "Ca", ",", "at", ",", "t#E", "#", ",", "#", "B#Ca", ",", "Cat", ",", "at#E", "#", "}", ",", "where", "\u201c", "#", "B", "#", "\u201d", "and", "\u201c", "#", "E", "#", "\u201d", "represent", "the", "beginning", "and", "the", "end", "of", "each", "word", ",", "respectively", ".", "Using", "the", "character", "embeddings", "efficiently", "provides", "morphological", "features", ".", "Each", "word", "is", "subsequently", "represented", "as", ",", "the", "concatenation", "of", "its", "corresponding", "word", "and", "character", "embeddings", "shared", "across", "the", "tasks", ".", "subsection", ":", "Word", "-", "Level", "Task", ":", "POS", "Tagging", "The", "first", "layer", "of", "the", "model", "is", "a", "bi", "-", "directional", "LSTM", "graves2005bilstm", ",", "hochreiter1997lstm", "whose", "hidden", "states", "are", "used", "to", "predict", "POS", "tags", ".", "We", "use", "the", "following", "Long", "Short", "-", "Term", "Memory", "(", "LSTM", ")", "units", "for", "the", "forward", "direction", ":", "where", "we", "define", "the", "input", "as", ",", "i.e.", "the", "concatenation", "of", "the", "previous", "hidden", "state", "and", "the", "word", "representation", "of", ".", "The", "backward", "pass", "is", "expanded", "in", "the", "same", "way", ",", "but", "a", "different", "set", "of", "weights", "are", "used", ".", "For", "predicting", "the", "POS", "tag", "of", ",", "we", "use", "the", "concatenation", "of", "the", "forward", "and", "backward", "states", "in", "a", "one", "-", "layer", "bi", "-", "LSTM", "layer", "corresponding", "to", "the", "-", "th", "word", ":", ".", "Then", "each", "is", "fed", "into", "a", "standard", "classifier", "with", "a", "single", "layer", "which", "outputs", "the", "probability", "vector", "for", "each", "of", "the", "POS", "tags", ".", "subsection", ":", "Word", "-", "Level", "Task", ":", "Chunking", "Chunking", "is", "also", "a", "word", "-", "level", "classification", "task", "which", "assigns", "a", "chunking", "tag", "(", "B", "-", "NP", ",", "I", "-", "VP", ",", "etc", ".", ")", "for", "each", "word", ".", "The", "tag", "specifies", "the", "region", "of", "major", "phrases", "(", "e.g.", ",", "noun", "phrases", ")", "in", "the", "sentence", ".", "Chunking", "is", "performed", "in", "the", "second", "bi", "-", "LSTM", "layer", "on", "top", "of", "the", "POS", "layer", ".", "When", "stacking", "the", "bi", "-", "LSTM", "layers", ",", "we", "use", "Eq", ".", "(", "[", "reference", "]", ")", "with", "input", ",", "where", "is", "the", "hidden", "state", "of", "the", "first", "(", "POS", ")", "layer", ".", "We", "define", "the", "weighted", "label", "embedding", "as", "follows", ":", "where", "is", "the", "number", "of", "the", "POS", "tags", ",", "is", "the", "probability", "value", "that", "the", "-", "th", "POS", "tag", "is", "assigned", "to", ",", "and", "is", "the", "corresponding", "label", "embedding", ".", "The", "probability", "values", "are", "predicted", "by", "the", "POS", "layer", ",", "and", "thus", "no", "gold", "POS", "tags", "are", "needed", ".", "This", "output", "embedding", "is", "similar", "to", "the", "-", "best", "POS", "tag", "feature", "which", "has", "been", "shown", "to", "be", "effective", "in", "syntactic", "tasks", "andor2016", ",", "alberti2016", ".", "For", "predicting", "the", "chunking", "tags", ",", "we", "employ", "the", "same", "strategy", "as", "POS", "tagging", "by", "using", "the", "concatenated", "bi", "-", "directional", "hidden", "states", "in", "the", "chunking", "layer", ".", "We", "also", "use", "a", "single", "hidden", "layer", "before", "the", "softmax", "classifier", ".", "subsection", ":", "Syntactic", "Task", ":", "Dependency", "Parsing", "D", "ependency", "parsing", "identifies", "syntactic", "relations", "(", "such", "as", "an", "adjective", "modifying", "a", "noun", ")", "between", "word", "pairs", "in", "a", "sentence", ".", "We", "use", "the", "third", "bi", "-", "LSTM", "layer", "to", "classify", "relations", "between", "all", "pairs", "of", "words", ".", "The", "input", "vector", "for", "the", "LSTM", "includes", "hidden", "states", ",", "word", "representations", ",", "and", "the", "label", "embeddings", "for", "the", "two", "previous", "tasks", ":", ",", "where", "we", "computed", "the", "chunking", "vector", "in", "a", "similar", "fashion", "as", "the", "POS", "vector", "in", "Eq", ".", "(", "[", "reference", "]", ")", ".", "We", "predict", "the", "parent", "node", "(", "head", ")", "for", "each", "word", ".", "Then", "a", "dependency", "label", "is", "predicted", "for", "each", "child", "-", "parent", "pair", ".", "This", "approach", "is", "related", "to", "biaffine2017", "and", "zhang2017head", ",", "where", "the", "main", "difference", "is", "that", "our", "model", "works", "on", "a", "multi", "-", "task", "framework", ".", "To", "predict", "the", "parent", "node", "of", ",", "we", "define", "a", "matching", "function", "between", "and", "the", "candidates", "of", "the", "parent", "node", "as", ",", "where", "is", "a", "parameter", "matrix", ".", "For", "the", "root", ",", "we", "define", "as", "a", "parameterized", "vector", ".", "To", "compute", "the", "probability", "that", "(", "or", "the", "root", "node", ")", "is", "the", "parent", "of", ",", "the", "scores", "are", "normalized", ":", "The", "dependency", "labels", "are", "predicted", "using", "as", "input", "to", "a", "classifier", "with", "a", "single", "layer", ".", "We", "greedily", "select", "the", "parent", "node", "and", "the", "dependency", "label", "for", "each", "word", ".", "When", "the", "parsing", "result", "is", "not", "a", "well", "-", "formed", "tree", ",", "we", "apply", "the", "first", "-", "order", "Eisner", "\u2019s", "algorithm", "eisner1996", "to", "obtain", "a", "well", "-", "formed", "tree", "from", "it", ".", "subsection", ":", "Semantic", "Task", ":", "Semantic", "relatedness", "The", "next", "two", "tasks", "model", "the", "semantic", "relationships", "between", "two", "input", "sentences", ".", "The", "first", "task", "measures", "the", "semantic", "relatedness", "between", "two", "sentences", ".", "The", "output", "is", "a", "real", "-", "valued", "relatedness", "score", "for", "the", "input", "sentence", "pair", ".", "The", "second", "task", "is", "textual", "entailment", ",", "which", "requires", "one", "to", "determine", "whether", "a", "premise", "sentence", "entails", "a", "hypothesis", "sentence", ".", "There", "are", "typically", "three", "classes", ":", "entailment", ",", "contradiction", ",", "and", "neutral", ".", "We", "use", "the", "fourth", "and", "fifth", "bi", "-", "LSTM", "layer", "for", "the", "relatedness", "and", "entailment", "task", ",", "respectively", ".", "Now", "it", "is", "required", "to", "obtain", "the", "sentence", "-", "level", "representation", "rather", "than", "the", "word", "-", "level", "representation", "used", "in", "the", "first", "three", "tasks", ".", "We", "compute", "the", "sentence", "-", "level", "representation", "as", "the", "element", "-", "wise", "maximum", "values", "across", "all", "of", "the", "word", "-", "level", "representations", "in", "the", "fourth", "layer", ":", "This", "max", "-", "pooling", "technique", "has", "proven", "effective", "in", "text", "classification", "tasks", "lai2015maxpooling", ".", "To", "model", "the", "semantic", "relatedness", "between", "and", ",", "we", "follow", "tai2015treelstm", ".", "The", "feature", "vector", "for", "representing", "the", "semantic", "relatedness", "is", "computed", "as", "follows", ":", "where", "is", "the", "absolute", "values", "of", "the", "element", "-", "wise", "subtraction", ",", "and", "is", "the", "element", "-", "wise", "multiplication", ".", "Then", "is", "fed", "into", "a", "classifier", "with", "a", "single", "hidden", "layer", "goodfellow2013", "to", "output", "a", "relatedness", "score", "(", "from", "1", "to", "5", "in", "our", "case", ")", ".", "subsection", ":", "Semantic", "Task", ":", "Textual", "entailment", "For", "entailment", "classification", ",", "we", "also", "use", "the", "max", "-", "pooling", "technique", "as", "in", "the", "semantic", "relatedness", "task", ".", "To", "classify", "the", "premise", "-", "hypothesis", "pair", "into", "one", "of", "the", "three", "classes", ",", "we", "compute", "the", "feature", "vector", "as", "in", "Eq", ".", "(", "[", "reference", "]", ")", "except", "that", "we", "do", "not", "use", "the", "absolute", "values", "of", "the", "element", "-", "wise", "subtraction", ",", "because", "we", "need", "to", "identify", "which", "is", "the", "premise", "(", "or", "hypothesis", ")", ".", "Then", "is", "fed", "into", "a", "classifier", ".", "To", "use", "the", "output", "from", "the", "relatedness", "layer", "directly", ",", "we", "use", "the", "label", "embeddings", "for", "the", "relatedness", "task", ".", "More", "concretely", ",", "we", "compute", "the", "class", "label", "embeddings", "for", "the", "semantic", "relatedness", "task", "similar", "to", "Eq", ".", "(", "[", "reference", "]", ")", ".", "The", "final", "feature", "vectors", "that", "are", "concatenated", "and", "fed", "into", "the", "entailment", "classifier", "are", "the", "weighted", "relatedness", "label", "embedding", "and", "the", "feature", "vector", ".", "We", "use", "three", "hidden", "layers", "before", "the", "classifier", ".", "section", ":", "Training", "the", "JMT", "Model", "The", "model", "is", "trained", "jointly", "over", "all", "datasets", ".", "During", "each", "epoch", ",", "the", "optimization", "iterates", "over", "each", "full", "training", "dataset", "in", "the", "same", "order", "as", "the", "corresponding", "tasks", "described", "in", "the", "modeling", "section", ".", "subsection", ":", "Pre", "-", "Training", "Word", "Representations", "We", "pre", "-", "train", "word", "embeddings", "using", "the", "Skip", "-", "gram", "model", "with", "negative", "sampling", "mikolov2013word2vec", ".", "We", "also", "pre", "-", "train", "the", "character", "-", "gram", "embeddings", "using", "Skip", "-", "gram", ".", "The", "only", "difference", "is", "that", "each", "input", "word", "embedding", "is", "replaced", "with", "its", "corresponding", "average", "character", "-", "gram", "embedding", "described", "in", "Section", "[", "reference", "]", ".", "These", "embeddings", "are", "fine", "-", "tuned", "during", "the", "model", "training", ".", "We", "denote", "the", "embedding", "parameters", "as", ".", "subsection", ":", "Training", "the", "POS", "Layer", "Let", "denote", "the", "set", "of", "model", "parameters", "associated", "with", "the", "POS", "layer", ",", "where", "is", "the", "set", "of", "the", "weight", "matrices", "in", "the", "first", "bi", "-", "LSTM", "and", "the", "classifier", ",", "and", "is", "the", "set", "of", "the", "bias", "vectors", ".", "The", "objective", "function", "to", "optimize", "is", "defined", "as", "follows", ":", "where", "is", "the", "probability", "value", "that", "the", "correct", "label", "is", "assigned", "to", "in", "the", "sentence", ",", "is", "the", "L2", "-", "norm", "regularization", "term", ",", "and", "is", "a", "hyperparameter", ".", "We", "call", "the", "second", "regularization", "term", "a", "successive", "regularization", "term", ".", "The", "successive", "regularization", "is", "based", "on", "the", "idea", "that", "we", "do", "not", "want", "the", "model", "to", "forget", "the", "information", "learned", "for", "the", "other", "tasks", ".", "In", "the", "case", "of", "POS", "tagging", ",", "the", "regularization", "is", "applied", "to", ",", "and", "is", "the", "embedding", "parameter", "after", "training", "the", "final", "task", "in", "the", "top", "-", "most", "layer", "at", "the", "previous", "training", "epoch", ".", "is", "a", "hyperparameter", ".", "subsection", ":", "Training", "the", "Chunking", "Layer", "The", "objective", "function", "is", "defined", "as", "follows", ":", "which", "is", "similar", "to", "that", "of", "POS", "tagging", ",", "and", "is", ",", "where", "and", "are", "the", "weight", "and", "bias", "parameters", "including", "those", "in", ",", "and", "is", "the", "set", "of", "the", "POS", "label", "embeddings", ".", "is", "the", "one", "after", "training", "the", "POS", "layer", "at", "the", "current", "training", "epoch", ".", "subsection", ":", "Training", "the", "Dependency", "Layer", "The", "objective", "function", "is", "defined", "as", "follows", ":", "where", "is", "the", "probability", "value", "assigned", "to", "the", "correct", "parent", "node", "for", ",", "and", "is", "the", "probability", "value", "assigned", "to", "the", "correct", "dependency", "label", "for", "the", "child", "-", "parent", "pair", ".", "is", "defined", "as", ",", "where", "and", "are", "the", "weight", "and", "bias", "parameters", "including", "those", "in", ",", "and", "is", "the", "set", "of", "the", "chunking", "label", "embeddings", ".", "subsection", ":", "Training", "the", "Relatedness", "Layer", "Following", "tai2015treelstm", ",", "the", "objective", "function", "is", "defined", "as", "follows", ":", "where", "is", "the", "gold", "distribution", "over", "the", "defined", "relatedness", "scores", ",", "is", "the", "predicted", "distribution", "given", "the", "the", "sentence", "representations", ",", "and", "is", "the", "KL", "-", "divergence", "between", "the", "two", "distributions", ".", "is", "defined", "as", ".", "subsection", ":", "Training", "the", "Entailment", "Layer", "The", "objective", "function", "is", "defined", "as", "follows", ":", "where", "is", "the", "probability", "value", "that", "the", "correct", "label", "is", "assigned", "to", "the", "premise", "-", "hypothesis", "pair", ".", "is", "defined", "as", ",", "where", "is", "the", "set", "of", "the", "relatedness", "label", "embeddings", ".", "section", ":", "Related", "Work", "Many", "deep", "learning", "approaches", "have", "proven", "to", "be", "effective", "in", "a", "variety", "of", "NLP", "tasks", "and", "are", "becoming", "more", "and", "more", "complex", ".", "They", "are", "typically", "designed", "to", "handle", "single", "tasks", ",", "or", "some", "of", "them", "are", "designed", "as", "general", "-", "purpose", "models", "kumar2016dmn", ",", "sutskever2014seq2seq", "but", "applied", "to", "different", "tasks", "independently", ".", "For", "handling", "multiple", "NLP", "tasks", ",", "multi", "-", "task", "learning", "models", "with", "deep", "neural", "networks", "have", "been", "proposed", "collobert2011senna", ",", "luong2016mtl", ",", "and", "more", "recently", "sogaard2016", "have", "suggested", "that", "using", "different", "layers", "for", "different", "tasks", "is", "more", "effective", "than", "using", "the", "same", "layer", "in", "jointly", "learning", "closely", "-", "related", "tasks", ",", "such", "as", "POS", "tagging", "and", "chunking", ".", "However", ",", "the", "number", "of", "tasks", "was", "limited", "or", "they", "have", "very", "similar", "task", "settings", "like", "word", "-", "level", "tagging", ",", "and", "it", "was", "not", "clear", "how", "lower", "-", "level", "tasks", "could", "be", "also", "improved", "by", "combining", "higher", "-", "level", "tasks", ".", "More", "related", "to", "our", "work", ",", "godwin2016multi", "also", "followed", "sogaard2016", "to", "jointly", "learn", "POS", "tagging", ",", "chunking", ",", "and", "language", "modeling", ",", "and", "zhang2016stackprop", "have", "shown", "that", "it", "is", "effective", "to", "jointly", "learn", "POS", "tagging", "and", "dependency", "parsing", "by", "sharing", "internal", "representations", ".", "In", "the", "field", "of", "relation", "extraction", ",", "miwa2016rel", "proposed", "a", "joint", "learning", "model", "for", "entity", "detection", "and", "relation", "extraction", ".", "All", "of", "them", "suggest", "the", "importance", "of", "multi", "-", "task", "learning", ",", "and", "we", "investigate", "the", "potential", "of", "handling", "different", "types", "of", "NLP", "tasks", "rather", "than", "closely", "-", "related", "ones", "in", "a", "single", "hierarchical", "deep", "model", ".", "In", "the", "field", "of", "computer", "vision", ",", "some", "transfer", "and", "multi", "-", "task", "learning", "approaches", "have", "also", "been", "proposed", "li2016multi", ",", "misra2016multi", ".", "For", "example", ",", "misra2016multi", "proposed", "a", "multi", "-", "task", "learning", "model", "to", "handle", "different", "tasks", ".", "However", ",", "they", "assume", "that", "each", "data", "sample", "has", "annotations", "for", "the", "different", "tasks", ",", "and", "do", "not", "explicitly", "consider", "task", "hierarchies", ".", "Recently", ",", "rusu2016progressive", "have", "proposed", "a", "progressive", "neural", "network", "model", "to", "handle", "multiple", "reinforcement", "learning", "tasks", ",", "such", "as", "Atari", "games", ".", "Like", "our", "JMT", "model", ",", "their", "model", "is", "also", "successively", "trained", "according", "to", "different", "tasks", "using", "different", "layers", "called", "columns", "in", "their", "paper", ".", "In", "their", "model", ",", "once", "the", "first", "task", "is", "completed", ",", "the", "model", "parameters", "for", "the", "first", "task", "are", "fixed", ",", "and", "then", "the", "second", "task", "is", "handled", "with", "new", "model", "parameters", ".", "Therefore", ",", "accuracy", "of", "the", "previously", "trained", "tasks", "is", "never", "improved", ".", "In", "NLP", "tasks", ",", "multi", "-", "task", "learning", "has", "the", "potential", "to", "improve", "not", "only", "higher", "-", "level", "tasks", ",", "but", "also", "lower", "-", "level", "tasks", ".", "Rather", "than", "fixing", "the", "pre", "-", "trained", "model", "parameters", ",", "our", "successive", "regularization", "allows", "our", "model", "to", "continuously", "train", "the", "lower", "-", "level", "tasks", "without", "significant", "accuracy", "drops", ".", "section", ":", "Experimental", "Settings", "subsection", ":", "Datasets", "POS", "tagging", ":", "To", "train", "the", "POS", "tagging", "layer", ",", "we", "used", "the", "Wall", "Street", "Journal", "(", "WSJ", ")", "portion", "of", "Penn", "Treebank", ",", "and", "followed", "the", "standard", "split", "for", "the", "training", "(", "Section", "0", "-", "18", ")", ",", "development", "(", "Section", "19", "-", "21", ")", ",", "and", "test", "(", "Section", "22", "-", "24", ")", "sets", ".", "The", "evaluation", "metric", "is", "the", "word", "-", "level", "accuracy", ".", "Chunking", ":", "For", "chunking", ",", "we", "also", "used", "the", "WSJ", "corpus", ",", "and", "followed", "the", "standard", "split", "for", "the", "training", "(", "Section", "15", "-", "18", ")", "and", "test", "(", "Section", "20", ")", "sets", "as", "in", "the", "CoNLL", "2000", "shared", "task", ".", "We", "used", "Section", "19", "as", "the", "development", "set", "and", "employed", "the", "IOBES", "tagging", "scheme", ".", "The", "evaluation", "metric", "is", "the", "F1", "score", "defined", "in", "the", "shared", "task", ".", "Dependency", "parsing", ":", "We", "also", "used", "the", "WSJ", "corpus", "for", "dependency", "parsing", ",", "and", "followed", "the", "standard", "split", "for", "the", "training", "(", "Section", "2", "-", "21", ")", ",", "development", "(", "Section", "22", ")", ",", "and", "test", "(", "Section", "23", ")", "sets", ".", "We", "obtained", "Stanford", "style", "dependencies", "using", "the", "version", "3.3.0", "of", "the", "Stanford", "converter", ".", "The", "evaluation", "metrics", "are", "the", "Unlabeled", "Attachment", "Score", "(", "UAS", ")", "and", "the", "Labeled", "Attachment", "Score", "(", "LAS", ")", ",", "and", "punctuations", "are", "excluded", "for", "the", "evaluation", ".", "Semantic", "relatedness", ":", "For", "the", "semantic", "relatedness", "task", ",", "we", "used", "the", "SICK", "dataset", "marelli2014", ",", "and", "followed", "the", "standard", "split", "for", "the", "training", ",", "development", ",", "and", "test", "sets", ".", "The", "evaluation", "metric", "is", "the", "Mean", "Squared", "Error", "(", "MSE", ")", "between", "the", "gold", "and", "predicted", "scores", ".", "Textual", "entailment", ":", "For", "textual", "entailment", ",", "we", "also", "used", "the", "SICK", "dataset", "and", "exactly", "the", "same", "data", "split", "as", "the", "semantic", "relatedness", "dataset", ".", "The", "evaluation", "metric", "is", "the", "accuracy", ".", "subsection", ":", "Training", "Details", "We", "set", "the", "dimensionality", "of", "the", "embeddings", "and", "the", "hidden", "states", "in", "the", "bi", "-", "LSTMs", "to", "100", ".", "At", "each", "training", "epoch", ",", "we", "trained", "our", "model", "in", "the", "order", "of", "POS", "tagging", ",", "chunking", ",", "dependency", "parsing", ",", "semantic", "relatedness", ",", "and", "textual", "entailment", ".", "We", "used", "mini", "-", "batch", "stochastic", "gradient", "decent", "and", "empirically", "found", "it", "effective", "to", "use", "a", "gradient", "clipping", "method", "with", "growing", "clipping", "values", "for", "the", "different", "tasks", ";", "concretely", ",", "we", "employed", "the", "simple", "function", ":", ",", "where", "is", "the", "number", "of", "bi", "-", "LSTM", "layers", "involved", "in", "each", "task", ",", "and", "is", "the", "maximum", "value", ".", "We", "applied", "our", "successive", "regularization", "to", "our", "model", ",", "along", "with", "L2", "-", "norm", "regularization", "and", "dropout", "dropout2014ver", ".", "More", "details", "are", "summarized", "in", "the", "supplemental", "material", ".", "section", ":", "Results", "and", "Discussion", "Table", "[", "reference", "]", "shows", "our", "results", "on", "the", "test", "sets", "of", "the", "five", "tasks", ".", "The", "column", "\u201c", "Single", "\u201d", "shows", "the", "results", "of", "handling", "each", "task", "separately", "using", "single", "-", "layer", "bi", "-", "LSTMs", ",", "and", "the", "column", "\u201c", "JMT", "\u201d", "shows", "the", "results", "of", "our", "JMT", "model", ".", "The", "single", "task", "settings", "only", "use", "the", "annotations", "of", "their", "own", "tasks", ".", "For", "example", ",", "when", "handling", "dependency", "parsing", "as", "a", "single", "task", ",", "the", "POS", "and", "chunking", "tags", "are", "not", "used", ".", "We", "can", "see", "that", "all", "results", "of", "the", "five", "tasks", "are", "improved", "in", "our", "JMT", "model", ",", "which", "shows", "that", "our", "JMT", "model", "can", "handle", "the", "five", "different", "tasks", "in", "a", "single", "model", ".", "Our", "JMT", "model", "allows", "us", "to", "access", "arbitrary", "information", "learned", "from", "the", "different", "tasks", ".", "If", "we", "want", "to", "use", "the", "model", "just", "as", "a", "POS", "tagger", ",", "we", "can", "use", "only", "first", "bi", "-", "LSTM", "layer", ".", "Table", "[", "reference", "]", "also", "shows", "the", "results", "of", "five", "subsets", "of", "the", "different", "tasks", ".", "For", "example", ",", "in", "the", "case", "of", "\u201c", "JMT", "\u201d", ",", "only", "the", "first", "three", "layers", "of", "the", "bi", "-", "LSTMs", "are", "used", "to", "handle", "the", "three", "tasks", ".", "In", "the", "case", "of", "\u201c", "JMT", "\u201d", ",", "only", "the", "top", "two", "layers", "are", "used", "as", "a", "two", "-", "layer", "bi", "-", "LSTM", "by", "omitting", "all", "information", "from", "the", "first", "three", "layers", ".", "The", "results", "of", "the", "closely", "-", "related", "tasks", "(", "\u201c", "AB", "\u201d", ",", "\u201c", "ABC", "\u201d", ",", "and", "\u201c", "DE", "\u201d", ")", "show", "that", "our", "JMT", "model", "improves", "both", "of", "the", "high", "-", "level", "and", "low", "-", "level", "tasks", ".", "The", "results", "of", "\u201c", "JMT", "\u201d", "and", "\u201c", "JMT", "\u201d", "show", "that", "the", "parsing", "task", "can", "be", "improved", "by", "the", "semantic", "tasks", ".", "It", "should", "be", "noted", "that", "in", "our", "analysis", "on", "the", "greedy", "parsing", "results", "of", "the", "\u201c", "JMT", "\u201d", "setting", ",", "we", "have", "found", "that", "more", "than", "95", "%", "are", "well", "-", "formed", "dependency", "trees", "on", "the", "development", "set", ".", "In", "the", "1", ",", "700", "sentences", "of", "the", "development", "data", ",", "11", "results", "have", "multiple", "root", "notes", ",", "11", "results", "have", "no", "root", "nodes", ",", "and", "61", "results", "have", "cycles", ".", "These", "83", "parsing", "results", "are", "converted", "into", "well", "-", "formed", "trees", "by", "Eisner", "\u2019s", "algorithm", ",", "and", "the", "accuracy", "does", "not", "significantly", "change", "(", "UAS", ":", "94.52", "%", "94.53", "%", ",", "LAS", ":", "92.61", "%", "92.62", "%", ")", ".", "subsection", ":", "Comparison", "with", "Published", "Results", "paragraph", ":", "POS", "tagging", "Table", "[", "reference", "]", "shows", "the", "results", "of", "POS", "tagging", ",", "and", "our", "JMT", "model", "achieves", "the", "score", "close", "to", "the", "state", "-", "of", "-", "the", "-", "art", "results", ".", "The", "best", "result", "to", "date", "has", "been", "achieved", "by", "ling2015charlstm", ",", "which", "uses", "character", "-", "based", "LSTMs", ".", "Incorporating", "the", "character", "-", "based", "encoders", "into", "our", "JMT", "model", "would", "be", "an", "interesting", "direction", ",", "but", "we", "have", "shown", "that", "the", "simple", "pre", "-", "trained", "character", "-", "gram", "embeddings", "lead", "to", "the", "promising", "result", ".", "paragraph", ":", "Chunking", "Table", "[", "reference", "]", "shows", "the", "results", "of", "chunking", ",", "and", "our", "JMT", "model", "achieves", "the", "state", "-", "of", "-", "the", "-", "art", "result", ".", "sogaard2016", "proposed", "to", "jointly", "learn", "POS", "tagging", "and", "chunking", "in", "different", "layers", ",", "but", "they", "only", "showed", "improvement", "for", "chunking", ".", "By", "contrast", ",", "our", "results", "show", "that", "the", "low", "-", "level", "tasks", "are", "also", "improved", ".", "paragraph", ":", "Dependency", "parsing", "Table", "[", "reference", "]", "shows", "the", "results", "of", "dependency", "parsing", "by", "using", "only", "the", "WSJ", "corpus", "in", "terms", "of", "the", "dependency", "annotations", ".", "It", "is", "notable", "that", "our", "simple", "greedy", "dependency", "parser", "outperforms", "the", "model", "in", "andor2016", "which", "is", "based", "on", "beam", "search", "with", "global", "information", ".", "The", "result", "suggests", "that", "the", "bi", "-", "LSTMs", "efficiently", "capture", "global", "information", "necessary", "for", "dependency", "parsing", ".", "Moreover", ",", "our", "single", "task", "result", "already", "achieves", "high", "accuracy", "without", "the", "POS", "and", "chunking", "information", ".", "The", "best", "result", "to", "date", "has", "been", "achieved", "by", "the", "model", "propsoed", "in", "biaffine2017", ",", "which", "uses", "higher", "dimensional", "representations", "than", "ours", "and", "proposes", "a", "more", "sophisticated", "attention", "mechanism", "called", "biaffine", "attention", ".", "It", "should", "be", "promising", "to", "incorporate", "their", "attention", "mechanism", "into", "our", "parsing", "component", ".", "paragraph", ":", "Semantic", "relatedness", "Table", "[", "reference", "]", "shows", "the", "results", "of", "the", "semantic", "relatedness", "task", ",", "and", "our", "JMT", "model", "achieves", "the", "state", "-", "of", "-", "the", "-", "art", "result", ".", "The", "result", "of", "\u201c", "JMT", "\u201d", "is", "already", "better", "than", "the", "previous", "state", "-", "of", "-", "the", "-", "art", "results", ".", "Both", "of", "zhou2016coling", "and", "tai2015treelstm", "explicitly", "used", "syntactic", "trees", ",", "and", "zhou2016coling", "relied", "on", "attention", "mechanisms", ".", "However", ",", "our", "method", "uses", "the", "simple", "max", "-", "pooling", "strategy", ",", "which", "suggests", "that", "it", "is", "worth", "investigating", "such", "simple", "methods", "before", "developing", "complex", "methods", "for", "simple", "tasks", ".", "Currently", ",", "our", "JMT", "model", "does", "not", "explicitly", "use", "the", "learned", "dependency", "structures", ",", "and", "thus", "the", "explicit", "use", "of", "the", "output", "from", "the", "dependency", "layer", "should", "be", "an", "interesting", "direction", "of", "future", "work", ".", "paragraph", ":", "Textual", "entailment", "Table", "[", "reference", "]", "shows", "the", "results", "of", "textual", "entailment", ",", "and", "our", "JMT", "model", "achieves", "the", "state", "-", "of", "-", "the", "-", "art", "result", ".", "The", "previous", "state", "-", "of", "-", "the", "-", "art", "result", "in", "yin2016abcnn", "relied", "on", "attention", "mechanisms", "and", "dataset", "-", "specific", "data", "pre", "-", "processing", "and", "features", ".", "Again", ",", "our", "simple", "max", "-", "pooling", "strategy", "achieves", "the", "state", "-", "of", "-", "the", "-", "art", "result", "boosted", "by", "the", "joint", "training", ".", "These", "results", "show", "the", "importance", "of", "jointly", "handling", "related", "tasks", ".", "subsection", ":", "Analysis", "on", "the", "Model", "Architectures", "We", "investigate", "the", "effectiveness", "of", "our", "model", "in", "detail", ".", "All", "of", "the", "results", "shown", "in", "this", "section", "are", "the", "development", "set", "results", ".", "paragraph", ":", "Shortcut", "connections", "Our", "JMT", "model", "feeds", "the", "word", "representations", "into", "all", "of", "the", "bi", "-", "LSTM", "layers", ",", "which", "is", "called", "the", "shortcut", "connection", ".", "Table", "[", "reference", "]", "shows", "the", "results", "of", "\u201c", "JMT", "\u201d", "with", "and", "without", "the", "shortcut", "connections", ".", "The", "results", "without", "the", "shortcut", "connections", "are", "shown", "in", "the", "column", "of", "\u201c", "w", "/", "o", "SC", "\u201d", ".", "These", "results", "clearly", "show", "that", "the", "importance", "of", "the", "shortcut", "connections", ",", "and", "in", "particular", ",", "the", "semantic", "tasks", "in", "the", "higher", "layers", "strongly", "rely", "on", "the", "shortcut", "connections", ".", "That", "is", ",", "simply", "stacking", "the", "LSTM", "layers", "is", "not", "sufficient", "to", "handle", "a", "variety", "of", "NLP", "tasks", "in", "a", "single", "model", ".", "In", "the", "supplementary", "material", ",", "it", "is", "qualitatively", "shown", "how", "the", "shortcut", "connections", "work", "in", "our", "model", ".", "paragraph", ":", "Output", "label", "embeddings", "Table", "[", "reference", "]", "also", "shows", "the", "results", "without", "using", "the", "output", "labels", "of", "the", "POS", ",", "chunking", ",", "and", "relatedness", "layers", ",", "in", "the", "column", "of", "\u201c", "w", "/", "o", "LE", "\u201d", ".", "These", "results", "show", "that", "the", "explicit", "use", "of", "the", "output", "information", "from", "the", "classifiers", "of", "the", "lower", "layers", "is", "important", "in", "our", "JMT", "model", ".", "The", "results", "in", "the", "column", "of", "\u201c", "w", "/", "o", "SC", "&", "LE", "\u201d", "are", "the", "ones", "without", "both", "of", "the", "shortcut", "connections", "and", "the", "label", "embeddings", ".", "paragraph", ":", "Different", "layers", "for", "different", "tasks", "Table", "[", "reference", "]", "shows", "the", "results", "of", "our", "\u201c", "JMT", "\u201d", "setting", "and", "that", "of", "not", "using", "the", "shortcut", "connections", "and", "the", "label", "embeddings", "(", "\u201c", "w", "/", "o", "SC", "&", "LE", "\u201d", ")", "as", "in", "Table", "[", "reference", "]", ".", "In", "addition", ",", "in", "the", "column", "of", "\u201c", "All", "-", "3", "\u201d", ",", "we", "show", "the", "results", "of", "using", "the", "highest", "(", "i.e.", ",", "the", "third", ")", "layer", "for", "all", "of", "the", "three", "tasks", "without", "any", "shortcut", "connections", "and", "label", "embeddings", ",", "and", "thus", "the", "two", "settings", "\u201c", "w", "/", "o", "SC", "&", "LE", "\u201d", "and", "\u201c", "All", "-", "3", "\u201d", "require", "exactly", "the", "same", "number", "of", "the", "model", "parameters", ".", "The", "\u201c", "All", "-", "3", "\u201d", "setting", "is", "similar", "to", "the", "multi", "-", "task", "model", "of", "collobert2011senna", "in", "that", "task", "-", "specific", "output", "layers", "are", "used", "but", "most", "of", "the", "model", "parameters", "are", "shared", ".", "The", "results", "show", "that", "using", "the", "same", "layers", "for", "the", "three", "different", "tasks", "hampers", "the", "effectiveness", "of", "our", "JMT", "model", ",", "and", "the", "design", "of", "the", "model", "is", "much", "more", "important", "than", "the", "number", "of", "the", "model", "parameters", ".", "paragraph", ":", "Successive", "regularization", "In", "Table", "[", "reference", "]", ",", "the", "column", "of", "\u201c", "w", "/", "o", "SR", "\u201d", "shows", "the", "results", "of", "omitting", "the", "successive", "regularization", "terms", "described", "in", "Section", "[", "reference", "]", ".", "We", "can", "see", "that", "the", "accuracy", "of", "chunking", "is", "improved", "by", "the", "successive", "regularization", ",", "while", "other", "results", "are", "not", "affected", "so", "much", ".", "The", "chunking", "dataset", "used", "here", "is", "relatively", "small", "compared", "with", "other", "low", "-", "level", "tasks", ",", "POS", "tagging", "and", "dependency", "parsing", ".", "Thus", ",", "these", "results", "suggest", "that", "the", "successive", "regularization", "is", "effective", "when", "dataset", "sizes", "are", "imbalanced", ".", "paragraph", ":", "Vertical", "connections", "We", "investigated", "our", "JMT", "results", "without", "using", "the", "vertical", "connections", "in", "the", "five", "-", "layer", "bi", "-", "LSTMs", ".", "More", "concretely", ",", "when", "constructing", "the", "input", "vectors", ",", "we", "do", "not", "use", "the", "bi", "-", "LSTM", "hidden", "states", "of", "the", "previous", "layers", ".", "Table", "[", "reference", "]", "also", "shows", "the", "JMT", "results", "with", "and", "without", "the", "vertical", "connections", ".", "As", "shown", "in", "the", "column", "of", "\u201c", "w", "/", "o", "VC", "\u201d", ",", "we", "observed", "the", "competitive", "results", ".", "Therefore", ",", "in", "the", "target", "tasks", "used", "in", "our", "model", ",", "sharing", "the", "word", "representations", "and", "the", "output", "label", "embeddings", "is", "more", "effective", "than", "just", "stacking", "the", "bi", "-", "LSTM", "layers", ".", "paragraph", ":", "Order", "of", "training", "Our", "JMT", "model", "iterates", "the", "training", "process", "in", "the", "order", "described", "in", "Section", "[", "reference", "]", ".", "Our", "hypothesis", "is", "that", "it", "is", "important", "to", "start", "from", "the", "lower", "-", "level", "tasks", "and", "gradually", "move", "to", "the", "higher", "-", "level", "tasks", ".", "Table", "[", "reference", "]", "shows", "the", "results", "of", "training", "our", "model", "by", "randomly", "shuffling", "the", "order", "of", "the", "tasks", "for", "each", "epoch", "in", "the", "column", "of", "\u201c", "Random", "\u201d", ".", "We", "see", "that", "the", "scores", "of", "the", "semantic", "tasks", "drop", "by", "the", "random", "strategy", ".", "In", "our", "preliminary", "experiments", ",", "we", "have", "found", "that", "constructing", "the", "mini", "-", "batch", "samples", "from", "different", "tasks", "also", "hampers", "the", "effectiveness", "of", "our", "model", ",", "which", "also", "supports", "our", "hypothesis", ".", "paragraph", ":", "Depth", "The", "single", "task", "settings", "shown", "in", "Table", "[", "reference", "]", "are", "obtained", "by", "using", "single", "layer", "bi", "-", "LSTMs", ",", "but", "in", "our", "JMT", "model", ",", "the", "higher", "-", "level", "tasks", "use", "successively", "deeper", "layers", ".", "To", "investigate", "the", "gap", "between", "the", "different", "number", "of", "the", "layers", "for", "each", "task", ",", "we", "also", "show", "the", "results", "of", "using", "multi", "-", "layer", "bi", "-", "LSTMs", "for", "the", "single", "task", "settings", ",", "in", "the", "column", "of", "\u201c", "Single", "+", "\u201d", "in", "Table", "[", "reference", "]", ".", "More", "concretely", ",", "we", "use", "the", "same", "number", "of", "the", "layers", "with", "our", "JMT", "model", ";", "for", "example", ",", "three", "layers", "are", "used", "for", "dependency", "parsing", ",", "and", "five", "layers", "are", "used", "for", "textual", "entailment", ".", "As", "shown", "in", "these", "results", ",", "deeper", "layers", "do", "not", "always", "lead", "to", "better", "results", ",", "and", "the", "joint", "learning", "is", "more", "important", "than", "making", "the", "models", "complex", "only", "for", "single", "tasks", ".", "paragraph", ":", "Character", "-", "gram", "embeddings", "Finally", ",", "Table", "[", "reference", "]", "shows", "the", "results", "for", "the", "three", "single", "tasks", "with", "and", "without", "the", "pre", "-", "trained", "character", "-", "gram", "embeddings", ".", "The", "column", "of", "\u201c", "W", "&", "C", "\u201d", "corresponds", "to", "using", "both", "of", "the", "word", "and", "character", "-", "gram", "embeddings", ",", "and", "that", "of", "\u201c", "Only", "W", "\u201d", "corresponds", "to", "using", "only", "the", "word", "embeddings", ".", "These", "results", "clearly", "show", "that", "jointly", "using", "the", "pre", "-", "trained", "word", "and", "character", "-", "gram", "embeddings", "is", "helpful", "in", "improving", "the", "results", ".", "The", "pre", "-", "training", "of", "the", "character", "-", "gram", "embeddings", "is", "also", "effective", ";", "for", "example", ",", "without", "the", "pre", "-", "training", ",", "the", "POS", "accuracy", "drops", "from", "97.52", "%", "to", "97.38", "%", "and", "the", "chunking", "accuracy", "drops", "from", "95.65", "%", "to", "95.14", "%", ".", "subsection", ":", "Discussion", "paragraph", ":", "Training", "strategies", "In", "our", "JMT", "model", ",", "it", "is", "not", "obvious", "when", "to", "stop", "the", "training", "while", "trying", "to", "maximize", "the", "scores", "of", "all", "the", "five", "tasks", ".", "We", "focused", "on", "maximizing", "the", "accuracy", "of", "dependency", "parsing", "on", "the", "development", "data", "in", "our", "experiments", ".", "However", ",", "the", "sizes", "of", "the", "training", "data", "are", "different", "across", "the", "different", "tasks", ";", "for", "example", ",", "the", "semantic", "tasks", "include", "only", "4", ",", "500", "sentence", "pairs", ",", "and", "the", "dependency", "parsing", "dataset", "includes", "39", ",", "832", "sentences", "with", "word", "-", "level", "annotations", ".", "Thus", ",", "in", "general", ",", "dependency", "parsing", "requires", "more", "training", "epochs", "than", "the", "semantic", "tasks", ",", "but", "currently", ",", "our", "model", "trains", "all", "of", "the", "tasks", "for", "the", "same", "training", "epochs", ".", "The", "same", "strategy", "for", "decreasing", "the", "learning", "rate", "is", "also", "shared", "across", "all", "the", "different", "tasks", ",", "although", "our", "growing", "gradient", "clipping", "method", "described", "in", "Section", "[", "reference", "]", "helps", "improve", "the", "results", ".", "Indeed", ",", "we", "observed", "that", "better", "scores", "of", "the", "semantic", "tasks", "can", "be", "achieved", "before", "the", "accuracy", "of", "dependency", "parsing", "reaches", "the", "best", "score", ".", "Developing", "a", "method", "for", "achieving", "the", "best", "scores", "for", "all", "of", "the", "tasks", "at", "the", "same", "time", "is", "important", "future", "work", ".", "paragraph", ":", "More", "tasks", "Our", "JMT", "model", "has", "the", "potential", "of", "handling", "more", "tasks", "than", "the", "five", "tasks", "used", "in", "our", "experiments", ";", "examples", "include", "entity", "detection", "and", "relation", "extraction", "as", "in", "miwa2016rel", "as", "well", "as", "language", "modeling", "godwin2016multi", ".", "It", "is", "also", "a", "promising", "direction", "to", "train", "each", "task", "for", "multiple", "domains", "by", "focusing", "on", "domain", "adaptation", "sogaard2016", ".", "In", "particular", ",", "incorporating", "language", "modeling", "tasks", "provides", "an", "opportunity", "to", "use", "large", "text", "data", ".", "Such", "large", "text", "data", "was", "used", "in", "our", "experiments", "to", "pre", "-", "train", "the", "word", "and", "character", "-", "gram", "embeddings", ".", "However", ",", "it", "would", "be", "preferable", "to", "efficiently", "use", "it", "for", "improving", "the", "entire", "model", ".", "paragraph", ":", "Task", "-", "oriented", "learning", "of", "low", "-", "level", "tasks", "Each", "task", "in", "our", "JMT", "model", "is", "supervised", "by", "its", "corresponding", "dataset", ".", "However", ",", "it", "would", "be", "possible", "to", "learn", "low", "-", "level", "tasks", "by", "optimizing", "high", "-", "level", "tasks", ",", "because", "the", "model", "parameters", "of", "the", "low", "-", "level", "tasks", "can", "be", "directly", "modified", "by", "learning", "the", "high", "-", "level", "tasks", ".", "One", "example", "has", "already", "been", "presented", "in", "hashimoto2017lgp", ",", "where", "our", "JMT", "model", "is", "extended", "to", "learning", "task", "-", "oriented", "latent", "graph", "structures", "of", "sentences", "by", "training", "our", "dependency", "parsing", "component", "according", "to", "a", "neural", "machine", "translation", "objective", ".", "section", ":", "Conclusion", "We", "presented", "a", "joint", "many", "-", "task", "model", "to", "handle", "multiple", "NLP", "tasks", "with", "growing", "depth", "in", "a", "single", "end", "-", "to", "-", "end", "model", ".", "Our", "model", "is", "successively", "trained", "by", "considering", "linguistic", "hierarchies", ",", "directly", "feeding", "word", "representations", "into", "all", "layers", ",", "explicitly", "using", "low", "-", "level", "predictions", ",", "and", "applying", "successive", "regularization", ".", "In", "experiments", "on", "five", "NLP", "tasks", ",", "our", "single", "model", "achieves", "the", "state", "-", "of", "-", "the", "-", "art", "or", "competitive", "results", "on", "chunking", ",", "dependency", "parsing", ",", "semantic", "relatedness", ",", "and", "textual", "entailment", ".", "subsubsection", ":", "Acknowledgments", "We", "thank", "the", "anonymous", "reviewers", "and", "the", "Salesforce", "Research", "team", "members", "for", "their", "fruitful", "comments", "and", "discussions", ".", "bibliography", ":", "References", "appendix", ":", "Supplemental", "Material", "appendix", ":", "Training", "Details", "paragraph", ":", "Pre", "-", "training", "embeddings", "We", "used", "the", "word2vec", "toolkit", "to", "pre", "-", "train", "the", "word", "embeddings", ".", "We", "created", "our", "training", "corpus", "by", "selecting", "lowercased", "English", "Wikipedia", "text", "and", "obtained", "100", "-", "dimensional", "Skip", "-", "gram", "word", "embeddings", "trained", "with", "the", "context", "window", "size", "1", ",", "the", "negative", "sampling", "method", "(", "15", "negative", "samples", ")", ",", "and", "the", "sub", "-", "sampling", "method", "(", "of", "the", "sub", "-", "sampling", "coefficient", ")", ".", "We", "also", "pre", "-", "trained", "the", "character", "-", "gram", "embeddings", "using", "the", "same", "parameter", "settings", "with", "the", "case", "-", "sensitive", "Wikipedia", "text", ".", "We", "trained", "the", "character", "-", "gram", "embeddings", "for", "in", "the", "pre", "-", "training", "step", ".", "paragraph", ":", "Embedding", "initialization", "We", "used", "the", "pre", "-", "trained", "word", "embeddings", "to", "initialize", "the", "word", "embeddings", ",", "and", "the", "word", "vocabulary", "was", "built", "based", "on", "the", "training", "data", "of", "the", "five", "tasks", ".", "All", "words", "in", "the", "training", "data", "were", "included", "in", "the", "word", "vocabulary", ",", "and", "we", "employed", "the", "word", "-", "dropout", "method", "kiperwasser2016", "to", "train", "the", "word", "embedding", "for", "the", "unknown", "words", ".", "We", "also", "built", "the", "character", "-", "gram", "vocabulary", "for", ",", "following", "wieting2016", ",", "and", "the", "character", "-", "gram", "embeddings", "were", "initialized", "with", "the", "pre", "-", "trained", "embeddings", ".", "All", "of", "the", "label", "embeddings", "were", "initialized", "with", "uniform", "random", "values", "in", ",", "where", "is", "the", "dimensionality", "of", "the", "label", "embeddings", "and", "is", "the", "number", "of", "labels", ".", "paragraph", ":", "Weight", "initialization", "The", "dimensionality", "of", "the", "hidden", "layers", "in", "the", "bi", "-", "LSTMs", "was", "set", "to", "100", ".", "We", "initialized", "all", "of", "the", "softmax", "parameters", "and", "bias", "vectors", ",", "except", "for", "the", "forget", "biases", "in", "the", "LSTMs", ",", "with", "zeros", ",", "and", "the", "weight", "matrix", "and", "the", "root", "node", "vector", "for", "dependency", "parsing", "were", "also", "initialized", "with", "zeros", ".", "All", "of", "the", "forget", "biases", "were", "initialized", "with", "ones", ".", "The", "other", "weight", "matrices", "were", "initialized", "with", "uniform", "random", "values", "in", ",", "where", "and", "are", "the", "number", "of", "rows", "and", "columns", "of", "the", "matrices", ",", "respectively", ".", "paragraph", ":", "Optimization", "At", "each", "epoch", ",", "we", "trained", "our", "model", "in", "the", "order", "of", "POS", "tagging", ",", "chunking", ",", "dependency", "parsing", ",", "semantic", "relatedness", ",", "and", "textual", "entailment", ".", "We", "used", "mini", "-", "batch", "stochastic", "gradient", "decent", "to", "train", "our", "model", ".", "The", "mini", "-", "batch", "size", "was", "set", "to", "25", "for", "POS", "tagging", ",", "chunking", ",", "and", "the", "SICK", "tasks", ",", "and", "15", "for", "dependency", "parsing", ".", "We", "used", "a", "gradient", "clipping", "strategy", "with", "growing", "clipping", "values", "for", "the", "different", "tasks", ";", "concretely", ",", "we", "employed", "the", "simple", "function", ":", ",", "where", "is", "the", "number", "of", "bi", "-", "LSTM", "layers", "involved", "in", "each", "task", ",", "and", "is", "the", "maximum", "value", ".", "The", "learning", "rate", "at", "the", "-", "th", "epoch", "was", "set", "to", ",", "where", "is", "the", "initial", "learning", "rate", ",", "and", "is", "the", "hyperparameter", "to", "decrease", "the", "learning", "rate", ".", "We", "set", "to", "1.0", "and", "to", "0.3", ".", "At", "each", "epoch", ",", "the", "same", "learning", "rate", "was", "shared", "across", "all", "of", "the", "tasks", ".", "paragraph", ":", "Regularization", "We", "set", "the", "regularization", "coefficient", "to", "for", "the", "LSTM", "weight", "matrices", ",", "for", "the", "weight", "matrices", "in", "the", "classifiers", ",", "and", "for", "the", "successive", "regularization", "term", "excluding", "the", "classifier", "parameters", "of", "the", "lower", "-", "level", "tasks", ",", "respectively", ".", "The", "successive", "regularization", "coefficient", "for", "the", "classifier", "parameters", "was", "set", "to", ".", "We", "also", "used", "dropout", "dropout2014ver", ".", "The", "dropout", "rate", "was", "set", "to", "0.2", "for", "the", "vertical", "connections", "in", "the", "multi", "-", "layer", "bi", "-", "LSTMs", "pham2015dropout", ",", "the", "word", "representations", "and", "the", "label", "embeddings", "of", "the", "entailment", "layer", ",", "and", "the", "classifier", "of", "the", "POS", "tagging", ",", "chunking", ",", "dependency", "parsing", ",", "and", "entailment", ".", "A", "different", "dropout", "rate", "of", "0.4", "was", "used", "for", "the", "word", "representations", "and", "the", "label", "embeddings", "of", "the", "POS", ",", "chunking", ",", "and", "dependency", "layers", ",", "and", "the", "classifier", "of", "the", "relatedness", "layer", ".", "appendix", ":", "Details", "of", "Character", "-", "Gram", "Embeddings", "Here", "we", "first", "describe", "the", "pre", "-", "training", "process", "of", "the", "character", "-", "gram", "embeddings", "in", "detail", "and", "then", "show", "further", "analysis", "on", "the", "results", "in", "Table", "12", ".", "subsection", ":", "Pre", "-", "Training", "with", "Skip", "-", "Gram", "Objective", "We", "pre", "-", "train", "the", "character", "-", "gram", "embeddings", "using", "the", "objective", "function", "of", "the", "Skip", "-", "gram", "model", "with", "negative", "sampling", "mikolov2013word2vec", ".", "We", "build", "the", "vocabulary", "of", "the", "character", "-", "grams", "based", "on", "the", "training", "corpus", ",", "the", "case", "-", "sensitive", "English", "Wikipedia", "text", ".", "This", "is", "because", "such", "case", "-", "sensitive", "information", "is", "important", "in", "handling", "some", "types", "of", "words", "like", "named", "entities", ".", "Assuming", "that", "a", "word", "has", "its", "corresponding", "character", "-", "grams", ",", "where", "any", "overlaps", "and", "unknown", "ones", "are", "removed", ".", "Then", "the", "word", "is", "represented", "with", "an", "embedding", "computed", "as", "follows", ":", "where", "is", "the", "parameterized", "embedding", "of", "the", "character", "-", "gram", ",", "and", "the", "computation", "of", "is", "exactly", "the", "same", "as", "the", "one", "used", "in", "our", "JMT", "model", "explained", "in", "Section", "2.1", ".", "The", "remaining", "part", "of", "the", "pre", "-", "training", "process", "is", "the", "same", "as", "the", "original", "Skip", "-", "gram", "model", ".", "For", "each", "word", "-", "context", "pair", "in", "the", "training", "corpus", ",", "negative", "context", "words", "are", "sampled", ",", "and", "the", "objective", "function", "is", "defined", "as", "follows", ":", "where", "is", "the", "logistic", "sigmoid", "function", ",", "is", "the", "weight", "vector", "for", "the", "context", "word", ",", "and", "is", "a", "negative", "sample", ".", "It", "should", "be", "noted", "that", "the", "weight", "vectors", "for", "the", "context", "words", "are", "parameterized", "for", "the", "words", "without", "any", "character", "information", ".", "subsection", ":", "Effectiveness", "on", "Unknown", "Words", "One", "expectation", "from", "the", "use", "of", "the", "character", "-", "gram", "embeddings", "is", "to", "better", "handle", "unknown", "words", ".", "We", "verified", "this", "assumption", "in", "the", "single", "task", "setting", "for", "POS", "tagging", ",", "based", "on", "the", "results", "reported", "in", "Table", "12", ".", "Table", "[", "reference", "]", "shows", "that", "the", "joint", "use", "of", "the", "word", "and", "character", "-", "gram", "embeddings", "improves", "the", "score", "by", "about", "19", "%", "in", "terms", "of", "the", "accuracy", "for", "unknown", "words", ".", "We", "also", "show", "the", "results", "of", "the", "single", "task", "setting", "for", "dependency", "parsing", "in", "Table", "[", "reference", "]", ".", "Again", ",", "we", "can", "see", "that", "using", "the", "character", "-", "level", "information", "is", "effective", ",", "and", "in", "particular", ",", "the", "improvement", "of", "the", "LAS", "score", "is", "large", ".", "These", "results", "suggest", "that", "it", "is", "better", "to", "use", "not", "only", "the", "word", "embeddings", ",", "but", "also", "the", "character", "-", "gram", "embeddings", "by", "default", ".", "Recently", ",", "the", "joint", "use", "of", "word", "and", "character", "information", "has", "proven", "to", "be", "effective", "in", "language", "modeling", "miyamoto2016char", ",", "but", "just", "using", "the", "simple", "character", "-", "gram", "embeddings", "is", "fast", "and", "also", "effective", ".", "appendix", ":", "Analysis", "on", "Dependency", "Parsing", "Our", "dependency", "parser", "is", "based", "on", "the", "idea", "of", "predicting", "a", "head", "(", "or", "parent", ")", "for", "each", "word", ",", "and", "thus", "the", "parsing", "results", "do", "not", "always", "lead", "to", "correct", "trees", ".", "To", "inspect", "this", "aspect", ",", "we", "checked", "the", "parsing", "results", "on", "the", "development", "set", "(", "1", ",", "700", "sentences", ")", ",", "using", "the", "\u201c", "JMT", "\u201d", "setting", ".", "In", "the", "dependency", "annotations", "used", "in", "this", "work", ",", "each", "sentence", "has", "only", "one", "root", "node", ",", "and", "we", "have", "found", "11", "sentences", "with", "multiple", "root", "nodes", "and", "11", "sentences", "with", "no", "root", "nodes", "in", "our", "parsing", "results", ".", "We", "show", "two", "examples", "below", ":", "Underneath", "the", "headline", "\u201c", "Diversification", ",", "\u201d", "it", "counsels", ",", "\u201c", "Based", "on", "the", "events", "of", "the", "past", "week", ",", "all", "investors", "need", "to", "know", "their", "portfolios", "are", "balanced", "to", "help", "protect", "them", "against", "the", "market", "\u2019s", "volatility", ".", "\u201d", "Mr.", "Eskandarian", ",", "who", "resigned", "his", "Della", "Femina", "post", "in", "September", ",", "becomes", "chairman", "and", "chief", "executive", "of", "Arnold", ".", "In", "the", "example", "(", "a", ")", ",", "the", "two", "boldfaced", "words", "\u201c", "counsels", "\u201d", "and", "\u201c", "need", "\u201d", "are", "predicted", "as", "child", "nodes", "of", "the", "root", "node", ",", "and", "the", "underlined", "word", "\u201c", "counsels", "\u201d", "is", "the", "correct", "one", "based", "on", "the", "gold", "annotations", ".", "This", "example", "sentence", "(", "a", ")", "consists", "of", "multiple", "internal", "sentences", ",", "and", "our", "parser", "misunderstood", "that", "both", "of", "the", "two", "verbs", "are", "the", "heads", "of", "the", "sentence", ".", "In", "the", "example", "(", "b", ")", ",", "none", "of", "the", "words", "is", "connected", "to", "the", "root", "node", ",", "and", "the", "correct", "child", "node", "of", "the", "root", "is", "the", "underlined", "word", "\u201c", "chairman", "\u201d", ".", "Without", "the", "internal", "phrase", "\u201c", "who", "resigned", "\u2026", "in", "September", "\u201d", ",", "the", "example", "sentence", "(", "b", ")", "is", "very", "simple", ",", "but", "we", "have", "found", "that", "such", "a", "simplified", "sentence", "is", "still", "not", "parsed", "correctly", ".", "In", "many", "cases", ",", "verbs", "are", "linked", "to", "the", "root", "nodes", ",", "but", "sometimes", "other", "types", "of", "words", "like", "nouns", "can", "be", "the", "candidates", ".", "In", "our", "model", ",", "the", "single", "parameterized", "vector", "is", "used", "to", "represent", "the", "root", "node", "for", "each", "sentence", ".", "Therefore", ",", "the", "results", "of", "the", "examples", "(", "a", ")", "and", "(", "b", ")", "suggest", "that", "it", "would", "be", "needed", "to", "capture", "various", "types", "of", "root", "nodes", ",", "and", "using", "sentence", "-", "dependent", "root", "representations", "would", "lead", "to", "better", "results", "in", "future", "work", ".", "appendix", ":", "Analysis", "on", "Semantic", "Tasks", "We", "inspected", "the", "development", "set", "results", "on", "the", "semantic", "tasks", "using", "the", "\u201c", "JMT", "\u201d", "setting", ".", "In", "our", "model", ",", "the", "highest", "-", "level", "task", "is", "the", "textual", "entailment", "task", ".", "We", "show", "an", "example", "premise", "-", "hypothesis", "pair", "which", "is", "misclassified", "in", "our", "results", ":", "Premise", ":", "\u201c", "A", "surfer", "is", "riding", "a", "big", "wave", "across", "dark", "green", "water", "\u201d", ",", "and", "Hypothesis", ":", "\u201c", "The", "surfer", "is", "riding", "a", "small", "wave", "\u201d", ".", "The", "predicted", "label", "is", "entailment", ",", "but", "the", "gold", "label", "is", "contradiction", ".", "This", "example", "is", "very", "easy", "by", "focusing", "on", "the", "difference", "between", "the", "two", "words", "\u201c", "big", "\u201d", "and", "\u201c", "small", "\u201d", ".", "However", ",", "our", "model", "fails", "to", "correctly", "classify", "this", "example", "because", "there", "are", "few", "opportunities", "to", "learn", "the", "difference", ".", "Our", "model", "relies", "on", "the", "pre", "-", "trained", "word", "embeddings", "based", "on", "word", "co", "-", "occurrence", "statistics", "mikolov2013word2vec", ",", "and", "it", "is", "widely", "known", "that", "such", "co", "-", "occurrence", "-", "based", "embeddings", "can", "rarely", "discriminate", "between", "antonyms", "and", "synonyms", "ono2015ant", ".", "Moreover", ",", "the", "other", "four", "tasks", "in", "our", "JMT", "model", "do", "not", "explicitly", "provide", "the", "opportunities", "to", "learn", "such", "semantic", "aspects", ".", "Even", "in", "the", "training", "data", "of", "the", "textual", "entailment", "task", ",", "we", "can", "find", "only", "one", "example", "to", "learn", "the", "difference", "between", "the", "two", "words", ",", "which", "is", "not", "enough", "to", "obtain", "generalization", "capacities", ".", "Therefore", ",", "it", "is", "worth", "investigating", "the", "explicit", "use", "of", "external", "dictionaries", "or", "the", "use", "of", "pre", "-", "trained", "word", "embeddings", "learned", "with", "such", "dictionaries", "ono2015ant", ",", "to", "see", "whether", "our", "JMT", "model", "is", "further", "improved", "not", "only", "for", "the", "semantic", "tasks", ",", "but", "also", "for", "the", "low", "-", "level", "tasks", ".", "appendix", ":", "How", "Do", "Shared", "Embeddings", "Change", "In", "our", "JMT", "model", ",", "the", "word", "and", "character", "-", "gram", "embedding", "matrices", "are", "shared", "across", "all", "of", "the", "five", "different", "tasks", ".", "To", "better", "qualitatively", "explain", "the", "importance", "of", "the", "shortcut", "connections", "shown", "in", "Table", "7", ",", "we", "inspected", "how", "the", "shared", "embeddings", "change", "when", "fed", "into", "the", "different", "bi", "-", "LSTM", "layers", ".", "More", "concretely", ",", "we", "checked", "closest", "neighbors", "in", "terms", "of", "the", "cosine", "similarity", "for", "the", "word", "representations", "before", "and", "after", "fed", "into", "the", "forward", "LSTM", "layers", ".", "In", "particular", ",", "we", "used", "the", "corresponding", "part", "of", "in", "Eq", ".", "(", "1", ")", "to", "perform", "linear", "transformation", "of", "the", "input", "embeddings", ",", "because", "directly", "affects", "the", "hidden", "states", "of", "the", "LSTMs", ".", "Thus", ",", "this", "is", "a", "context", "-", "independent", "analysis", ".", "Table", "[", "reference", "]", "shows", "the", "examples", "of", "the", "word", "\u201c", "standing", "\u201d", ".", "The", "row", "of", "\u201c", "Embedding", "\u201d", "shows", "the", "cases", "of", "using", "the", "shared", "embeddings", ",", "and", "the", "others", "show", "the", "results", "of", "using", "the", "linear", "-", "transformed", "embeddings", ".", "In", "the", "column", "of", "\u201c", "Only", "word", "\u201d", ",", "the", "results", "of", "using", "only", "the", "word", "embeddings", "are", "shown", ".", "The", "closest", "neighbors", "in", "the", "case", "of", "\u201c", "Embedding", "\u201d", "capture", "the", "semantic", "similarity", ",", "but", "after", "fed", "into", "the", "POS", "layer", ",", "the", "semantic", "similarity", "is", "almost", "washed", "out", ".", "This", "is", "not", "surprising", "because", "it", "is", "sufficient", "to", "cluster", "the", "words", "of", "the", "same", "POS", "tags", ":", "here", ",", "NN", ",", "VBG", ",", "etc", ".", "In", "the", "chunking", "layer", ",", "the", "similarity", "in", "terms", "of", "verbs", "is", "captured", ",", "and", "this", "is", "because", "it", "is", "sufficient", "to", "identify", "the", "coarse", "chunking", "tags", ":", "here", ",", "VP", ".", "In", "the", "dependency", "layer", ",", "the", "closest", "neighbors", "are", "adverbs", ",", "gerunds", "of", "verbs", ",", "and", "nouns", ",", "and", "all", "of", "them", "can", "be", "child", "nodes", "of", "verbs", "in", "dependency", "trees", ".", "However", ",", "this", "information", "is", "not", "sufficient", "in", "further", "classifying", "the", "dependency", "labels", ".", "Then", "we", "can", "see", "that", "in", "the", "column", "of", "\u201c", "Word", "and", "char", "\u201d", ",", "jointly", "using", "the", "character", "-", "gram", "embeddings", "adds", "the", "morphological", "information", ",", "and", "as", "shown", "in", "Table", "12", ",", "the", "LAS", "score", "is", "substantially", "improved", ".", "In", "the", "case", "of", "semantic", "tasks", ",", "the", "projected", "embeddings", "capture", "not", "only", "syntactic", ",", "but", "also", "semantic", "similarities", ".", "These", "results", "show", "that", "different", "tasks", "need", "different", "aspects", "of", "the", "word", "similarities", ",", "and", "our", "JMT", "model", "efficiently", "transforms", "the", "shared", "embeddings", "for", "the", "different", "tasks", "by", "the", "simple", "linear", "transformation", ".", "Therefore", ",", "without", "the", "shortcut", "connections", ",", "the", "information", "about", "the", "word", "representations", "are", "fed", "into", "the", "semantic", "tasks", "after", "transformed", "in", "the", "lower", "layers", "where", "the", "semantic", "similarities", "are", "not", "always", "important", ".", "Indeed", ",", "the", "results", "of", "the", "semantic", "tasks", "are", "very", "poor", "without", "the", "shortcut", "connections", "."]}