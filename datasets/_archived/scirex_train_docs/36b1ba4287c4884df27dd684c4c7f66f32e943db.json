{"coref": {"FB15k-237": [[133, 134], [697, 700], [2439, 2440], [2466, 2469], [2507, 2510], [2704, 2707], [2806, 2809], [3161, 3164], [3470, 3473], [3699, 3702]], "Hits_1": [[2934, 2935], [2969, 2970], [3000, 3001], [3335, 3336]], "Hits_10": [[2929, 2930], [2969, 2970]], "Hits_3": [[2931, 2932], [2969, 2970]], "HypER": [[51, 53], [394, 395], [648, 649], [685, 686], [804, 805], [1126, 1127], [1177, 1178], [1199, 1200], [1432, 1433], [1499, 1501], [1965, 1967], [2135, 2136], [2357, 2358], [2379, 2380], [2397, 2398], [2565, 2566], [2649, 2651], [2770, 2771], [2904, 2905], [3068, 3069], [3140, 3141], [3188, 3189], [3272, 3274], [3316, 3317], [3339, 3340], [3349, 3350], [3375, 3376], [3383, 3384], [3417, 3418], [3445, 3447], [3465, 3466], [3475, 3477], [3510, 3512], [3551, 3552], [3794, 3795], [3797, 3799], [3806, 3807], [3826, 3828], [3849, 3850], [3955, 3956], [480, 481], [576, 577], [737, 738], [1096, 1097], [1659, 1660], [1683, 1684], [1972, 1973], [2103, 2104], [2295, 2296], [2414, 2415], [3432, 3433], [3908, 3909]], "Link_Prediction": [[23, 25], [114, 116], [233, 235], [255, 257], [633, 635], [839, 841], [853, 856], [940, 942], [1306, 1308], [1309, 1311], [1502, 1504], [2151, 2153], [2419, 2422], [2912, 2914], [3027, 3029], [3090, 3093], [3800, 3802], [1367, 1369]], "MRR": [[2658, 2661], [2922, 2925], [2953, 2956], [2996, 2999], [3150, 3153], [3695, 3698]], "WN18": [[131, 132], [705, 706], [2451, 2452], [2456, 2457], [2484, 2485], [2526, 2527], [3154, 3155], [3165, 3166], [2537, 2538]], "WN18RR": [[701, 702], [2521, 2522], [3159, 3160], [3261, 3262], [3343, 3344], [3468, 3469], [3632, 3633], [3724, 3725]], "_FB15k": [[133, 134], [703, 704], [2434, 2435], [2439, 2440], [2482, 2483], [2514, 2515], [2361, 2362], [3738, 3739]]}, "coref_non_salient": {"0": [[29, 34], [240, 246]], "1": [[186, 188], [189, 191]], "10": [[55, 58], [406, 408], [759, 760], [1612, 1614], [2303, 2305], [2402, 2404], [3129, 3131], [3497, 3499], [4000, 4002]], "11": [[896, 897], [929, 930], [2158, 2159], [3237, 3238]], "12": [[835, 838], [1287, 1289], [2148, 2150]], "13": [[522, 524], [3605, 3607], [3886, 3889]], "14": [[466, 471], [3458, 3460]], "15": [[1136, 1141], [3812, 3817]], "16": [[762, 765], [1016, 1019], [1522, 1525], [1741, 1744], [3483, 3486]], "17": [[3721, 3723]], "18": [[2176, 2180], [2262, 2266], [2322, 2326], [2828, 2832], [3248, 3252]], "19": [[335, 336], [369, 370], [663, 664], [802, 803], [959, 961], [980, 982], [1558, 1559], [1761, 1762], [3919, 3921], [3939, 3940]], "2": [[859, 861], [1423, 1425], [1670, 1672], [1676, 1681]], "20": [[311, 314], [2172, 2173], [2260, 2261]], "21": [[3983, 3987]], "22": [[594, 597], [1132, 1135], [1301, 1303], [1806, 1809], [1871, 1874], [1936, 1939], [2003, 2006]], "23": [[949, 952], [954, 957]], "24": [[1505, 1507], [3803, 3805]], "25": [[3641, 3642]], "26": [[1983, 1985], [3912, 3914]], "27": [[2662, 2663], [2919, 2920], [2926, 2927]], "28": [[2916, 2918], [2936, 2938], [2940, 2942], [3156, 3158], [3174, 3176], [3003, 3005]], "29": [[3945, 3946]], "3": [[1786, 1787], [3527, 3529]], "30": [[665, 667], [1607, 1609]], "31": [[1170, 1172]], "32": [[2546, 2547]], "33": [[3952, 3954]], "34": [[2182, 2184], [2796, 2798]], "35": [[2623, 2624]], "36": [[2630, 2632]], "37": [[2209, 2211], [2212, 2214], [3745, 3747], [4017, 4019]], "38": [[927, 928], [2160, 2161], [3239, 3240]], "39": [[1401, 1404], [1896, 1898]], "4": [[3643, 3645], [3821, 3824]], "40": [[401, 402], [413, 414], [484, 485], [1144, 1145], [1250, 1251], [1512, 1513], [1738, 1739], [3453, 3454], [3809, 3810]], "41": [[1041, 1042], [3218, 3219], [3241, 3242], [3377, 3378]], "42": [[1222, 1224]], "43": [[2222, 2223]], "44": [[1377, 1380]], "45": [[382, 387], [1560, 1564]], "46": [[1247, 1249], [1768, 1770]], "47": [[356, 358], [1566, 1568]], "48": [[3419, 3421]], "49": [[3096, 3098]], "5": [[490, 495], [580, 584], [1815, 1819], [1947, 1951], [3869, 3873]], "50": [[3947, 3949]], "51": [[2567, 2568]], "52": [[2633, 2634]], "53": [[1715, 1719]], "54": [[2084, 2091]], "55": [[1069, 1070]], "56": [[2187, 2192]], "57": [[379, 381]], "58": [[3202, 3204]], "59": [[2227, 2228]], "6": [[2719, 2721], [2736, 2738], [2739, 2742]], "60": [[196, 198]], "61": [[1455, 1457]], "62": [[319, 321], [372, 374]], "63": [[680, 682]], "64": [[1167, 1169]], "65": [[136, 139]], "66": [[884, 885]], "67": [[1865, 1867]], "68": [[2110, 2114]], "69": [[322, 329]], "7": [[3108, 3112], [3612, 3616]], "70": [[192, 194]], "71": [[265, 271]], "72": [[1854, 1857]], "73": [[2282, 2283]], "74": [[353, 355]], "75": [[707, 710], [2539, 2542], [3168, 3171]], "76": [[1778, 1782]], "77": [[690, 693], [1396, 1399], [3853, 3856]], "78": [[3566, 3568]], "79": [[3519, 3523], [3838, 3842]], "8": [[3679, 3681], [3707, 3709], [3713, 3715], [3761, 3763], [3778, 3780]], "80": [[643, 645], [811, 814], [1967, 1969], [3931, 3934]], "81": [[1515, 1517]], "82": [[849, 850], [2156, 2157]], "83": [[1587, 1589]], "84": [[2287, 2289]], "85": [[360, 361]], "86": [[1212, 1215]], "87": [[944, 948]], "88": [[1673, 1675]], "89": [[104, 107]], "9": [[262, 263], [655, 657], [1204, 1208]], "90": [[917, 919]], "91": [[2277, 2279]], "92": [[2, 6], [1487, 1491]], "93": [[674, 676]], "94": [[1710, 1711]]}, "doc_id": "36b1ba4287c4884df27dd684c4c7f66f32e943db", "method_subrelations": {"HypER": [[[0, 5], "HypER"]]}, "n_ary_relations": [{"Material": "_FB15k", "Method": "HypER", "Metric": "Hits_1", "Task": "Link_Prediction", "score": "0.734"}, {"Material": "_FB15k", "Method": "HypER", "Metric": "Hits_10", "Task": "Link_Prediction", "score": "0.885"}, {"Material": "_FB15k", "Method": "HypER", "Metric": "Hits_3", "Task": "Link_Prediction", "score": "0.829"}, {"Material": "_FB15k", "Method": "HypER", "Metric": "MRR", "Task": "Link_Prediction", "score": "0.790"}, {"Material": "FB15k-237", "Method": "HypER", "Metric": "Hits_1", "Task": "Link_Prediction", "score": "0.252"}, {"Material": "FB15k-237", "Method": "HypER", "Metric": "Hits_10", "Task": "Link_Prediction", "score": "0.520"}, {"Material": "FB15k-237", "Method": "HypER", "Metric": "Hits_3", "Task": "Link_Prediction", "score": "0.376"}, {"Material": "FB15k-237", "Method": "HypER", "Metric": "MRR", "Task": "Link_Prediction", "score": "0.341"}, {"Material": "WN18", "Method": "HypER", "Metric": "Hits_1", "Task": "Link_Prediction", "score": "0.947"}, {"Material": "WN18", "Method": "HypER", "Metric": "Hits_10", "Task": "Link_Prediction", "score": "0.958"}, {"Material": "WN18", "Method": "HypER", "Metric": "Hits_3", "Task": "Link_Prediction", "score": "0.955"}, {"Material": "WN18", "Method": "HypER", "Metric": "MRR", "Task": "Link_Prediction", "score": "0.951"}, {"Material": "WN18RR", "Method": "HypER", "Metric": "Hits_1", "Task": "Link_Prediction", "score": "0.436"}, {"Material": "WN18RR", "Method": "HypER", "Metric": "Hits_10", "Task": "Link_Prediction", "score": "0.522"}, {"Material": "WN18RR", "Method": "HypER", "Metric": "Hits_3", "Task": "Link_Prediction", "score": "0.477"}, {"Material": "WN18RR", "Method": "HypER", "Metric": "MRR", "Task": "Link_Prediction", "score": "0.465"}], "ner": [[2, 6, "Task"], [23, 25, "Task"], [29, 34, "Task"], [51, 53, "Method"], [55, 58, "Method"], [104, 107, "Method"], [114, 116, "Task"], [131, 132, "Material"], [133, 134, "Material"], [136, 139, "Material"], [186, 188, "Task"], [189, 191, "Task"], [192, 194, "Task"], [196, 198, "Task"], [233, 235, "Task"], [240, 246, "Task"], [255, 257, "Task"], [262, 263, "Method"], [265, 271, "Method"], [311, 314, "Method"], [319, 321, "Method"], [322, 329, "Method"], [335, 336, "Method"], [353, 355, "Method"], [356, 358, "Task"], [360, 361, "Task"], [369, 370, "Method"], [372, 374, "Method"], [379, 381, "Task"], [382, 387, "Task"], [394, 395, "Method"], [401, 402, "Method"], [406, 408, "Method"], [413, 414, "Method"], [466, 471, "Task"], [484, 485, "Method"], [490, 495, "Method"], [522, 524, "Method"], [580, 584, "Method"], [594, 597, "Method"], [633, 635, "Task"], [643, 645, "Method"], [648, 649, "Method"], [655, 657, "Method"], [663, 664, "Method"], [665, 667, "Method"], [674, 676, "Method"], [680, 682, "Method"], [685, 686, "Method"], [690, 693, "Method"], [697, 700, "Material"], [701, 702, "Material"], [703, 704, "Material"], [705, 706, "Material"], [707, 710, "Material"], [759, 760, "Method"], [762, 765, "Method"], [802, 803, "Method"], [804, 805, "Method"], [811, 814, "Method"], [835, 838, "Method"], [839, 841, "Task"], [849, 850, "Method"], [853, 856, "Task"], [859, 861, "Method"], [884, 885, "Method"], [896, 897, "Method"], [917, 919, "Method"], [927, 928, "Method"], [929, 930, "Method"], [940, 942, "Task"], [944, 948, "Method"], [949, 952, "Method"], [954, 957, "Method"], [959, 961, "Method"], [980, 982, "Method"], [1016, 1019, "Method"], [1041, 1042, "Method"], [1069, 1070, "Metric"], [1126, 1127, "Method"], [1132, 1135, "Method"], [1136, 1141, "Method"], [1144, 1145, "Method"], [1167, 1169, "Method"], [1170, 1172, "Method"], [1177, 1178, "Method"], [1199, 1200, "Method"], [1204, 1208, "Method"], [1212, 1215, "Method"], [1222, 1224, "Method"], [1247, 1249, "Method"], [1250, 1251, "Method"], [1287, 1289, "Method"], [1301, 1303, "Method"], [1306, 1308, "Task"], [1309, 1311, "Task"], [1377, 1380, "Method"], [1396, 1399, "Method"], [1401, 1404, "Method"], [1423, 1425, "Method"], [1432, 1433, "Method"], [1455, 1457, "Metric"], [1487, 1491, "Task"], [1499, 1501, "Method"], [1502, 1504, "Task"], [1505, 1507, "Task"], [1512, 1513, "Method"], [1515, 1517, "Method"], [1522, 1525, "Method"], [1558, 1559, "Method"], [1560, 1564, "Task"], [1566, 1568, "Task"], [1587, 1589, "Task"], [1607, 1609, "Method"], [1612, 1614, "Method"], [1670, 1672, "Method"], [1673, 1675, "Method"], [1676, 1681, "Method"], [1710, 1711, "Method"], [1715, 1719, "Method"], [1738, 1739, "Method"], [1741, 1744, "Method"], [1761, 1762, "Method"], [1768, 1770, "Method"], [1778, 1782, "Method"], [1786, 1787, "Metric"], [1806, 1809, "Method"], [1815, 1819, "Method"], [1854, 1857, "Method"], [1865, 1867, "Method"], [1871, 1874, "Method"], [1896, 1898, "Method"], [1936, 1939, "Method"], [1947, 1951, "Method"], [1965, 1967, "Method"], [1967, 1969, "Method"], [1983, 1985, "Method"], [2003, 2006, "Method"], [2084, 2091, "Method"], [2110, 2114, "Method"], [2135, 2136, "Method"], [2148, 2150, "Method"], [2151, 2153, "Task"], [2156, 2157, "Method"], [2158, 2159, "Method"], [2160, 2161, "Method"], [2172, 2173, "Method"], [2176, 2180, "Method"], [2182, 2184, "Method"], [2187, 2192, "Metric"], [2209, 2211, "Task"], [2212, 2214, "Task"], [2222, 2223, "Task"], [2227, 2228, "Task"], [2260, 2261, "Method"], [2262, 2266, "Method"], [2277, 2279, "Metric"], [2282, 2283, "Metric"], [2287, 2289, "Method"], [2303, 2305, "Method"], [2322, 2326, "Method"], [2357, 2358, "Method"], [2379, 2380, "Method"], [2397, 2398, "Method"], [2402, 2404, "Method"], [2419, 2422, "Task"], [2434, 2435, "Material"], [2439, 2440, "Material"], [2451, 2452, "Material"], [2456, 2457, "Material"], [2466, 2469, "Material"], [2482, 2483, "Material"], [2484, 2485, "Material"], [2507, 2510, "Material"], [2514, 2515, "Material"], [2521, 2522, "Material"], [2526, 2527, "Material"], [2539, 2542, "Material"], [2546, 2547, "Method"], [2565, 2566, "Method"], [2567, 2568, "Method"], [2623, 2624, "Task"], [2630, 2632, "Method"], [2633, 2634, "Method"], [2649, 2651, "Method"], [2658, 2661, "Metric"], [2662, 2663, "Metric"], [2704, 2707, "Material"], [2719, 2721, "Metric"], [2736, 2738, "Metric"], [2739, 2742, "Metric"], [2770, 2771, "Method"], [2796, 2798, "Method"], [2806, 2809, "Material"], [2828, 2832, "Method"], [2904, 2905, "Method"], [2912, 2914, "Task"], [2916, 2918, "Metric"], [2919, 2920, "Metric"], [2922, 2925, "Metric"], [2926, 2927, "Metric"], [2929, 2930, "Metric"], [2931, 2932, "Metric"], [2934, 2935, "Metric"], [2936, 2938, "Metric"], [2940, 2942, "Metric"], [2953, 2956, "Metric"], [2969, 2970, "Metric"], [2996, 2999, "Metric"], [3000, 3001, "Metric"], [3027, 3029, "Task"], [3068, 3069, "Method"], [3090, 3093, "Task"], [3096, 3098, "Method"], [3108, 3112, "Method"], [3129, 3131, "Method"], [3140, 3141, "Method"], [3150, 3153, "Metric"], [3154, 3155, "Material"], [3156, 3158, "Metric"], [3159, 3160, "Material"], [3161, 3164, "Material"], [3165, 3166, "Material"], [3174, 3176, "Metric"], [3188, 3189, "Method"], [3202, 3204, "Metric"], [3218, 3219, "Method"], [3237, 3238, "Method"], [3239, 3240, "Method"], [3241, 3242, "Method"], [3248, 3252, "Method"], [3261, 3262, "Material"], [3272, 3274, "Method"], [3316, 3317, "Method"], [3339, 3340, "Method"], [3343, 3344, "Material"], [3349, 3350, "Method"], [3375, 3376, "Method"], [3377, 3378, "Method"], [3383, 3384, "Method"], [3417, 3418, "Method"], [3419, 3421, "Method"], [3445, 3447, "Method"], [3453, 3454, "Method"], [3458, 3460, "Task"], [3465, 3466, "Method"], [3468, 3469, "Material"], [3470, 3473, "Material"], [3475, 3477, "Method"], [3483, 3486, "Method"], [3497, 3499, "Method"], [3510, 3512, "Method"], [3519, 3523, "Task"], [3527, 3529, "Metric"], [3551, 3552, "Method"], [3566, 3568, "Method"], [3605, 3607, "Method"], [3612, 3616, "Method"], [3632, 3633, "Material"], [3641, 3642, "Task"], [3643, 3645, "Task"], [3679, 3681, "Method"], [3695, 3698, "Metric"], [3699, 3702, "Material"], [3707, 3709, "Method"], [3713, 3715, "Method"], [3721, 3723, "Metric"], [3724, 3725, "Material"], [3745, 3747, "Task"], [3761, 3763, "Method"], [3778, 3780, "Method"], [3794, 3795, "Method"], [3797, 3799, "Method"], [3800, 3802, "Task"], [3803, 3805, "Task"], [3806, 3807, "Method"], [3809, 3810, "Method"], [3812, 3817, "Method"], [3821, 3824, "Task"], [3826, 3828, "Method"], [3838, 3842, "Task"], [3849, 3850, "Method"], [3853, 3856, "Method"], [3869, 3873, "Method"], [3886, 3889, "Method"], [3912, 3914, "Method"], [3919, 3921, "Method"], [3931, 3934, "Method"], [3939, 3940, "Method"], [3945, 3946, "Metric"], [3947, 3949, "Metric"], [3952, 3954, "Method"], [3955, 3956, "Method"], [3983, 3987, "Task"], [4000, 4002, "Method"], [4017, 4019, "Task"], [480, 481, "Method"], [576, 577, "Method"], [737, 738, "Method"], [1096, 1097, "Method"], [1367, 1369, "Task"], [1659, 1660, "Method"], [1683, 1684, "Method"], [1972, 1973, "Method"], [2103, 2104, "Method"], [2295, 2296, "Method"], [2361, 2362, "Material"], [2414, 2415, "Method"], [2537, 2538, "Material"], [3003, 3005, "Metric"], [3168, 3171, "Material"], [3335, 3336, "Metric"], [3432, 3433, "Method"], [3738, 3739, "Material"], [3908, 3909, "Method"]], "sections": [[0, 123], [123, 830], [830, 1304], [1304, 1485], [1485, 1668], [1668, 1962], [1962, 2162], [2162, 2340], [2340, 2405], [2405, 2408], [2408, 2559], [2559, 3024], [3024, 3785], [3785, 4036], [4036, 4039]], "sentences": [[0, 6], [6, 23], [23, 45], [45, 72], [72, 92], [92, 123], [123, 126], [126, 170], [170, 199], [199, 224], [224, 247], [247, 276], [276, 287], [287, 307], [307, 330], [330, 362], [362, 371], [371, 388], [388, 412], [412, 447], [447, 478], [478, 502], [502, 551], [551, 573], [573, 598], [598, 622], [622, 658], [658, 683], [683, 726], [726, 830], [830, 834], [834, 845], [845, 884], [884, 896], [896, 927], [927, 935], [935, 954], [954, 968], [968, 1006], [1006, 1039], [1039, 1073], [1073, 1094], [1094, 1124], [1124, 1146], [1146, 1175], [1175, 1187], [1187, 1235], [1235, 1272], [1272, 1304], [1304, 1308], [1308, 1339], [1339, 1367], [1367, 1393], [1393, 1422], [1422, 1458], [1458, 1462], [1462, 1485], [1485, 1491], [1491, 1508], [1508, 1545], [1545, 1554], [1554, 1583], [1583, 1610], [1610, 1644], [1644, 1656], [1656, 1668], [1668, 1675], [1675, 1713], [1713, 1737], [1737, 1771], [1771, 1783], [1783, 1805], [1805, 1833], [1833, 1851], [1851, 1895], [1895, 1919], [1919, 1962], [1962, 1969], [1969, 1997], [1997, 2032], [2032, 2054], [2054, 2070], [2070, 2100], [2100, 2132], [2132, 2162], [2162, 2166], [2166, 2212], [2212, 2224], [2224, 2227], [2227, 2257], [2257, 2290], [2290, 2313], [2313, 2340], [2340, 2345], [2345, 2371], [2371, 2397], [2397, 2405], [2405, 2408], [2408, 2411], [2411, 2432], [2432, 2434], [2434, 2451], [2451, 2466], [2466, 2507], [2507, 2521], [2521, 2539], [2539, 2559], [2559, 2563], [2563, 2575], [2575, 2577], [2577, 2596], [2596, 2621], [2621, 2646], [2646, 2669], [2669, 2716], [2716, 2748], [2748, 2790], [2790, 2803], [2803, 2833], [2833, 2847], [2847, 2876], [2876, 2902], [2902, 2936], [2936, 2953], [2953, 2969], [2969, 2988], [2988, 3006], [3006, 3024], [3024, 3027], [3027, 3053], [3053, 3138], [3138, 3172], [3172, 3206], [3206, 3268], [3268, 3296], [3296, 3314], [3314, 3330], [3330, 3345], [3345, 3366], [3366, 3423], [3423, 3445], [3445, 3447], [3447, 3500], [3500, 3527], [3527, 3553], [3553, 3596], [3596, 3617], [3617, 3634], [3634, 3679], [3679, 3726], [3726, 3754], [3754, 3785], [3785, 3788], [3788, 3806], [3806, 3825], [3825, 3845], [3845, 3878], [3878, 3904], [3904, 3905], [3905, 3935], [3935, 3955], [3955, 3988], [3988, 4010], [4010, 4036], [4036, 4039]], "words": ["document", ":", "Hypernetwork", "Knowledge", "Graph", "Embeddings", "Knowledge", "graphs", "are", "large", "graph", "-", "structured", "databases", "of", "facts", ",", "which", "typically", "suffer", "from", "incompleteness", ".", "Link", "prediction", "is", "the", "task", "of", "inferring", "missing", "relations", "(", "links", ")", "between", "entities", "(", "nodes", ")", "in", "a", "knowledge", "graph", ".", "We", "approach", "this", "task", "using", "a", "hypernetwork", "architecture", "to", "generate", "convolutional", "layer", "filters", "specific", "to", "each", "relation", "and", "apply", "those", "filters", "to", "the", "subject", "entity", "embeddings", ".", "This", "architecture", "enables", "a", "trade", "-", "off", "between", "non", "-", "linear", "expressiveness", "and", "the", "number", "of", "parameters", "to", "learn", ".", "Our", "model", "simplifies", "the", "entity", "and", "relation", "embedding", "interactions", "introduced", "by", "the", "predecessor", "convolutional", "model", ",", "while", "outperforming", "all", "previous", "approaches", "to", "link", "prediction", "across", "all", "standard", "link", "prediction", "datasets", ".", "section", ":", "Introduction", "Knowledge", "graphs", ",", "such", "as", "WordNet", ",", "Freebase", ",", "and", "Google", "Knowledge", "Graph", ",", "are", "large", "graph", "-", "structured", "databases", "of", "facts", ",", "containing", "information", "in", "the", "form", "of", "triples", ",", "where", "and", "represent", "subject", "and", "object", "entities", "and", "a", "relationship", "between", "them", ".", "They", "are", "considered", "important", "information", "resources", ",", "used", "for", "a", "wide", "variety", "of", "tasks", "ranging", "from", "question", "answering", "to", "information", "retrieval", ",", "coreference", "resolution", ",", "and", "text", "summarization", ".", "One", "of", "the", "main", "challenges", "with", "existing", "knowledge", "graphs", "is", "their", "incompleteness", ":", "many", "of", "the", "links", "between", "entities", "in", "the", "graph", "are", "missing", ".", "This", "has", "inspired", "substantial", "work", "in", "the", "field", "of", "link", "prediction", ",", "i.e.", "the", "task", "of", "inferring", "missing", "links", "in", "knowledge", "graphs", ".", "Until", "recently", ",", "the", "majority", "of", "approaches", "to", "link", "prediction", "have", "been", "based", "on", "different", "factorizations", "of", "a", "3", "-", "moded", "binary", "tensor", "representation", "of", "the", "training", "triples", ".", "Such", "approaches", "are", "shallow", "and", "linear", ",", "with", "limited", "expressiveness", ".", "However", ",", "attempts", "to", "increase", "expressiveness", "with", "additional", "fully", "connected", "layers", "and", "non", "-", "linearities", "often", "lead", "to", "overfitting", ".", "For", "this", "reason", ",", "dettmers2017convolutional", "introduce", "ConvE", ",", "a", "model", "that", "uses", "2D", "convolutions", "over", "reshaped", "and", "concatenated", "entity", "and", "relation", "embeddings", ".", "They", "motivate", "the", "use", "of", "convolutions", "by", "being", "parameter", "efficient", "and", "fast", "to", "compute", "on", "a", "GPU", ",", "as", "well", "as", "having", "various", "robust", "methods", "from", "computer", "vision", "to", "prevent", "overfitting", ".", "However", ",", "it", "is", "highly", "unintuitive", "that", "convolution", "\u2013", "particularly", "2D", "convolution", "\u2013", "should", "be", "effective", "for", "extracting", "information", "from", "1D", "entity", "and", "relation", "embeddings", ".", "In", "this", "paper", ",", "we", "introduce", "HypER", ",", "a", "model", "that", "uses", "a", "hypernetwork", "to", "generate", "weights", "of", "convolutional", "filters", "for", "each", "relation", ".", "A", "hypernetwork", "is", "an", "approach", "by", "which", "one", "network", "generates", "weights", "for", "another", "network", ",", "that", "can", "be", "used", "to", "enable", "weight", "-", "sharing", "across", "layers", "and", "to", "dynamically", "synthesize", "weights", "given", "an", "input", ".", "In", "our", "context", ",", "we", "generate", "relation", "-", "specific", "filter", "weights", "to", "process", "input", "entities", ",", "and", "also", "achieve", "multi", "-", "task", "knowledge", "sharing", "across", "relations", "in", "the", "knowledge", "graph", ".", "Our", "proposed", "HypER", "model", "uses", "a", "hypernetwork", "to", "generate", "a", "set", "of", "1D", "relation", "-", "specific", "filters", "to", "process", "the", "subject", "entity", "embeddings", ".", "This", "simplifies", "the", "interaction", "between", "subject", "entity", "and", "relation", "embeddings", "compared", "to", "ConvE", ",", "in", "which", "a", "global", "set", "of", "2D", "filters", "are", "convolved", "over", "reshaped", "and", "concatenated", "subject", "entity", "and", "relation", "embeddings", ",", "which", "is", "unintuitive", "as", "it", "suggests", "the", "presence", "of", "2D", "structure", "in", "word", "embeddings", ".", "Moreover", ",", "interaction", "between", "subject", "and", "relation", "in", "ConvE", "depends", "on", "an", "arbitrary", "choice", "about", "how", "they", "are", "reshaped", "and", "concatenated", ".", "In", "contrast", ",", "HypER", "\u2019s", "hypernetwork", "generates", "relation", "-", "specific", "filters", ",", "and", "thus", "extracts", "relation", "-", "specific", "features", "from", "the", "subject", "entity", "embedding", ".", "This", "necessitates", "no", "2D", "reshaping", ",", "and", "allows", "entity", "and", "relation", "to", "interact", "more", "completely", ",", "rather", "than", "only", "around", "the", "concatenation", "boundary", ".", "We", "show", "that", "this", "simplified", "approach", ",", "in", "addition", "to", "improving", "link", "prediction", "performance", ",", "can", "be", "understood", "in", "terms", "of", "tensor", "factorization", ",", "thus", "placing", "HypER", "within", "a", "well", "established", "family", "of", "factorization", "models", ".", "The", "apparent", "obscurity", "of", "using", "convolution", "within", "word", "embeddings", "is", "thereby", "explained", "as", "simply", "a", "convenient", "computational", "means", "of", "introducing", "sparsity", "and", "parameter", "tying", ".", "We", "evaluate", "HypER", "against", "several", "previously", "proposed", "link", "prediction", "models", "using", "standard", "datasets", "(", "FB15k", "-", "237", ",", "WN18RR", ",", "FB15k", ",", "WN18", ",", "YAGO3", "-", "10", ")", ",", "across", "which", "it", "consistently", "achieves", "state", "-", "of", "-", "the", "-", "art", "performance", ".", "In", "summary", ",", "our", "key", "contributions", "are", ":", "proposing", "a", "new", "HypER", "model", "which", "provides", "a", "good", "combination", "of", "expressiveness", "and", "relatively", "few", "parameters", "to", "learn", ";", "showing", "that", "the", "benefit", "of", "using", "convolutional", "instead", "of", "fully", "connected", "layers", "is", "due", "to", "restricting", "the", "number", "of", "dimensions", "that", "interact", "(", "i.e.", "explicit", "regularization", ")", ",", "rather", "than", "higher", "dimensional", "structure", "in", "the", "embeddings", "(", "as", "implied", "by", "ConvE", ")", ";", "showing", "that", "despite", "the", "use", "of", "convolution", ",", "HypER", "falls", "within", "a", "broad", "class", "of", "tensor", "factorization", "models", ";", "and", "demonstrating", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "five", "contemporary", "datasets", ".", "section", ":", "Related", "Work", "Numerous", "matrix", "factorization", "approaches", "to", "link", "prediction", "have", "been", "proposed", ".", "An", "early", "model", ",", "RESCAL", ",", "tackles", "the", "link", "prediction", "task", "by", "optimizing", "a", "scoring", "function", "containing", "a", "bilinear", "product", "between", "vectors", "for", "each", "of", "the", "subject", "and", "object", "entities", "and", "a", "full", "rank", "matrix", "for", "each", "relation", ".", "TransE", "represents", "a", "relation", "as", "a", "translation", "operation", "between", "entity", "vectors", ".", "DistMult", "can", "be", "viewed", "as", "a", "special", "case", "of", "RESCAL", "with", "a", "diagonal", "matrix", "per", "relation", "type", ",", "which", "limits", "the", "linear", "transformation", "performed", "on", "entity", "vectors", "to", "a", "stretch", ".", "ComplEx", "extends", "DistMult", "to", "the", "complex", "domain", ".", "A", "somewhat", "separate", "line", "of", "link", "prediction", "research", "introduces", "Relational", "Graph", "Convolutional", "Networks", "(", "R", "-", "GCNs", ")", ".", "R", "-", "GCNs", "use", "a", "convolution", "operator", "to", "capture", "locality", "information", "in", "graphs", ".", "The", "model", "closest", "to", "our", "own", ",", "is", "ConvE", ",", "where", "a", "convolution", "operation", "is", "performed", "on", "the", "subject", "entity", "vector", "and", "the", "relation", "vector", ",", "after", "they", "are", "each", "reshaped", "to", "a", "matrix", "and", "lengthwise", "concatenated", ".", "The", "obtained", "feature", "maps", "are", "flattened", ",", "put", "through", "a", "fully", "connected", "layer", ",", "and", "the", "inner", "product", "is", "taken", "with", "all", "object", "entity", "vectors", "to", "generate", "a", "score", "for", "each", "triple", ".", "Advantages", "of", "ConvE", "over", "previous", "approaches", "include", "its", "expressiveness", ",", "achieved", "by", "using", "multiple", "layers", "of", "non", "-", "linear", "features", ",", "its", "scalability", "to", "large", "knowledge", "graphs", ",", "and", "its", "robustness", "to", "overfitting", ".", "However", ",", "it", "is", "not", "intuitive", "why", "convolving", "across", "concatenated", "and", "reshaped", "subject", "entity", "and", "relation", "vectors", "should", "be", "effective", ".", "The", "proposed", "HypER", "model", "does", "no", "such", "reshaping", "or", "concatenation", "and", "thus", "avoids", "both", "implying", "any", "inherent", "2D", "structure", "in", "the", "embeddings", "and", "restricting", "interaction", "to", "the", "concatenation", "boundary", ".", "Instead", ",", "HypER", "convolves", "every", "dimension", "of", "the", "subject", "entity", "embedding", "with", "relation", "-", "specific", "convolutional", "filters", "generated", "by", "the", "hypernetwork", ".", "This", "way", ",", "entity", "and", "relation", "embeddings", "are", "combined", "in", "a", "non", "-", "linear", "(", "quadratic", ")", "manner", ",", "unlike", "the", "linear", "combination", "(", "weighted", "sum", ")", "in", "ConvE.", "This", "gives", "HypER", "more", "expressive", "power", ",", "while", "also", "reducing", "parameters", ".", "Interestingly", ",", "we", "find", "that", "the", "differences", "in", "moving", "from", "ConvE", "to", "HypER", "in", "fact", "bring", "the", "factorization", "and", "convolutional", "approaches", "together", ",", "since", "the", "1D", "convolution", "process", "is", "equivalent", "to", "multiplication", "by", "a", "highly", "sparse", "tensor", "with", "tied", "weights", "(", "see", "Figure", "[", "reference", "]", ")", ".", "The", "multiplication", "of", "this", "\u201c", "convolutional", "tensor", "\u201d", "(", "defined", "by", "the", "relation", "embedding", "and", "hypernetwork", ")", "and", "other", "weights", "gives", "an", "implicit", "relation", "matrix", ",", "corresponding", "to", "those", "in", "e.g.", "RESCAL", ",", "DistMult", "and", "ComplEx", ".", "Other", "than", "the", "method", "of", "deriving", "these", "relation", "matrices", ",", "the", "key", "difference", "to", "existing", "factorization", "approaches", "is", "the", "ReLU", "non", "-", "linearity", "applied", "prior", "to", "interaction", "with", "the", "object", "embedding", ".", "section", ":", "Link", "Prediction", "In", "link", "prediction", ",", "the", "aim", "is", "to", "learn", "a", "scoring", "function", "that", "assigns", "a", "score", "to", "each", "input", "triple", ",", "where", "are", "subject", "and", "object", "entities", "and", "a", "relation", ".", "The", "score", "indicates", "the", "strength", "of", "prediction", "that", "the", "given", "triple", "corresponds", "to", "a", "true", "fact", ",", "with", "positive", "scores", "meaning", "true", "and", "negative", "scores", ",", "false", ".", "Link", "prediction", "models", "typically", "map", "entity", "pair", "to", "their", "corresponding", "distributed", "embedding", "representations", "and", "a", "score", "is", "assigned", "using", "a", "relation", "-", "specific", "function", ",", ".", "The", "majority", "of", "link", "prediction", "models", "apply", "the", "logistic", "sigmoid", "function", "to", "the", "score", "to", "give", "a", "probabilistically", "interpretable", "prediction", "as", "to", "whether", "the", "queried", "fact", "is", "true", ".", "The", "scoring", "functions", "for", "models", "from", "across", "the", "literature", "and", "HypER", "are", "summarized", "in", "Table", "[", "reference", "]", ",", "together", "with", "the", "dimensionality", "of", "their", "relation", "parameters", "and", "the", "significant", "terms", "of", "their", "space", "complexity", ".", "FC", ".", ".", ".", "0.3", "0.1", "0.3", "0.2", "0.5", "0.9", "0.1", "0.2", "0.8", "0.4", "FC", "and", "reshape", "Convolve", "f", "explicitly", "learned", "parameters", "induced", "filter", "weights", "zero", "weights", "section", ":", "Hypernetwork", "Knowledge", "Graph", "Embeddings", "In", "this", "work", ",", "we", "propose", "a", "novel", "hypernetwork", "model", "for", "link", "prediction", "in", "knowledge", "graphs", ".", "In", "summary", ",", "the", "hypernetwork", "projects", "a", "vector", "embedding", "of", "each", "relation", "via", "a", "fully", "connected", "layer", ",", "the", "result", "of", "which", "is", "reshaped", "to", "give", "a", "set", "of", "convolutional", "filter", "weight", "vectors", "for", "each", "relation", ".", "We", "explain", "this", "process", "in", "more", "detail", "below", ".", "The", "idea", "of", "using", "convolutions", "on", "entity", "and", "relation", "embeddings", "stems", "from", "computer", "vision", ",", "where", "feature", "maps", "reflect", "patterns", "in", "the", "image", "such", "as", "lines", "or", "edges", ".", "Their", "role", "in", "the", "text", "domain", "is", "harder", "to", "interpret", ",", "since", "little", "is", "known", "of", "the", "meaning", "of", "a", "single", "dimension", "in", "a", "word", "embedding", ".", "We", "believe", "convolutional", "filters", "have", "a", "regularizing", "effect", "when", "applied", "to", "word", "embeddings", "(", "compared", "to", "the", "corresponding", "full", "tensor", ")", ",", "as", "the", "filter", "size", "restricts", "which", "dimensions", "of", "embeddings", "can", "interact", ".", "This", "allows", "nonlinear", "expressiveness", "while", "limiting", "overfitting", "by", "using", "few", "parameters", ".", "A", "visualization", "of", "HypER", "is", "given", "in", "Figure", "[", "reference", "]", ".", "subsection", ":", "Scoring", "Function", "and", "Model", "Architecture", "The", "relation", "-", "specific", "scoring", "function", "for", "the", "HypER", "model", "is", ":", "where", "the", "operator", "reshapes", "a", "vector", "to", "a", "matrix", ",", "and", "non", "-", "linearity", "is", "chosen", "to", "be", "a", "rectified", "linear", "unit", "(", "ReLU", ")", ".", "In", "the", "feed", "-", "forward", "pass", ",", "the", "model", "obtains", "embeddings", "for", "the", "input", "triple", "from", "the", "entity", "and", "relation", "embedding", "matrices", "and", ".", "The", "hypernetwork", "is", "a", "fully", "connected", "layer", "(", "denotes", "filter", "length", "and", "the", "number", "of", "filters", "per", "relation", ",", "i.e.", "output", "channels", "of", "the", "convolution", ")", "that", "is", "applied", "to", "the", "relation", "embedding", ".", "The", "result", "is", "reshaped", "to", "generate", "a", "matrix", "of", "convolutional", "filters", ".", "Whilst", "the", "overall", "dimensionality", "of", "the", "filter", "set", "is", ",", "the", "rank", "is", "restricted", "to", "to", "encourage", "parameter", "sharing", "between", "relations", ".", "The", "subject", "entity", "embedding", "is", "convolved", "with", "the", "set", "of", "relation", "-", "specific", "filters", "to", "give", "a", "2D", "feature", "map", ",", "where", "is", "the", "feature", "map", "length", ".", "The", "feature", "map", "is", "vectorized", "to", ",", "and", "projected", "to", "-", "dimensional", "space", "by", "the", "weight", "matrix", ".", "After", "applying", "a", "ReLU", "activation", "function", ",", "the", "result", "is", "combined", "by", "way", "of", "inner", "product", "with", "each", "and", "every", "object", "entity", "embedding", ",", "where", "varies", "over", "all", "entities", "in", "the", "dataset", "(", "of", "size", ")", ",", "to", "give", "a", "vector", "of", "scores", ".", "The", "logistic", "sigmoid", "is", "applied", "element", "-", "wise", "to", "the", "score", "vector", "to", "obtain", "the", "predicted", "probability", "of", "each", "prospective", "triple", "being", "true", ".", "For", "high", "level", "intuition", ",", "Figure", "[", "reference", "]", "shows", "a", "t", "-", "SNE", "plot", "of", "a", "subject", "entity", "embedding", "before", "and", "after", "it", "has", "been", "transformed", "by", "relation", "-", "specific", "filters", ",", "i.e.", "prior", "to", "combining", "it", "with", "the", "object", "embeddings", ".", "subsection", ":", "Understanding", "HypER", "as", "Tensor", "Factorization", "Having", "described", "the", "HypER", "architecture", ",", "we", "can", "view", "it", "as", "a", "series", "of", "tensor", "operations", "by", "considering", "the", "hypernetwork", "and", "weight", "matrix", "as", "tensors", "and", "respectively", ".", "The", "act", "of", "convolving", "over", "the", "subject", "entity", "embedding", "is", "equivalent", "to", "the", "multiplication", "of", "by", "a", "sparse", "tensor", "within", "which", "is", "diagonally", "duplicated", "with", "zeros", "elsewhere", "(", "see", "Figure", "[", "reference", "]", ")", ".", "The", "result", "is", "multiplied", "by", "to", "give", "a", "vector", ",", "which", "is", "subject", "to", "ReLU", "before", "the", "final", "dot", "product", "with", ".", "Linearity", "allows", "the", "product", "to", "be", "considered", "separately", "as", "generating", "a", "matrix", "for", "each", "relation", ".", "Further", ",", "rather", "than", "duplicating", "entries", "of", "within", ",", "we", "can", "generalize", "to", "a", "relation", "-", "agnostic", "sparse", "4", "moded", "tensor", "by", "replacing", "entries", "with", "-", "dimensional", "strands", "of", ".", "Thus", ",", "the", "HypER", "model", "can", "be", "described", "explicitly", "as", "tensor", "multiplication", "of", "and", "with", "a", "core", "tensor", ",", "where", "is", "heavily", "constrained", "in", "terms", "of", "its", "number", "of", "free", "variables", ".", "This", "insight", "allows", "HypER", "to", "be", "viewed", "in", "a", "very", "similar", "light", "to", "the", "family", "of", "factorization", "approaches", "to", "link", "prediction", ",", "such", "as", "RESCAL", ",", "DistMult", "and", "ComplEx", ".", "subsection", ":", "Training", "Procedure", "Following", "the", "training", "procedure", "introduced", "by", "dettmers2017convolutional", ",", "we", "use", "1", "-", "N", "scoring", "with", "the", "Adam", "optimizer", "to", "minimize", "the", "binary", "cross", "-", "entropy", "loss", ":", "where", "is", "the", "label", "vector", "containing", "ones", "for", "true", "triples", "and", "zeros", "otherwise", ",", "subject", "to", "label", "smoothing", ".", "Label", "smoothing", "is", "a", "widely", "used", "technique", "shown", "to", "improve", "generalization", ".", "1", "-", "N", "scoring", "refers", "to", "simultaneously", "scoring", ",", "i.e.", "for", "all", "entities", ",", "in", "contrast", "to", "1", "-", "1", "scoring", ",", "the", "practice", "of", "training", "individual", "triples", "one", "at", "a", "time", ".", "As", "shown", "by", "dettmers2017convolutional", ",", "1", "-", "N", "scoring", "offers", "a", "significant", "speedup", "(", "3x", "on", "train", "and", "300x", "on", "test", "time", ")", "and", "improved", "accuracy", "compared", "to", "1", "-", "1", "scoring", ".", "A", "potential", "extension", "of", "the", "HypER", "model", "described", "above", "would", "be", "to", "apply", "convolutional", "filters", "to", "both", "subject", "and", "object", "entity", "embeddings", ".", "However", ",", "since", "this", "is", "not", "trivially", "implementable", "with", "1", "-", "N", "scoring", "and", "wanting", "to", "keep", "its", "benefits", ",", "we", "leave", "this", "to", "future", "work", ".", "subsection", ":", "Number", "of", "Parameters", "Table", "[", "reference", "]", "compares", "the", "number", "of", "parameters", "of", "ConvE", "and", "HypER", "(", "for", "the", "FB15k", "-", "237", "dataset", ",", "which", "determines", "an", ")", ".", "It", "can", "be", "seen", "that", ",", "overall", ",", "HypER", "has", "fewer", "parameters", "(", "4.3", "M", ")", "than", "ConvE", "(", "5.1", "M", ")", "due", "to", "the", "way", "HypER", "directly", "transforms", "relations", "to", "convolutional", "filters", ".", "section", ":", "Experiments", "subsection", ":", "Datasets", "We", "evaluate", "our", "HypER", "model", "on", "the", "standard", "link", "prediction", "task", "using", "the", "following", "datasets", "(", "see", "Table", "[", "reference", "]", ")", ":", "FB15k", "is", "a", "subset", "of", "Freebase", ",", "a", "large", "database", "of", "facts", "about", "the", "real", "world", ".", "WN18", "is", "a", "subset", "of", "Wordnet", ",", "a", "database", "containing", "lexical", "relations", "between", "words", ".", "FB15k", "-", "237", "was", "created", "by", "toutanova2015representing", ",", "noting", "that", "the", "validation", "and", "test", "sets", "of", "FB15k", "and", "WN18", "contain", "the", "inverse", "of", "many", "relations", "present", "in", "the", "training", "set", ",", "making", "it", "easy", "for", "simple", "models", "to", "do", "well", ".", "FB15k", "-", "237", "is", "a", "subset", "of", "FB15k", "with", "the", "inverse", "relations", "removed", ".", "WN18RR", "is", "a", "subset", "of", "WN18", ",", "created", "by", "dettmers2017convolutional", "by", "removing", "the", "inverse", "relations", "from", "WN18", ".", "YAGO3", "-", "10", "is", "a", "subset", "of", "YAGO3", ",", "containing", "entities", "which", "have", "a", "minimum", "of", "10", "relations", "each", ".", "subsection", ":", "Experimental", "Setup", "We", "implement", "HypER", "in", "PyTorch", "and", "make", "our", "code", "publicly", "available", ".", "Implementation", "Details", "We", "train", "our", "model", "with", "200", "dimension", "entity", "and", "relation", "embeddings", "(", ")", "and", "1", "-", "N", "scoring", ".", "Whilst", "the", "relation", "embedding", "dimension", "does", "not", "have", "to", "equal", "the", "entity", "embedding", "dimension", ",", "we", "set", "to", "match", "ConvE", "for", "fairness", "of", "comparison", ".", "To", "accelerate", "training", "and", "prevent", "overfitting", ",", "we", "use", "batch", "normalization", "and", "dropout", "on", "the", "input", "embeddings", ",", "feature", "maps", "and", "the", "hidden", "layer", ".", "We", "perform", "a", "hyperparameter", "search", "and", "select", "the", "best", "performing", "model", "by", "mean", "reciprocal", "rank", "(", "MRR", ")", "on", "the", "validation", "set", ".", "Having", "tested", "the", "values", ",", "we", "find", "that", "the", "following", "combination", "of", "parameters", "works", "well", "across", "all", "datasets", ":", "input", "dropout", "0.2", ",", "feature", "map", "dropout", "0.2", ",", "and", "hidden", "dropout", "0.3", ",", "apart", "from", "FB15k", "-", "237", ",", "where", "we", "set", "input", "dropout", "to", "0.3", ".", "We", "select", "the", "learning", "rate", "from", "and", "exponential", "learning", "rate", "decay", "from", "for", "each", "dataset", "and", "find", "the", "best", "performing", "learning", "rate", "and", "learning", "rate", "decay", "to", "be", "dataset", "-", "specific", ".", "We", "set", "the", "convolution", "stride", "to", "1", ",", "number", "of", "feature", "maps", "to", "32", "with", "the", "filter", "size", "for", "ConvE", "and", "for", "HypER", ",", "after", "testing", "different", "numbers", "of", "feature", "maps", "and", "filter", "sizes", "(", "see", "Table", "[", "reference", "]", ")", ".", "We", "train", "all", "models", "using", "the", "Adam", "optimizer", "with", "batch", "size", "128", ".", "One", "epoch", "on", "FB15k", "-", "237", "takes", "approximately", "12", "seconds", "on", "a", "single", "GPU", "compared", "to", "1", "minute", "for", "e.g.", "RESCAL", ",", "largely", "due", "to", "1", "-", "N", "scoring", ".", "Evaluation", "Results", "are", "obtained", "by", "iterating", "over", "all", "triples", "in", "the", "test", "set", ".", "A", "particular", "triple", "is", "evaluated", "by", "replacing", "the", "object", "entity", "with", "all", "entities", "while", "keeping", "the", "subject", "entity", "fixed", "and", "vice", "versa", ",", "obtaining", "scores", "for", "each", "combination", ".", "These", "scores", "are", "then", "ranked", "using", "the", "\u201c", "filtered", "\u201d", "setting", "only", ",", "i.e.", "we", "remove", "all", "true", "cases", "other", "than", "the", "current", "test", "triple", ".", "We", "evaluate", "HypER", "on", "five", "different", "metrics", "found", "throughout", "the", "link", "prediction", "literature", ":", "mean", "rank", "(", "MR", ")", ",", "mean", "reciprocal", "rank", "(", "MRR", ")", ",", "hits@10", ",", "hits@3", ",", "and", "hits@1", ".", "Mean", "rank", "is", "the", "average", "rank", "assigned", "to", "the", "true", "triple", ",", "over", "all", "test", "triples", ".", "Mean", "reciprocal", "rank", "takes", "the", "average", "of", "the", "reciprocal", "rank", "assigned", "to", "the", "true", "triple", ".", "Hits@k", "measures", "the", "percentage", "of", "cases", "in", "which", "the", "true", "triple", "appears", "in", "the", "top", "k", "ranked", "triples", ".", "Overall", ",", "the", "aim", "is", "to", "achieve", "high", "mean", "reciprocal", "rank", "and", "hits@k", "and", "low", "mean", "rank", ".", "For", "a", "more", "extensive", "description", "of", "how", "each", "of", "these", "metrics", "is", "calculated", ",", "we", "refer", "to", ".", "subsection", ":", "Results", "Link", "prediction", "results", "for", "all", "models", "across", "the", "five", "datasets", "are", "shown", "in", "Tables", "[", "reference", "]", ",", "[", "reference", "]", "and", "[", "reference", "]", ".", "Our", "key", "findings", "are", ":", "whilst", "having", "fewer", "parameters", "than", "the", "closest", "comparator", "ConvE", ",", "HypER", "consistently", "outperforms", "all", "other", "models", "across", "all", "datasets", ",", "thereby", "achieving", "state", "-", "of", "-", "the", "-", "art", "results", "on", "the", "link", "prediction", "task", ";", "and", "our", "filter", "dimension", "study", "suggests", "that", "no", "benefit", "is", "gained", "by", "convolving", "over", "reshaped", "2D", "entity", "embeddings", "in", "comparison", "with", "1D", "entity", "embedding", "vectors", "and", "that", "most", "information", "can", "be", "extracted", "with", "very", "small", "convolutional", "filters", "(", "Table", "[", "reference", "]", ")", ".", "Overall", ",", "HypER", "outperforms", "all", "other", "models", "on", "all", "metrics", "apart", "from", "mean", "reciprocal", "rank", "on", "WN18", "and", "mean", "rank", "on", "WN18RR", ",", "FB15k", "-", "237", ",", "WN18", ",", "and", "YAGO3", "-", "10", ".", "Given", "that", "mean", "rank", "is", "known", "to", "be", "highly", "sensitive", "to", "outliers", ",", "this", "suggests", "that", "HypER", "correctly", "ranks", "many", "true", "triples", "in", "the", "top", "10", ",", "but", "makes", "larger", "ranking", "errors", "elsewhere", ".", "Given", "that", "most", "models", "in", "the", "literature", ",", "with", "the", "exception", "of", "ConvE", ",", "were", "trained", "with", "100", "dimension", "embeddings", "and", "1", "-", "1", "scoring", ",", "we", "reimplement", "previous", "models", "(", "DistMult", ",", "ComplEx", "and", "ConvE", ")", "with", "200", "dimension", "embeddings", "and", "1", "-", "N", "scoring", "for", "fair", "comparison", "and", "report", "the", "obtained", "results", "on", "WN18RR", "in", "Table", "[", "reference", "]", ".", "We", "perform", "the", "same", "hyperparameter", "search", "for", "every", "model", "and", "present", "the", "mean", "and", "standard", "deviation", "of", "each", "result", "across", "five", "runs", "(", "different", "random", "seeds", ")", ".", "This", "improves", "most", "previously", "published", "results", ",", "except", "for", "ConvE", "where", "we", "fail", "to", "replicate", "some", "values", ".", "Notwithstanding", ",", "HypER", "remains", "the", "best", "performing", "model", "overall", "despite", "better", "tuning", "of", "the", "competitors", ".", "Table", "[", "reference", "]", "shows", "hits@1", "per", "relation", "for", "HypER", "and", "ConvE", "on", "WN18RR", ".", "We", "can", "see", "that", "HypER", "performs", "comparably", "or", "better", "than", "ConvE", "on", "8", "out", "of", "11", "relations", "in", "the", "dataset", ".", "To", "ensure", "that", "the", "difference", "between", "reported", "results", "for", "HypER", "and", "ConvE", "is", "not", "simply", "due", "to", "HypER", "having", "a", "reduced", "number", "of", "parameters", "(", "implicit", "regularization", ")", ",", "we", "trained", "ConvE", "reducing", "the", "number", "of", "feature", "maps", "to", "16", "instead", "of", "32", "to", "have", "a", "comparable", "number", "of", "parameters", "to", "HypER", "(", "explicit", "regularization", ")", ".", "This", "showed", "no", "improvement", "in", "ConvE", "results", ",", "indicating", "HypER", "\u2019s", "architecture", "does", "more", "than", "merely", "reducing", "the", "number", "of", "parameters", ".", "Hypernetwork", "Influence", "To", "test", "the", "influence", "of", "the", "hypernetwork", "and", ",", "thereby", ",", "knowledge", "sharing", "between", "relations", ",", "we", "compare", "HypER", "results", "on", "WN18RR", "and", "FB15k", "-", "237", "with", "the", "hypernetwork", "component", "removed", ",", "i.e.", "without", "the", "first", "fully", "connected", "layer", "and", "with", "the", "relation", "embeddings", "directly", "corresponding", "to", "a", "set", "of", "convolutional", "filters", ".", "Results", "presented", "in", "Table", "[", "reference", "]", "show", "that", "the", "hypernetwork", "component", "improves", "performance", ",", "demonstrating", "the", "value", "of", "multi", "-", "task", "learning", "across", "different", "relations", ".", "Filter", "Dimension", "Study", "Table", "[", "reference", "]", "shows", "results", "of", "our", "study", "investigating", "the", "influence", "of", "different", "convolutional", "filter", "sizes", "on", "the", "performance", "of", "HypER", ".", "In", "the", "upper", "part", "of", "the", "table", ",", "we", "vary", "the", "length", "of", "1D", "filters", ",", "showing", "that", "comparable", "results", "can", "be", "achieved", "with", "filter", "sizes", "and", ",", "with", "diminishing", "results", "for", "smaller", "(", "e.g.", ")", "and", "larger", "(", "e.g.", ")", "filters", ".", "The", "lower", "part", "of", "the", "table", "shows", "results", "for", "2D", "filters", "convolved", "over", "reshaped", "(", ")", "2D", "subject", "entity", "embeddings", ".", "It", "can", "be", "seen", "that", "reshaping", "the", "embeddings", "is", "of", "no", "benefit", ",", "especially", "on", "WN18RR", ".", "These", "results", "indicate", "that", "the", "purpose", "of", "convolution", "on", "word", "embeddings", "is", "not", "to", "find", "patterns", "in", "a", "2D", "embedding", "(", "as", "with", "images", ")", ",", "but", "perhaps", "to", "limit", "the", "number", "of", "dimensions", "that", "can", "interact", "with", "each", "other", ",", "thereby", "avoiding", "overfitting", ".", "Label", "Smoothing", "Contrary", "to", "the", "ablation", "study", "of", "dettmers2017convolutional", ",", "showing", "the", "influence", "of", "hyperparameters", "on", "mean", "reciprocal", "rank", "for", "FB15k", "-", "237", ",", "from", "which", "they", "deem", "label", "smoothing", "unimportant", ",", "we", "find", "label", "smoothing", "to", "give", "a", "significant", "improvement", "in", "prediction", "scores", "for", "WN18RR", ".", "However", ",", "we", "find", "it", "does", "have", "a", "negative", "influence", "on", "the", "FB15k", "scores", "and", "as", "such", ",", "exclude", "label", "smoothing", "from", "our", "experiments", "on", "that", "dataset", ".", "We", "therefore", "recommend", "evaluating", "the", "influence", "of", "label", "smoothing", "on", "a", "per", "dataset", "basis", "and", "leave", "to", "future", "work", "analysis", "of", "the", "utility", "of", "label", "smoothing", "in", "the", "general", "case", ".", "section", ":", "Conclusion", "In", "this", "work", ",", "we", "introduce", "HypER", ",", "a", "hypernetwork", "model", "for", "link", "prediction", "on", "knowledge", "graphs", ".", "HypER", "uses", "a", "hypernetwork", "to", "generate", "relation", "-", "specific", "convolutional", "filters", "and", "applies", "them", "to", "subject", "entity", "embeddings", ".", "The", "hypernetwork", "component", "allows", "information", "to", "be", "shared", "between", "relation", "vectors", ",", "enabling", "multi", "-", "task", "learning", "across", "relations", ".", "To", "our", "knowledge", ",", "HypER", "is", "the", "first", "link", "prediction", "model", "that", "creates", "non", "-", "linear", "interaction", "between", "entity", "and", "relation", "embeddings", "by", "convolving", "relation", "-", "specific", "filters", "over", "the", "entity", "embeddings", ".", "We", "show", "that", "no", "benefit", "is", "gained", "from", "2D", "convolutional", "filters", "over", "1D", ",", "dispelling", "the", "suggestion", "that", "2D", "structure", "exists", "in", "entity", "embeddings", "implied", "by", "ConvE.", "We", "also", "recast", "HypER", "in", "terms", "of", "tensor", "operations", "showing", "that", ",", "despite", "the", "convolution", "operation", ",", "it", "is", "closely", "related", "to", "the", "established", "family", "of", "tensor", "factorization", "models", ".", "Our", "results", "suggest", "that", "convolution", "provides", "a", "good", "tradeoff", "between", "expressiveness", "and", "parameter", "number", "compared", "to", "a", "dense", "network", ".", "HypER", "is", "fast", ",", "robust", "to", "overfitting", ",", "has", "relatively", "few", "parameters", ",", "and", "achieves", "state", "-", "of", "-", "the", "-", "art", "results", "across", "almost", "all", "metrics", "on", "multiple", "link", "prediction", "datasets", ".", "Future", "work", "might", "include", "the", "expansion", "of", "the", "current", "architecture", "by", "applying", "convolutional", "filters", "to", "both", "subject", "and", "object", "entity", "embeddings", ".", "We", "may", "also", "analyze", "the", "influence", "of", "label", "smoothing", "and", "explore", "the", "interpretability", "of", "convolutional", "feature", "maps", "to", "gain", "insight", "and", "potentially", "improve", "the", "model", ".", "bibliography", ":", "References"]}