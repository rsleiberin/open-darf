{"coref": {"Accuracy": [[154, 155], [881, 882], [4677, 4678], [6137, 6138], [2777, 2778]], "IMDb": [[3289, 3290], [3438, 3439], [3515, 3516], [3549, 3550], [3648, 3649], [3674, 3675], [3838, 3839], [3938, 3939], [3940, 3941], [4243, 4244], [4338, 4339], [4480, 4481], [4695, 4696], [4742, 4743], [5051, 5052], [5152, 5153], [5212, 5213], [3443, 3444], [3510, 3511], [5053, 5054], [5287, 5288], [5512, 5513]], "Sentiment_Analysis": [], "seq2-bown-CNN": [[4343, 4349]]}, "coref_non_salient": {"0": [[742, 746], [845, 848], [4989, 4992]], "1": [[1005, 1015], [2469, 2475], [2483, 2490], [3182, 3188], [4397, 4401], [5711, 5718], [6100, 6107]], "10": [[670, 672], [2033, 2034]], "100": [[673, 676]], "101": [[3189, 3190], [3202, 3203]], "102": [[953, 956], [985, 988], [1131, 1134], [1913, 1916], [1922, 1925], [2939, 2942], [3926, 3929], [3981, 3984], [4073, 4076], [4194, 4197], [4202, 4205], [4817, 4820], [4852, 4855]], "11": [[137, 139], [147, 149], [431, 433], [484, 486], [706, 708], [755, 757], [974, 976], [1059, 1061], [1151, 1153], [1182, 1184], [1339, 1341], [1449, 1451], [1501, 1503], [1529, 1531], [1774, 1776], [1869, 1871], [1890, 1892], [2191, 2193], [2214, 2216], [2247, 2249], [2706, 2710], [3920, 3922], [5518, 5520], [5533, 5535]], "12": [[805, 806], [1067, 1070], [4470, 4472]], "13": [[65, 67], [886, 887], [5732, 5733], [5756, 5757], [5851, 5852]], "14": [[1588, 1591], [2453, 2456], [4090, 4093], [4143, 4146]], "15": [[635, 639], [4772, 4776]], "16": [[594, 596], [688, 691]], "17": [[2884, 2885], [3102, 3103]], "18": [[1155, 1157], [1535, 1537], [1562, 1564], [1566, 1568], [2158, 2159], [2218, 2219], [2318, 2320], [2373, 2374], [2384, 2385], [3034, 3036], [3968, 3970], [5548, 5549]], "19": [[4657, 4663], [4671, 4674]], "2": [[290, 292], [2494, 2496]], "20": [[1141, 1142], [2169, 2171], [2386, 2387]], "21": [[2304, 2305]], "22": [[99, 104], [6089, 6095]], "23": [[2878, 2879], [3097, 3098]], "24": [[3865, 3867], [4649, 4651], [4758, 4760], [5056, 5058]], "25": [[3434, 3436], [3480, 3481], [3668, 3670], [3832, 3834]], "26": [[3923, 3925], [4192, 4193], [1896, 1897], [1901, 1902], [2149, 2150], [4252, 4253], [4358, 4359], [4493, 4494]], "27": [[3732, 3734], [4839, 4841]], "28": [[1390, 1392], [5564, 5566]], "29": [[4066, 4067], [4829, 4830]], "3": [[3297, 3298], [3303, 3305], [3348, 3351], [4752, 4753]], "30": [[3057, 3062], [3082, 3087]], "31": [[8, 10], [48, 50], [179, 181], [201, 203], [221, 223], [256, 258], [350, 352], [362, 364], [389, 391], [462, 464], [700, 702], [919, 921], [3680, 3682], [4063, 4065], [4668, 4670], [4895, 4897], [5122, 5124], [6086, 6088]], "32": [[18, 19], [46, 47], [86, 87], [116, 117], [404, 405], [407, 408], [460, 461], [501, 502], [544, 545], [575, 576], [790, 791], [917, 918], [924, 925], [934, 935], [963, 964], [1084, 1085], [1102, 1103], [1109, 1110], [1120, 1121], [1139, 1140], [1142, 1143], [1612, 1613], [1620, 1621], [1635, 1636], [2299, 2300], [2467, 2468], [2564, 2565], [2695, 2696], [2836, 2837], [2865, 2866], [2992, 2993], [3090, 3091], [3868, 3869], [3892, 3893], [3917, 3918], [3975, 3976], [4998, 4999], [5028, 5029], [5227, 5228], [5238, 5239], [5740, 5741], [6049, 6050], [6074, 6075], [606, 607], [652, 653], [901, 902], [946, 947], [1020, 1021], [1898, 1899], [2691, 2692], [2734, 2735], [4240, 4241], [4478, 4479], [4882, 4883], [4914, 4915], [4930, 4931], [5131, 5132], [5180, 5181], [6111, 6112], [6116, 6117]], "33": [[3238, 3239], [5158, 5159]], "34": [[5979, 5980]], "35": [[5095, 5097]], "36": [[3368, 3370], [3947, 3949], [4077, 4079]], "37": [[5104, 5107]], "38": [[3268, 3269], [4714, 4715]], "39": [[3678, 3679], [3682, 3683], [3695, 3696], [4699, 4700], [5214, 5215]], "4": [[4572, 4575], [6060, 6065]], "40": [[4993, 4994]], "41": [[4778, 4785]], "42": [[938, 941], [981, 984], [1127, 1130], [1766, 1769], [1931, 1934], [2909, 2912], [3977, 3980], [4206, 4209], [4279, 4282], [5505, 5508], [5982, 5985]], "43": [[551, 553]], "44": [[1926, 1927]], "45": [[554, 556], [2335, 2337], [5000, 5002]], "46": [[5144, 5146]], "47": [[436, 438], [1187, 1189], [1264, 1266], [1462, 1464], [4411, 4413]], "48": [[5178, 5179]], "49": [[11, 14], [14, 17], [400, 403]], "5": [[3192, 3193], [4245, 4248], [4319, 4322], [4369, 4372], [4510, 4513]], "50": [[1592, 1595], [2307, 2310], [2368, 2371], [2392, 2395], [3963, 3966], [4004, 4007], [4272, 4275]], "51": [[3196, 3197], [3211, 3212], [4405, 4406], [4750, 4751], [5150, 5151], [5261, 5262]], "52": [[1342, 1344], [1422, 1424]], "53": [[3693, 3694], [3819, 3820], [3848, 3849], [4833, 4834], [4842, 4843], [4856, 4857]], "54": [[3721, 3725], [3754, 3758], [4822, 4828]], "55": [[3020, 3022]], "56": [[1585, 1587]], "57": [[2156, 2157]], "58": [[5010, 5014]], "59": [[694, 696]], "6": [[557, 560], [6007, 6008]], "60": [[3685, 3690]], "61": [[2699, 2701]], "62": [[621, 622]], "63": [[3054, 3056], [5147, 5149]], "64": [[314, 316], [2153, 2155]], "65": [[3113, 3120]], "66": [[3342, 3345]], "67": [[2052, 2053]], "68": [[2880, 2883]], "69": [[4873, 4877]], "7": [[857, 859], [2946, 2947]], "70": [[538, 540]], "71": [[3286, 3288]], "72": [[4638, 4639]], "73": [[561, 564]], "74": [[531, 535]], "75": [[4863, 4865]], "76": [[235, 237]], "77": [[2056, 2058]], "78": [[5479, 5482]], "79": [[4900, 4903]], "8": [[2133, 2136], [2598, 2602], [4446, 4450], [4567, 4571]], "80": [[22, 24], [410, 412], [1886, 1888]], "81": [[3266, 3267]], "82": [[1375, 1383]], "83": [[2412, 2414]], "84": [[2784, 2788]], "85": [[5844, 5847]], "86": [[129, 135], [966, 972], [2088, 2094]], "87": [[185, 191]], "88": [[247, 251]], "89": [[817, 821]], "9": [[107, 108], [239, 241], [321, 323], [507, 509], [989, 991], [995, 997], [1049, 1051], [1104, 1106], [1122, 1125], [1171, 1172], [2458, 2460], [2610, 2612], [2841, 2843], [2844, 2846], [3122, 3124], [3158, 3160], [3450, 3452], [3935, 3937], [4056, 4058], [4108, 4110], [4116, 4118], [4615, 4617], [4887, 4890], [5703, 5704], [6148, 6150], [6151, 6153]], "90": [[1145, 1150]], "91": [[2328, 2333]], "92": [[3246, 3249], [3252, 3255], [4437, 4440], [4634, 4637], [4688, 4691], [4746, 4749]], "93": [[517, 523]], "94": [[3241, 3242]], "95": [[294, 295], [2498, 2499], [3051, 3052], [5259, 5260], [5282, 5283], [5342, 5343], [5359, 5360], [5405, 5406]], "96": [[2262, 2267]], "97": [[2796, 2799]], "98": [[330, 334]], "99": [[1637, 1641]]}, "doc_id": "364da079f91a6cb385997be990af06e9ddf6e888", "method_subrelations": {"seq2-bown-CNN": [[[0, 13], "seq2-bown-CNN"]]}, "n_ary_relations": [{"Material": "IMDb", "Method": "seq2-bown-CNN", "Metric": "Accuracy", "Task": "Sentiment_Analysis", "score": "92.33"}], "ner": [[8, 10, "Task"], [11, 14, "Method"], [14, 17, "Method"], [18, 19, "Method"], [22, 24, "Method"], [46, 47, "Method"], [48, 50, "Task"], [65, 67, "Task"], [86, 87, "Method"], [99, 104, "Task"], [107, 108, "Task"], [116, 117, "Method"], [129, 135, "Method"], [137, 139, "Method"], [147, 149, "Method"], [154, 155, "Metric"], [179, 181, "Task"], [185, 191, "Task"], [201, 203, "Task"], [221, 223, "Task"], [235, 237, "Task"], [239, 241, "Task"], [247, 251, "Task"], [256, 258, "Task"], [290, 292, "Method"], [294, 295, "Method"], [314, 316, "Method"], [321, 323, "Task"], [330, 334, "Method"], [350, 352, "Task"], [362, 364, "Task"], [389, 391, "Task"], [400, 403, "Method"], [404, 405, "Method"], [407, 408, "Method"], [410, 412, "Method"], [431, 433, "Method"], [436, 438, "Method"], [460, 461, "Method"], [462, 464, "Task"], [484, 486, "Method"], [501, 502, "Method"], [507, 509, "Task"], [517, 523, "Task"], [531, 535, "Task"], [538, 540, "Task"], [544, 545, "Method"], [551, 553, "Task"], [554, 556, "Task"], [557, 560, "Task"], [561, 564, "Task"], [575, 576, "Method"], [594, 596, "Method"], [621, 622, "Method"], [635, 639, "Method"], [670, 672, "Task"], [673, 676, "Task"], [688, 691, "Method"], [694, 696, "Task"], [700, 702, "Task"], [706, 708, "Method"], [742, 746, "Method"], [755, 757, "Method"], [790, 791, "Method"], [805, 806, "Task"], [817, 821, "Method"], [845, 848, "Method"], [857, 859, "Task"], [881, 882, "Metric"], [886, 887, "Task"], [917, 918, "Method"], [919, 921, "Task"], [924, 925, "Method"], [934, 935, "Method"], [938, 941, "Method"], [953, 956, "Method"], [963, 964, "Method"], [966, 972, "Method"], [974, 976, "Method"], [981, 984, "Method"], [985, 988, "Method"], [989, 991, "Task"], [995, 997, "Task"], [1005, 1015, "Method"], [1049, 1051, "Task"], [1059, 1061, "Method"], [1067, 1070, "Task"], [1084, 1085, "Method"], [1102, 1103, "Method"], [1104, 1106, "Task"], [1109, 1110, "Method"], [1120, 1121, "Method"], [1122, 1125, "Task"], [1127, 1130, "Method"], [1131, 1134, "Method"], [1139, 1140, "Method"], [1141, 1142, "Task"], [1142, 1143, "Method"], [1145, 1150, "Method"], [1151, 1153, "Method"], [1155, 1157, "Method"], [1171, 1172, "Task"], [1182, 1184, "Method"], [1187, 1189, "Method"], [1264, 1266, "Method"], [1339, 1341, "Method"], [1342, 1344, "Method"], [1375, 1383, "Method"], [1390, 1392, "Method"], [1422, 1424, "Method"], [1449, 1451, "Method"], [1462, 1464, "Method"], [1501, 1503, "Method"], [1529, 1531, "Method"], [1535, 1537, "Method"], [1562, 1564, "Method"], [1566, 1568, "Method"], [1585, 1587, "Method"], [1588, 1591, "Method"], [1592, 1595, "Method"], [1612, 1613, "Method"], [1620, 1621, "Method"], [1635, 1636, "Method"], [1637, 1641, "Method"], [1766, 1769, "Method"], [1774, 1776, "Method"], [1869, 1871, "Method"], [1886, 1888, "Method"], [1890, 1892, "Method"], [1913, 1916, "Method"], [1922, 1925, "Method"], [1926, 1927, "Task"], [1931, 1934, "Method"], [2033, 2034, "Task"], [2052, 2053, "Metric"], [2056, 2058, "Metric"], [2088, 2094, "Method"], [2133, 2136, "Method"], [2153, 2155, "Method"], [2156, 2157, "Method"], [2158, 2159, "Method"], [2169, 2171, "Task"], [2191, 2193, "Method"], [2214, 2216, "Method"], [2218, 2219, "Method"], [2247, 2249, "Method"], [2262, 2267, "Method"], [2299, 2300, "Method"], [2304, 2305, "Task"], [2307, 2310, "Method"], [2318, 2320, "Method"], [2328, 2333, "Method"], [2335, 2337, "Task"], [2368, 2371, "Method"], [2373, 2374, "Method"], [2384, 2385, "Method"], [2386, 2387, "Task"], [2392, 2395, "Method"], [2412, 2414, "Method"], [2453, 2456, "Method"], [2458, 2460, "Task"], [2467, 2468, "Method"], [2469, 2475, "Method"], [2483, 2490, "Method"], [2494, 2496, "Method"], [2498, 2499, "Method"], [2564, 2565, "Method"], [2598, 2602, "Method"], [2610, 2612, "Task"], [2695, 2696, "Method"], [2699, 2701, "Method"], [2706, 2710, "Method"], [2784, 2788, "Method"], [2796, 2799, "Method"], [2836, 2837, "Method"], [2841, 2843, "Task"], [2844, 2846, "Task"], [2865, 2866, "Method"], [2878, 2879, "Method"], [2880, 2883, "Method"], [2884, 2885, "Method"], [2909, 2912, "Method"], [2939, 2942, "Method"], [2946, 2947, "Task"], [2992, 2993, "Method"], [3020, 3022, "Method"], [3034, 3036, "Method"], [3051, 3052, "Method"], [3054, 3056, "Method"], [3057, 3062, "Method"], [3082, 3087, "Method"], [3090, 3091, "Method"], [3097, 3098, "Method"], [3102, 3103, "Method"], [3113, 3120, "Task"], [3122, 3124, "Task"], [3158, 3160, "Task"], [3182, 3188, "Method"], [3189, 3190, "Method"], [3192, 3193, "Method"], [3196, 3197, "Method"], [3202, 3203, "Method"], [3211, 3212, "Method"], [3238, 3239, "Method"], [3241, 3242, "Task"], [3246, 3249, "Method"], [3252, 3255, "Method"], [3266, 3267, "Method"], [3268, 3269, "Method"], [3286, 3288, "Method"], [3289, 3290, "Material"], [3297, 3298, "Method"], [3303, 3305, "Method"], [3342, 3345, "Method"], [3348, 3351, "Method"], [3368, 3370, "Method"], [3434, 3436, "Task"], [3438, 3439, "Material"], [3450, 3452, "Task"], [3480, 3481, "Task"], [3515, 3516, "Material"], [3549, 3550, "Material"], [3648, 3649, "Material"], [3668, 3670, "Task"], [3674, 3675, "Material"], [3678, 3679, "Method"], [3680, 3682, "Task"], [3682, 3683, "Method"], [3685, 3690, "Material"], [3693, 3694, "Material"], [3695, 3696, "Method"], [3721, 3725, "Task"], [3732, 3734, "Method"], [3754, 3758, "Task"], [3819, 3820, "Material"], [3832, 3834, "Task"], [3838, 3839, "Material"], [3848, 3849, "Material"], [3865, 3867, "Metric"], [3868, 3869, "Method"], [3892, 3893, "Method"], [3917, 3918, "Method"], [3920, 3922, "Method"], [3923, 3925, "Method"], [3926, 3929, "Method"], [3935, 3937, "Task"], [3938, 3939, "Material"], [3940, 3941, "Material"], [3947, 3949, "Method"], [3963, 3966, "Method"], [3968, 3970, "Method"], [3975, 3976, "Method"], [3977, 3980, "Method"], [3981, 3984, "Method"], [4004, 4007, "Method"], [4056, 4058, "Task"], [4063, 4065, "Task"], [4066, 4067, "Task"], [4073, 4076, "Method"], [4077, 4079, "Method"], [4090, 4093, "Method"], [4108, 4110, "Task"], [4116, 4118, "Task"], [4143, 4146, "Method"], [4192, 4193, "Method"], [4194, 4197, "Method"], [4202, 4205, "Method"], [4206, 4209, "Method"], [4243, 4244, "Material"], [4245, 4248, "Method"], [4272, 4275, "Method"], [4279, 4282, "Method"], [4319, 4322, "Method"], [4338, 4339, "Material"], [4343, 4349, "Method"], [4369, 4372, "Method"], [4397, 4401, "Method"], [4405, 4406, "Method"], [4411, 4413, "Method"], [4437, 4440, "Method"], [4446, 4450, "Method"], [4470, 4472, "Task"], [4480, 4481, "Material"], [4510, 4513, "Method"], [4567, 4571, "Method"], [4572, 4575, "Method"], [4615, 4617, "Task"], [4634, 4637, "Method"], [4638, 4639, "Method"], [4649, 4651, "Metric"], [4657, 4663, "Method"], [4668, 4670, "Task"], [4671, 4674, "Method"], [4677, 4678, "Metric"], [4688, 4691, "Method"], [4695, 4696, "Material"], [4699, 4700, "Method"], [4714, 4715, "Method"], [4742, 4743, "Material"], [4746, 4749, "Method"], [4750, 4751, "Method"], [4752, 4753, "Method"], [4758, 4760, "Metric"], [4772, 4776, "Method"], [4778, 4785, "Method"], [4817, 4820, "Method"], [4822, 4828, "Task"], [4829, 4830, "Task"], [4833, 4834, "Material"], [4839, 4841, "Method"], [4842, 4843, "Material"], [4852, 4855, "Method"], [4856, 4857, "Material"], [4863, 4865, "Method"], [4873, 4877, "Method"], [4887, 4890, "Task"], [4895, 4897, "Task"], [4900, 4903, "Task"], [4989, 4992, "Method"], [4993, 4994, "Method"], [4998, 4999, "Method"], [5000, 5002, "Task"], [5010, 5014, "Method"], [5028, 5029, "Method"], [5051, 5052, "Material"], [5056, 5058, "Metric"], [5095, 5097, "Method"], [5104, 5107, "Task"], [5122, 5124, "Task"], [5144, 5146, "Method"], [5147, 5149, "Method"], [5150, 5151, "Method"], [5152, 5153, "Material"], [5158, 5159, "Method"], [5178, 5179, "Method"], [5212, 5213, "Material"], [5214, 5215, "Method"], [5227, 5228, "Method"], [5238, 5239, "Method"], [5259, 5260, "Method"], [5261, 5262, "Method"], [5282, 5283, "Method"], [5342, 5343, "Method"], [5359, 5360, "Method"], [5405, 5406, "Method"], [5479, 5482, "Method"], [5505, 5508, "Method"], [5518, 5520, "Method"], [5533, 5535, "Method"], [5548, 5549, "Method"], [5564, 5566, "Method"], [5703, 5704, "Task"], [5711, 5718, "Method"], [5732, 5733, "Task"], [5740, 5741, "Method"], [5756, 5757, "Task"], [5844, 5847, "Method"], [5851, 5852, "Task"], [5979, 5980, "Task"], [5982, 5985, "Method"], [6007, 6008, "Task"], [6049, 6050, "Method"], [6060, 6065, "Method"], [6074, 6075, "Method"], [6086, 6088, "Task"], [6089, 6095, "Task"], [6100, 6107, "Method"], [6137, 6138, "Metric"], [6148, 6150, "Task"], [6151, 6153, "Task"], [606, 607, "Method"], [652, 653, "Method"], [901, 902, "Method"], [946, 947, "Method"], [1020, 1021, "Method"], [1896, 1897, "Method"], [1898, 1899, "Method"], [1901, 1902, "Method"], [2149, 2150, "Method"], [2691, 2692, "Method"], [2734, 2735, "Method"], [2777, 2778, "Metric"], [3443, 3444, "Material"], [3510, 3511, "Material"], [4240, 4241, "Method"], [4252, 4253, "Method"], [4358, 4359, "Method"], [4478, 4479, "Method"], [4493, 4494, "Method"], [4882, 4883, "Method"], [4914, 4915, "Method"], [4930, 4931, "Method"], [5053, 5054, "Material"], [5131, 5132, "Method"], [5180, 5181, "Method"], [5287, 5288, "Material"], [5512, 5513, "Material"], [6111, 6112, "Method"], [6116, 6117, "Method"]], "sections": [[0, 176], [176, 1100], [1100, 1135], [1135, 1610], [1610, 1764], [1764, 1920], [1920, 2156], [2156, 2465], [2465, 2686], [2686, 2830], [2830, 2863], [2863, 3042], [3042, 3244], [3244, 3366], [3366, 3427], [3427, 3436], [3436, 3508], [3508, 3676], [3676, 3855], [3855, 4602], [4602, 4716], [4716, 4879], [4879, 5127], [5127, 5223], [5223, 6067], [6067, 6159], [6159, 6187], [6187, 6190]], "sentences": [[0, 14], [14, 43], [43, 68], [68, 109], [109, 142], [142, 156], [156, 176], [176, 179], [179, 198], [198, 252], [252, 296], [296, 324], [324, 341], [341, 383], [383, 407], [407, 458], [458, 501], [501, 524], [524, 569], [569, 597], [597, 629], [629, 645], [645, 681], [681, 703], [703, 737], [737, 762], [762, 779], [779, 787], [787, 849], [849, 900], [900, 912], [912, 931], [931, 977], [977, 1029], [1029, 1053], [1053, 1076], [1076, 1100], [1100, 1106], [1106, 1135], [1135, 1142], [1142, 1181], [1181, 1218], [1218, 1262], [1262, 1289], [1289, 1335], [1335, 1345], [1345, 1394], [1394, 1421], [1421, 1443], [1443, 1496], [1496, 1524], [1524, 1561], [1561, 1582], [1582, 1610], [1610, 1615], [1615, 1625], [1625, 1635], [1635, 1655], [1655, 1700], [1700, 1719], [1719, 1750], [1750, 1751], [1751, 1756], [1756, 1764], [1764, 1771], [1771, 1813], [1813, 1834], [1834, 1883], [1883, 1900], [1900, 1920], [1920, 1927], [1927, 1985], [1985, 2010], [2010, 2023], [2023, 2081], [2081, 2128], [2128, 2156], [2156, 2161], [2161, 2206], [2206, 2250], [2250, 2296], [2296, 2327], [2327, 2372], [2372, 2402], [2402, 2444], [2444, 2465], [2465, 2475], [2475, 2500], [2500, 2529], [2529, 2561], [2561, 2585], [2585, 2613], [2613, 2624], [2624, 2636], [2636, 2669], [2669, 2678], [2678, 2686], [2686, 2692], [2692, 2711], [2711, 2754], [2754, 2779], [2779, 2830], [2830, 2833], [2833, 2847], [2847, 2863], [2863, 2866], [2866, 2887], [2887, 2925], [2925, 2938], [2938, 2974], [2974, 2985], [2985, 3004], [3004, 3017], [3017, 3042], [3042, 3046], [3046, 3073], [3073, 3079], [3079, 3111], [3111, 3157], [3157, 3177], [3177, 3188], [3188, 3236], [3236, 3244], [3244, 3249], [3249, 3299], [3299, 3313], [3313, 3315], [3315, 3346], [3346, 3366], [3366, 3370], [3370, 3427], [3427, 3436], [3436, 3442], [3442, 3453], [3453, 3467], [3467, 3479], [3479, 3494], [3494, 3508], [3508, 3515], [3515, 3522], [3522, 3532], [3532, 3545], [3545, 3607], [3607, 3633], [3633, 3657], [3657, 3668], [3668, 3676], [3676, 3682], [3682, 3695], [3695, 3716], [3716, 3748], [3748, 3775], [3775, 3807], [3807, 3817], [3817, 3832], [3832, 3855], [3855, 3859], [3859, 3876], [3876, 3906], [3906, 3934], [3934, 3996], [3996, 4045], [4045, 4059], [4059, 4111], [4111, 4162], [4162, 4186], [4186, 4235], [4235, 4242], [4242, 4283], [4283, 4314], [4314, 4333], [4333, 4343], [4343, 4357], [4357, 4401], [4401, 4441], [4441, 4473], [4473, 4502], [4502, 4514], [4514, 4534], [4534, 4602], [4602, 4606], [4606, 4649], [4649, 4664], [4664, 4688], [4688, 4716], [4716, 4728], [4728, 4768], [4768, 4789], [4789, 4806], [4806, 4815], [4815, 4835], [4835, 4844], [4844, 4879], [4879, 4883], [4883, 4898], [4898, 4916], [4916, 4942], [4942, 4960], [4960, 4975], [4975, 4993], [4993, 5003], [5003, 5031], [5031, 5050], [5050, 5075], [5075, 5078], [5078, 5098], [5098, 5127], [5127, 5131], [5131, 5146], [5146, 5172], [5172, 5201], [5201, 5223], [5223, 5230], [5230, 5248], [5248, 5393], [5393, 5432], [5432, 5473], [5473, 5491], [5491, 5514], [5514, 5567], [5567, 5597], [5597, 5627], [5627, 5657], [5657, 5694], [5694, 5709], [5709, 5734], [5734, 5792], [5792, 5853], [5853, 5874], [5874, 5903], [5903, 5915], [5915, 5951], [5951, 5952], [5952, 5972], [5972, 6046], [6046, 6060], [6060, 6067], [6067, 6070], [6070, 6113], [6113, 6139], [6139, 6159], [6159, 6162], [6162, 6171], [6171, 6187], [6187, 6190]], "words": ["document", ":", "Effective", "Use", "of", "Word", "Order", "for", "Text", "Categorization", "with", "Convolutional", "Neural", "Networks", "Convolutional", "neural", "network", "(", "CNN", ")", "is", "a", "neural", "network", "that", "can", "make", "use", "of", "the", "internal", "structure", "of", "data", "such", "as", "the", "2D", "structure", "of", "image", "data", ".", "This", "paper", "studies", "CNN", "on", "text", "categorization", "to", "exploit", "the", "1D", "structure", "(", "namely", ",", "word", "order", ")", "of", "text", "data", "for", "accurate", "prediction", ".", "Instead", "of", "using", "low", "-", "dimensional", "word", "vectors", "as", "input", "as", "is", "often", "done", ",", "we", "directly", "apply", "CNN", "to", "high", "-", "dimensional", "text", "data", ",", "which", "leads", "to", "directly", "learning", "embedding", "of", "small", "text", "regions", "for", "use", "in", "classification", ".", "In", "addition", "to", "a", "straightforward", "adaptation", "of", "CNN", "from", "image", "to", "text", ",", "a", "simple", "but", "new", "variation", "which", "employs", "bag", "-", "of", "-", "word", "conversion", "in", "the", "convolution", "layer", "is", "proposed", ".", "An", "extension", "to", "combine", "multiple", "convolution", "layers", "is", "also", "explored", "for", "higher", "accuracy", ".", "The", "experiments", "demonstrate", "the", "effectiveness", "of", "our", "approach", "in", "comparison", "with", "state", "-", "of", "-", "the", "-", "art", "methods", ".", "section", ":", "Introduction", "Text", "categorization", "is", "the", "task", "of", "automatically", "assigning", "pre", "-", "defined", "categories", "to", "documents", "written", "in", "natural", "languages", ".", "Several", "types", "of", "text", "categorization", "have", "been", "studied", ",", "each", "of", "which", "deals", "with", "different", "types", "of", "documents", "and", "categories", ",", "such", "as", "topic", "categorization", "to", "detect", "discussed", "topics", "(", "e.g.", ",", "sports", ",", "politics", ")", ",", "spam", "detection", ",", "and", "sentiment", "classification", "to", "determine", "the", "sentiment", "typically", "in", "product", "or", "movie", "reviews", ".", "A", "standard", "approach", "to", "text", "categorization", "is", "to", "represent", "documents", "by", "bag", "-", "of", "-", "word", "vectors", ",", "namely", ",", "vectors", "that", "indicate", "which", "words", "appear", "in", "the", "documents", "but", "do", "not", "preserve", "word", "order", ",", "and", "use", "classification", "models", "such", "as", "SVM", ".", "It", "has", "been", "noted", "that", "loss", "of", "word", "order", "caused", "by", "bag", "-", "of", "-", "word", "vectors", "(", "bow", "vectors", ")", "is", "particularly", "problematic", "on", "sentiment", "classification", ".", "A", "simple", "remedy", "is", "to", "use", "word", "bi", "-", "grams", "in", "addition", "to", "uni", "-", "grams", ".", "However", ",", "use", "of", "word", "-", "grams", "with", "on", "text", "categorization", "in", "general", "is", "not", "always", "effective", ";", "e.g.", ",", "on", "topic", "categorization", ",", "simply", "adding", "phrases", "or", "-", "grams", "is", "not", "effective", "(", "see", ",", "e.g.", ",", "references", "in", ")", ".", "To", "benefit", "from", "word", "order", "on", "text", "categorization", ",", "we", "take", "a", "different", "approach", ",", "which", "employs", "convolutional", "neural", "networks", "(", "CNN", ")", ".", "CNN", "is", "a", "neural", "network", "that", "can", "make", "use", "of", "the", "internal", "structure", "of", "data", "such", "as", "the", "2D", "structure", "of", "image", "data", "through", "convolution", "layers", ",", "where", "each", "computation", "unit", "responds", "to", "a", "small", "region", "of", "input", "data", "(", "e.g.", ",", "a", "small", "square", "of", "a", "large", "image", ")", ".", "We", "apply", "CNN", "to", "text", "categorization", "to", "make", "use", "of", "the", "1D", "structure", "(", "word", "order", ")", "of", "document", "data", "so", "that", "each", "unit", "in", "the", "convolution", "layer", "responds", "to", "a", "small", "region", "of", "a", "document", "(", "a", "sequence", "of", "words", ")", ".", "CNN", "has", "been", "very", "successful", "on", "image", "classification", ";", "see", "e.g.", ",", "the", "winning", "solutions", "of", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", ".", "On", "text", ",", "since", "the", "work", "on", "token", "-", "level", "applications", "(", "e.g.", ",", "POS", "tagging", ")", "by", "nnnlpJMLR11", ",", "CNN", "has", "been", "used", "in", "systems", "for", "entity", "search", ",", "sentence", "modeling", ",", "word", "embedding", "learning", ",", "product", "feature", "mining", ",", "and", "so", "on", ".", "Notably", ",", "in", "many", "of", "these", "CNN", "studies", "on", "text", ",", "the", "first", "layer", "of", "the", "network", "converts", "words", "in", "sentences", "to", "word", "vectors", "by", "table", "lookup", ".", "The", "word", "vectors", "are", "either", "trained", "as", "part", "of", "CNN", "training", ",", "or", "fixed", "to", "those", "learned", "by", "some", "other", "method", "(", "e.g.", ",", "word2vec", ")", "from", "an", "additional", "large", "corpus", ".", "The", "latter", "is", "a", "form", "of", "semi", "-", "supervised", "learning", ",", "which", "we", "study", "elsewhere", ".", "We", "are", "interested", "in", "the", "effectiveness", "of", "CNN", "itself", "without", "aid", "of", "additional", "resources", ";", "therefore", ",", "word", "vectors", "should", "be", "trained", "as", "part", "of", "network", "training", "if", "word", "vector", "lookup", "is", "to", "be", "done", ".", "A", "question", "arises", ",", "however", ",", "whether", "word", "vector", "lookup", "in", "a", "purely", "supervised", "setting", "is", "really", "useful", "for", "text", "categorization", ".", "The", "essence", "of", "convolution", "layers", "is", "to", "convert", "text", "regions", "of", "a", "fixed", "size", "(", "e.g.", ",", "\u201c", "am", "so", "happy", "\u201d", "with", "size", "3", ")", "to", "feature", "vectors", ",", "as", "described", "later", ".", "In", "that", "sense", ",", "a", "word", "vector", "learning", "layer", "is", "a", "special", "(", "and", "unusual", ")", "case", "of", "convolution", "layer", "with", "region", "size", "one", ".", "Why", "is", "size", "one", "appropriate", "if", "bi", "-", "grams", "are", "more", "discriminating", "than", "uni", "-", "grams", "?", "Hence", ",", "we", "take", "a", "different", "approach", ".", "We", "directly", "apply", "CNN", "to", "high", "-", "dimensional", "one", "-", "hot", "vectors", ";", "i.e.", ",", "we", "directly", "learn", "embedding", "We", "use", "the", "term", "\u2018", "embedding", "\u2019", "loosely", "to", "mean", "a", "structure", "-", "preserving", "function", ",", "in", "particular", ",", "a", "function", "that", "generates", "low", "-", "dimensional", "features", "that", "preserve", "the", "predictive", "structure", ".", "of", "text", "regions", "without", "going", "through", "word", "embedding", "learning", ".", "This", "approach", "is", "made", "possible", "by", "solving", "the", "computational", "issue", "through", "efficient", "handling", "of", "high", "-", "dimensional", "sparse", "data", "on", "GPU", ",", "and", "it", "turned", "out", "to", "have", "the", "merits", "of", "improving", "accuracy", "with", "fast", "training", "/", "prediction", "and", "simplifying", "the", "system", "(", "fewer", "hyper", "-", "parameters", "to", "tune", ")", ".", "Our", "CNN", "code", "for", "text", "is", "publicly", "available", "on", "the", "internet", ".", "We", "study", "the", "effectiveness", "of", "CNN", "on", "text", "categorization", "and", "explain", "why", "CNN", "is", "suitable", "for", "the", "task", ".", "Two", "types", "of", "CNN", "are", "tested", ":", "seq", "-", "CNN", "is", "a", "straightforward", "adaptation", "of", "CNN", "from", "image", "to", "text", ",", "and", "bow", "-", "CNN", "is", "a", "simple", "but", "new", "variation", "of", "CNN", "that", "employs", "bag", "-", "of", "-", "word", "conversion", "in", "the", "convolution", "layer", ".", "The", "experiments", "show", "that", "seq", "-", "CNN", "outperforms", "bow", "-", "CNN", "on", "sentiment", "classification", ",", "vice", "versa", "on", "topic", "classification", ",", "and", "the", "winner", "generally", "outperforms", "the", "conventional", "bag", "-", "of", "-", "-", "gram", "vector", "-", "based", "methods", ",", "as", "well", "as", "previous", "CNN", "models", "for", "text", "which", "are", "more", "complex", ".", "In", "particular", ",", "to", "our", "knowledge", ",", "this", "is", "the", "first", "work", "that", "has", "successfully", "used", "word", "order", "to", "improve", "topic", "classification", "performance", ".", "A", "simple", "extension", "that", "combines", "multiple", "convolution", "layers", "(", "thus", "combining", "multiple", "types", "of", "text", "region", "embedding", ")", "leads", "to", "further", "improvement", ".", "Through", "empirical", "analysis", ",", "we", "will", "show", "that", "CNN", "can", "make", "effective", "use", "of", "high", "-", "order", "-", "grams", "when", "conventional", "methods", "fail", ".", "section", ":", "CNN", "for", "document", "classification", "We", "first", "review", "CNN", "applied", "to", "image", "data", "and", "then", "discuss", "the", "application", "of", "CNN", "to", "document", "classification", "tasks", "to", "introduce", "seq", "-", "CNN", "and", "bow", "-", "CNN", ".", "subsection", ":", "Preliminary", ":", "CNN", "for", "image", "CNN", "is", "a", "feed", "-", "forward", "neural", "network", "with", "convolution", "layers", "interleaved", "with", "pooling", "layers", ",", "as", "illustrated", "in", "Figure", "[", "reference", "]", ",", "where", "the", "top", "layer", "performs", "classification", "using", "the", "features", "generated", "by", "the", "layers", "below", ".", "A", "convolution", "layer", "consists", "of", "several", "computation", "units", ",", "each", "of", "which", "takes", "as", "input", "a", "region", "vector", "that", "represents", "a", "small", "region", "of", "the", "input", "image", "and", "applies", "a", "non", "-", "linear", "function", "to", "it", ".", "Typically", ",", "the", "region", "vector", "is", "a", "concatenation", "of", "pixels", "in", "the", "region", ",", "which", "would", "be", ",", "for", "example", ",", "75", "-", "dimensional", "if", "the", "region", "is", "and", "the", "number", "of", "channels", "is", "three", "(", "red", ",", "green", ",", "and", "blue", ")", ".", "Conceptually", ",", "computation", "units", "are", "placed", "over", "the", "input", "image", "so", "that", "the", "entire", "image", "is", "collectively", "covered", ",", "as", "illustrated", "in", "Figure", "[", "reference", "]", ".", "The", "region", "stride", "(", "distance", "between", "the", "region", "centers", ")", "is", "often", "set", "to", "a", "small", "value", "such", "as", "1", "so", "that", "regions", "overlap", "with", "each", "other", ",", "though", "the", "stride", "in", "Figure", "[", "reference", "]", "is", "set", "larger", "than", "the", "region", "size", "for", "illustration", ".", "A", "distinguishing", "feature", "of", "convolution", "layers", "is", "weight", "sharing", ".", "Given", "input", ",", "a", "unit", "associated", "with", "the", "-", "th", "region", "computes", "where", "is", "a", "region", "vector", "representing", "the", "region", "of", "at", "location", ",", "and", "is", "a", "pre", "-", "defined", "component", "-", "wise", "non", "-", "linear", "activation", "function", ",", "(", "e.g.", ",", "applying", "to", "each", "vector", "component", ")", ".", "The", "matrix", "of", "weights", "and", "the", "vector", "of", "biases", "are", "learned", "through", "training", ",", "and", "they", "are", "shared", "by", "the", "computation", "units", "in", "the", "same", "layer", ".", "This", "weight", "sharing", "enables", "learning", "useful", "features", "irrespective", "of", "their", "location", ",", "while", "preserving", "the", "location", "where", "the", "useful", "features", "appeared", ".", "We", "regard", "the", "output", "of", "a", "convolution", "layer", "as", "an", "\u2018", "image", "\u2019", "so", "that", "the", "output", "of", "each", "computation", "unit", "is", "considered", "to", "be", "a", "\u2018", "pixel", "\u2019", "of", "channels", "where", "is", "the", "number", "of", "weight", "vectors", "(", "i.e.", ",", "the", "number", "of", "rows", "of", ")", "or", "the", "number", "of", "neurons", ".", "In", "other", "words", ",", "a", "convolution", "layer", "converts", "image", "regions", "to", "m", "-", "dim", "vectors", ",", "and", "the", "locations", "of", "the", "regions", "are", "inherited", "through", "this", "conversion", ".", "The", "output", "image", "of", "the", "convolution", "layer", "is", "passed", "to", "a", "pooling", "layer", ",", "which", "essentially", "shrinks", "the", "image", "by", "merging", "neighboring", "pixels", ",", "so", "that", "higher", "layers", "can", "deal", "with", "more", "abstract", "/", "global", "information", ".", "A", "pooling", "layer", "consists", "of", "pooling", "units", ",", "each", "of", "which", "is", "associated", "with", "a", "small", "region", "of", "the", "image", ".", "Commonly", "-", "used", "merging", "methods", "are", "average", "-", "pooling", "and", "max", "-", "pooling", ",", "which", "respectively", "compute", "the", "channel", "-", "wise", "average", "/", "maximum", "of", "each", "region", ".", "subsection", ":", "CNN", "for", "text", "Now", "we", "consider", "application", "of", "CNN", "to", "text", "data", ".", "Suppose", "that", "we", "are", "given", "a", "document", "with", "vocabulary", ".", "CNN", "requires", "vector", "representation", "of", "data", "that", "preserves", "internal", "locations", "(", "word", "order", "in", "this", "case", ")", "as", "input", ".", "A", "straightforward", "representation", "would", "be", "to", "treat", "each", "word", "as", "a", "pixel", ",", "treat", "as", "if", "it", "were", "an", "image", "of", "pixels", "with", "channels", ",", "and", "to", "represent", "each", "pixel", "(", "i.e.", ",", "each", "word", ")", "as", "a", "-", "dimensional", "one", "-", "hot", "vector", ".", "As", "a", "running", "toy", "example", ",", "suppose", "that", "vocabulary", "\u201c", "do", "n\u2019t", "\u201d", ",", "\u201c", "hate", "\u201d", ",", "\u201c", "I", "\u201d", ",", "\u201c", "it", "\u201d", ",", "\u201c", "love", "\u201d", "and", "we", "associate", "the", "words", "with", "dimensions", "of", "vector", "in", "alphabetical", "order", "(", "as", "shown", ")", ",", "and", "that", "document", "=", "\u201c", "I", "love", "it", "\u201d", ".", "Then", ",", "we", "have", "a", "document", "vector", ":", "subsubsection", ":", "seq", "-", "CNN", "for", "text", "As", "in", "the", "convolution", "layer", "for", "image", ",", "we", "represent", "each", "region", "(", "which", "each", "computation", "unit", "responds", "to", ")", "by", "a", "concatenation", "of", "the", "pixels", ",", "which", "makes", "-", "dimensional", "region", "vectors", "where", "is", "the", "region", "size", "fixed", "in", "advance", ".", "For", "example", ",", "on", "the", "example", "document", "vector", "above", ",", "with", "and", "stride", "1", ",", "we", "would", "have", "two", "regions", "\u201c", "I", "love", "\u201d", "and", "\u201c", "love", "it", "\u201d", "represented", "by", "the", "following", "vectors", ":", "The", "rest", "is", "the", "same", "as", "image", ";", "the", "text", "region", "vectors", "are", "converted", "to", "feature", "vectors", ",", "i.e.", ",", "the", "convolution", "layer", "learns", "to", "embed", "text", "regions", "into", "low", "-", "dimensional", "vector", "space", ".", "We", "call", "a", "neural", "net", "with", "a", "convolution", "layer", "with", "this", "region", "representation", "seq", "-", "CNN", "(", "\u2018", "seq", "\u2019", "for", "keeping", "sequences", "of", "words", ")", "to", "distinguish", "it", "from", "bow", "-", "CNN", ",", "described", "next", ".", "subsubsection", ":", "bow", "-", "CNN", "for", "text", "A", "potential", "problem", "of", "seq", "-", "CNN", "however", ",", "is", "that", "unlike", "image", "data", "with", "3", "RGB", "channels", ",", "the", "number", "of", "\u2018", "channels", "\u2019", "(", "size", "of", "vocabulary", ")", "may", "be", "very", "large", "(", "e.g.", ",", "100", "K", ")", ",", "which", "could", "make", "each", "region", "vector", "very", "high", "-", "dimensional", "if", "the", "region", "size", "is", "large", ".", "Since", "the", "dimensionality", "of", "region", "vectors", "determines", "the", "dimensionality", "of", "weight", "vectors", ",", "having", "high", "-", "dimensional", "region", "vectors", "means", "more", "parameters", "to", "learn", ".", "If", "is", "too", "large", ",", "the", "model", "becomes", "too", "complex", "(", "w.r.t", ".", "the", "amount", "of", "training", "data", "available", ")", "and", "/", "or", "training", "becomes", "unaffordably", "expensive", "even", "with", "efficient", "handling", "of", "sparse", "data", ";", "therefore", ",", "one", "has", "to", "lower", "the", "dimensionality", "by", "lowering", "the", "vocabulary", "size", "and", "/", "or", "the", "region", "size", ",", "which", "may", "or", "may", "not", "be", "desirable", ",", "depending", "on", "the", "nature", "of", "the", "task", ".", "An", "alternative", "we", "provide", "is", "to", "perform", "bag", "-", "of", "-", "word", "conversion", "to", "make", "region", "vectors", "-", "dimensional", "instead", "of", "-", "dimensional", ";", "e.g.", ",", "the", "example", "region", "vectors", "above", "would", "be", "converted", "to", ":", "With", "this", "representation", ",", "we", "have", "fewer", "parameters", "to", "learn", ".", "Essentially", ",", "the", "expressiveness", "of", "bow", "-", "convolution", "(", "which", "loses", "word", "order", "only", "within", "small", "regions", ")", "is", "somewhere", "between", "seq", "-", "convolution", "and", "bow", "vectors", ".", "subsubsection", ":", "Pooling", "for", "text", "Whereas", "the", "size", "of", "images", "is", "fixed", "in", "image", "applications", ",", "documents", "are", "naturally", "variable", "-", "sized", ",", "and", "therefore", ",", "with", "a", "fixed", "stride", ",", "the", "output", "of", "a", "convolution", "layer", "is", "also", "variable", "-", "sized", "as", "shown", "in", "Figure", "[", "reference", "]", ".", "Given", "the", "variable", "-", "sized", "output", "of", "the", "convolution", "layer", ",", "standard", "pooling", "for", "image", "(", "which", "uses", "a", "fixed", "pooling", "region", "size", "and", "a", "fixed", "stride", ")", "would", "produce", "variable", "-", "sized", "output", ",", "which", "can", "be", "passed", "to", "another", "convolution", "layer", ".", "To", "produce", "fixed", "-", "sized", "output", ",", "which", "is", "required", "by", "the", "fully", "-", "connected", "top", "layer", ",", "we", "fix", "the", "number", "of", "pooling", "units", "and", "dynamically", "determine", "the", "pooling", "region", "size", "on", "each", "data", "point", "so", "that", "the", "entire", "data", "is", "covered", "without", "overlapping", ".", "In", "the", "previous", "CNN", "work", "on", "text", ",", "pooling", "is", "typically", "max", "-", "pooling", "over", "the", "entire", "data", "(", "i.e.", ",", "one", "pooling", "unit", "associated", "with", "the", "whole", "text", ")", ".", "The", "dynamic", "k", "-", "max", "pooling", "of", "for", "sentence", "modeling", "extends", "it", "to", "take", "the", "largest", "values", "where", "is", "a", "function", "of", "the", "sentence", "length", ",", "but", "it", "is", "again", "over", "the", "entire", "data", ",", "and", "the", "operation", "is", "limited", "to", "max", "-", "pooling", ".", "Our", "pooling", "differs", "in", "that", "it", "is", "a", "natural", "extension", "of", "standard", "pooling", "for", "image", ",", "in", "which", "not", "only", "max", "-", "pooling", "but", "other", "types", "can", "be", "applied", ".", "With", "multiple", "pooling", "units", "associated", "with", "different", "regions", ",", "the", "top", "layer", "can", "receive", "locational", "information", "(", "e.g.", ",", "if", "there", "are", "two", "pooling", "units", ",", "the", "features", "from", "the", "first", "half", "and", "last", "half", "of", "a", "document", "are", "distinguished", ")", ".", "This", "turned", "out", "to", "be", "useful", "(", "along", "with", "average", "-", "pooling", ")", "on", "topic", "classification", ",", "as", "shown", "later", ".", "subsection", ":", "CNN", "vs.", "bag", "-", "of", "-", "-", "grams", "Traditional", "methods", "represent", "each", "document", "entirely", "with", "one", "bag", "-", "of", "-", "-", "gram", "vector", "and", "then", "apply", "a", "classifier", "model", "such", "as", "SVM", ".", "However", ",", "since", "high", "-", "order", "-", "grams", "are", "susceptible", "to", "data", "sparsity", ",", "use", "of", "a", "large", "such", "as", "20", "is", "not", "only", "infeasible", "but", "also", "ineffective", ".", "Also", "note", "that", "a", "bag", "-", "of", "-", "-", "gram", "represents", "each", "-", "gram", "by", "a", "one", "-", "hot", "vector", "and", "ignores", "the", "fact", "that", "some", "-", "grams", "share", "constituent", "words", ".", "By", "contrast", ",", "CNN", "internally", "learns", "embedding", "of", "text", "regions", "(", "given", "the", "consituent", "words", "as", "input", ")", "useful", "for", "the", "intended", "task", ".", "Consequently", ",", "a", "large", "such", "as", "20", "can", "be", "used", "especially", "with", "the", "bow", "-", "convolution", "layer", ",", "which", "turned", "out", "to", "be", "useful", "on", "topic", "classification", ".", "A", "neuron", "trained", "to", "assign", "a", "large", "value", "to", ",", "e.g.", ",", "\u201c", "I", "love", "\u201d", "(", "and", "a", "small", "value", "to", "\u201c", "I", "hate", "\u201d", ")", "is", "likely", "to", "assign", "a", "large", "value", "to", "\u201c", "we", "love", "\u201d", "(", "and", "a", "small", "value", "to", "\u201c", "we", "hate", "\u201d", ")", "as", "well", ",", "even", "though", "\u201c", "we", "love", "\u201d", "was", "never", "seen", "during", "training", ".", "We", "will", "confirm", "these", "points", "empirically", "later", ".", "subsection", ":", "Extension", ":", "parallel", "CNN", "We", "have", "described", "CNN", "with", "the", "simplest", "network", "architecture", "that", "has", "one", "pair", "of", "convolution", "and", "pooling", "layers", ".", "While", "this", "can", "be", "extended", "in", "several", "ways", "(", "e.g.", ",", "with", "deeper", "layers", ")", ",", "in", "our", "experiments", ",", "we", "explored", "parallel", "CNN", ",", "which", "has", "two", "or", "more", "convolution", "layers", "in", "parallel", ",", "as", "illustrated", "in", "Figure", "[", "reference", "]", ".", "The", "idea", "is", "to", "learn", "multiple", "types", "of", "embedding", "of", "small", "text", "regions", "so", "that", "they", "can", "complement", "each", "other", "to", "improve", "model", "accuracy", ".", "In", "this", "architecture", ",", "multiple", "convolution", "-", "pooling", "pairs", "with", "different", "region", "sizes", "(", "and", "possibly", "different", "region", "vector", "representations", ")", "are", "given", "one", "-", "hot", "vectors", "as", "input", "and", "produce", "feature", "vectors", "for", "each", "region", ";", "the", "top", "layer", "takes", "the", "concatenation", "of", "the", "produced", "feature", "vectors", "as", "input", ".", "section", ":", "Experiments", "We", "experimented", "with", "CNN", "on", "two", "tasks", ",", "topic", "classification", "and", "sentiment", "classification", ".", "Detailed", "information", "for", "reproducing", "the", "results", "is", "available", "on", "the", "internet", "along", "with", "our", "code", ".", "subsection", ":", "CNN", "We", "fixed", "the", "activation", "function", "to", "rectifier", "and", "minimized", "square", "loss", "with", "regularization", "by", "stochastic", "gradient", "descent", "(", "SGD", ")", ".", "We", "only", "used", "the", "30", "K", "words", "that", "appeared", "most", "frequently", "in", "the", "training", "set", ";", "thus", ",", "for", "example", ",", "in", "seq", "-", "CNN", "with", "region", "size", "3", ",", "a", "region", "vector", "is", "90", "K", "dimensional", ".", "Out", "-", "of", "-", "vocabulary", "words", "were", "represented", "by", "a", "zero", "vector", ".", "On", "bow", "-", "CNN", ",", "to", "speed", "up", "computation", ",", "we", "used", "variable", "region", "stride", "so", "that", "a", "larger", "stride", "was", "taken", "where", "repetition", "of", "the", "same", "region", "vectors", "can", "be", "avoided", "by", "doing", "so", ".", "Padding", "size", "was", "fixed", "to", "where", "is", "the", "region", "size", ".", "We", "used", "two", "techniques", "commonly", "used", "with", "CNN", "on", "image", ",", "which", "typically", "led", "to", "small", "performance", "improvements", ".", "One", "is", "dropout", "optionally", "applied", "to", "the", "input", "to", "the", "top", "layer", ".", "The", "other", "is", "response", "normalization", "as", "in", ",", "which", "in", "our", "case", "scales", "the", "output", "of", "the", "pooling", "layer", "at", "each", "location", "by", "multiplying", ".", "subsection", ":", "Baseline", "methods", "For", "comparison", ",", "we", "tested", "SVM", "with", "the", "linear", "kernel", "and", "fully", "-", "connected", "neural", "networks", "(", "see", "e.g.", ",", "Bishop95", ")", "with", "bag", "-", "of", "-", "-", "gram", "vectors", "as", "input", ".", "To", "experiment", "with", "fully", "-", "connected", "neural", "nets", ",", "as", "in", "CNN", ",", "we", "minimized", "square", "loss", "with", "regularization", "and", "optional", "dropout", "by", "SGD", ",", "and", "activation", "was", "fixed", "to", "rectifier", ".", "To", "generate", "bag", "-", "of", "-", "-", "gram", "vectors", ",", "on", "topic", "classification", ",", "we", "first", "set", "each", "component", "to", "where", "is", "the", "word", "frequency", "in", "the", "document", "and", "then", "scaled", "them", "to", "unit", "vectors", ",", "which", "we", "found", "always", "improved", "performance", "over", "raw", "frequency", ".", "On", "sentiment", "classification", ",", "as", "is", "often", "done", ",", "we", "generated", "binary", "vectors", "and", "scaled", "them", "to", "unit", "vectors", ".", "We", "tested", "three", "types", "of", "bag", "-", "of", "-", "-", "gram", ":", "bow1", "with", ",", "bow2", "with", ",", "and", "bow3", "with", ";", "that", "is", ",", "bow1", "is", "the", "traditional", "bow", "vectors", ",", "and", "with", "bow3", ",", "each", "component", "of", "the", "vectors", "corresponds", "to", "either", "uni", "-", "gram", ",", "bi", "-", "gram", ",", "or", "tri", "-", "gram", "of", "words", ".", "We", "used", "SVMlight", "for", "the", "SVM", "experiments", ".", "paragraph", ":", "NB", "-", "LM", "We", "also", "tested", "NB", "-", "LM", ",", "which", "first", "appeared", "(", "but", "without", "performance", "report", ")", "as", "NBSVM", "in", "WM12", "and", "later", "with", "a", "small", "modification", "produced", "performance", "that", "exceeds", "state", "-", "of", "-", "the", "-", "art", "supervised", "methods", "on", "IMDB", "(", "which", "we", "experimented", "with", ")", "in", "MMRB14", ".", "We", "experimented", "with", "the", "MMRB14", "version", ",", "which", "generates", "binary", "bag", "-", "of", "-", "-", "gram", "vectors", ",", "multiplies", "the", "component", "for", "each", "-", "gram", "with", "(", "NB", "-", "weight", ")", "where", "the", "probabilities", "are", "estimated", "using", "the", "training", "data", ",", "and", "does", "logistic", "regression", "training", ".", "We", "used", "MMRB14", "\u2019s", "software", "with", "a", "modification", "so", "that", "the", "regularization", "parameter", "can", "be", "tuned", "on", "development", "data", ".", "subsection", ":", "Model", "selection", "For", "all", "the", "methods", ",", "the", "hyper", "-", "parameters", "such", "as", "net", "configurations", "and", "regularization", "parameters", "were", "chosen", "based", "on", "the", "performance", "on", "the", "development", "data", "(", "held", "-", "out", "portion", "of", "the", "training", "data", ")", ",", "and", "using", "the", "chosen", "hyper", "-", "parameters", ",", "the", "models", "were", "re", "-", "trained", "using", "all", "the", "training", "data", ".", "subsection", ":", "Data", ",", "tasks", ",", "and", "data", "preprocessing", "paragraph", ":", "IMDB", ":", "movie", "reviews", "The", "IMDB", "dataset", "is", "a", "benchmark", "dataset", "for", "sentiment", "classification", ".", "The", "task", "is", "to", "determine", "if", "the", "movie", "reviews", "are", "positive", "or", "negative", ".", "Both", "the", "training", "and", "test", "sets", "consist", "of", "25", "K", "reviews", ".", "For", "preprocessing", ",", "we", "tokenized", "the", "text", "so", "that", "emoticons", "such", "as", "\u201c", ":", "-)", "\u201d", "are", "treated", "as", "tokens", "and", "converted", "all", "the", "characters", "to", "lower", "case", ".", "paragraph", ":", "Elec", ":", "electronics", "product", "reviews", "Elec", "consists", "of", "electronic", "product", "reviews", ".", "It", "is", "part", "of", "a", "large", "Amazon", "review", "dataset", ".", "We", "chose", "electronics", "as", "it", "seemed", "to", "be", "very", "different", "from", "movies", ".", "Following", "the", "generation", "of", "IMDB", ",", "we", "chose", "the", "training", "set", "and", "the", "test", "set", "so", "that", "one", "half", "of", "each", "set", "consists", "of", "positive", "reviews", "and", "the", "other", "half", "is", "negative", ",", "regarding", "rating", "1", "and", "2", "as", "negative", "and", "4", "and", "5", "as", "positive", ",", "and", "that", "the", "reviewed", "products", "are", "disjoint", "between", "the", "training", "set", "and", "test", "set", ".", "Note", "that", "to", "extract", "text", "from", "the", "original", "data", ",", "we", "only", "used", "the", "text", "section", ",", "and", "we", "did", "not", "use", "the", "summary", "section", ".", "This", "way", ",", "we", "obtained", "a", "test", "set", "of", "25", "K", "reviews", "(", "same", "as", "IMDB", ")", "and", "training", "sets", "of", "various", "sizes", ".", "The", "training", "and", "test", "sets", "are", "available", "on", "the", "internet", ".", "Data", "preprocessing", "was", "the", "same", "as", "IMDB", ".", "paragraph", ":", "RCV1", ":", "topic", "categorization", "RCV1", "is", "a", "corpus", "of", "Reuters", "news", "articles", "as", "described", "in", "LYRL04", ".", "RCV1", "has", "103", "topic", "categories", "in", "a", "hierarchy", ",", "and", "one", "document", "may", "be", "associated", "with", "more", "than", "one", "topic", ".", "Performance", "on", "this", "task", "(", "multi", "-", "label", "categorization", ")", "is", "known", "to", "be", "sensitive", "to", "thresholding", "strategies", ",", "which", "are", "algorithms", "additional", "to", "the", "models", "we", "would", "like", "to", "test", ".", "Therefore", ",", "we", "also", "experimented", "with", "single", "-", "label", "categorization", "to", "assign", "one", "of", "55", "second", "-", "level", "topics", "to", "each", "document", "to", "directly", "evaluate", "models", ".", "For", "this", "task", ",", "we", "used", "the", "documents", "from", "a", "one", "-", "month", "period", "as", "the", "test", "set", "and", "generated", "various", "sizes", "of", "training", "sets", "from", "the", "documents", "with", "earlier", "dates", ".", "Data", "sizes", "are", "shown", "in", "Table", "[", "reference", "]", ".", "As", "in", "LYRL04", ",", "we", "used", "the", "concatenation", "of", "the", "headline", "and", "text", "elements", ".", "Data", "preprocessing", "was", "the", "same", "as", "IMDB", "except", "that", "we", "used", "the", "stopword", "list", "provided", "by", "LYRL04", "and", "regarded", "numbers", "as", "stopwords", ".", "subsection", ":", "Performance", "results", "Table", "[", "reference", "]", "shows", "the", "error", "rates", "of", "CNN", "in", "comparison", "with", "the", "baseline", "methods", ".", "The", "first", "thing", "to", "note", "is", "that", "on", "all", "the", "datasets", ",", "the", "best", "-", "performing", "CNN", "outperforms", "the", "baseline", "methods", ",", "which", "demonstrates", "the", "effectiveness", "of", "our", "approach", ".", "To", "look", "into", "the", "details", ",", "let", "us", "first", "focus", "on", "CNN", "with", "one", "convolution", "layer", "(", "seq", "-", "and", "bow", "-", "CNN", "in", "the", "table", ")", ".", "On", "sentiment", "classification", "(", "IMDB", "and", "Elec", ")", ",", "the", "configuration", "chosen", "by", "model", "selection", "was", ":", "region", "size", "3", ",", "stride", "1", ",", "1000", "weight", "vectors", ",", "and", "max", "-", "pooling", "with", "one", "pooling", "unit", ",", "for", "both", "types", "of", "CNN", ";", "seq", "-", "CNN", "outperforms", "bow", "-", "CNN", ",", "as", "well", "as", "all", "the", "baseline", "methods", "except", "for", "one", ".", "Note", "that", "with", "a", "small", "region", "size", "and", "max", "-", "pooling", ",", "if", "a", "review", "contains", "a", "short", "phrase", "that", "conveys", "strong", "sentiment", "(", "e.g.", ",", "\u201c", "A", "great", "movie", "!", "\u201d", ")", ",", "the", "review", "could", "receive", "a", "high", "score", "irrespective", "of", "the", "rest", "of", "the", "review", ".", "It", "is", "sensible", "that", "this", "type", "of", "configuration", "is", "effective", "on", "sentiment", "classification", ".", "By", "contrast", ",", "on", "topic", "categorization", "(", "RCV1", ")", ",", "the", "configuration", "chosen", "for", "bow", "-", "CNN", "by", "model", "selection", "was", ":", "region", "size", "20", ",", "variable", "-", "stride", "2", ",", "average", "-", "pooling", "with", "10", "pooling", "units", ",", "and", "1000", "weight", "vectors", ",", "which", "is", "very", "different", "from", "sentiment", "classification", ".", "This", "is", "presumably", "because", "on", "topic", "classification", ",", "a", "larger", "context", "would", "be", "more", "predictive", "than", "short", "fragments", "(", "larger", "region", "size", ")", ",", "the", "entire", "document", "matters", "(", "the", "effectiveness", "of", "average", "-", "pooling", ")", ",", "and", "the", "location", "of", "predictive", "text", "also", "matters", "(", "multiple", "pooling", "units", ")", ".", "The", "last", "point", "may", "be", "because", "news", "documents", "tend", "to", "have", "crucial", "sentences", "(", "as", "well", "as", "the", "headline", ")", "at", "the", "beginning", ".", "On", "this", "task", ",", "while", "both", "seq", "and", "bow", "-", "CNN", "outperform", "the", "baseline", "methods", ",", "bow", "-", "CNN", "outperforms", "seq", "-", "CNN", ",", "which", "indicates", "that", "in", "this", "setting", "the", "merit", "of", "having", "fewer", "parameters", "is", "larger", "than", "the", "benefit", "of", "keeping", "word", "order", "in", "each", "region", ".", "Now", "we", "turn", "to", "parallel", "CNN", ".", "On", "IMDB", ",", "seq2", "-", "CNN", ",", "which", "has", "two", "seq", "-", "convolution", "layers", "(", "region", "size", "2", "and", "3", ";", "1000", "neurons", "each", ";", "followed", "by", "one", "unit", "of", "max", "-", "pooling", "each", ")", ",", "outperforms", "seq", "-", "CNN", ".", "With", "more", "neurons", "(", "3000", "neurons", "each", ";", "Table", "[", "reference", "]", ")", "it", "further", "exceeds", "the", "best", "-", "performing", "baseline", ",", "which", "is", "also", "the", "best", "previous", "supervised", "result", ".", "We", "presume", "the", "effectiveness", "of", "seq2", "-", "CNN", "indicates", "that", "the", "length", "of", "predictive", "text", "regions", "is", "variable", ".", "The", "best", "performance", "7.67", "on", "IMDB", "was", "obtained", "by", "\u2018", "seq2", "-", "bow", "-", "CNN", "\u2019", ",", "equipped", "with", "three", "layers", "in", "parallel", ":", "two", "seq", "-", "convolution", "layers", "(", "1000", "neurons", "each", ")", "as", "in", "seq2", "-", "CNN", "above", "and", "one", "layer", "(", "20", "neurons", ")", "that", "regards", "the", "entire", "document", "as", "one", "region", "and", "represents", "the", "region", "(", "document", ")", "by", "a", "bag", "-", "of", "-", "-", "gram", "vector", "(", "bow3", ")", "as", "input", "to", "the", "computation", "unit", ";", "in", "particular", ",", "we", "generated", "bow3", "vectors", "by", "multiplying", "the", "NB", "-", "weights", "with", "binary", "vectors", ",", "motivated", "by", "the", "good", "performance", "of", "NB", "-", "LM", ".", "This", "third", "layer", "is", "a", "bow", "-", "convolution", "layer", "with", "one", "region", "of", "variable", "size", "that", "takes", "one", "-", "hot", "vectors", "with", "-", "gram", "vocabulary", "as", "input", "to", "learn", "document", "embedding", ".", "The", "seq2", "-", "bow", "-", "CNN", "for", "Elec", "in", "the", "table", "is", "the", "same", "except", "that", "the", "regions", "sizes", "of", "seq", "-", "convolution", "layers", "are", "3", "and", "4", ".", "On", "both", "datasets", ",", "performance", "is", "improved", "over", "seq2", "-", "CNN", ".", "The", "results", "suggest", "that", "what", "can", "be", "learned", "through", "these", "three", "layers", "are", "distinct", "enough", "to", "complement", "each", "other", ".", "The", "effectiveness", "of", "the", "third", "layer", "indicates", "that", "not", "only", "short", "word", "sequences", "but", "also", "global", "context", "in", "a", "large", "window", "may", "be", "useful", "on", "this", "task", ";", "thus", ",", "inclusion", "of", "a", "bow", "-", "convolution", "layer", "with", "-", "gram", "vocabulary", "with", "a", "large", "fixed", "region", "size", "might", "be", "even", "more", "effective", ",", "providing", "more", "focused", "context", ",", "but", "we", "did", "not", "pursue", "it", "in", "this", "work", ".", "paragraph", ":", "Baseline", "methods", "Comparing", "the", "baseline", "methods", "with", "each", "other", ",", "on", "sentiment", "classification", ",", "reducing", "the", "vocabulary", "to", "the", "most", "frequent", "-", "grams", "notably", "hurt", "performance", "(", "also", "observed", "on", "NB", "-", "LM", "and", "NN", ")", "even", "though", "some", "reduction", "is", "a", "common", "practice", ".", "Error", "rates", "were", "clearly", "improved", "by", "addition", "of", "bi", "-", "and", "tri", "-", "grams", ".", "By", "contrast", ",", "on", "topic", "categorization", ",", "bi", "-", "grams", "only", "slightly", "improved", "accuracy", ",", "and", "reduction", "of", "vocabulary", "did", "not", "hurt", "performance", ".", "NB", "-", "LM", "is", "very", "strong", "on", "IMDB", "and", "poor", "on", "RCV1", ";", "its", "effectiveness", "appears", "to", "be", "data", "-", "dependent", ",", "as", "also", "observed", "by", "WM12", ".", "paragraph", ":", "Comparison", "with", "state", "-", "of", "-", "the", "-", "art", "results", "As", "shown", "in", "Table", "[", "reference", "]", ",", "the", "previous", "best", "supervised", "result", "on", "IMDB", "is", "8.13", "by", "NB", "-", "LM", "with", "bow3", "(", "MMRB14", ")", ",", "and", "our", "best", "error", "rate", "7.67", "is", "better", "by", "nearly", "0.5", "%", ".", "reports", "7.46", "with", "the", "semi", "-", "supervised", "method", "that", "learns", "low", "-", "dimensional", "vector", "representations", "of", "documents", "from", "unlabeled", "data", ".", "Their", "result", "is", "not", "directly", "comparable", "with", "our", "supervised", "results", "due", "to", "use", "of", "additional", "resource", ".", "Nevertheless", ",", "our", "best", "result", "rivals", "their", "result", ".", "We", "tested", "bow", "-", "CNN", "on", "the", "multi", "-", "label", "topic", "categorization", "task", "on", "RCV1", "to", "compare", "with", "LYRL04", ".", "We", "used", "the", "same", "thresholding", "strategy", "as", "LYRL04", ".", "As", "shown", "in", "Table", "[", "reference", "]", ",", "bow", "-", "CNN", "outperforms", "LYRL04", "\u2019s", "best", "results", "even", "though", "our", "data", "preprocessing", "is", "much", "simpler", "(", "no", "stemming", "and", "no", "tf", "-", "idf", "weighting", ")", ".", "paragraph", ":", "Previous", "CNN", "We", "focus", "on", "the", "sentence", "classification", "studies", "due", "to", "its", "relation", "to", "text", "categorization", ".", "Kim14", "studied", "fine", "-", "tuning", "of", "pre", "-", "trained", "word", "vectors", "to", "produce", "input", "to", "parallel", "CNN", ".", "He", "reported", "that", "performance", "was", "poor", "when", "word", "vectors", "were", "trained", "as", "part", "of", "CNN", "training", "(", "i.e.", ",", "no", "additional", "method", "/", "corpus", ")", ".", "On", "our", "tasks", ",", "we", "were", "also", "unable", "to", "outperform", "the", "baselines", "with", "this", "type", "of", "model", ".", "Also", ",", "with", "our", "approach", ",", "a", "system", "is", "simpler", "with", "one", "fewer", "layer", "\u2013", "no", "need", "to", "tune", "the", "dimensionality", "of", "word", "vectors", "or", "meta", "-", "parameters", "for", "word", "vector", "learning", ".", "KGB14", "proposed", "complex", "modifications", "of", "CNN", "for", "sentence", "modeling", ".", "Notably", ",", "given", "word", "vectors", ",", "their", "convolution", "with", "feature", "maps", "produces", "for", "each", "region", "a", "matrix", "(", "instead", "of", "a", "vector", "as", "in", "standard", "CNN", ")", ".", "Using", "the", "provided", "code", ",", "we", "found", "that", "their", "model", "is", "too", "resource", "-", "demanding", "for", "our", "tasks", ".", "On", "IMDB", "and", "Elec", "the", "best", "error", "rates", "we", "obtained", "by", "training", "with", "various", "configurations", "that", "fit", "in", "memory", "for", "24", "hours", "each", "on", "GPU", "(", "cf", ".", "Fig", "[", "reference", "]", ")", "were", "10.13", "and", "9.37", ",", "respectively", ",", "which", "is", "no", "better", "than", "SVM", "bow2", ".", "Since", "excellent", "performances", "were", "reported", "on", "short", "sentence", "classification", ",", "we", "presume", "that", "their", "model", "is", "optimized", "for", "short", "sentences", ",", "but", "not", "for", "text", "categorization", "in", "general", ".", "paragraph", ":", "Performance", "dependency", "CNN", "training", "is", "known", "to", "be", "expensive", ",", "compared", "with", ",", "e.g.", ",", "linear", "models", "\u2013", "linear", "SVM", "with", "bow3", "on", "IMDB", "only", "takes", "9", "minutes", "using", "SVMlight", "(", "single", "-", "core", ")", "on", "a", "high", "-", "end", "Intel", "CPU", ".", "Nevertheless", ",", "with", "our", "code", "on", "GPU", ",", "CNN", "training", "only", "takes", "minutes", "(", "to", "a", "few", "hours", ")", "on", "these", "datasets", "shown", "in", "Figure", "[", "reference", "]", ".", "Finally", ",", "the", "results", "with", "training", "sets", "of", "various", "sizes", "on", "Elec", "and", "RCV1", "are", "shown", "in", "Figure", "[", "reference", "]", ".", "subsection", ":", "Why", "is", "CNN", "effective", "?", "In", "this", "section", "we", "explain", "the", "effectiveness", "of", "CNN", "through", "looking", "into", "what", "it", "learns", "from", "training", ".", "First", ",", "for", "comparison", ",", "we", "show", "the", "-", "grams", "that", "SVM", "with", "bow3", "found", "to", "be", "the", "most", "predictive", ";", "i.e.", ",", "the", "following", "-", "grams", "were", "assigned", "the", "10", "largest", "weights", "by", "SVM", "with", "binary", "features", "on", "Elec", "for", "the", "negative", "and", "positive", "class", ",", "respectively", ":", "poor", ",", "useless", ",", "returned", ",", "not", "worth", ",", "return", ",", "worse", ",", "disappointed", ",", "terrible", ",", "worst", ",", "horrible", "great", ",", "excellent", ",", "perfect", ",", "love", ",", "easy", ",", "amazing", ",", "awesome", ",", "no", "problems", ",", "perfectly", ",", "beat", "Note", "that", ",", "even", "though", "SVM", "was", "also", "given", "bi", "-", "and", "tri", "-", "grams", ",", "the", "top", "10", "features", "chosen", "by", "SVM", "with", "binary", "features", "are", "mostly", "uni", "-", "grams", ";", "furthermore", ",", "the", "top", "100", "features", "(", "50", "for", "each", "class", ")", "include", "28", "bi", "-", "grams", "but", "only", "four", "tri", "-", "grams", ".", "This", "means", "that", ",", "with", "the", "given", "size", "of", "training", "data", ",", "SVM", "still", "heavily", "counts", "on", "uni", "-", "grams", ",", "which", "could", "be", "ambiguous", ",", "and", "can", "not", "fully", "take", "advantage", "of", "higher", "-", "order", "-", "grams", ".", "By", "contrast", ",", "NB", "-", "weights", "tend", "to", "promote", "-", "grams", "with", "a", "larger", ";", "the", "100", "features", "that", "were", "assigned", "the", "largest", "NB", "-", "weights", "are", "7", "uni", "-", ",", "33", "bi", "-", ",", "and", "60", "tri", "-", "grams", ".", "However", ",", "as", "seen", "above", ",", "NB", "-", "weights", "do", "not", "always", "lead", "to", "the", "best", "performance", ".", "In", "Table", "[", "reference", "]", ",", "we", "show", "some", "of", "text", "regions", "learned", "by", "seq", "-", "CNN", "to", "be", "predictive", "on", "Elec", ".", "This", "net", "has", "one", "convolution", "layer", "with", "region", "size", "3", "and", "1000", "neurons", ";", "thus", ",", "embedding", "by", "the", "convolution", "layer", "produces", "a", "1000", "-", "dim", "vector", "for", "each", "region", ",", "which", "(", "after", "pooling", ")", "serves", "as", "features", "in", "the", "top", "layer", "where", "weights", "are", "assigned", "to", "the", "1000", "vector", "components", ".", "In", "the", "table", ",", "N", "/", "P", "indicates", "the", "component", "that", "received", "the", "-", "th", "highest", "weight", "in", "the", "top", "layer", "for", "the", "negative", "/", "positive", "class", ",", "respectively", ".", "The", "table", "shows", "the", "text", "regions", "(", "in", "the", "training", "set", ")", "whose", "embedded", "vectors", "have", "a", "large", "value", "in", "the", "corresponding", "component", ",", "i.e.", ",", "predictive", "text", "regions", ".", "Note", "that", "the", "embedded", "vectors", "for", "the", "text", "regions", "listed", "in", "the", "same", "row", "are", "close", "to", "each", "other", "as", "they", "have", "a", "large", "value", "in", "the", "same", "component", ".", "That", "is", ",", "Table", "[", "reference", "]", "also", "shows", "that", "the", "proximity", "of", "the", "embedded", "vectors", "tends", "to", "reflect", "the", "proximity", "in", "terms", "of", "the", "relations", "to", "the", "target", "classes", "(", "positive", "/", "negative", "sentiment", ")", ".", "This", "is", "the", "effect", "of", "embedding", ",", "which", "helps", "classification", "by", "the", "top", "layer", ".", "With", "the", "bag", "-", "of", "-", "-", "gram", "representation", ",", "only", "the", "-", "grams", "that", "appear", "in", "the", "training", "data", "can", "participate", "in", "prediction", ".", "By", "contrast", ",", "one", "strength", "of", "CNN", "is", "that", "-", "grams", "(", "or", "text", "regions", "of", "size", ")", "can", "contribute", "to", "accurate", "prediction", "even", "if", "they", "did", "not", "appear", "in", "the", "training", "data", ",", "as", "long", "as", "(", "some", "of", ")", "their", "constituent", "words", "did", ",", "because", "input", "of", "embedding", "is", "the", "constituent", "words", "of", "the", "region", ".", "To", "see", "this", "point", ",", "in", "Table", "[", "reference", "]", "we", "show", "the", "text", "regions", "from", "the", "test", "set", ",", "which", "did", "not", "appear", "in", "the", "training", "data", ",", "either", "entirely", "or", "partially", "as", "bi", "-", "grams", ",", "and", "yet", "whose", "embedded", "features", "have", "large", "values", "in", "the", "heavily", "-", "weighted", "(", "predictive", ")", "component", "thus", "contributing", "to", "the", "prediction", ".", "There", "are", "many", "more", "of", "these", ",", "and", "we", "only", "show", "a", "small", "part", "of", "them", "that", "fit", "certain", "patterns", ".", "One", "noticeable", "pattern", "is", "(", "be", "-", "verb", ",", "adverb", ",", "sentiment", "adjective", ")", "such", "as", "\u201c", "am", "entirely", "satisfied", "\u201d", "and", "\u201c", "\u2019", "m", "overall", "impressed", "\u201d", ".", "These", "adjectives", "alone", "could", "be", "ambiguous", "as", "they", "may", "be", "negated", ".", "To", "know", "that", "the", "writer", "is", "indeed", "\u201c", "satisfied", "\u201d", ",", "we", "need", "to", "see", "the", "sequence", "\u201c", "am", "satisfied", "\u201d", ",", "but", "the", "insertion", "of", "adverb", "such", "as", "\u201c", "entirely", "\u201d", "is", "very", "common", ".", "\u201c", "best", "X", "ever", "\u2019", "is", "another", "pattern", "that", "a", "discriminating", "pair", "of", "words", "are", "not", "adjacent", "to", "each", "other", ".", "These", "patterns", "require", "tri", "-", "grams", "for", "disambiguation", ",", "and", "seq", "-", "CNN", "successfully", "makes", "use", "of", "them", "even", "though", "the", "exact", "tri", "-", "grams", "were", "not", "seen", "during", "training", ",", "as", "a", "result", "of", "learning", ",", "e.g.", ",", "\u201c", "am", "X", "satisfied", "\u201d", "with", "non", "-", "negative", "X", "(", "e.g.", ",", "\u201c", "am", "very", "satisfied", "\u201d", ",", "\u201c", "am", "so", "satisfied", "\u201d", ")", "to", "be", "predictive", "of", "the", "positive", "class", "through", "training", ".", "That", "is", ",", "CNN", "can", "effectively", "use", "word", "order", "when", "bag", "-", "of", "-", "-", "gram", "-", "based", "approaches", "fail", ".", "section", ":", "Conclusion", "This", "paper", "showed", "that", "CNN", "provides", "an", "alternative", "mechanism", "for", "effective", "use", "of", "word", "order", "for", "text", "categorization", "through", "direct", "embedding", "of", "small", "text", "regions", ",", "different", "from", "the", "traditional", "bag", "-", "of", "-", "-", "gram", "approach", "or", "word", "-", "vector", "CNN", ".", "With", "the", "parallel", "CNN", "framework", ",", "several", "types", "of", "embedding", "can", "be", "learned", "and", "combined", "so", "that", "they", "can", "complement", "each", "other", "for", "higher", "accuracy", ".", "State", "-", "of", "-", "the", "-", "art", "performances", "on", "sentiment", "classification", "and", "topic", "classification", "were", "achieved", "using", "this", "approach", ".", "section", ":", "Acknowledgements", "We", "thank", "the", "anonymous", "reviewers", "for", "useful", "suggestions", ".", "The", "second", "author", "was", "supported", "by", "NSF", "IIS", "-", "1250985", "and", "NSF", "IIS", "-", "1407939", ".", "bibliography", ":", "References"]}