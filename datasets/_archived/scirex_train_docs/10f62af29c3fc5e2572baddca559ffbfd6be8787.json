{"coref": {"Accuracy": [[3975, 3977], [4283, 4285]], "C-LSTM": [[3, 8], [3680, 3684]], "Error": [[2370, 2374], [2399, 2400], [4132, 4133]], "SST-2_Binary_classification": [[2743, 2746], [2747, 2748], [3052, 3053], [3329, 3330], [3498, 3501]], "SST-5_Fine-grained_classification": [[2743, 2746], [2747, 2748], [3052, 3053], [3329, 3330], [3498, 3501]], "Sentiment_Analysis": [], "TREC-6": [[2949, 2950], [2951, 2952], [3094, 3095], [3375, 3376], [4089, 4091], [3978, 3979]], "Text_Classification": [[9, 11], [88, 90], [156, 158], [159, 162], [211, 213], [896, 898], [899, 904], [1010, 1012], [1037, 1039], [1493, 1495], [1496, 1502], [2328, 2330], [2331, 2333], [2695, 2697], [2702, 2705], [2722, 2724], [2813, 2815], [2819, 2823], [2827, 2829], [2836, 2838], [2894, 2897], [2898, 2900], [3450, 3452], [3453, 3457], [3473, 3475], [3794, 3799], [3805, 3808], [4287, 4293], [4308, 4311], [4498, 4500], [4501, 4505]]}, "coref_non_salient": {"0": [[298, 302], [323, 327], [378, 386], [463, 467], [538, 542]], "1": [[11, 14], [857, 859], [1020, 1023], [1051, 1054]], "10": [[1189, 1195], [1879, 1884], [3630, 3635]], "100": [[525, 529]], "101": [[1557, 1563], [4444, 4450]], "102": [[236, 239]], "103": [[3669, 3674]], "104": [[3505, 3507]], "105": [[219, 225]], "106": [[670, 674]], "107": [[1832, 1835]], "108": [[1016, 1019]], "109": [[3645, 3658]], "11": [[1137, 1140], [1873, 1878]], "110": [[2206, 2209]], "111": [[500, 504]], "112": [[652, 654]], "113": [[1373, 1375]], "114": [[1974, 1980]], "115": [[648, 649]], "116": [[1256, 1258]], "117": [[3308, 3310]], "118": [[1609, 1613]], "119": [[1243, 1244]], "12": [[2620, 2623], [2666, 2668], [3416, 3418]], "120": [[1601, 1606]], "121": [[1615, 1617]], "122": [[1046, 1049]], "123": [[474, 477]], "124": [[3569, 3572]], "125": [[587, 589]], "126": [[1246, 1248]], "127": [[448, 450]], "128": [[2433, 2434]], "13": [[1186, 1187], [3628, 3629]], "14": [[2607, 2608], [2609, 2610]], "15": [[2618, 2619], [2626, 2627], [2640, 2641]], "16": [[1207, 1211], [4523, 4527]], "17": [[121, 122], [176, 177], [664, 666], [1513, 1515], [3910, 3912]], "18": [[1670, 1671], [1706, 1707], [1789, 1790], [1846, 1847], [4208, 4209]], "19": [[1811, 1813], [1842, 1844]], "2": [[3467, 3470], [4295, 4297], [4365, 4367]], "20": [[3509, 3511], [3524, 3526]], "21": [[4376, 4380]], "22": [[4528, 4532]], "23": [[30, 33], [353, 356], [1072, 1075], [1550, 1553], [4440, 4443], [3512, 3515]], "24": [[293, 297], [303, 307], [458, 462], [533, 536], [1455, 1459], [1518, 1522]], "25": [[407, 409], [1369, 1372]], "26": [[991, 993], [1468, 1470]], "27": [[3698, 3702]], "28": [[4137, 4139]], "29": [[198, 200], [416, 418], [468, 470], [1308, 1310], [1354, 1357]], "3": [[3752, 3753], [3998, 4000], [4111, 4112]], "30": [[37, 40], [360, 363], [1079, 1082], [1960, 1963], [117, 120]], "31": [[196, 197], [413, 414]], "32": [[1224, 1226], [2306, 2308], [2457, 2459], [2652, 2654], [3126, 3128], [3158, 3160], [3170, 3172], [3236, 3238], [3286, 3288], [3321, 3323], [3966, 3968], [4193, 4195], [4202, 4204], [4222, 4224], [4235, 4237], [4265, 4267], [4338, 4340], [4467, 4469]], "33": [[1607, 1608], [1673, 1675], [1892, 1893], [1949, 1951], [3211, 3212], [3948, 3949], [4521, 4522]], "34": [[4043, 4045]], "35": [[2357, 2359], [2662, 2664], [3428, 3430]], "36": [[3703, 3706], [3717, 3720]], "37": [[3860, 3862]], "38": [[4076, 4079]], "39": [[1510, 1512], [3907, 3909]], "4": [[34, 35], [95, 96], [174, 175], [357, 358], [401, 402], [419, 420], [451, 452], [557, 558], [699, 700], [713, 714], [743, 744], [787, 788], [938, 939], [1076, 1077], [1106, 1107], [1346, 1347], [1361, 1362], [1390, 1391], [1417, 1418], [1476, 1477], [1554, 1555], [1575, 1576], [1940, 1941], [3065, 3066], [3595, 3596], [738, 739], [946, 947], [1153, 1154], [1404, 1405], [3603, 3604], [3612, 3613], [3623, 3624], [3638, 3639], [3642, 3643], [4033, 4034]], "40": [[701, 702], [740, 741], [800, 801], [809, 810], [940, 941], [955, 956], [1322, 1323], [1348, 1349], [1363, 1364], [1428, 1429], [1435, 1436], [1564, 1565], [1586, 1587], [1866, 1867], [1907, 1908], [2033, 2034], [2064, 2065], [2170, 2171], [2283, 2284], [2303, 2304], [2348, 2349], [2659, 2660], [3070, 3071], [3130, 3132], [3221, 3222], [3348, 3349], [3363, 3365], [3402, 3404], [3687, 3688], [3914, 3915], [4405, 4406], [4482, 4483], [4535, 4536], [83, 84], [93, 94], [131, 132], [171, 172], [516, 517], [696, 697], [891, 892], [912, 913], [1335, 1336], [1527, 1528], [1535, 1536], [1785, 1786], [1932, 1933], [2078, 2079], [2183, 2184], [2326, 2327], [2686, 2687], [3517, 3518], [3660, 3661], [3891, 3892], [4085, 4086], [4163, 4164], [4437, 4438], [4456, 4457]], "41": [[884, 887], [4409, 4412], [4494, 4497]], "42": [[4155, 4160]], "43": [[3754, 3758]], "44": [[3926, 3928]], "45": [[3761, 3765]], "46": [[3578, 3579]], "47": [[3871, 3873]], "48": [[3574, 3577]], "49": [[2195, 2198]], "5": [[78, 80], [727, 729], [1351, 1353], [4432, 4434]], "50": [[410, 412], [1376, 1378]], "51": [[4036, 4042]], "52": [[3581, 3591]], "53": [[2629, 2632]], "54": [[3358, 3361], [3397, 3400]], "55": [[1384, 1388]], "56": [[3033, 3034]], "57": [[1857, 1862]], "58": [[3766, 3768]], "59": [[3565, 3568]], "6": [[85, 87], [278, 281]], "60": [[3216, 3218]], "61": [[126, 128], [308, 310], [341, 343], [3537, 3539]], "62": [[4451, 4453]], "63": [[3971, 3974]], "64": [[215, 217]], "65": [[2084, 2086]], "66": [[4327, 4330]], "67": [[2418, 2419]], "68": [[3759, 3760]], "69": [[764, 770]], "7": [[25, 29], [549, 553]], "70": [[2428, 2430]], "71": [[435, 437], [1123, 1125]], "72": [[1006, 1009], [2056, 2059]], "73": [[1104, 1105], [1946, 1947]], "74": [[1040, 1042]], "75": [[2435, 2438]], "76": [[2734, 2739]], "77": [[1004, 1005]], "78": [[1701, 1704]], "79": [[3106, 3108]], "8": [[41, 42], [364, 365], [507, 508], [543, 544], [583, 584], [715, 716], [1083, 1084], [1259, 1260], [1280, 1281], [1302, 1303], [1392, 1393], [1406, 1407], [1964, 1965], [2009, 2010], [2094, 2095], [478, 479], [514, 515], [949, 950]], "80": [[244, 246]], "81": [[1776, 1777]], "82": [[3036, 3038]], "83": [[2293, 2298]], "84": [[2414, 2417]], "85": [[1915, 1916]], "86": [[3951, 3957]], "87": [[979, 985]], "88": [[3675, 3679]], "89": [[3562, 3563]], "9": [[101, 106], [4541, 4545]], "90": [[1954, 1960]], "91": [[873, 876]], "92": [[3559, 3561]], "93": [[3000, 3002]], "94": [[995, 1003]], "95": [[2906, 2909]], "96": [[3006, 3008]], "97": [[1919, 1921]], "98": [[2351, 2353]], "99": [[49, 51]]}, "doc_id": "10f62af29c3fc5e2572baddca559ffbfd6be8787", "method_subrelations": {"C-LSTM": [[[0, 6], "C-LSTM"]]}, "n_ary_relations": [{"Material": "SST-2_Binary_classification", "Method": "C-LSTM", "Metric": "Accuracy", "Task": "Sentiment_Analysis", "score": "87.8"}, {"Material": "SST-5_Fine-grained_classification", "Method": "C-LSTM", "Metric": "Accuracy", "Task": "Sentiment_Analysis", "score": "49.2"}, {"Material": "TREC-6", "Method": "C-LSTM", "Metric": "Error", "Task": "Text_Classification", "score": "5.4"}], "ner": [[3, 8, "Method"], [9, 11, "Task"], [11, 14, "Method"], [25, 29, "Task"], [30, 33, "Method"], [34, 35, "Method"], [37, 40, "Method"], [41, 42, "Method"], [49, 51, "Task"], [78, 80, "Method"], [85, 87, "Task"], [88, 90, "Task"], [95, 96, "Method"], [101, 106, "Method"], [121, 122, "Method"], [126, 128, "Method"], [156, 158, "Task"], [159, 162, "Task"], [174, 175, "Method"], [176, 177, "Method"], [196, 197, "Task"], [198, 200, "Task"], [211, 213, "Task"], [215, 217, "Method"], [219, 225, "Method"], [236, 239, "Method"], [244, 246, "Method"], [278, 281, "Task"], [293, 297, "Method"], [298, 302, "Method"], [303, 307, "Method"], [308, 310, "Method"], [323, 327, "Method"], [341, 343, "Method"], [353, 356, "Method"], [357, 358, "Method"], [360, 363, "Method"], [364, 365, "Method"], [378, 386, "Method"], [401, 402, "Method"], [407, 409, "Task"], [410, 412, "Task"], [413, 414, "Task"], [416, 418, "Task"], [419, 420, "Method"], [435, 437, "Method"], [448, 450, "Method"], [451, 452, "Method"], [458, 462, "Method"], [463, 467, "Method"], [468, 470, "Task"], [474, 477, "Method"], [500, 504, "Task"], [507, 508, "Method"], [525, 529, "Task"], [533, 536, "Method"], [538, 542, "Method"], [543, 544, "Method"], [549, 553, "Task"], [557, 558, "Method"], [583, 584, "Method"], [587, 589, "Task"], [648, 649, "Metric"], [652, 654, "Method"], [664, 666, "Method"], [670, 674, "Method"], [699, 700, "Method"], [701, 702, "Method"], [713, 714, "Method"], [715, 716, "Method"], [727, 729, "Method"], [740, 741, "Method"], [743, 744, "Method"], [764, 770, "Method"], [787, 788, "Method"], [800, 801, "Method"], [809, 810, "Method"], [857, 859, "Method"], [873, 876, "Method"], [884, 887, "Method"], [896, 898, "Task"], [899, 904, "Task"], [938, 939, "Method"], [940, 941, "Method"], [955, 956, "Method"], [979, 985, "Method"], [991, 993, "Task"], [995, 1003, "Task"], [1004, 1005, "Task"], [1006, 1009, "Task"], [1010, 1012, "Task"], [1016, 1019, "Method"], [1020, 1023, "Method"], [1037, 1039, "Task"], [1040, 1042, "Task"], [1046, 1049, "Task"], [1051, 1054, "Method"], [1072, 1075, "Method"], [1076, 1077, "Method"], [1079, 1082, "Method"], [1083, 1084, "Method"], [1104, 1105, "Method"], [1106, 1107, "Method"], [1123, 1125, "Method"], [1137, 1140, "Method"], [1186, 1187, "Method"], [1189, 1195, "Method"], [1207, 1211, "Method"], [1224, 1226, "Method"], [1243, 1244, "Method"], [1246, 1248, "Method"], [1256, 1258, "Method"], [1259, 1260, "Method"], [1280, 1281, "Method"], [1302, 1303, "Method"], [1308, 1310, "Task"], [1322, 1323, "Method"], [1346, 1347, "Method"], [1348, 1349, "Method"], [1351, 1353, "Method"], [1354, 1357, "Task"], [1361, 1362, "Method"], [1363, 1364, "Method"], [1369, 1372, "Task"], [1373, 1375, "Task"], [1376, 1378, "Task"], [1384, 1388, "Method"], [1390, 1391, "Method"], [1392, 1393, "Method"], [1406, 1407, "Method"], [1417, 1418, "Method"], [1428, 1429, "Method"], [1435, 1436, "Method"], [1455, 1459, "Method"], [1468, 1470, "Task"], [1476, 1477, "Method"], [1493, 1495, "Task"], [1496, 1502, "Task"], [1510, 1512, "Method"], [1513, 1515, "Method"], [1518, 1522, "Method"], [1550, 1553, "Method"], [1554, 1555, "Method"], [1557, 1563, "Method"], [1564, 1565, "Method"], [1575, 1576, "Method"], [1586, 1587, "Method"], [1601, 1606, "Task"], [1607, 1608, "Method"], [1609, 1613, "Method"], [1615, 1617, "Method"], [1670, 1671, "Method"], [1673, 1675, "Method"], [1701, 1704, "Method"], [1706, 1707, "Method"], [1776, 1777, "Method"], [1789, 1790, "Method"], [1811, 1813, "Method"], [1832, 1835, "Method"], [1842, 1844, "Method"], [1846, 1847, "Method"], [1857, 1862, "Method"], [1866, 1867, "Method"], [1873, 1878, "Method"], [1879, 1884, "Method"], [1892, 1893, "Method"], [1907, 1908, "Method"], [1915, 1916, "Task"], [1919, 1921, "Method"], [1940, 1941, "Method"], [1946, 1947, "Method"], [1949, 1951, "Method"], [1954, 1960, "Task"], [1960, 1963, "Method"], [1964, 1965, "Method"], [1974, 1980, "Method"], [2009, 2010, "Method"], [2033, 2034, "Method"], [2056, 2059, "Task"], [2064, 2065, "Method"], [2084, 2086, "Method"], [2094, 2095, "Method"], [2170, 2171, "Method"], [2195, 2198, "Method"], [2206, 2209, "Method"], [2283, 2284, "Method"], [2293, 2298, "Task"], [2303, 2304, "Method"], [2306, 2308, "Method"], [2328, 2330, "Task"], [2331, 2333, "Task"], [2348, 2349, "Method"], [2351, 2353, "Method"], [2357, 2359, "Method"], [2370, 2374, "Metric"], [2399, 2400, "Metric"], [2414, 2417, "Method"], [2418, 2419, "Method"], [2428, 2430, "Method"], [2433, 2434, "Task"], [2435, 2438, "Task"], [2457, 2459, "Method"], [2607, 2608, "Task"], [2609, 2610, "Task"], [2618, 2619, "Method"], [2620, 2623, "Method"], [2626, 2627, "Method"], [2629, 2632, "Task"], [2640, 2641, "Method"], [2652, 2654, "Method"], [2659, 2660, "Method"], [2662, 2664, "Method"], [2666, 2668, "Method"], [2695, 2697, "Task"], [2702, 2705, "Task"], [2722, 2724, "Task"], [2734, 2739, "Task"], [2743, 2746, "Material"], [2747, 2748, "Material"], [2813, 2815, "Task"], [2819, 2823, "Task"], [2827, 2829, "Task"], [2836, 2838, "Task"], [2894, 2897, "Task"], [2898, 2900, "Task"], [2906, 2909, "Task"], [2949, 2950, "Material"], [2951, 2952, "Material"], [3000, 3002, "Method"], [3006, 3008, "Task"], [3033, 3034, "Method"], [3036, 3038, "Task"], [3052, 3053, "Material"], [3065, 3066, "Method"], [3070, 3071, "Method"], [3094, 3095, "Material"], [3106, 3108, "Task"], [3126, 3128, "Method"], [3130, 3132, "Method"], [3158, 3160, "Method"], [3170, 3172, "Method"], [3211, 3212, "Method"], [3216, 3218, "Method"], [3221, 3222, "Method"], [3236, 3238, "Method"], [3286, 3288, "Method"], [3308, 3310, "Metric"], [3321, 3323, "Method"], [3329, 3330, "Material"], [3348, 3349, "Method"], [3358, 3361, "Method"], [3363, 3365, "Method"], [3375, 3376, "Material"], [3397, 3400, "Method"], [3402, 3404, "Method"], [3416, 3418, "Method"], [3428, 3430, "Method"], [3450, 3452, "Task"], [3453, 3457, "Task"], [3467, 3470, "Method"], [3473, 3475, "Task"], [3498, 3501, "Material"], [3505, 3507, "Method"], [3509, 3511, "Method"], [3524, 3526, "Method"], [3537, 3539, "Method"], [3559, 3561, "Method"], [3562, 3563, "Method"], [3565, 3568, "Method"], [3569, 3572, "Method"], [3574, 3577, "Method"], [3578, 3579, "Method"], [3581, 3591, "Method"], [3595, 3596, "Method"], [3628, 3629, "Method"], [3630, 3635, "Method"], [3645, 3658, "Method"], [3669, 3674, "Method"], [3675, 3679, "Method"], [3680, 3684, "Method"], [3687, 3688, "Method"], [3698, 3702, "Method"], [3703, 3706, "Method"], [3717, 3720, "Method"], [3752, 3753, "Method"], [3754, 3758, "Method"], [3759, 3760, "Method"], [3761, 3765, "Method"], [3766, 3768, "Method"], [3794, 3799, "Task"], [3805, 3808, "Task"], [3860, 3862, "Method"], [3871, 3873, "Method"], [3907, 3909, "Method"], [3910, 3912, "Method"], [3914, 3915, "Method"], [3926, 3928, "Method"], [3948, 3949, "Method"], [3951, 3957, "Method"], [3966, 3968, "Method"], [3971, 3974, "Method"], [3975, 3977, "Metric"], [3998, 4000, "Method"], [4036, 4042, "Method"], [4043, 4045, "Method"], [4076, 4079, "Method"], [4089, 4091, "Material"], [4111, 4112, "Method"], [4137, 4139, "Method"], [4155, 4160, "Task"], [4193, 4195, "Method"], [4202, 4204, "Method"], [4208, 4209, "Method"], [4222, 4224, "Method"], [4235, 4237, "Method"], [4265, 4267, "Method"], [4283, 4285, "Metric"], [4287, 4293, "Task"], [4295, 4297, "Method"], [4308, 4311, "Task"], [4327, 4330, "Method"], [4338, 4340, "Method"], [4365, 4367, "Method"], [4376, 4380, "Method"], [4405, 4406, "Method"], [4409, 4412, "Method"], [4432, 4434, "Method"], [4440, 4443, "Method"], [4444, 4450, "Method"], [4451, 4453, "Method"], [4467, 4469, "Method"], [4482, 4483, "Method"], [4494, 4497, "Method"], [4498, 4500, "Task"], [4501, 4505, "Task"], [4521, 4522, "Method"], [4523, 4527, "Method"], [4528, 4532, "Method"], [4535, 4536, "Method"], [4541, 4545, "Method"], [83, 84, "Method"], [93, 94, "Method"], [117, 120, "Method"], [131, 132, "Method"], [171, 172, "Method"], [478, 479, "Method"], [514, 515, "Method"], [516, 517, "Method"], [696, 697, "Method"], [738, 739, "Method"], [891, 892, "Method"], [912, 913, "Method"], [946, 947, "Method"], [949, 950, "Method"], [1153, 1154, "Method"], [1335, 1336, "Method"], [1404, 1405, "Method"], [1527, 1528, "Method"], [1535, 1536, "Method"], [1785, 1786, "Method"], [1932, 1933, "Method"], [2078, 2079, "Method"], [2183, 2184, "Method"], [2326, 2327, "Method"], [2686, 2687, "Method"], [3512, 3515, "Method"], [3517, 3518, "Method"], [3603, 3604, "Method"], [3612, 3613, "Method"], [3623, 3624, "Method"], [3638, 3639, "Method"], [3642, 3643, "Method"], [3660, 3661, "Method"], [3891, 3892, "Method"], [3978, 3979, "Material"], [4033, 4034, "Method"], [4085, 4086, "Method"], [4132, 4133, "Metric"], [4163, 4164, "Method"], [4437, 4438, "Method"], [4456, 4457, "Method"]], "sections": [[0, 186], [186, 975], [975, 1523], [1523, 1599], [1599, 1952], [1952, 2321], [2321, 2431], [2431, 2605], [2605, 2678], [2678, 2719], [2719, 2987], [2987, 3434], [3434, 3471], [3471, 3969], [3969, 4178], [4178, 4420], [4420, 4546], [4546, 4549]], "sentences": [[0, 11], [11, 30], [30, 62], [62, 91], [91, 129], [129, 150], [150, 163], [163, 186], [186, 189], [189, 214], [214, 257], [257, 274], [274, 303], [303, 323], [323, 353], [353, 387], [387, 415], [415, 451], [451, 471], [471, 495], [495, 530], [530, 554], [554, 599], [599, 636], [636, 660], [660, 683], [683, 706], [706, 742], [742, 771], [771, 802], [802, 839], [839, 877], [877, 905], [905, 931], [931, 975], [975, 979], [979, 1015], [1015, 1043], [1043, 1069], [1069, 1090], [1090, 1116], [1116, 1141], [1141, 1150], [1150, 1167], [1167, 1174], [1174, 1196], [1196, 1239], [1239, 1243], [1243, 1254], [1254, 1277], [1277, 1291], [1291, 1311], [1311, 1318], [1318, 1340], [1340, 1358], [1358, 1379], [1379, 1410], [1410, 1449], [1449, 1490], [1490, 1523], [1523, 1529], [1529, 1567], [1567, 1599], [1599, 1608], [1608, 1628], [1628, 1644], [1644, 1657], [1657, 1676], [1676, 1705], [1705, 1770], [1770, 1782], [1782, 1796], [1796, 1836], [1836, 1854], [1854, 1872], [1872, 1905], [1905, 1928], [1928, 1952], [1952, 1960], [1960, 1981], [1981, 2006], [2006, 2028], [2028, 2060], [2060, 2077], [2077, 2096], [2096, 2144], [2144, 2161], [2161, 2182], [2182, 2191], [2191, 2221], [2221, 2283], [2283, 2321], [2321, 2330], [2330, 2362], [2362, 2375], [2375, 2412], [2412, 2431], [2431, 2438], [2438, 2455], [2455, 2490], [2490, 2534], [2534, 2559], [2559, 2568], [2568, 2589], [2589, 2605], [2605, 2608], [2608, 2624], [2624, 2633], [2633, 2665], [2665, 2678], [2678, 2681], [2681, 2706], [2706, 2719], [2719, 2722], [2722, 2725], [2725, 2740], [2740, 2751], [2751, 2778], [2778, 2810], [2810, 2834], [2834, 2849], [2849, 2860], [2860, 2894], [2894, 2918], [2918, 2920], [2920, 2930], [2930, 2941], [2941, 2951], [2951, 2972], [2972, 2987], [2987, 2991], [2991, 3015], [3015, 3035], [3035, 3051], [3051, 3093], [3093, 3117], [3117, 3136], [3136, 3180], [3180, 3195], [3195, 3223], [3223, 3275], [3275, 3289], [3289, 3299], [3299, 3312], [3312, 3328], [3328, 3357], [3357, 3374], [3374, 3396], [3396, 3413], [3413, 3434], [3434, 3440], [3440, 3458], [3458, 3471], [3471, 3475], [3475, 3483], [3483, 3502], [3502, 3523], [3523, 3553], [3553, 3594], [3594, 3659], [3659, 3695], [3695, 3709], [3709, 3744], [3744, 3778], [3778, 3803], [3803, 3826], [3826, 3836], [3836, 3839], [3839, 3887], [3887, 3900], [3900, 3930], [3930, 3969], [3969, 3974], [3974, 3987], [3987, 3997], [3997, 4031], [4031, 4046], [4046, 4057], [4057, 4093], [4093, 4096], [4096, 4119], [4119, 4151], [4151, 4178], [4178, 4182], [4182, 4200], [4200, 4219], [4219, 4256], [4256, 4277], [4277, 4298], [4298, 4312], [4312, 4333], [4333, 4351], [4351, 4402], [4402, 4420], [4420, 4426], [4426, 4454], [4454, 4490], [4490, 4510], [4510, 4533], [4533, 4546], [4546, 4549]], "words": ["document", ":", "A", "C", "-", "LSTM", "Neural", "Network", "for", "Text", "Classification", "Neural", "network", "models", "have", "been", "demonstrated", "to", "be", "capable", "of", "achieving", "remarkable", "performance", "in", "sentence", "and", "document", "modeling", ".", "Convolutional", "neural", "network", "(", "CNN", ")", "and", "recurrent", "neural", "network", "(", "RNN", ")", "are", "two", "mainstream", "architectures", "for", "such", "modeling", "tasks", ",", "which", "adopt", "totally", "different", "ways", "of", "understanding", "natural", "languages", ".", "In", "this", "work", ",", "we", "combine", "the", "strengths", "of", "both", "architectures", "and", "propose", "a", "novel", "and", "unified", "model", "called", "C", "-", "LSTM", "for", "sentence", "representation", "and", "text", "classification", ".", "C", "-", "LSTM", "utilizes", "CNN", "to", "extract", "a", "sequence", "of", "higher", "-", "level", "phrase", "representations", ",", "and", "are", "fed", "into", "a", "long", "short", "-", "term", "memory", "recurrent", "neural", "network", "(", "LSTM", ")", "to", "obtain", "the", "sentence", "representation", ".", "C", "-", "LSTM", "is", "able", "to", "capture", "both", "local", "features", "of", "phrases", "as", "well", "as", "global", "and", "temporal", "sentence", "semantics", ".", "We", "evaluate", "the", "proposed", "architecture", "on", "sentiment", "classification", "and", "question", "classification", "tasks", ".", "The", "experimental", "results", "show", "that", "the", "C", "-", "LSTM", "outperforms", "both", "CNN", "and", "LSTM", "and", "can", "achieve", "excellent", "performance", "on", "these", "tasks", ".", "section", ":", "Introduction", "As", "one", "of", "the", "core", "steps", "in", "NLP", ",", "sentence", "modeling", "aims", "at", "representing", "sentences", "as", "meaningful", "features", "for", "tasks", "such", "as", "sentiment", "classification", ".", "Traditional", "sentence", "modeling", "uses", "the", "bag", "-", "of", "-", "words", "model", "which", "often", "suffers", "from", "the", "curse", "of", "dimensionality", ";", "others", "use", "composition", "based", "methods", "instead", ",", "e.g.", ",", "an", "algebraic", "operation", "over", "semantic", "word", "vectors", "to", "produce", "the", "semantic", "sentence", "vector", ".", "However", ",", "such", "methods", "may", "not", "perform", "well", "due", "to", "the", "loss", "of", "word", "order", "information", ".", "More", "recent", "models", "for", "distributed", "sentence", "representation", "fall", "into", "two", "categories", "according", "to", "the", "form", "of", "input", "sentence", ":", "sequence", "-", "based", "models", "and", "tree", "-", "structured", "models", ".", "Sequence", "-", "based", "models", "construct", "sentence", "representations", "from", "word", "sequences", "by", "taking", "in", "account", "the", "relationship", "between", "successive", "words", ".", "Tree", "-", "structured", "models", "treat", "each", "word", "token", "as", "a", "node", "in", "a", "syntactic", "parse", "tree", "and", "learn", "sentence", "representations", "from", "leaves", "to", "the", "root", "in", "a", "recursive", "manner", ".", "Convolutional", "neural", "networks", "(", "CNNs", ")", "and", "recurrent", "neural", "networks", "(", "RNNs", ")", "have", "emerged", "as", "two", "widely", "used", "architectures", "and", "are", "often", "combined", "with", "sequence", "-", "based", "or", "tree", "-", "structured", "models", ".", "Owing", "to", "the", "capability", "of", "capturing", "local", "correlations", "of", "spatial", "or", "temporal", "structures", ",", "CNNs", "have", "achieved", "top", "performance", "in", "computer", "vision", ",", "speech", "recognition", "and", "NLP", ".", "For", "sentence", "modeling", ",", "CNNs", "perform", "excellently", "in", "extracting", "n", "-", "gram", "features", "at", "different", "positions", "of", "a", "sentence", "through", "convolutional", "filters", ",", "and", "can", "learn", "short", "and", "long", "-", "range", "relations", "through", "pooling", "operations", ".", "CNNs", "have", "been", "successfully", "combined", "with", "both", "sequence", "-", "based", "model", "and", "tree", "-", "structured", "model", "in", "sentence", "modeling", ".", "The", "other", "popular", "neural", "network", "architecture", "\u2013", "RNN", "\u2013", "is", "able", "to", "handle", "sequences", "of", "any", "length", "and", "capture", "long", "-", "term", "dependencies", ".", "To", "avoid", "the", "problem", "of", "gradient", "exploding", "or", "vanishing", "in", "the", "standard", "RNN", ",", "Long", "Short", "-", "term", "Memory", "RNN", "(", "LSTM", ")", "and", "other", "variants", "were", "designed", "for", "better", "remembering", "and", "memory", "accesses", ".", "Along", "with", "the", "sequence", "-", "based", "or", "the", "tree", "-", "structured", "models", ",", "RNNs", "have", "achieved", "remarkable", "results", "in", "sentence", "or", "document", "modeling", ".", "To", "conclude", ",", "CNN", "is", "able", "to", "learn", "local", "response", "from", "temporal", "or", "spatial", "data", "but", "lacks", "the", "ability", "of", "learning", "sequential", "correlations", ";", "on", "the", "other", "hand", ",", "RNN", "is", "specilized", "for", "sequential", "modelling", "but", "unable", "to", "extract", "features", "in", "a", "parallel", "way", ".", "It", "has", "been", "shown", "that", "higher", "-", "level", "modeling", "of", "can", "help", "to", "disentangle", "underlying", "factors", "of", "variation", "within", "the", "input", ",", "which", "should", "then", "make", "it", "easier", "to", "learn", "temporal", "structure", "between", "successive", "time", "steps", ".", "For", "example", ",", "Sainath", "et", "al", ".", "have", "obtained", "respectable", "improvements", "in", "WER", "by", "learning", "a", "deep", "LSTM", "from", "multi", "-", "scale", "inputs", ".", "We", "explore", "training", "the", "LSTM", "model", "directly", "from", "sequences", "of", "higher", "-", "level", "representaions", "while", "preserving", "the", "sequence", "order", "of", "these", "representaions", ".", "In", "this", "paper", ",", "we", "introduce", "a", "new", "architecture", "short", "for", "C", "-", "LSTM", "by", "combining", "CNN", "and", "LSTM", "to", "model", "sentences", ".", "To", "benefit", "from", "the", "advantages", "of", "both", "CNN", "and", "RNN", ",", "we", "design", "a", "simple", "end", "-", "to", "-", "end", ",", "unified", "architecture", "by", "feeding", "the", "output", "of", "a", "one", "-", "layer", "CNN", "into", "LSTM", ".", "The", "CNN", "is", "constructed", "on", "top", "of", "the", "pre", "-", "trained", "word", "vectors", "from", "massive", "unlabeled", "text", "data", "to", "learn", "higher", "-", "level", "representions", "of", "n", "-", "grams", ".", "Then", "to", "learn", "sequential", "correlations", "from", "higher", "-", "level", "suqence", "representations", ",", "the", "feature", "maps", "of", "CNN", "are", "organized", "as", "sequential", "window", "features", "to", "serve", "as", "the", "input", "of", "LSTM", ".", "In", "this", "way", ",", "instead", "of", "constructing", "LSTM", "directly", "from", "the", "input", "sentence", ",", "we", "first", "transform", "each", "sentence", "into", "successive", "window", "(", "n", "-", "gram", ")", "features", "to", "help", "disentangle", "factors", "of", "variations", "within", "sentences", ".", "We", "choose", "sequence", "-", "based", "input", "other", "than", "relying", "on", "the", "syntactic", "parse", "trees", "before", "feeding", "in", "the", "neural", "network", ",", "thus", "our", "model", "does", "n\u2019t", "rely", "on", "any", "external", "language", "knowledge", "and", "complicated", "pre", "-", "processing", ".", "In", "our", "experiments", ",", "we", "evaluate", "the", "semantic", "sentence", "representations", "learned", "from", "C", "-", "LSTM", "with", "two", "tasks", ":", "sentiment", "classification", "and", "6", "-", "way", "question", "classification", ".", "Our", "evaluations", "show", "that", "the", "C", "-", "LSTM", "model", "can", "achieve", "excellent", "results", "with", "several", "benchmarks", "as", "compared", "with", "a", "wide", "range", "of", "baseline", "models", ".", "We", "also", "show", "that", "the", "combination", "of", "CNN", "and", "LSTM", "outperforms", "individual", "multi", "-", "layer", "CNN", "models", "and", "RNN", "models", ",", "which", "indicates", "that", "LSTM", "can", "learn", "long", "-", "term", "dependencies", "from", "sequences", "of", "higher", "-", "level", "representations", "better", "than", "the", "other", "models", ".", "section", ":", "Related", "Work", "Deep", "learning", "based", "neural", "network", "models", "have", "achieved", "great", "success", "in", "many", "NLP", "tasks", ",", "including", "learning", "distributed", "word", ",", "sentence", "and", "document", "representation", ",", "parsing", ",", "statistical", "machine", "translation", ",", "sentiment", "classification", ",", "etc", ".", "Learning", "distributed", "sentence", "representation", "through", "neural", "network", "models", "requires", "little", "external", "domain", "knowledge", "and", "can", "reach", "satisfactory", "results", "in", "related", "tasks", "like", "sentiment", "classification", ",", "text", "categorization", ".", "In", "many", "recent", "sentence", "representation", "learning", "works", ",", "neural", "network", "models", "are", "constructed", "upon", "either", "the", "input", "word", "sequences", "or", "the", "transformed", "syntactic", "parse", "tree", ".", "Among", "them", ",", "convolutional", "neural", "network", "(", "CNN", ")", "and", "recurrent", "neural", "network", "(", "RNN", ")", "are", "two", "popular", "ones", ".", "The", "capability", "of", "capturing", "local", "correlations", "along", "with", "extracting", "higher", "-", "level", "correlations", "through", "pooling", "empowers", "CNN", "to", "model", "sentences", "naturally", "from", "consecutive", "context", "windows", ".", "In", ",", "Collobert", "et", "al", ".", "applied", "convolutional", "filters", "to", "successive", "windows", "for", "a", "given", "sequence", "to", "extract", "global", "features", "by", "max", "-", "pooling", ".", "As", "a", "slight", "variant", ",", "Kim", "et", "al", ".", "kim", "proposed", "a", "CNN", "architecture", "with", "multiple", "filters", "(", "with", "a", "varying", "window", "size", ")", "and", "two", "\u2018", "channels", "\u2019", "of", "word", "vectors", ".", "To", "capture", "word", "relations", "of", "varying", "sizes", ",", "Kalchbrenner", "et", "al", ".", "dcnn", "proposed", "a", "dynamic", "k", "-", "max", "pooling", "mechanism", ".", "In", "a", "more", "recent", "work", ",", "Tao", "et", "al", ".", "apply", "tensor", "-", "based", "operations", "between", "words", "to", "replace", "linear", "operations", "on", "concatenated", "word", "vectors", "in", "the", "standard", "convolutional", "layer", "and", "explore", "the", "non", "-", "linear", "interactions", "between", "nonconsective", "n", "-", "grams", ".", "Mou", "et", "al", ".", "mou", "also", "explores", "convolutional", "models", "on", "tree", "-", "structured", "sentences", ".", "As", "a", "sequence", "model", ",", "RNN", "is", "able", "to", "deal", "with", "variable", "-", "length", "input", "sequences", "and", "discover", "long", "-", "term", "dependencies", ".", "Various", "variants", "of", "RNN", "have", "been", "proposed", "to", "better", "store", "and", "access", "memories", ".", "With", "the", "ability", "of", "explicitly", "modeling", "time", "-", "series", "data", ",", "RNNs", "are", "being", "increasingly", "applied", "to", "sentence", "modeling", ".", "For", "example", ",", "Tai", "et", "al", ".", "tai2015", "adjusted", "the", "standard", "LSTM", "to", "tree", "-", "structured", "topologies", "and", "obtained", "superior", "results", "over", "a", "sequential", "LSTM", "on", "related", "tasks", ".", "In", "this", "paper", ",", "we", "stack", "CNN", "and", "LSTM", "in", "a", "unified", "architecture", "for", "semantic", "sentence", "modeling", ".", "The", "combination", "of", "CNN", "and", "LSTM", "can", "be", "seen", "in", "some", "computer", "vision", "tasks", "like", "image", "caption", "and", "speech", "recognition", ".", "Most", "of", "these", "models", "use", "multi", "-", "layer", "CNNs", "and", "train", "CNNs", "and", "RNNs", "separately", "or", "throw", "the", "output", "of", "a", "fully", "connected", "layer", "of", "CNN", "into", "RNN", "as", "inputs", ".", "Our", "approach", "is", "different", ":", "we", "apply", "CNN", "to", "text", "data", "and", "feed", "consecutive", "window", "features", "directly", "to", "LSTM", ",", "and", "so", "our", "architecture", "enables", "LSTM", "to", "learn", "long", "-", "range", "dependencies", "from", "higher", "-", "order", "sequential", "features", ".", "In", ",", "the", "authors", "suggest", "that", "sequence", "-", "based", "models", "are", "sufficient", "to", "capture", "the", "compositional", "semantics", "for", "many", "NLP", "tasks", ",", "thus", "in", "this", "work", "the", "CNN", "is", "directly", "built", "upon", "word", "sequences", "other", "than", "the", "syntactic", "parse", "tree", ".", "Our", "experiments", "on", "sentiment", "classification", "and", "6", "-", "way", "question", "classification", "tasks", "clearly", "demonstrate", "the", "superiority", "of", "our", "model", "over", "single", "CNN", "or", "LSTM", "model", "and", "other", "related", "sequence", "-", "based", "models", ".", "section", ":", "C", "-", "LSTM", "Model", "The", "architecture", "of", "the", "C", "-", "LSTM", "model", "is", "shown", "in", "Figure", "1", ",", "which", "consists", "of", "two", "main", "components", ":", "convolutional", "neural", "network", "(", "CNN", ")", "and", "long", "short", "-", "term", "memory", "network", "(", "LSTM", ")", ".", "The", "following", "two", "subsections", "describe", "how", "we", "apply", "CNN", "to", "extract", "higher", "-", "level", "sequences", "of", "word", "features", "and", "LSTM", "to", "capture", "long", "-", "term", "dependencies", "over", "window", "feature", "sequences", "respectively", ".", "subsection", ":", "N", "-", "gram", "Feature", "Extraction", "through", "Convolution", "The", "one", "-", "dimensional", "convolution", "involves", "a", "filter", "vector", "sliding", "over", "a", "sequence", "and", "detecting", "features", "at", "different", "positions", ".", "Let", "be", "the", "-", "dimensional", "word", "vectors", "for", "the", "-", "th", "word", "in", "a", "sentence", ".", "Let", "denote", "the", "input", "sentence", "where", "is", "the", "length", "of", "the", "sentence", ".", "Let", "be", "the", "length", "of", "the", "filter", ",", "and", "the", "vector", "is", "a", "filter", "for", "the", "convolution", "operation", ".", "For", "each", "position", "in", "the", "sentence", ",", "we", "have", "a", "window", "vector", "with", "consecutive", "word", "vectors", ",", "denoted", "as", ":", "Here", ",", "the", "commas", "represent", "row", "vector", "concatenation", ".", "A", "filter", "convolves", "with", "the", "window", "vectors", "(", "-", "grams", ")", "at", "each", "position", "in", "a", "valid", "way", "to", "generate", "a", "feature", "map", ";", "each", "element", "of", "the", "feature", "map", "for", "window", "vector", "is", "produced", "as", "follows", ":", "where", "is", "element", "-", "wise", "multiplication", ",", "is", "a", "bias", "term", "and", "is", "a", "nonlinear", "transformation", "function", "that", "can", "be", "sigmoid", ",", "hyperbolic", "tangent", ",", "etc", ".", "In", "our", "case", ",", "we", "choose", "ReLU", "as", "the", "nonlinear", "function", ".", "The", "C", "-", "LSTM", "model", "uses", "multiple", "filters", "to", "generate", "multiple", "feature", "maps", ".", "For", "filters", "with", "the", "same", "length", ",", "the", "generated", "feature", "maps", "can", "be", "rearranged", "as", "feature", "representations", "for", "each", "window", ",", "Here", ",", "semicolons", "represent", "column", "vector", "concatenation", "and", "is", "the", "feature", "map", "generated", "with", "the", "-", "th", "filter", ".", "Each", "row", "of", "is", "the", "new", "feature", "representation", "generated", "from", "filters", "for", "the", "window", "vector", "at", "position", ".", "The", "new", "successive", "higher", "-", "order", "window", "representations", "then", "are", "fed", "into", "LSTM", "which", "is", "described", "below", ".", "A", "max", "-", "over", "-", "pooling", "or", "dynamic", "k", "-", "max", "pooling", "is", "often", "applied", "to", "feature", "maps", "after", "the", "convolution", "to", "select", "the", "most", "or", "the", "k", "-", "most", "important", "features", ".", "However", ",", "LSTM", "is", "specified", "for", "sequence", "input", ",", "and", "pooling", "will", "break", "such", "sequence", "organization", "due", "to", "the", "discontinuous", "selected", "features", ".", "Since", "we", "stack", "an", "LSTM", "neural", "neural", "network", "on", "top", "of", "the", "CNN", ",", "we", "will", "not", "apply", "pooling", "after", "the", "convolution", "operation", ".", "subsection", ":", "Long", "Short", "-", "Term", "Memory", "Networks", "Recurrent", "neural", "networks", "(", "RNNs", ")", "are", "able", "to", "propagate", "historical", "information", "via", "a", "chain", "-", "like", "neural", "network", "architecture", ".", "While", "processing", "sequential", "data", ",", "it", "looks", "at", "the", "current", "input", "as", "well", "as", "the", "previous", "output", "of", "hidden", "state", "at", "each", "time", "step", ".", "However", ",", "standard", "RNNs", "becomes", "unable", "to", "learn", "long", "-", "term", "dependencies", "as", "the", "gap", "between", "two", "time", "steps", "becomes", "large", ".", "To", "address", "this", "issue", ",", "LSTM", "was", "first", "introduced", "in", "and", "re", "-", "emerged", "as", "a", "successful", "architecture", "since", "Ilya", "et", "al", ".", "seq", "obtained", "remarkable", "performance", "in", "statistical", "machine", "translation", ".", "Although", "many", "variants", "of", "LSTM", "were", "proposed", ",", "we", "adopt", "the", "standard", "architecture", "in", "this", "work", ".", "The", "LSTM", "architecture", "has", "a", "range", "of", "repeated", "modules", "for", "each", "time", "step", "as", "in", "a", "standard", "RNN", ".", "At", "each", "time", "step", ",", "the", "output", "of", "the", "module", "is", "controlled", "by", "a", "set", "of", "gates", "in", "as", "a", "function", "of", "the", "old", "hidden", "state", "and", "the", "input", "at", "the", "current", "time", "step", ":", "the", "forget", "gate", ",", "the", "input", "gate", ",", "and", "the", "output", "gate", ".", "These", "gates", "collectively", "decide", "how", "to", "update", "the", "current", "memory", "cell", "and", "the", "current", "hidden", "state", ".", "We", "use", "to", "denote", "the", "memory", "dimension", "in", "the", "LSTM", "and", "all", "vectors", "in", "this", "architecture", "share", "the", "same", "dimension", ".", "The", "LSTM", "transition", "functions", "are", "defined", "as", "follows", ":", "Here", ",", "is", "the", "logistic", "sigmoid", "function", "that", "has", "an", "output", "in", ",", "denotes", "the", "hyperbolic", "tangent", "function", "that", "has", "an", "output", "in", ",", "and", "denotes", "the", "elementwise", "multiplication", ".", "To", "understand", "the", "mechanism", "behind", "the", "architecture", ",", "we", "can", "view", "as", "the", "function", "to", "control", "to", "what", "extent", "the", "information", "from", "the", "old", "memory", "cell", "is", "going", "to", "be", "thrown", "away", ",", "to", "control", "how", "much", "new", "information", "is", "going", "to", "be", "stored", "in", "the", "current", "memory", "cell", ",", "and", "to", "control", "what", "to", "output", "based", "on", "the", "memory", "cell", ".", "LSTM", "is", "explicitly", "designed", "for", "time", "-", "series", "data", "for", "learning", "long", "-", "term", "dependencies", ",", "and", "therefore", "we", "choose", "LSTM", "upon", "the", "convolution", "layer", "to", "learn", "such", "dependencies", "in", "the", "sequence", "of", "higher", "-", "level", "features", ".", "section", ":", "Learning", "C", "-", "LSTM", "for", "Text", "Classification", "For", "text", "classification", ",", "we", "regard", "the", "output", "of", "the", "hidden", "state", "at", "the", "last", "time", "step", "of", "LSTM", "as", "the", "document", "representation", "and", "we", "add", "a", "softmax", "layer", "on", "top", ".", "We", "train", "the", "entire", "model", "by", "minimizing", "the", "cross", "-", "entropy", "error", ".", "Given", "a", "training", "sample", "and", "its", "true", "label", "where", "is", "the", "number", "of", "possible", "labels", "and", "the", "estimated", "probabilities", "for", "each", "label", ",", "the", "error", "is", "defined", "as", ":", "where", "is", "an", "indicator", "such", "that", "otherwise", ".", "We", "employ", "stochastic", "gradient", "descent", "(", "SGD", ")", "to", "learn", "the", "model", "parameters", "and", "adopt", "the", "optimizer", "RMSprop", ".", "subsection", ":", "Padding", "and", "Word", "Vector", "Initialization", "First", ",", "we", "use", "to", "denote", "the", "maximum", "length", "of", "the", "sentence", "in", "the", "training", "set", ".", "As", "the", "convolution", "layer", "in", "our", "model", "requires", "fixed", "-", "length", "input", ",", "we", "pad", "each", "sentence", "that", "has", "a", "length", "less", "than", "with", "special", "symbols", "at", "the", "end", "that", "indicate", "the", "unknown", "words", ".", "For", "a", "sentence", "in", "the", "test", "dataset", ",", "we", "pad", "sentences", "that", "are", "shorter", "than", "in", "the", "same", "way", ",", "but", "for", "sentences", "that", "have", "a", "length", "longer", "than", ",", "we", "simply", "cut", "extra", "words", "at", "the", "end", "of", "these", "sentences", "to", "reach", ".", "We", "initialize", "word", "vectors", "with", "the", "publicly", "available", "word2vec", "vectors", "that", "are", "pre", "-", "trained", "using", "about", "100B", "words", "from", "the", "Google", "News", "Dataset", ".", "The", "dimensionality", "of", "the", "word", "vectors", "is", "300", ".", "We", "also", "initialize", "the", "word", "vector", "for", "the", "unknown", "words", "from", "the", "uniform", "distribution", "[", "-", "0.25", ",", "0.25", "]", ".", "We", "then", "fine", "-", "tune", "the", "word", "vectors", "along", "with", "other", "model", "parameters", "during", "training", ".", "subsection", ":", "Regularization", "For", "regularization", ",", "we", "employ", "two", "commonly", "used", "techniques", ":", "dropout", "and", "L2", "weight", "regularization", ".", "We", "apply", "dropout", "to", "prevent", "co", "-", "adaptation", ".", "In", "our", "model", ",", "we", "either", "apply", "dropout", "to", "word", "vectors", "before", "feeding", "the", "sequence", "of", "words", "into", "the", "convolutional", "layer", "or", "to", "the", "output", "of", "LSTM", "before", "the", "softmax", "layer", ".", "The", "L2", "regularization", "is", "applied", "to", "the", "weight", "of", "the", "softmax", "layer", ".", "section", ":", "Experiments", "We", "evaluate", "the", "C", "-", "LSTM", "model", "on", "two", "tasks", ":", "(", "1", ")", "sentiment", "classification", ",", "and", "(", "2", ")", "question", "type", "classification", ".", "In", "this", "section", ",", "we", "introduce", "the", "datasets", "and", "the", "experimental", "settings", ".", "subsection", ":", "Datasets", "Sentiment", "Classification", ":", "Our", "task", "in", "this", "regard", "is", "to", "predict", "the", "sentiment", "polarity", "of", "movie", "reviews", ".", "We", "use", "the", "Stanford", "Sentiment", "Treebank", "(", "SST", ")", "benchmark", ".", "This", "dataset", "consists", "of", "11855", "movie", "reviews", "and", "are", "split", "into", "train", "(", "8544", ")", ",", "dev", "(", "1101", ")", ",", "and", "test", "(", "2210", ")", ".", "Sentences", "in", "this", "corpus", "are", "parsed", "and", "all", "phrases", "along", "with", "the", "sentences", "are", "fully", "annotated", "with", "5", "labels", ":", "very", "positive", ",", "positive", ",", "neural", ",", "negative", ",", "very", "negative", ".", "We", "consider", "two", "classification", "tasks", "on", "this", "dataset", ":", "fine", "-", "grained", "classification", "with", "5", "labels", "and", "binary", "classification", "by", "removing", "neural", "labels", ".", "For", "the", "binary", "classification", ",", "the", "dataset", "has", "a", "split", "of", "train", "(", "6920", ")", "/", "dev", "(", "872", ")", "/", "test", "(", "1821", ")", ".", "Since", "the", "data", "is", "provided", "in", "the", "format", "of", "sub", "-", "sentences", ",", "we", "train", "the", "model", "on", "both", "phrases", "and", "sentences", "but", "only", "test", "on", "the", "sentences", "as", "in", "several", "previous", "works", ".", "Question", "type", "classification", ":", "Question", "classification", "is", "an", "important", "step", "in", "a", "question", "answering", "system", "that", "classifies", "a", "question", "into", "a", "specific", "type", ",", "e.g.", "\u201c", "what", "is", "the", "highest", "waterfall", "in", "the", "United", "States", "?", "\u201d", "is", "a", "question", "that", "belongs", "to", "\u201c", "location", "\u201d", ".", "For", "this", "task", ",", "we", "use", "the", "benchmark", "TREC", ".", "TREC", "divides", "all", "questions", "into", "6", "categories", ",", "including", "location", ",", "human", ",", "entity", ",", "abbreviation", ",", "description", "and", "numeric", ".", "The", "training", "dataset", "contains", "5452", "labelled", "questions", "while", "the", "testing", "dataset", "contains", "500", "questions", ".", "subsection", ":", "Experimental", "Settings", "We", "implement", "our", "model", "based", "on", "Theano", "\u2013", "a", "python", "library", ",", "which", "supports", "efficient", "symbolic", "differentiation", "and", "transparent", "use", "of", "a", "GPU", ".", "To", "benefit", "from", "the", "efficiency", "of", "parallel", "computation", "of", "the", "tensors", ",", "we", "train", "the", "model", "on", "a", "GPU", ".", "For", "text", "preprocessing", ",", "we", "only", "convert", "all", "characters", "in", "the", "dataset", "to", "lower", "case", ".", "For", "SST", ",", "we", "conduct", "hyperparameter", "(", "number", "of", "filters", ",", "filter", "length", "in", "CNN", ";", "memory", "dimension", "in", "LSTM", ";", "dropout", "rate", "and", "which", "layer", "to", "apply", ",", "etc", ".", ")", "tuning", "on", "the", "validation", "data", "in", "the", "standard", "split", ".", "For", "TREC", ",", "we", "hold", "out", "1000", "samples", "from", "the", "training", "dataset", "for", "hyperparameter", "search", "and", "train", "the", "model", "using", "the", "remaining", "data", ".", "In", "our", "final", "settings", ",", "we", "only", "use", "one", "convolutional", "layer", "and", "one", "LSTM", "layer", "for", "both", "tasks", ".", "For", "the", "filter", "size", ",", "we", "investigated", "filter", "lengths", "of", "2", ",", "3", "and", "4", "in", "two", "cases", ":", "a", ")", "single", "convolutional", "layer", "with", "the", "same", "filter", "length", ",", "and", "b", ")", "multiple", "convolutional", "layers", "with", "different", "lengths", "of", "filters", "in", "parallel", ".", "Here", "we", "denote", "the", "number", "of", "filters", "of", "length", "by", "for", "ease", "of", "clarification", ".", "For", "the", "first", "case", ",", "each", "n", "-", "gram", "window", "is", "transformed", "into", "convoluted", "features", "after", "convolution", "and", "the", "sequence", "of", "window", "representations", "is", "fed", "into", "LSTM", ".", "For", "the", "latter", "case", ",", "since", "the", "number", "of", "windows", "generated", "from", "each", "convolution", "layer", "varies", "when", "the", "filter", "length", "varies", "(", "see", "below", "equation", "(", "3", ")", ")", ",", "we", "cut", "the", "window", "sequence", "at", "the", "end", "based", "on", "the", "maximum", "filter", "length", "that", "gives", "the", "shortest", "number", "of", "windows", ".", "Each", "window", "is", "represented", "as", "the", "concatenation", "of", "outputs", "from", "different", "convolutional", "layers", ".", "We", "also", "exploit", "different", "combinations", "of", "different", "filter", "lengths", ".", "We", "further", "present", "experimental", "analysis", "of", "the", "exploration", "on", "filter", "size", "later", ".", "According", "to", "the", "experiments", ",", "we", "choose", "a", "single", "convolutional", "layer", "with", "filter", "length", "3", ".", "For", "SST", ",", "the", "number", "of", "filters", "of", "length", "3", "is", "set", "to", "be", "150", "and", "the", "memory", "dimension", "of", "LSTM", "is", "set", "to", "be", "150", ",", "too", ".", "The", "word", "vector", "layer", "and", "the", "LSTM", "layer", "are", "dropped", "out", "with", "a", "probability", "of", "0.5", ".", "For", "TREC", ",", "the", "number", "of", "filters", "is", "set", "to", "be", "300", "and", "the", "memory", "dimension", "is", "set", "to", "be", "300", ".", "The", "word", "vector", "layer", "and", "the", "LSTM", "layer", "are", "dropped", "out", "with", "a", "probability", "of", "0.5", ".", "We", "also", "add", "L2", "regularization", "with", "a", "factor", "of", "0.001", "to", "the", "weights", "in", "the", "softmax", "layer", "for", "both", "tasks", ".", "section", ":", "Results", "and", "Model", "Analysis", "In", "this", "section", ",", "we", "show", "our", "evaluation", "results", "on", "sentiment", "classification", "and", "question", "type", "classification", "tasks", ".", "Moreover", ",", "we", "give", "some", "model", "analysis", "on", "the", "filter", "size", "configuration", ".", "subsection", ":", "Sentiment", "Classification", "The", "results", "are", "shown", "in", "Table", "1", ".", "We", "compare", "our", "model", "with", "a", "large", "set", "of", "well", "-", "performed", "models", "on", "the", "Stanford", "Sentiment", "Treebank", ".", "Generally", ",", "the", "baseline", "models", "consist", "of", "recursive", "models", ",", "convolutional", "neural", "network", "models", ",", "LSTM", "related", "models", "and", "others", ".", "The", "recursive", "models", "employ", "a", "syntactic", "parse", "tree", "as", "the", "sentence", "structure", "and", "the", "sentence", "representation", "is", "computed", "recursively", "in", "a", "bottom", "-", "up", "manner", "along", "the", "parse", "tree", ".", "Under", "this", "category", ",", "we", "choose", "recursive", "autoencoder", "(", "RAE", ")", ",", "matrix", "-", "vector", "(", "MV", "-", "RNN", ")", ",", "tensor", "based", "composition", "(", "RNTN", ")", "and", "multi", "-", "layer", "stacked", "(", "DRNN", ")", "recursive", "neural", "network", "as", "baselines", ".", "Among", "CNNs", ",", "we", "compare", "with", "Kim", "\u2019s", "kim", "CNN", "model", "with", "fine", "-", "tuned", "word", "vectors", "(", "CNN", "-", "non", "-", "static", ")", "and", "multi", "-", "channels", "(", "CNN", "-", "multichannel", ")", ",", "DCNN", "with", "dynamic", "k", "-", "max", "pooling", ",", "Tao", "\u2019s", "CNN", "(", "Molding", "-", "CNN", ")", "with", "low", "-", "rank", "tensor", "based", "non", "-", "linear", "and", "non", "-", "consecutive", "convolutions", ".", "Among", "LSTM", "related", "models", ",", "we", "first", "compare", "with", "two", "tree", "-", "structured", "LSTM", "models", "(", "Dependence", "Tree", "-", "LSTM", "and", "Constituency", "Tree", "-", "LSTM", ")", "that", "adjust", "LSTM", "to", "tree", "-", "structured", "network", "topologies", ".", "Then", "we", "implement", "one", "-", "layer", "LSTM", "and", "Bi", "-", "LSTM", "by", "ourselves", ".", "Since", "we", "could", "not", "tune", "the", "result", "of", "Bi", "-", "LSTM", "to", "be", "as", "good", "as", "what", "has", "been", "reported", "in", "even", "if", "following", "their", "untied", "weight", "configuration", ",", "we", "report", "our", "own", "results", ".", "For", "other", "baseline", "methods", ",", "we", "compare", "against", "SVM", "with", "unigram", "and", "bigram", "features", ",", "NBoW", "with", "average", "word", "vector", "features", "and", "paragraph", "vector", "that", "infers", "the", "new", "paragraph", "vector", "for", "unseen", "documents", ".", "To", "the", "best", "of", "our", "knowledge", ",", "we", "achieve", "the", "fourth", "best", "published", "result", "for", "the", "5", "-", "class", "classification", "task", "on", "this", "dataset", ".", "For", "the", "binary", "classification", "task", ",", "we", "achieve", "comparable", "results", "with", "respect", "to", "the", "state", "-", "of", "-", "the", "-", "art", "ones", ".", "From", "Table", "1", ",", "we", "have", "the", "following", "observations", ":", "(", "1", ")", "Although", "we", "did", "not", "beat", "the", "state", "-", "of", "-", "the", "-", "art", "ones", ",", "as", "an", "end", "-", "to", "-", "end", "model", ",", "the", "result", "is", "still", "promising", "and", "comparable", "with", "thoes", "models", "that", "heavily", "rely", "on", "linguistic", "annotations", "and", "knowledge", ",", "especially", "syntactic", "parse", "trees", ".", "This", "indicates", "C", "-", "LSTM", "will", "be", "more", "feasible", "for", "various", "scenarios", ".", "(", "2", ")", "Comparing", "our", "results", "against", "single", "CNN", "and", "LSTM", "models", "shows", "that", "LSTM", "does", "learn", "long", "-", "term", "dependencies", "across", "sequences", "of", "higher", "-", "level", "representations", "better", ".", "We", "could", "explore", "in", "the", "future", "how", "to", "learn", "more", "compact", "higher", "-", "level", "representations", "by", "replacing", "standard", "convolution", "with", "other", "non", "-", "linear", "feature", "mapping", "functions", "or", "appealing", "to", "tree", "-", "structured", "topologies", "before", "the", "convolutional", "layer", ".", "subsection", ":", "Question", "Type", "Classification", "The", "prediction", "accuracy", "on", "TREC", "question", "classification", "is", "reported", "in", "Table", "2", ".", "We", "compare", "our", "model", "with", "a", "variety", "of", "models", ".", "The", "SVM", "classifier", "uses", "unigrams", ",", "bigrams", ",", "wh", "-", "word", ",", "head", "word", ",", "POS", "tags", ",", "parser", ",", "hypernyms", ",", "WordNet", "synsets", "as", "engineered", "features", "and", "60", "hand", "-", "coded", "rules", ".", "Ada", "-", "CNN", "is", "a", "self", "-", "adaptiive", "hierarchical", "sentence", "model", "with", "gating", "networks", ".", "Other", "baseline", "models", "have", "been", "introduced", "in", "the", "last", "task", ".", "From", "Table", "2", ",", "we", "have", "the", "following", "observations", ":", "(", "1", ")", "Our", "result", "consistently", "outperforms", "all", "published", "neural", "baseline", "models", ",", "which", "means", "that", "C", "-", "LSTM", "captures", "intentions", "of", "TREC", "questions", "well", ".", "(", "2", ")", "Our", "result", "is", "close", "to", "that", "of", "the", "state", "-", "of", "-", "the", "-", "art", "SVM", "that", "depends", "on", "highly", "engineered", "features", ".", "Such", "engineered", "features", "not", "only", "demands", "human", "laboring", "but", "also", "leads", "to", "the", "error", "propagation", "in", "the", "existing", "NLP", "tools", ",", "thus", "could", "n\u2019t", "generalize", "well", "in", "other", "datasets", "and", "tasks", ".", "With", "the", "ability", "of", "automatically", "learning", "semantic", "sentence", "representations", ",", "C", "-", "LSTM", "does", "n\u2019t", "require", "any", "human", "-", "designed", "features", "and", "has", "a", "better", "scalibility", ".", "subsection", ":", "Model", "Analysis", "Here", "we", "investigate", "the", "impact", "of", "different", "filter", "configurations", "in", "the", "convolutional", "layer", "on", "the", "model", "performance", ".", "In", "the", "convolutional", "layer", "of", "our", "model", ",", "filters", "are", "used", "to", "capture", "local", "n", "-", "gram", "features", ".", "Intuitively", ",", "multiple", "convolutional", "layers", "in", "parallel", "with", "different", "filter", "sizes", "should", "perform", "better", "than", "single", "convolutional", "layers", "with", "the", "same", "length", "filters", "in", "that", "different", "filter", "sizes", "could", "exploit", "features", "of", "different", "n", "-", "grams", ".", "However", ",", "we", "found", "in", "our", "experiments", "that", "single", "convolutional", "layer", "with", "filter", "length", "3", "always", "outperforms", "the", "other", "cases", ".", "We", "show", "in", "Figure", "2", "the", "prediction", "accuracies", "on", "the", "6", "-", "way", "question", "classification", "task", "using", "different", "filter", "configurations", ".", "Note", "that", "we", "also", "observe", "the", "similar", "phenomenon", "in", "the", "sentiment", "classification", "task", ".", "For", "each", "filter", "configuration", ",", "we", "report", "in", "Figure", "2", "the", "best", "result", "under", "extensive", "grid", "-", "search", "on", "hyperparameters", ".", "It", "it", "shown", "that", "single", "convolutional", "layer", "with", "filter", "length", "3", "performs", "best", "among", "all", "filter", "configurations", ".", "For", "the", "case", "of", "multiple", "convolutional", "layers", "in", "parallel", ",", "it", "is", "shown", "that", "filter", "configurations", "with", "filter", "length", "3", "performs", "better", "that", "those", "without", "tri", "-", "gram", "filters", ",", "which", "further", "confirms", "that", "tri", "-", "gram", "features", "do", "play", "a", "significant", "role", "in", "capturing", "local", "features", "in", "our", "tasks", ".", "We", "conjecture", "that", "LSTM", "could", "learn", "better", "semantic", "sentence", "representations", "from", "sequences", "of", "tri", "-", "gram", "features", ".", "section", ":", "Conclusion", "and", "Future", "Work", "We", "have", "described", "a", "novel", ",", "unified", "model", "called", "C", "-", "LSTM", "that", "combines", "convolutional", "neural", "network", "with", "long", "short", "-", "term", "memory", "network", "(", "LSTM", ")", ".", "C", "-", "LSTM", "is", "able", "to", "learn", "phrase", "-", "level", "features", "through", "a", "convolutional", "layer", ";", "sequences", "of", "such", "higher", "-", "level", "representations", "are", "then", "fed", "into", "the", "LSTM", "to", "learn", "long", "-", "term", "dependencies", ".", "We", "evaluated", "the", "learned", "semantic", "sentence", "representations", "on", "sentiment", "classification", "and", "question", "type", "classification", "tasks", "with", "very", "satisfactory", "results", ".", "We", "could", "explore", "in", "the", "future", "ways", "to", "replace", "the", "standard", "convolution", "with", "tensor", "-", "based", "operations", "or", "tree", "-", "structured", "convolutions", ".", "We", "believe", "LSTM", "will", "benefit", "from", "more", "structured", "higher", "-", "level", "representations", ".", "bibliography", ":", "References"]}