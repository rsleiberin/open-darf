{"coref": {"EM": [[973, 975], [2518, 2520], [2521, 2522], [3165, 3166], [2805, 2807]], "F1": [[978, 980], [2524, 2526], [2813, 2815], [3167, 3169]], "MEMEN": [[2, 3], [4, 11], [118, 125], [126, 127], [603, 610], [611, 612], [1617, 1621], [3006, 3007], [3748, 3749], [3777, 3778]], "MEMEN___single_model_": [], "MEMEN__ensemble_": [], "Question_Answering": [[3421, 3428], [3779, 3784]], "SQuAD1_1": [[202, 206], [207, 208], [295, 296], [950, 951], [966, 967], [2330, 2331], [2639, 2640], [2645, 2649], [2650, 2651], [2652, 2653], [2734, 2735], [3503, 3507], [3591, 3592], [3839, 3840], [2778, 2779], [2893, 2894], [2982, 2983], [3145, 3146], [3220, 3221], [3508, 3509]], "TriviaQA": [[225, 227], [962, 964], [2441, 2442], [2455, 2456], [2458, 2459], [2489, 2490], [2635, 2636], [3574, 3575], [3589, 3590], [3833, 3835], [3594, 3595]], "ensemble": [[2798, 2800], [2839, 2841], [2876, 2878], [2950, 2952]], "single_model": [[3037, 3041], [3064, 3069]]}, "coref_non_salient": {"0": [[1050, 1054], [1916, 1917]], "1": [[1686, 1687], [1783, 1785]], "10": [[362, 366], [367, 371], [1139, 1143], [1492, 1496], [1497, 1501]], "100": [[685, 693]], "101": [[665, 670]], "102": [[1445, 1448]], "103": [[3432, 3433]], "104": [[69, 71]], "105": [[3021, 3025]], "106": [[3697, 3701]], "107": [[933, 934]], "108": [[3369, 3374]], "109": [[2790, 2791]], "11": [[141, 145], [736, 740], [779, 783], [1231, 1235], [1300, 1304], [1356, 1360], [2282, 2286]], "110": [[1822, 1827]], "111": [[1334, 1335]], "12": [[198, 199], [2534, 2535], [3057, 3058], [3126, 3127]], "13": [[502, 505], [821, 824], [826, 828], [854, 856]], "14": [[129, 132], [3612, 3614], [3885, 3888]], "15": [[3487, 3491]], "16": [[2189, 2190], [2398, 2399]], "17": [[1705, 1710], [3344, 3349]], "18": [[808, 815], [1519, 1526], [2031, 2038], [3798, 3805], [167, 174]], "19": [[135, 137], [160, 162], [339, 341], [1105, 1107]], "2": [[1485, 1487], [2080, 2084]], "20": [[721, 725], [3788, 3792]], "21": [[1691, 1693], [1809, 1811], [1860, 1862]], "22": [[671, 675], [1067, 1071], [1561, 1566]], "23": [[506, 509], [882, 885]], "24": [[3728, 3730]], "25": [[775, 777], [1433, 1436]], "26": [[534, 536], [615, 622]], "27": [[3047, 3051], [3100, 3104]], "28": [[3002, 3004]], "29": [[200, 201], [3128, 3129]], "3": [[12, 14], [231, 233], [623, 626], [2843, 2845], [14, 16]], "30": [[416, 418], [449, 451]], "31": [[3095, 3099]], "32": [[2239, 2241]], "33": [[2911, 2913], [2939, 2941]], "34": [[3765, 3767]], "35": [[3702, 3709]], "36": [[3214, 3215], [3844, 3848]], "37": [[637, 642], [1098, 1103]], "38": [[1178, 1179], [2371, 2372]], "39": [[234, 235], [17, 18]], "4": [[760, 762], [1502, 1504], [1867, 1869], [3275, 3276]], "40": [[3676, 3679]], "41": [[3867, 3869]], "42": [[2536, 2538]], "43": [[3636, 3638]], "44": [[758, 759], [1255, 1256], [1285, 1286], [2322, 2323], [3271, 3272]], "45": [[1550, 1553], [1554, 1557]], "46": [[1597, 1601], [1983, 1987]], "47": [[3882, 3884]], "48": [[27, 30], [255, 258]], "49": [[2292, 2294]], "5": [[323, 325], [493, 495], [1526, 1528], [3627, 3629], [3649, 3652], [3751, 3755]], "50": [[3087, 3089]], "51": [[1073, 1075], [2162, 2164], [2427, 2429], [3762, 3764]], "52": [[3878, 3881]], "53": [[1884, 1887], [2010, 2013]], "54": [[2992, 2997]], "55": [[3622, 3625]], "56": [[743, 748], [1240, 1245], [1270, 1275], [2257, 2262]], "57": [[1320, 1322]], "58": [[259, 261]], "59": [[1462, 1463]], "6": [[3283, 3287], [3395, 3399], [3655, 3656]], "60": [[2367, 2370]], "61": [[2300, 2301]], "62": [[1025, 1028]], "63": [[2515, 2517]], "64": [[2904, 2906]], "65": [[1364, 1367]], "66": [[1152, 1155]], "67": [[3608, 3611]], "68": [[988, 994]], "69": [[2374, 2377]], "7": [[749, 750], [1246, 1247], [1276, 1277], [2319, 2320], [3248, 3249], [3264, 3265]], "70": [[3639, 3641]], "71": [[1959, 1960]], "72": [[316, 318]], "73": [[114, 117]], "74": [[2105, 2107]], "75": [[511, 514]], "76": [[2570, 2573]], "77": [[1681, 1683]], "78": [[1970, 1973]], "79": [[2264, 2269]], "8": [[2420, 2422], [2901, 2903]], "80": [[2185, 2188]], "81": [[1610, 1613]], "82": [[3312, 3316]], "83": [[1803, 1805]], "84": [[2549, 2551]], "85": [[380, 381]], "86": [[2530, 2532]], "87": [[2052, 2057]], "88": [[1174, 1177]], "89": [[3690, 3695]], "9": [[1892, 1894], [3298, 3300]], "90": [[40, 42], [64, 65]], "91": [[2415, 2417]], "92": [[3732, 3737]], "93": [[1729, 1731]], "94": [[2076, 2078], [2098, 2100]], "95": [[2024, 2027]], "96": [[3682, 3687]], "97": [[2402, 2405]], "98": [[1130, 1133]], "99": [[1638, 1641]]}, "doc_id": "12e20e4ea572dbe476fd894c5c9a9930cf250dd2", "method_subrelations": {"MEMEN": [[[0, 5], "MEMEN"]], "MEMEN___single_model_": [[[0, 5], "MEMEN"], [[8, 20], "single_model"]], "MEMEN__ensemble_": [[[0, 5], "MEMEN"], [[7, 15], "ensemble"]]}, "n_ary_relations": [{"Material": "SQuAD1_1", "Method": "MEMEN___single_model_", "Metric": "EM", "Task": "Question_Answering", "score": "78.234"}, {"Material": "SQuAD1_1", "Method": "MEMEN__ensemble_", "Metric": "EM", "Task": "Question_Answering", "score": "75.370"}, {"Material": "SQuAD1_1", "Method": "MEMEN___single_model_", "Metric": "F1", "Task": "Question_Answering", "score": "85.344"}, {"Material": "SQuAD1_1", "Method": "MEMEN__ensemble_", "Metric": "F1", "Task": "Question_Answering", "score": "82.658"}, {"Material": "TriviaQA", "Method": "MEMEN", "Metric": "EM", "Task": "Question_Answering", "score": "43.16"}, {"Material": "TriviaQA", "Method": "MEMEN", "Metric": "F1", "Task": "Question_Answering", "score": "46.90"}], "ner": [[2, 3, "Method"], [4, 11, "Method"], [12, 14, "Task"], [27, 30, "Task"], [40, 42, "Task"], [64, 65, "Task"], [69, 71, "Method"], [114, 117, "Method"], [118, 125, "Method"], [126, 127, "Method"], [129, 132, "Task"], [135, 137, "Method"], [141, 145, "Method"], [160, 162, "Method"], [198, 199, "Metric"], [200, 201, "Metric"], [202, 206, "Material"], [207, 208, "Material"], [225, 227, "Material"], [231, 233, "Task"], [234, 235, "Task"], [255, 258, "Task"], [259, 261, "Task"], [295, 296, "Material"], [316, 318, "Method"], [323, 325, "Method"], [339, 341, "Method"], [362, 366, "Method"], [367, 371, "Method"], [380, 381, "Method"], [416, 418, "Method"], [449, 451, "Method"], [493, 495, "Method"], [502, 505, "Method"], [506, 509, "Method"], [511, 514, "Task"], [534, 536, "Method"], [603, 610, "Method"], [611, 612, "Method"], [615, 622, "Method"], [623, 626, "Task"], [637, 642, "Task"], [665, 670, "Method"], [671, 675, "Method"], [685, 693, "Method"], [721, 725, "Method"], [736, 740, "Method"], [743, 748, "Task"], [749, 750, "Material"], [758, 759, "Task"], [760, 762, "Method"], [775, 777, "Task"], [779, 783, "Method"], [808, 815, "Method"], [821, 824, "Method"], [826, 828, "Method"], [854, 856, "Method"], [882, 885, "Method"], [933, 934, "Metric"], [950, 951, "Material"], [962, 964, "Material"], [966, 967, "Material"], [973, 975, "Metric"], [978, 980, "Metric"], [988, 994, "Method"], [1025, 1028, "Method"], [1050, 1054, "Method"], [1067, 1071, "Method"], [1073, 1075, "Method"], [1098, 1103, "Task"], [1105, 1107, "Method"], [1130, 1133, "Method"], [1139, 1143, "Method"], [1152, 1155, "Method"], [1174, 1177, "Method"], [1178, 1179, "Method"], [1231, 1235, "Method"], [1240, 1245, "Task"], [1246, 1247, "Material"], [1255, 1256, "Task"], [1300, 1304, "Method"], [1320, 1322, "Task"], [1334, 1335, "Material"], [1356, 1360, "Method"], [1364, 1367, "Metric"], [1433, 1436, "Task"], [1445, 1448, "Method"], [1462, 1463, "Method"], [1485, 1487, "Method"], [1492, 1496, "Method"], [1497, 1501, "Method"], [1502, 1504, "Method"], [1519, 1526, "Method"], [1526, 1528, "Method"], [1550, 1553, "Method"], [1554, 1557, "Method"], [1561, 1566, "Method"], [1597, 1601, "Method"], [1610, 1613, "Task"], [1617, 1621, "Method"], [1638, 1641, "Method"], [1681, 1683, "Method"], [1686, 1687, "Method"], [1691, 1693, "Method"], [1705, 1710, "Method"], [1729, 1731, "Method"], [1783, 1785, "Method"], [1803, 1805, "Method"], [1809, 1811, "Method"], [1822, 1827, "Method"], [1860, 1862, "Method"], [1867, 1869, "Method"], [1884, 1887, "Method"], [1892, 1894, "Method"], [1916, 1917, "Method"], [1959, 1960, "Task"], [1970, 1973, "Metric"], [1983, 1987, "Method"], [2010, 2013, "Method"], [2024, 2027, "Method"], [2031, 2038, "Method"], [2052, 2057, "Method"], [2076, 2078, "Method"], [2080, 2084, "Method"], [2098, 2100, "Method"], [2105, 2107, "Method"], [2162, 2164, "Method"], [2185, 2188, "Method"], [2189, 2190, "Method"], [2239, 2241, "Task"], [2264, 2269, "Method"], [2282, 2286, "Method"], [2292, 2294, "Method"], [2300, 2301, "Method"], [2330, 2331, "Material"], [2367, 2370, "Method"], [2371, 2372, "Method"], [2374, 2377, "Task"], [2402, 2405, "Method"], [2415, 2417, "Method"], [2420, 2422, "Metric"], [2427, 2429, "Method"], [2441, 2442, "Material"], [2455, 2456, "Material"], [2458, 2459, "Material"], [2489, 2490, "Material"], [2515, 2517, "Metric"], [2518, 2520, "Metric"], [2521, 2522, "Metric"], [2524, 2526, "Metric"], [2530, 2532, "Metric"], [2534, 2535, "Metric"], [2536, 2538, "Metric"], [2549, 2551, "Method"], [2570, 2573, "Task"], [2635, 2636, "Material"], [2639, 2640, "Material"], [2645, 2649, "Material"], [2650, 2651, "Material"], [2652, 2653, "Material"], [2734, 2735, "Material"], [2790, 2791, "Method"], [2798, 2800, "Method"], [2813, 2815, "Metric"], [2839, 2841, "Method"], [2843, 2845, "Task"], [2876, 2878, "Method"], [2901, 2903, "Metric"], [2904, 2906, "Metric"], [2911, 2913, "Method"], [2939, 2941, "Method"], [2950, 2952, "Method"], [2992, 2997, "Method"], [3002, 3004, "Metric"], [3006, 3007, "Method"], [3021, 3025, "Method"], [3037, 3041, "Method"], [3047, 3051, "Method"], [3057, 3058, "Metric"], [3064, 3069, "Method"], [3087, 3089, "Metric"], [3095, 3099, "Method"], [3100, 3104, "Method"], [3126, 3127, "Metric"], [3128, 3129, "Metric"], [3165, 3166, "Metric"], [3167, 3169, "Metric"], [3214, 3215, "Method"], [3275, 3276, "Method"], [3283, 3287, "Task"], [3298, 3300, "Method"], [3312, 3316, "Task"], [3344, 3349, "Method"], [3369, 3374, "Task"], [3395, 3399, "Task"], [3421, 3428, "Task"], [3432, 3433, "Method"], [3487, 3491, "Method"], [3503, 3507, "Material"], [3574, 3575, "Material"], [3589, 3590, "Material"], [3591, 3592, "Material"], [3608, 3611, "Method"], [3612, 3614, "Task"], [3622, 3625, "Task"], [3627, 3629, "Method"], [3636, 3638, "Method"], [3639, 3641, "Method"], [3649, 3652, "Method"], [3655, 3656, "Task"], [3676, 3679, "Method"], [3682, 3687, "Method"], [3690, 3695, "Task"], [3697, 3701, "Method"], [3702, 3709, "Method"], [3728, 3730, "Method"], [3732, 3737, "Method"], [3748, 3749, "Method"], [3751, 3755, "Method"], [3762, 3764, "Method"], [3765, 3767, "Task"], [3777, 3778, "Method"], [3779, 3784, "Task"], [3788, 3792, "Method"], [3798, 3805, "Method"], [3833, 3835, "Material"], [3839, 3840, "Material"], [3844, 3848, "Method"], [3867, 3869, "Task"], [3878, 3881, "Method"], [3882, 3884, "Task"], [3885, 3888, "Task"], [14, 16, "Task"], [17, 18, "Task"], [167, 174, "Method"], [1270, 1275, "Task"], [1276, 1277, "Material"], [1285, 1286, "Task"], [2257, 2262, "Task"], [2319, 2320, "Material"], [2322, 2323, "Task"], [2398, 2399, "Method"], [2778, 2779, "Material"], [2805, 2807, "Metric"], [2893, 2894, "Material"], [2982, 2983, "Material"], [3145, 3146, "Material"], [3220, 3221, "Material"], [3248, 3249, "Material"], [3264, 3265, "Material"], [3271, 3272, "Task"], [3508, 3509, "Material"], [3594, 3595, "Material"]], "sections": [[0, 228], [228, 1015], [1015, 1096], [1096, 1517], [1517, 1636], [1636, 1703], [1703, 1820], [1820, 2039], [2039, 2224], [2224, 2227], [2227, 2439], [2439, 2637], [2637, 2832], [2832, 2962], [2962, 3130], [3130, 3400], [3400, 3404], [3404, 3606], [3606, 3768], [3768, 3889], [3889, 3892]], "sentences": [[0, 14], [14, 19], [19, 31], [31, 66], [66, 106], [106, 133], [133, 163], [163, 185], [185, 228], [228, 231], [231, 262], [262, 285], [285, 297], [297, 326], [326, 351], [351, 372], [372, 401], [401, 419], [419, 455], [455, 490], [490, 510], [510, 537], [537, 556], [556, 596], [596, 627], [627, 704], [704, 715], [715, 734], [734, 756], [756, 760], [760, 774], [774, 803], [803, 816], [816, 839], [839, 886], [886, 916], [916, 935], [935, 965], [965, 981], [981, 1015], [1015, 1019], [1019, 1033], [1033, 1055], [1055, 1081], [1081, 1096], [1096, 1103], [1103, 1134], [1134, 1147], [1147, 1165], [1165, 1199], [1199, 1228], [1228, 1253], [1253, 1259], [1259, 1283], [1283, 1297], [1297, 1340], [1340, 1392], [1392, 1413], [1413, 1424], [1424, 1455], [1455, 1488], [1488, 1506], [1506, 1517], [1517, 1526], [1526, 1544], [1544, 1584], [1584, 1602], [1602, 1622], [1622, 1636], [1636, 1641], [1641, 1652], [1652, 1688], [1688, 1703], [1703, 1710], [1710, 1732], [1732, 1737], [1737, 1759], [1759, 1806], [1806, 1820], [1820, 1827], [1827, 1855], [1855, 1870], [1870, 1906], [1906, 1918], [1918, 1950], [1950, 1974], [1974, 2004], [2004, 2028], [2028, 2039], [2039, 2043], [2043, 2065], [2065, 2101], [2101, 2165], [2165, 2198], [2198, 2224], [2224, 2227], [2227, 2231], [2231, 2243], [2243, 2254], [2254, 2280], [2280, 2310], [2310, 2345], [2345, 2364], [2364, 2386], [2386, 2412], [2412, 2425], [2425, 2439], [2439, 2443], [2443, 2458], [2458, 2489], [2489, 2508], [2508, 2542], [2542, 2567], [2567, 2583], [2583, 2606], [2606, 2637], [2637, 2641], [2641, 2658], [2658, 2678], [2678, 2699], [2699, 2731], [2731, 2765], [2765, 2780], [2780, 2832], [2832, 2836], [2836, 2871], [2871, 2891], [2891, 2925], [2925, 2945], [2945, 2962], [2962, 2967], [2967, 3005], [3005, 3034], [3034, 3055], [3055, 3090], [3090, 3116], [3116, 3130], [3130, 3135], [3135, 3158], [3158, 3181], [3181, 3210], [3210, 3229], [3229, 3244], [3244, 3256], [3256, 3281], [3281, 3311], [3311, 3343], [3343, 3368], [3368, 3400], [3400, 3404], [3404, 3411], [3411, 3432], [3432, 3443], [3443, 3468], [3468, 3476], [3476, 3499], [3499, 3527], [3527, 3574], [3574, 3606], [3606, 3614], [3614, 3634], [3634, 3646], [3646, 3662], [3662, 3680], [3680, 3696], [3696, 3715], [3715, 3731], [3731, 3747], [3747, 3768], [3768, 3771], [3771, 3785], [3785, 3815], [3815, 3841], [3841, 3870], [3870, 3889], [3889, 3892]], "words": ["document", ":", "MEMEN", ":", "Multi", "-", "layer", "Embedding", "with", "Memory", "Networks", "for", "Machine", "Comprehension", "Machine", "comprehension", "(", "MC", ")", "style", "question", "answering", "is", "a", "representative", "problem", "in", "natural", "language", "processing", ".", "Previous", "methods", "rarely", "spend", "time", "on", "the", "improvement", "of", "encoding", "layer", ",", "especially", "the", "embedding", "of", "syntactic", "information", "and", "name", "entity", "of", "the", "words", ",", "which", "are", "very", "crucial", "to", "the", "quality", "of", "encoding", ".", "Moreover", ",", "existing", "attention", "methods", "represent", "each", "query", "word", "as", "a", "vector", "or", "use", "a", "single", "vector", "to", "represent", "the", "whole", "query", "sentence", ",", "neither", "of", "them", "can", "handle", "the", "proper", "weight", "of", "the", "key", "words", "in", "query", "sentence", ".", "In", "this", "paper", ",", "we", "introduce", "a", "novel", "neural", "network", "architecture", "called", "Multi", "-", "layer", "Embedding", "with", "Memory", "Network", "(", "MEMEN", ")", "for", "machine", "reading", "task", ".", "In", "the", "encoding", "layer", ",", "we", "employ", "classic", "skip", "-", "gram", "model", "to", "the", "syntactic", "and", "semantic", "information", "of", "the", "words", "to", "train", "a", "new", "kind", "of", "embedding", "layer", ".", "We", "also", "propose", "a", "memory", "network", "of", "full", "-", "orientation", "matching", "of", "the", "query", "and", "passage", "to", "catch", "more", "pivotal", "information", ".", "Experiments", "show", "that", "our", "model", "has", "competitive", "results", "both", "from", "the", "perspectives", "of", "precision", "and", "efficiency", "in", "Stanford", "Question", "Answering", "Dataset", "(", "SQuAD", ")", "among", "all", "published", "results", "and", "achieves", "the", "state", "-", "of", "-", "the", "-", "art", "results", "on", "TriviaQA", "dataset", ".", "section", ":", "Introduction", "Machine", "comprehension", "(", "MC", ")", "has", "gained", "significant", "popularity", "over", "the", "past", "few", "years", "and", "it", "is", "a", "coveted", "goal", "in", "the", "field", "of", "natural", "language", "processing", "and", "artificial", "intelligence", ".", "Its", "task", "is", "to", "teach", "machine", "to", "understand", "the", "content", "of", "a", "given", "passage", "and", "then", "answer", "the", "question", "related", "to", "it", ".", "Figure", "1", "shows", "a", "simple", "example", "from", "the", "popular", "dataset", "SQuAD", ".", "Many", "significant", "works", "are", "based", "on", "this", "task", ",", "and", "most", "of", "them", "focus", "on", "the", "improvement", "of", "a", "sequence", "model", "that", "is", "augmented", "with", "an", "attention", "mechanism", ".", "However", ",", "the", "encoding", "of", "the", "words", "is", "also", "crucial", "and", "a", "better", "encoding", "layer", "can", "lead", "to", "substantial", "difference", "to", "the", "final", "performance", ".", "Many", "powerful", "methods", "only", "represent", "their", "words", "in", "two", "ways", ",", "word", "-", "level", "embeddings", "and", "character", "-", "level", "embeddings", ".", "They", "use", "pre", "-", "train", "vectors", ",", "like", "GloVe", ",", "to", "do", "the", "word", "-", "level", "embeddings", ",", "which", "ignore", "syntactic", "information", "and", "name", "entity", "of", "the", "words", ".", "construct", "a", "sequence", "of", "syntactic", "nodes", "for", "the", "words", "and", "encodes", "the", "sequence", "into", "a", "vector", "representation", ".", "However", ",", "they", "neglected", "the", "optimization", "of", "the", "initial", "embedding", "and", "did", "n\u2019t", "take", "the", "semantic", "information", "of", "the", "words", "into", "account", ",", "which", "are", "very", "important", "parts", "in", "the", "vector", "representations", "of", "the", "words", ".", "For", "example", ",", "the", "word", "\u201c", "Apple", "\u201d", "is", "a", "fixed", "vector", "in", "GloVe", "and", "noun", "in", "syntactics", "whatever", "it", "represents", "the", "fruit", "or", "the", "company", ",", "but", "name", "entity", "tags", "can", "help", "recognize", ".", "Moreover", ",", "the", "attention", "mechanism", "can", "be", "divided", "into", "two", "categories", ":", "one", "dimensional", "attention", "and", "two", "dimensional", "attention", ".", "In", "one", "dimensional", "attention", ",", "the", "whole", "query", "is", "represented", "by", "one", "embedding", "vector", ",", "which", "is", "usually", "the", "last", "hidden", "state", "in", "the", "neural", "network", ".", "However", ",", "using", "only", "one", "vector", "to", "represent", "the", "whole", "query", "will", "attenuate", "the", "attention", "of", "key", "words", ".", "On", "the", "contrary", ",", "every", "word", "in", "the", "query", "has", "its", "own", "embedding", "vector", "in", "the", "situation", "of", "two", "dimensional", "attention", ",", "but", "many", "words", "in", "the", "question", "sentence", "are", "useless", "even", "if", "disturbing", ",", "such", "as", "the", "stopwords", ".", "In", "this", "paper", ",", "we", "introduce", "the", "Multi", "-", "layer", "Embedding", "with", "Memory", "Networks", "(", "MEMEN", ")", ",", "an", "end", "-", "to", "-", "end", "neural", "network", "for", "machine", "comprehension", "task", ".", "Our", "model", "consists", "of", "three", "parts", ":", "1", ")", "the", "encoding", "of", "context", "and", "query", ",", "in", "which", "we", "add", "useful", "syntactic", "and", "semantic", "information", "in", "the", "embedding", "of", "every", "word", ",", "2", ")", "the", "high", "-", "efficiency", "multi", "-", "layer", "memory", "network", "of", "full", "-", "orientation", "matching", "to", "match", "the", "question", "and", "context", ",", "3", ")", "the", "pointer", "-", "network", "based", "answer", "boundary", "prediction", "layer", "to", "get", "the", "location", "of", "the", "answer", "in", "the", "passage", ".", "The", "contributions", "of", "this", "paper", "can", "be", "summarized", "as", "follows", ".", "First", ",", "we", "propose", "a", "novel", "multi", "-", "layer", "embedding", "of", "the", "words", "in", "the", "passage", "and", "query", ".", "We", "use", "skip", "-", "gram", "model", "to", "train", "the", "part", "-", "of", "-", "speech", "(", "POS", ")", "tags", "and", "name", "-", "entity", "recognition", "(", "NER", ")", "tags", "embedding", "that", "represent", "the", "syntactic", "and", "semantic", "information", "of", "the", "words", "respectively", ".", "The", "analogy", "inference", "provided", "by", "skip", "-", "gram", "model", "can", "make", "the", "similar", "attributes", "close", "in", "their", "embedding", "space", "such", "that", "more", "adept", "at", "helping", "find", "the", "answer", ".", "Second", ",", "we", "introduce", "a", "memory", "networks", "of", "full", "-", "orientation", "matching", ".", "To", "combines", "the", "advantages", "of", "one", "dimensional", "attention", "and", "two", "dimensional", "attention", ",", "our", "novel", "hierarchical", "attention", "vectors", "contain", "both", "of", "them", ".", "Because", "key", "words", "in", "query", "often", "appear", "at", "ends", "of", "the", "sentence", ",", "one", "-", "dimensional", "attention", ",", "in", "which", "the", "bi", "-", "directional", "last", "hidden", "states", "are", "regarded", "as", "representation", ",", "is", "able", "to", "capture", "more", "useful", "information", "compared", "to", "only", "applying", "two", "dimensional", "attention", ".", "In", "order", "to", "deepen", "the", "memory", "and", "better", "understand", "the", "passage", "according", "to", "the", "query", ",", "we", "employ", "the", "structure", "of", "multi", "-", "hops", "to", "repeatedly", "read", "the", "passage", ".", "Moreover", ",", "we", "add", "a", "gate", "to", "the", "end", "of", "each", "memory", "to", "improve", "the", "speed", "of", "convergence", ".", "Finally", ",", "the", "proposed", "method", "yields", "competitive", "results", "on", "the", "large", "machine", "comprehension", "bench", "marks", "SQuAD", "and", "the", "state", "-", "of", "-", "the", "-", "art", "results", "on", "TriviaQA", "dataset", ".", "On", "SQuAD", ",", "our", "model", "achieves", "75.37", "%", "exact", "match", "and", "82.66", "%", "F1", "score", ".", "Moreover", ",", "our", "model", "avoids", "the", "high", "computation", "complexity", "self", "-", "matching", "mechanism", "which", "is", "popular", "in", "many", "previous", "works", ",", "thus", "we", "spend", "much", "less", "time", "and", "memory", "when", "training", "the", "model", ".", "section", ":", "Model", "Structure", "As", "Figure", "2", "shows", ",", "our", "machine", "reading", "model", "consists", "of", "three", "parts", ".", "First", ",", "we", "concatenate", "several", "layers", "of", "embedding", "of", "questions", "and", "contexts", "and", "pass", "them", "into", "a", "bi", "-", "directional", "RNN", ".", "Then", "we", "obtain", "the", "relationship", "between", "query", "and", "context", "through", "a", "novel", "full", "-", "orientation", "matching", "and", "apply", "memory", "networks", "in", "order", "to", "deeply", "understand", ".", "In", "the", "end", ",", "the", "output", "layer", "helps", "locate", "the", "answer", "in", "the", "passage", ".", "subsection", ":", "Encoding", "of", "Context", "and", "Query", "In", "the", "encoding", "layer", ",", "we", "represent", "all", "tokens", "in", "the", "context", "and", "question", "as", "a", "sequence", "of", "embeddings", "and", "pass", "them", "as", "the", "input", "to", "a", "recurrent", "neural", "network", ".", "Word", "-", "level", "embeddings", "and", "character", "-", "level", "embeddings", "are", "first", "applied", ".", "We", "use", "pre", "-", "trained", "word", "vectors", "GloVe", "to", "obtain", "the", "fixed", "word", "embedding", "of", "each", "word", ".", "The", "character", "-", "level", "embeddings", "are", "generated", "by", "using", "Convolutional", "Neural", "Networks", "(", "CNN", ")", "which", "is", "applied", "to", "the", "characters", "of", "each", "word", "(", "Kim", ",", "et", "al", ".", ",", "2014", ")", ".", "This", "layer", "maps", "each", "token", "to", "a", "high", "dimensional", "vector", "space", "and", "is", "proved", "to", "be", "helpful", "in", "handling", "out", "-", "of", "-", "vocab", "(", "OOV", ")", "words", ".", "We", "also", "use", "skip", "-", "gram", "model", "to", "train", "the", "embeddings", "of", "part", "-", "of", "-", "speech", "(", "POS", ")", "tags", "and", "named", "-", "entity", "recognition", "(", "NER", ")", "tags", ".", "We", "first", "transform", "all", "of", "the", "given", "training", "set", "into", "their", "part", "-", "of", "-", "speech", "(", "POS", ")", "tags", "and", "named", "-", "entity", "recognition", "(", "NER", ")", "tags", ",", "which", "can", "be", "showed", "in", "Figure", "3", ".", "Then", "we", "employ", "skip", "-", "sram", "model", ",", "which", "is", "one", "of", "the", "core", "algorithms", "in", "the", "popular", "off", "-", "the", "-", "shelf", "embedding", "word2vec", ",", "to", "the", "transformed", "\u201c", "passage", "\u201d", "just", "like", "it", "works", "in", "word2vec", "for", "the", "normal", "passage", ".", "Given", "a", "sequence", "of", "training", "words", "in", "the", "transformed", "passage", ":", ",", "the", "objective", "of", "the", "skip", "-", "gram", "model", "is", "to", "maximize", "the", "average", "log", "probability", ":", "where", "is", "the", "size", "of", "the", "context", "which", "can", "be", "set", "manually", ",", "a", "large", "means", "more", "accurate", "results", "and", "more", "training", "time", ".", "The", "is", "defined", "by", ":", "where", "and", "are", "the", "input", "and", "output", "vector", "of", ",", "and", "is", "the", "vocabulary", "size", ".", "We", "finally", "get", "the", "fixed", "length", "embedding", "of", "each", "tag", ".", "Although", "the", "number", "of", "tags", "limits", "the", "effect", "of", "word", "analogy", "inference", ",", "it", "still", "be", "very", "helpful", "compared", "to", "simple", "one", "hot", "embedding", "since", "similar", "tags", "have", "similar", "surroundings", ".", "In", "the", "end", ",", "we", "use", "a", "BiLSTM", "to", "encode", "both", "the", "context", "and", "query", "embeddings", "and", "obtain", "their", "representations", "and", "and", "the", "last", "hidden", "state", "of", "both", "directions", "of", "query", "representation", ".", "where", ",", ",", "represent", "word", "-", "level", "embedding", ",", "character", "-", "level", "embedding", "and", "tags", "embedding", "respectively", ".", "is", "the", "concatenation", "of", "both", "directions", "\u2019", "last", "hidden", "state", ".", "subsection", ":", "Memory", "Network", "of", "Full", "-", "Orientation", "Matching", "Attention", "mechanism", "is", "a", "common", "way", "to", "link", "and", "blend", "the", "content", "between", "the", "context", "and", "query", ".", "Unlike", "previous", "methods", "that", "are", "either", "two", "dimensional", "matching", "or", "one", "dimensional", "matching", ",", "we", "propose", "a", "full", "-", "orientation", "matching", "layer", "that", "synthesizes", "both", "of", "them", "and", "thus", "combine", "the", "advantages", "of", "both", "side", "and", "hedge", "the", "weakness", ".", "After", "concatenating", "all", "the", "attention", "vectors", ",", "we", "will", "pass", "them", "into", "a", "bi", "-", "directional", "LSTM", ".", "We", "start", "by", "describing", "our", "model", "in", "the", "single", "layer", "case", ",", "which", "implements", "a", "single", "memory", "hop", "operation", ".", "We", "then", "show", "it", "can", "be", "stacked", "to", "give", "multiple", "hops", "in", "memory", ".", "subsubsection", ":", "Integral", "Query", "Matching", "The", "input", "of", "this", "step", "is", "the", "representations", ",", "and", ".", "At", "first", "we", "obtain", "the", "importance", "of", "each", "word", "in", "passage", "according", "to", "the", "integral", "query", "by", "means", "of", "computing", "the", "match", "between", "and", "each", "representation", "by", "taking", "the", "inner", "product", "followed", "by", "a", "softmax", ":", "Subsequently", "the", "first", "matching", "module", "is", "the", "sum", "of", "the", "inputs", "weighted", "by", "attention", ":", "subsubsection", ":", "Query", "-", "Based", "Similarity", "Matching", "We", "then", "obtain", "an", "alignment", "matrix", "between", "the", "query", "and", "context", "by", ",", "is", "the", "weight", "parameter", ",", "is", "elementwise", "multiplication", ".", "Like", "Seo", "et", "al", ".", "(", "2017", ")", ",", "we", "use", "this", "alignment", "matrix", "to", "compute", "whether", "the", "query", "words", "are", "relevant", "to", "each", "context", "word", ".", "For", "each", "context", "word", ",", "there", "is", "an", "attention", "weight", "that", "represents", "how", "much", "it", "is", "relevant", "to", "every", "query", "word", ":", "means", "the", "softmax", "function", "is", "performed", "across", "the", "row", "vector", ",", "and", "each", "attention", "vector", "is", ",", "which", "is", "based", "on", "the", "query", "embedding", ".", "Hence", "the", "second", "matching", "module", "is", ",", "where", "each", "is", "the", "column", "of", ".", "subsubsection", ":", "Context", "-", "Based", "Similarity", "Matching", "When", "we", "consider", "the", "relevance", "between", "context", "and", "query", ",", "the", "most", "representative", "word", "in", "the", "query", "sentence", "can", "be", "chosen", "by", ",", "and", "the", "attention", "is", ".", "Then", "we", "obtain", "the", "last", "matching", "module", "which", "is", "based", "on", "the", "context", "embedding", ".", "We", "put", "all", "of", "the", "memories", "in", "a", "linear", "function", "to", "get", "the", "integrated", "hierarchical", "matching", "module", ":", "where", "is", "an", "simple", "linear", "function", ",", "and", "are", "matrixes", "that", "are", "tiled", "n", "times", "by", "and", ".", "Moreover", ",", "add", "an", "additional", "gate", "to", "the", "input", "of", "RNN", ":", "The", "gate", "is", "based", "on", "the", "integration", "of", "hierarchical", "attention", "vectors", ",", "and", "it", "effectively", "filtrates", "the", "part", "of", "tokens", "that", "are", "helpful", "in", "understanding", "the", "relation", "between", "passage", "and", "query", ".", "Additionally", ",", "we", "add", "a", "bias", "to", "improve", "the", "estimation", ":", "Experiments", "prove", "that", "this", "gate", "can", "also", "accelerate", "the", "speed", "of", "convergence", ".", "Finally", ",", "the", "integrated", "memory", "is", "passed", "into", "a", "bi", "-", "directional", "LSTM", ",", "and", "the", "output", "will", "captures", "the", "interaction", "among", "the", "context", "words", "and", "the", "query", "words", ":", "In", "multiple", "layers", ",", "the", "integrated", "hierarchical", "matching", "module", "can", "be", "regarded", "as", "the", "input", "of", "next", "layer", "after", "a", "dimensionality", "reduction", "processing", ".", "We", "call", "this", "memory", "networks", "of", "full", "-", "orientation", "matching", ".", "subsection", ":", "Output", "layer", "In", "this", "layer", ",", "we", "follow", "to", "use", "the", "boundary", "model", "of", "pointer", "networks", "to", "locate", "the", "answer", "in", "the", "passage", ".", "Moreover", ",", "we", "follow", "to", "initialize", "the", "hidden", "state", "of", "the", "pointer", "network", "by", "a", "query", "-", "aware", "representation", ":", "where", ",", "and", "are", "parameters", ",", "is", "the", "initial", "hidden", "state", "of", "the", "pointer", "network", ".", "Then", "we", "use", "the", "passage", "representation", "along", "with", "the", "initialized", "hidden", "state", "to", "predict", "the", "indices", "that", "represent", "the", "answer", "\u2019s", "location", "in", "the", "passage", ":", "where", "is", "parameter", ",", "that", "respectively", "represent", "the", "start", "point", "and", "the", "end", "point", "of", "the", "answer", ",", "is", "the", "vector", "that", "represents", "-", "th", "word", "in", "the", "passage", "of", "the", "final", "output", "of", "the", "memory", "networks", ".", "To", "get", "the", "next", "layer", "of", "hidden", "state", ",", "we", "need", "to", "pass", "weighted", "by", "current", "predicted", "probability", "to", "the", "Gated", "Recurrent", "Unit", "(", "GRU", ")(", "Chung", "et", "al", ".", ",", "2014", ")", ":", "For", "the", "loss", "function", ",", "we", "minimize", "the", "sum", "of", "the", "negative", "probabilities", "of", "the", "true", "start", "and", "end", "indices", "by", "the", "predicted", "distributions", ".", "section", ":", "Experiment", "subsection", ":", "Implementation", "Settings", "The", "tokenizers", "we", "use", "in", "the", "step", "of", "preprocessing", "data", "are", "from", "Stanford", "CoreNLP", "(", "Manning", "et", "al", ".", ",", "2014", ")", ".", "We", "also", "use", "part", "-", "of", "-", "speech", "tagger", "and", "named", "-", "entity", "recognition", "tagger", "in", "Stanford", "CoreNLP", "utilities", "to", "transform", "the", "passage", "and", "question", ".", "For", "the", "skip", "-", "gram", "model", ",", "our", "model", "refers", "to", "the", "word2vec", "module", "in", "open", "source", "software", "library", ",", "Tensorflow", ",", "the", "skip", "window", "is", "set", "as", "2", ".", "The", "dataset", "we", "use", "to", "train", "the", "embedding", "of", "POS", "tags", "and", "NER", "tags", "are", "the", "training", "set", "given", "by", "SQuAD", ",", "in", "which", "all", "the", "sentences", "are", "tokenized", "and", "regrouped", "as", "a", "list", ".", "To", "improve", "the", "reliability", "and", "stabllity", ",", "we", "screen", "out", "the", "sentences", "whose", "length", "are", "shorter", "than", "9", ".", "We", "use", "100", "one", "dimensional", "filters", "for", "CNN", "in", "the", "character", "level", "embedding", ",", "with", "width", "of", "5", "for", "each", "one", ".", "We", "set", "the", "hidden", "size", "as", "100", "for", "all", "the", "LSTM", "and", "GRU", "layers", "and", "apply", "dropout", "between", "layers", "with", "a", "dropout", "ratio", "as", "0.2", ".", "We", "use", "the", "AdaDelta", "optimizer", "with", "a", "initial", "learning", "rate", "as", "0.001", ".", "For", "the", "memory", "networks", ",", "we", "set", "the", "number", "of", "layer", "as", "3", ".", "subsection", ":", "TriviaQA", "Results", "We", "first", "evaluate", "our", "model", "on", "a", "large", "scale", "reading", "comprehension", "dataset", "TriviaQA", "version1.0", ".", "TriviaQA", "contains", "over", "650", "K", "question", "-", "answer", "-", "evidence", "triples", ",", "that", "are", "derived", "from", "Web", "search", "results", "and", "Wikipedia", "pages", "\u00e2\u0080\u0093", "with", "highly", "differing", "levels", "of", "information", "redundancy", ".", "TriviaQA", "is", "the", "first", "dataset", "where", "questions", "are", "authored", "by", "trivia", "enthusiasts", ",", "independently", "of", "the", "evidence", "documents", ".", "There", "are", "two", "different", "metrics", "to", "evaluate", "model", "accuracy", ":", "Exact", "Match", "(", "EM", ")", "and", "F1", "Score", ",", "which", "measures", "the", "weighted", "average", "of", "the", "precision", "and", "recall", "rate", "at", "character", "level", ".", "Because", "the", "evidence", "is", "gathered", "by", "an", "automated", "process", ",", "the", "documents", "are", "not", "guaranteed", "to", "contain", "all", "facts", "needed", "to", "answer", "the", "question", ".", "In", "addition", "to", "distant", "supervision", "evaluation", ",", "we", "also", "evaluate", "models", "on", "a", "verified", "subsets", ".", "Because", "the", "test", "set", "is", "not", "released", ",", "we", "train", "our", "model", "on", "training", "set", "and", "evaluate", "our", "model", "on", "dev", "set", ".", "As", "we", "can", "see", "in", "Figure", "4", ",", "our", "model", "outperforms", "all", "other", "baselines", "and", "achieves", "the", "state", "-", "of", "-", "the", "-", "art", "result", "on", "all", "subsets", "on", "TriviaQA", ".", "subsection", ":", "SQuAD", "Results", "We", "also", "use", "the", "Stanford", "Question", "Answering", "Dataset", "(", "SQuAD", ")", "v1.1", "to", "conduct", "our", "experiments", ".", "Passages", "in", "the", "dataset", "are", "retrieved", "from", "English", "Wikipedia", "by", "means", "of", "Project", "Nayuki", "\u2019s", "Wikipedia", "\u2019s", "internal", "PageRanks", ".", "They", "sampled", "536", "articles", "uniformly", "at", "random", "with", "a", "wide", "range", "of", "topics", ",", "from", "musical", "celebrities", "to", "abstract", "concepts", ".", "The", "dataset", "is", "partitioned", "randomly", "into", "a", "training", "set", "(", "80", "%", ")", ",", "a", "development", "set", "(", "10", "%", ")", ",", "and", "a", "hidden", "test", "set", "(", "10", "%", ")", ".", "The", "host", "of", "SQuAD", "did", "n\u2019t", "release", "the", "test", "set", "to", "the", "public", ",", "so", "everybody", "has", "to", "submit", "their", "model", "and", "the", "host", "will", "run", "it", "on", "the", "test", "set", "for", "them", ".", "Figure", "5", "shows", "the", "performance", "of", "our", "model", "and", "competing", "approaches", "on", "the", "SQuAD", ".", "The", "results", "of", "this", "dataset", "are", "all", "exhibited", "on", "a", "leaderboard", ",", "and", "top", "methods", "are", "almost", "all", "ensemble", "models", ",", "our", "model", "achieves", "an", "exact", "match", "score", "of", "75.37", "%", "and", "an", "F1", "score", "of", "82.66", "%", ",", "which", "is", "competitive", "to", "state", "-", "of", "-", "the", "-", "art", "method", ".", "subsection", ":", "Ensemble", "Details", "The", "main", "current", "ensemble", "methods", "in", "the", "machine", "comprehension", "is", "simply", "choosing", "the", "answer", "with", "the", "highest", "sum", "of", "confidence", "scores", "among", "several", "single", "models", "which", "are", "exactly", "identical", "except", "the", "random", "initial", "seed", ".", "However", ",", "the", "performance", "of", "ensemble", "model", "can", "obviously", "be", "better", "if", "there", "is", "some", "diversity", "among", "single", "models", ".", "In", "our", "SQuAD", "experiment", ",", "we", "get", "the", "value", "of", "learning", "rate", "and", "dropout", "ratio", "of", "each", "model", "by", "a", "gaussian", "distribution", ",", "in", "which", "the", "mean", "value", "are", "0.001", "and", "0.2", "respectively", ".", "To", "keep", "the", "diversity", "in", "a", "reasonable", "scope", ",", "we", "set", "the", "variance", "of", "gaussian", "distribution", "as", "and", "respectively", ".", "Finally", ",", "we", "build", "an", "ensemble", "model", "which", "consists", "of", "14", "single", "models", "with", "different", "parameters", ".", "subsection", ":", "Speed", "and", "Efficiency", "Compared", "to", ",", "which", "achieves", "state", "-", "of", "-", "the", "-", "art", "result", "on", "the", "SQuAD", "test", "set", ",", "our", "model", "does", "n\u2019t", "contain", "the", "self", "-", "matching", "attention", "layer", "which", "is", "stuck", "with", "high", "computational", "complexity", ".", "Our", "MEMEN", "was", "trained", "with", "NVIDIA", "Titan", "X", "GPU", ",", "and", "the", "training", "process", "of", "the", "3", "-", "hops", "model", "took", "roughly", "5", "hours", "on", "a", "single", "GPU", ".", "However", ",", "an", "one", "-", "hop", "model", "took", "22", "hours", "when", "we", "added", "self", "-", "matching", "layer", "in", "attention", "memory", ".", "Although", "the", "accuracy", "is", "improved", "a", "little", "compared", "to", "one", "-", "hop", "MEMEN", "model", ",", "it", "declined", "sharply", "as", "the", "number", "of", "hops", "increased", ",", "not", "to", "speak", "of", "the", "disadvantage", "of", "running", "time", ".", "The", "reason", "might", "be", "that", "multi", "-", "hops", "model", "with", "self", "-", "matching", "layer", "is", "too", "complex", "to", "efficiently", "learn", "the", "features", "for", "this", "dataset", ".", "As", "a", "result", ",", "our", "model", "is", "competitive", "both", "in", "accuracy", "and", "efficiency", ".", "subsection", ":", "Hops", "and", "Ablations", "Figure", "6", "shows", "the", "performance", "of", "our", "single", "model", "on", "SQuAD", "dev", "set", "with", "different", "number", "of", "hops", "in", "the", "memory", "network", ".", "As", "we", "can", "see", ",", "both", "the", "EM", "and", "F1", "score", "increase", "as", "the", "number", "of", "hops", "enlarges", "until", "it", "arrives", "3", ".", "After", "the", "model", "achieves", "the", "best", "performance", "with", "3", "hops", ",", "the", "performance", "gets", "worse", "as", "the", "number", "of", "hops", "gets", "large", ",", "which", "might", "result", "in", "overfitting", ".", "We", "also", "run", "the", "ablations", "of", "our", "single", "model", "on", "SQuAD", "dev", "set", "to", "evaluate", "the", "individual", "contribution", ".", "As", "Figure", "7", "shows", ",", "both", "syntactic", "embeddings", "and", "semantic", "embeddings", "contribute", "towards", "the", "model", "\u2019s", "performance", "and", "the", "POS", "tags", "seem", "to", "be", "more", "important", ".", "The", "reason", "may", "be", "that", "the", "number", "of", "POS", "tags", "is", "larger", "than", "that", "of", "NER", "tags", "so", "the", "embedding", "is", "easier", "to", "train", ".", "For", "the", "full", "-", "orientation", "matching", ",", "we", "remove", "each", "kind", "of", "attention", "vector", "respectively", "and", "the", "linear", "function", "can", "handle", "any", "two", "of", "the", "rest", "hierarchical", "attention", "vectors", ".", "For", "ablating", "integral", "query", "matching", ",", "the", "result", "drops", "about", "2", "%", "on", "both", "metrics", "and", "it", "shows", "that", "the", "integral", "information", "of", "query", "for", "each", "word", "in", "passage", "is", "crucial", ".", "The", "query", "-", "based", "similarity", "matching", "accounts", "for", "about", "10", "%", "performance", "degradation", ",", "which", "proves", "the", "effectiveness", "of", "alignment", "context", "words", "against", "query", ".", "For", "context", "-", "based", "similarity", "matching", ",", "we", "simply", "took", "out", "the", "from", "the", "linear", "function", "and", "it", "is", "proved", "to", "be", "contributory", "to", "the", "performance", "of", "full", "-", "orientation", "matching", ".", "section", ":", "Related", "Work", "subsection", ":", "Machine", "Reading", "Comprehension", "Dataset", ".", "Several", "benchmark", "datasets", "play", "an", "important", "role", "in", "progress", "of", "machine", "comprehension", "task", "and", "question", "answering", "research", "in", "recent", "years", ".", "MCTest", "is", "one", "of", "the", "famous", "and", "high", "quality", "datasets", ".", "There", "are", "660", "fictional", "stories", "and", "4", "multiple", "choice", "questions", "per", "story", "contained", "in", "it", ",", "and", "the", "labels", "are", "all", "made", "by", "humans", ".", "Researchers", "also", "released", "cloze", "-", "style", "datasets", ".", "However", ",", "these", "datasets", "are", "either", "not", "large", "enough", "to", "support", "deep", "neural", "network", "models", "or", "too", "easy", "to", "challenge", "natural", "language", ".", "Recently", ",", "released", "the", "Stanford", "Question", "Answering", "dataset", "(", "SQuAD", ")", ",", "which", "is", "almost", "two", "orders", "of", "magnitude", "larger", "than", "all", "previous", "hand", "-", "annotated", "datasets", ".", "Moreover", ",", "this", "dataset", "consists", "100", ",", "000", "+", "questions", "posed", "by", "crowdworkers", "on", "a", "set", "of", "Wikipedia", "articles", ",", "where", "the", "answer", "to", "each", "question", "is", "a", "segment", "of", "text", "from", "the", "corresponding", "passage", ",", "rather", "than", "a", "limited", "set", "of", "multiple", "choices", "or", "entities", ".", "TriviaQA", "is", "also", "a", "large", "and", "high", "quality", "dataset", ",", "and", "the", "crucial", "difference", "between", "TriviaQA", "and", "SQuAD", "is", "that", "TriviaQA", "questions", "have", "not", "been", "crowdsourced", "from", "pre", "-", "selected", "passages", ".", "subsection", ":", "Attention", "Based", "Models", "for", "Machine", "Reading", "Many", "works", "are", "based", "on", "the", "task", "of", "machine", "reading", "comprehension", ",", "and", "attention", "mechanism", "have", "been", "particularly", "successful", ".", "present", "a", "coattention", "encoder", "and", "dynamic", "decoder", "to", "locate", "the", "answer", ".", "propose", "a", "two", "side", "attention", "mechanism", "to", "compute", "the", "matching", "between", "the", "passage", "and", "query", ".", "match", "the", "passage", "and", "query", "from", "several", "perspectives", "and", "predict", "the", "answer", "by", "globally", "normalizing", "probability", "distributions", ".", "propose", "a", "bi", "-", "directional", "attention", "flow", "to", "achieve", "a", "query", "-", "aware", "context", "representation", ".", "propose", "self", "-", "aware", "representation", "and", "multi", "-", "hop", "query", "-", "sensitive", "pointer", "to", "predict", "the", "answer", "span", ".", "propose", "iterarively", "inferring", "the", "answer", "with", "a", "dynamic", "number", "of", "steps", "trained", "with", "reinforcement", "learning", ".", "employ", "gated", "self", "-", "matching", "attention", "to", "obtain", "the", "relation", "between", "the", "question", "and", "passage", ".", "Our", "MEMEN", "construct", "a", "hierarchical", "orientation", "attention", "mechanism", "to", "get", "a", "wider", "match", "while", "applying", "memory", "network", "for", "deeper", "understand", ".", "section", ":", "Conclusion", "In", "this", "paper", ",", "we", "introduce", "MEMEN", "for", "Machine", "comprehension", "style", "question", "answering", ".", "We", "propose", "the", "multi", "-", "layer", "embedding", "to", "encode", "the", "document", "and", "the", "memory", "network", "of", "full", "-", "orientation", "matching", "to", "obtain", "the", "interaction", "of", "the", "context", "and", "query", ".", "The", "experimental", "evaluation", "shows", "that", "our", "model", "achieves", "the", "state", "-", "of", "-", "the", "-", "art", "result", "on", "TriviaQA", "dataset", "and", "competitive", "result", "in", "SQuAD", ".", "Moreover", ",", "the", "ablations", "and", "hops", "analysis", "demonstrate", "the", "importance", "of", "every", "part", "of", "the", "hierarchical", "attention", "vectors", "and", "the", "benefit", "of", "multi", "-", "hops", "in", "memory", "network", ".", "For", "future", "work", ",", "we", "will", "focus", "on", "question", "generative", "method", "and", "sentence", "ranking", "in", "machine", "reading", "tasks", ".", "bibliography", ":", "References"]}