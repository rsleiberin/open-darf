{"coref": {"CBS-1": [[2353, 2356]], "CBS-1___ESIM": [], "ESIM": [[4337, 4338], [4346, 4348]], "Natural_Language_Inference": [[98, 101], [645, 648], [3140, 3143], [3188, 3191], [3520, 3523], [3780, 3783], [3832, 3835], [4364, 4367], [2425, 2428]], "SNLI": [[3778, 3779], [4376, 4377], [3786, 3787], [3846, 3847]], "__Test_Accuracy": [[781, 784], [2532, 2534], [2603, 2605], [2676, 2678], [2681, 2683], [2697, 2699], [2702, 2704], [2749, 2750], [2778, 2779], [2923, 2924], [2954, 2955], [2975, 2976], [3264, 3265], [3276, 3279]]}, "coref_non_salient": {"0": [[1889, 1890], [1915, 1917], [1936, 1937], [2018, 2022], [2173, 2175], [2180, 2182], [2208, 2211], [2215, 2217], [2377, 2380], [3177, 3178], [3248, 3249], [4326, 4329]], "1": [[2027, 2028], [2133, 2134], [2342, 2343], [2371, 2372], [3645, 3646], [3652, 3656], [3723, 3727]], "10": [[230, 233], [613, 615], [3031, 3033]], "100": [[3664, 3667]], "101": [[394, 396]], "102": [[158, 161]], "103": [[253, 255], [384, 386]], "104": [[2521, 2524], [2544, 2547], [2684, 2687], [2719, 2722], [3571, 3574], [3882, 3885], [3948, 3951], [3997, 4000]], "105": [[20, 23], [438, 441], [3076, 3079]], "106": [[1705, 1708]], "107": [[1574, 1578]], "108": [[3153, 3154]], "109": [[2135, 2136]], "11": [[1498, 1500], [1585, 1588]], "110": [[4045, 4047]], "111": [[796, 798]], "112": [[411, 413]], "113": [[1136, 1139]], "114": [[3007, 3008]], "115": [[265, 266]], "116": [[519, 521]], "117": [[1431, 1439]], "118": [[1995, 2001]], "119": [[1565, 1567]], "12": [[1976, 1978], [2029, 2031], [2344, 2346], [2373, 2375], [3708, 3710], [3716, 3719]], "13": [[2024, 2026], [2149, 2153], [2332, 2334]], "14": [[751, 753], [2600, 2602]], "15": [[2362, 2366], [3118, 3122]], "16": [[617, 619], [3045, 3048]], "17": [[852, 854], [2716, 2718]], "18": [[78, 84], [1115, 1118], [1328, 1331]], "19": [[860, 862], [886, 890]], "2": [[12, 15], [665, 670], [1740, 1744], [2813, 2817], [2878, 2882]], "20": [[5, 9], [71, 75], [452, 456], [1579, 1583], [2414, 2418], [3111, 3115], [3338, 3342], [4421, 4425], [4498, 4503]], "21": [[2525, 2526], [2792, 2793], [3600, 3601], [4115, 4116]], "22": [[1120, 1122], [1899, 1900]], "23": [[358, 360], [1321, 1323]], "24": [[4644, 4646]], "25": [[122, 123], [631, 633], [1972, 1975]], "26": [[63, 65], [1570, 1571], [4378, 4380]], "27": [[3735, 3736]], "28": [[3, 4], [299, 301], [1353, 1355], [2846, 2847]], "29": [[4057, 4060]], "3": [[4155, 4158], [4228, 4231]], "30": [[893, 895], [1818, 1821]], "31": [[421, 422], [622, 623], [1416, 1417], [3052, 3053]], "32": [[1701, 1704], [3871, 3874]], "33": [[4532, 4537], [4543, 4545]], "34": [[1979, 1984], [2347, 2352]], "35": [[3943, 3944]], "36": [[145, 147], [1085, 1087], [3234, 3237], [3266, 3268], [4654, 4656]], "37": [[3567, 3568], [3575, 3578]], "38": [[26, 28], [269, 271], [342, 344], [362, 364], [1447, 1449]], "39": [[475, 477], [963, 965], [1018, 1020], [1257, 1259], [1514, 1516], [2947, 2950], [2962, 2964], [2981, 2983], [3910, 3912], [3972, 3974], [4013, 4015], [4091, 4093], [4133, 4135], [4187, 4189], [4260, 4262]], "4": [[2897, 2901], [3878, 3879]], "40": [[2117, 2118]], "41": [[4174, 4175], [4247, 4248]], "42": [[942, 943], [946, 947]], "43": [[1901, 1903], [2122, 2124], [3240, 3242], [3500, 3502]], "44": [[1479, 1482], [2634, 2637]], "45": [[1720, 1722]], "46": [[326, 328], [1391, 1393], [3864, 3866]], "47": [[1486, 1489]], "48": [[4635, 4637]], "49": [[4385, 4388]], "5": [[103, 105], [649, 651], [1711, 1713], [1727, 1729], [2576, 2578], [3145, 3147], [3192, 3195], [3254, 3256], [3478, 3480], [3559, 3563], [3899, 3901], [3961, 3963], [4126, 4128], [4639, 4641]], "50": [[4077, 4079]], "51": [[125, 127], [1954, 1957], [2493, 2495], [2538, 2540], [3204, 3206]], "52": [[2218, 2219], [2240, 2241], [2471, 2472], [2510, 2511], [2641, 2642], [2714, 2715], [2727, 2728], [2928, 2929], [3226, 3227], [3271, 3272], [608, 609], [626, 627], [657, 658], [674, 675], [725, 726], [760, 761], [1679, 1680], [1736, 1737], [1850, 1851], [1874, 1875], [1929, 1930], [1967, 1968], [2006, 2007], [2041, 2042], [2110, 2111], [2339, 2340], [2368, 2369], [2398, 2399], [2440, 2441], [2518, 2519], [2552, 2553], [2566, 2567], [2590, 2591], [2621, 2622], [2657, 2658], [2871, 2872], [2943, 2944], [2958, 2959], [3003, 3004], [3026, 3027], [3039, 3040], [3168, 3169], [3398, 3399], [4412, 4413], [4489, 4490], [4510, 4511], [4523, 4524], [4578, 4579]], "53": [[305, 306], [844, 845]], "54": [[3937, 3939], [4039, 4041]], "55": [[3217, 3218]], "56": [[3607, 3611]], "57": [[1670, 1673]], "58": [[561, 564], [773, 775], [2731, 2733]], "59": [[2770, 2775]], "6": [[218, 220], [244, 245], [465, 466], [488, 489], [908, 909], [926, 928], [986, 987], [1192, 1193], [1461, 1462], [1510, 1511], [1615, 1616], [1662, 1663], [3102, 3103]], "60": [[3371, 3374]], "61": [[223, 228]], "62": [[3995, 3996]], "63": [[863, 864]], "64": [[1274, 1277]], "65": [[2744, 2745], [2767, 2768]], "66": [[1105, 1108]], "67": [[309, 310]], "68": [[1862, 1863], [3232, 3233], [3238, 3239], [141, 142], [739, 740], [2329, 2330], [2765, 2766], [2789, 2790], [3409, 3410]], "69": [[1092, 1096]], "7": [[239, 243], [1111, 1114]], "70": [[3386, 3389]], "71": [[938, 941]], "72": [[1767, 1771]], "73": [[3830, 3831], [4373, 4374], [3837, 3838]], "74": [[1143, 1146]], "75": [[1893, 1896]], "76": [[2790, 2791], [4113, 4114]], "77": [[868, 869]], "78": [[3150, 3151]], "79": [[478, 480]], "8": [[434, 436], [2819, 2821]], "80": [[4368, 4369]], "81": [[346, 353]], "82": [[164, 171]], "83": [[55, 57]], "84": [[4350, 4353]], "85": [[58, 61]], "86": [[2908, 2911]], "87": [[2886, 2888]], "88": [[2689, 2692], [2740, 2743]], "89": [[2198, 2201]], "9": [[331, 333], [3473, 3476]], "90": [[95, 97], [115, 117], [639, 641], [1791, 1793], [3137, 3139], [3157, 3159], [3711, 3713], [4167, 4169], [4240, 4242]], "91": [[539, 542]], "92": [[1335, 1342]], "93": [[913, 917]], "94": [[3148, 3149]], "95": [[234, 235]], "96": [[214, 217]], "97": [[50, 54]], "98": [[416, 420]], "99": [[2663, 2666]]}, "doc_id": "4087ebc37a1650dbb5d8205af0850bee74f3784b", "method_subrelations": {"CBS-1___ESIM": [[[0, 5], "CBS-1"], [[8, 12], "ESIM"]]}, "n_ary_relations": [{"Material": "SNLI", "Method": "CBS-1___ESIM", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "86.73"}], "ner": [[3, 4, "Task"], [5, 9, "Method"], [12, 15, "Task"], [20, 23, "Task"], [26, 28, "Method"], [50, 54, "Task"], [55, 57, "Method"], [58, 61, "Task"], [63, 65, "Task"], [71, 75, "Method"], [78, 84, "Method"], [95, 97, "Task"], [98, 101, "Task"], [103, 105, "Task"], [115, 117, "Task"], [122, 123, "Metric"], [125, 127, "Metric"], [145, 147, "Method"], [158, 161, "Method"], [164, 171, "Method"], [214, 217, "Method"], [218, 220, "Method"], [223, 228, "Method"], [230, 233, "Method"], [234, 235, "Method"], [239, 243, "Method"], [244, 245, "Method"], [253, 255, "Metric"], [265, 266, "Task"], [269, 271, "Method"], [299, 301, "Task"], [305, 306, "Method"], [309, 310, "Method"], [326, 328, "Method"], [331, 333, "Task"], [342, 344, "Method"], [346, 353, "Task"], [358, 360, "Method"], [362, 364, "Method"], [384, 386, "Metric"], [394, 396, "Task"], [411, 413, "Method"], [416, 420, "Method"], [421, 422, "Method"], [434, 436, "Method"], [438, 441, "Task"], [452, 456, "Method"], [465, 466, "Method"], [475, 477, "Metric"], [478, 480, "Metric"], [488, 489, "Method"], [519, 521, "Method"], [539, 542, "Method"], [561, 564, "Method"], [613, 615, "Method"], [617, 619, "Method"], [631, 633, "Metric"], [639, 641, "Task"], [645, 648, "Task"], [649, 651, "Task"], [665, 670, "Task"], [751, 753, "Metric"], [773, 775, "Method"], [781, 784, "Metric"], [796, 798, "Method"], [844, 845, "Method"], [852, 854, "Method"], [860, 862, "Method"], [863, 864, "Method"], [868, 869, "Metric"], [886, 890, "Method"], [893, 895, "Method"], [908, 909, "Method"], [913, 917, "Metric"], [926, 928, "Method"], [938, 941, "Method"], [942, 943, "Method"], [963, 965, "Metric"], [986, 987, "Method"], [1018, 1020, "Metric"], [1085, 1087, "Method"], [1092, 1096, "Task"], [1105, 1108, "Method"], [1111, 1114, "Method"], [1115, 1118, "Method"], [1120, 1122, "Metric"], [1136, 1139, "Method"], [1143, 1146, "Task"], [1192, 1193, "Method"], [1257, 1259, "Metric"], [1274, 1277, "Method"], [1321, 1323, "Method"], [1328, 1331, "Method"], [1335, 1342, "Task"], [1353, 1355, "Task"], [1391, 1393, "Method"], [1431, 1439, "Method"], [1447, 1449, "Method"], [1461, 1462, "Method"], [1479, 1482, "Method"], [1486, 1489, "Method"], [1498, 1500, "Method"], [1510, 1511, "Method"], [1514, 1516, "Metric"], [1565, 1567, "Task"], [1570, 1571, "Task"], [1574, 1578, "Method"], [1579, 1583, "Method"], [1585, 1588, "Method"], [1615, 1616, "Method"], [1662, 1663, "Method"], [1670, 1673, "Method"], [1701, 1704, "Method"], [1705, 1708, "Task"], [1711, 1713, "Task"], [1720, 1722, "Task"], [1727, 1729, "Task"], [1740, 1744, "Task"], [1767, 1771, "Metric"], [1791, 1793, "Task"], [1818, 1821, "Method"], [1862, 1863, "Method"], [1889, 1890, "Metric"], [1893, 1896, "Metric"], [1899, 1900, "Metric"], [1901, 1903, "Method"], [1915, 1917, "Metric"], [1936, 1937, "Metric"], [1954, 1957, "Metric"], [1972, 1975, "Metric"], [1976, 1978, "Material"], [1979, 1984, "Method"], [1995, 2001, "Method"], [2018, 2022, "Metric"], [2024, 2026, "Method"], [2027, 2028, "Material"], [2029, 2031, "Material"], [2117, 2118, "Task"], [2122, 2124, "Method"], [2133, 2134, "Material"], [2135, 2136, "Material"], [2149, 2153, "Method"], [2173, 2175, "Metric"], [2180, 2182, "Metric"], [2198, 2201, "Method"], [2208, 2211, "Metric"], [2215, 2217, "Metric"], [2218, 2219, "Method"], [2240, 2241, "Method"], [2332, 2334, "Method"], [2342, 2343, "Material"], [2344, 2346, "Material"], [2347, 2352, "Method"], [2353, 2356, "Method"], [2362, 2366, "Method"], [2371, 2372, "Material"], [2373, 2375, "Material"], [2377, 2380, "Metric"], [2414, 2418, "Method"], [2471, 2472, "Method"], [2493, 2495, "Metric"], [2510, 2511, "Method"], [2521, 2524, "Material"], [2525, 2526, "Material"], [2532, 2534, "Metric"], [2538, 2540, "Metric"], [2544, 2547, "Material"], [2576, 2578, "Task"], [2600, 2602, "Metric"], [2603, 2605, "Metric"], [2634, 2637, "Method"], [2641, 2642, "Method"], [2663, 2666, "Method"], [2676, 2678, "Metric"], [2681, 2683, "Metric"], [2684, 2687, "Material"], [2689, 2692, "Method"], [2697, 2699, "Metric"], [2702, 2704, "Metric"], [2714, 2715, "Method"], [2716, 2718, "Method"], [2719, 2722, "Material"], [2727, 2728, "Method"], [2731, 2733, "Method"], [2740, 2743, "Method"], [2744, 2745, "Method"], [2749, 2750, "Metric"], [2767, 2768, "Method"], [2770, 2775, "Method"], [2778, 2779, "Metric"], [2790, 2791, "Method"], [2792, 2793, "Material"], [2813, 2817, "Task"], [2819, 2821, "Method"], [2846, 2847, "Task"], [2878, 2882, "Task"], [2886, 2888, "Method"], [2897, 2901, "Method"], [2908, 2911, "Method"], [2923, 2924, "Metric"], [2928, 2929, "Method"], [2947, 2950, "Metric"], [2954, 2955, "Metric"], [2962, 2964, "Metric"], [2975, 2976, "Metric"], [2981, 2983, "Metric"], [3007, 3008, "Task"], [3031, 3033, "Method"], [3045, 3048, "Method"], [3076, 3079, "Task"], [3102, 3103, "Method"], [3111, 3115, "Method"], [3118, 3122, "Method"], [3137, 3139, "Task"], [3140, 3143, "Task"], [3145, 3147, "Task"], [3148, 3149, "Method"], [3150, 3151, "Method"], [3153, 3154, "Method"], [3157, 3159, "Task"], [3177, 3178, "Metric"], [3188, 3191, "Task"], [3192, 3195, "Task"], [3204, 3206, "Metric"], [3217, 3218, "Metric"], [3226, 3227, "Method"], [3232, 3233, "Method"], [3234, 3237, "Method"], [3238, 3239, "Method"], [3240, 3242, "Method"], [3248, 3249, "Metric"], [3254, 3256, "Task"], [3264, 3265, "Metric"], [3266, 3268, "Method"], [3271, 3272, "Method"], [3276, 3279, "Metric"], [3338, 3342, "Method"], [3371, 3374, "Method"], [3386, 3389, "Method"], [3473, 3476, "Task"], [3478, 3480, "Task"], [3500, 3502, "Method"], [3520, 3523, "Task"], [3559, 3563, "Task"], [3567, 3568, "Material"], [3571, 3574, "Material"], [3575, 3578, "Material"], [3600, 3601, "Material"], [3607, 3611, "Material"], [3645, 3646, "Material"], [3652, 3656, "Material"], [3664, 3667, "Material"], [3708, 3710, "Material"], [3711, 3713, "Task"], [3716, 3719, "Material"], [3723, 3727, "Material"], [3735, 3736, "Material"], [3778, 3779, "Material"], [3780, 3783, "Task"], [3830, 3831, "Material"], [3832, 3835, "Task"], [3864, 3866, "Method"], [3871, 3874, "Method"], [3878, 3879, "Method"], [3899, 3901, "Task"], [3910, 3912, "Metric"], [3937, 3939, "Task"], [3943, 3944, "Method"], [3961, 3963, "Task"], [3972, 3974, "Metric"], [3995, 3996, "Method"], [4013, 4015, "Metric"], [4039, 4041, "Task"], [4045, 4047, "Method"], [4057, 4060, "Method"], [4077, 4079, "Method"], [4091, 4093, "Metric"], [4113, 4114, "Method"], [4126, 4128, "Task"], [4133, 4135, "Metric"], [4155, 4158, "Method"], [4167, 4169, "Task"], [4174, 4175, "Method"], [4187, 4189, "Metric"], [4228, 4231, "Method"], [4240, 4242, "Task"], [4247, 4248, "Method"], [4260, 4262, "Metric"], [4326, 4329, "Metric"], [4337, 4338, "Method"], [4346, 4348, "Method"], [4350, 4353, "Method"], [4364, 4367, "Task"], [4368, 4369, "Method"], [4373, 4374, "Material"], [4376, 4377, "Material"], [4378, 4380, "Task"], [4385, 4388, "Method"], [4421, 4425, "Method"], [4498, 4503, "Method"], [4532, 4537, "Method"], [4543, 4545, "Method"], [4635, 4637, "Task"], [4639, 4641, "Task"], [4644, 4646, "Method"], [4654, 4656, "Method"], [141, 142, "Method"], [608, 609, "Method"], [622, 623, "Method"], [626, 627, "Method"], [657, 658, "Method"], [674, 675, "Method"], [725, 726, "Method"], [739, 740, "Method"], [760, 761, "Method"], [946, 947, "Method"], [1416, 1417, "Method"], [1679, 1680, "Method"], [1736, 1737, "Method"], [1850, 1851, "Method"], [1874, 1875, "Method"], [1929, 1930, "Method"], [1967, 1968, "Method"], [2006, 2007, "Method"], [2041, 2042, "Method"], [2110, 2111, "Method"], [2329, 2330, "Method"], [2339, 2340, "Method"], [2368, 2369, "Method"], [2398, 2399, "Method"], [2425, 2428, "Task"], [2440, 2441, "Method"], [2518, 2519, "Method"], [2552, 2553, "Method"], [2566, 2567, "Method"], [2590, 2591, "Method"], [2621, 2622, "Method"], [2657, 2658, "Method"], [2765, 2766, "Method"], [2789, 2790, "Method"], [2871, 2872, "Method"], [2943, 2944, "Method"], [2958, 2959, "Method"], [3003, 3004, "Method"], [3026, 3027, "Method"], [3039, 3040, "Method"], [3052, 3053, "Method"], [3168, 3169, "Method"], [3398, 3399, "Method"], [3409, 3410, "Method"], [3786, 3787, "Material"], [3837, 3838, "Material"], [3846, 3847, "Material"], [3882, 3885, "Material"], [3948, 3951, "Material"], [3997, 4000, "Material"], [4115, 4116, "Material"], [4412, 4413, "Method"], [4489, 4490, "Method"], [4510, 4511, "Method"], [4523, 4524, "Method"], [4578, 4579, "Method"]], "sections": [[0, 9], [9, 148], [148, 788], [788, 1130], [1130, 1688], [1688, 1787], [1787, 2574], [2574, 2811], [2811, 3013], [3013, 3283], [3283, 3416], [3416, 4665], [4665, 4677], [4677, 4679]], "sentences": [[0, 9], [9, 12], [12, 24], [24, 43], [43, 66], [66, 85], [85, 106], [106, 148], [148, 151], [151, 204], [204, 214], [214, 237], [237, 256], [256, 272], [272, 289], [289, 310], [310, 320], [320, 334], [334, 356], [356, 387], [387, 397], [397, 425], [425, 467], [467, 502], [502, 506], [506, 549], [549, 591], [591, 600], [600, 601], [601, 625], [625, 652], [652, 671], [671, 672], [672, 696], [696, 719], [719, 720], [720, 733], [733, 754], [754, 788], [788, 792], [792, 830], [830, 855], [855, 896], [896, 921], [921, 945], [945, 978], [978, 993], [993, 1039], [1039, 1072], [1072, 1097], [1097, 1130], [1130, 1133], [1133, 1155], [1155, 1179], [1179, 1191], [1191, 1252], [1252, 1273], [1273, 1319], [1319, 1348], [1348, 1374], [1374, 1394], [1394, 1425], [1425, 1440], [1440, 1463], [1463, 1490], [1490, 1501], [1501, 1529], [1529, 1554], [1554, 1572], [1572, 1584], [1584, 1610], [1610, 1637], [1637, 1678], [1678, 1688], [1688, 1691], [1691, 1714], [1714, 1733], [1733, 1748], [1748, 1766], [1766, 1787], [1787, 1791], [1791, 1850], [1850, 1868], [1868, 1885], [1885, 1921], [1921, 1964], [1964, 2002], [2002, 2013], [2013, 2015], [2015, 2049], [2049, 2059], [2059, 2103], [2103, 2159], [2159, 2186], [2186, 2218], [2218, 2246], [2246, 2262], [2262, 2290], [2290, 2324], [2324, 2367], [2367, 2408], [2408, 2436], [2436, 2462], [2462, 2482], [2482, 2514], [2514, 2527], [2527, 2529], [2529, 2548], [2548, 2574], [2574, 2579], [2579, 2606], [2606, 2638], [2638, 2649], [2649, 2688], [2688, 2723], [2723, 2754], [2754, 2763], [2763, 2788], [2788, 2811], [2811, 2817], [2817, 2864], [2864, 2883], [2883, 2905], [2905, 2927], [2927, 2940], [2940, 2958], [2958, 2979], [2979, 3000], [3000, 3013], [3013, 3016], [3016, 3025], [3025, 3034], [3034, 3072], [3072, 3104], [3104, 3155], [3155, 3187], [3187, 3219], [3219, 3238], [3238, 3266], [3266, 3283], [3283, 3286], [3286, 3312], [3312, 3330], [3330, 3352], [3352, 3383], [3383, 3416], [3416, 3421], [3421, 3444], [3444, 3464], [3464, 3477], [3477, 3478], [3478, 3481], [3481, 3499], [3499, 3500], [3500, 3503], [3503, 3519], [3519, 3520], [3520, 3524], [3524, 3548], [3548, 3550], [3550, 3558], [3558, 3559], [3559, 3565], [3565, 3583], [3583, 3599], [3599, 3600], [3600, 3606], [3606, 3632], [3632, 3644], [3644, 3645], [3645, 3651], [3651, 3668], [3668, 3687], [3687, 3707], [3707, 3708], [3708, 3715], [3715, 3737], [3737, 3757], [3757, 3777], [3777, 3778], [3778, 3785], [3785, 3814], [3814, 3829], [3829, 3830], [3830, 3836], [3836, 3864], [3864, 3867], [3867, 3875], [3875, 3878], [3878, 3902], [3902, 3927], [3927, 3940], [3940, 3941], [3941, 3943], [3943, 3964], [3964, 3992], [3992, 3995], [3995, 4001], [4001, 4005], [4005, 4029], [4029, 4042], [4042, 4045], [4045, 4052], [4052, 4068], [4068, 4110], [4110, 4113], [4113, 4152], [4152, 4155], [4155, 4170], [4170, 4204], [4204, 4225], [4225, 4228], [4228, 4243], [4243, 4277], [4277, 4298], [4298, 4319], [4319, 4334], [4334, 4337], [4337, 4338], [4338, 4342], [4342, 4378], [4378, 4388], [4388, 4389], [4389, 4391], [4391, 4411], [4411, 4438], [4438, 4448], [4448, 4462], [4462, 4488], [4488, 4489], [4489, 4522], [4522, 4523], [4523, 4546], [4546, 4574], [4574, 4610], [4610, 4634], [4634, 4654], [4654, 4665], [4665, 4670], [4670, 4677], [4677, 4679]], "words": ["Parameter", "Re", "-", "Initialization", "through", "Cyclical", "Batch", "Size", "Schedules", "section", ":", "Abstract", "Optimal", "parameter", "initialization", "remains", "a", "crucial", "problem", "for", "neural", "network", "training", ".", "A", "poor", "weight", "initialization", "may", "take", "longer", "to", "train", "and", "/", "or", "converge", "to", "sub", "-", "optimal", "solutions", ".", "Here", ",", "we", "propose", "a", "method", "of", "weight", "re", "-", "initialization", "by", "repeated", "annealing", "and", "injection", "of", "noise", "in", "the", "training", "process", ".", "We", "implement", "this", "through", "a", "cyclical", "batch", "size", "schedule", "motivated", "by", "a", "Bayesian", "perspective", "of", "neural", "network", "training", ".", "We", "evaluate", "our", "methods", "through", "extensive", "experiments", "on", "tasks", "in", "language", "modeling", ",", "natural", "language", "inference", ",", "and", "image", "classification", ".", "We", "demonstrate", "the", "ability", "of", "our", "method", "to", "improve", "language", "modeling", "performance", "by", "up", "to", "7.91", "perplexity", "and", "reduce", "training", "iterations", "by", "up", "to", "61", "%", ",", "in", "addition", "to", "its", "flexibility", "in", "enabling", "snapshot", "ensembling", "and", "use", "with", "adversarial", "training", ".", "section", ":", "Introduction", "Despite", "many", "promising", "empirical", "results", "at", "using", "stochastic", "optimization", "methods", "to", "train", "highly", "non", "-", "convex", "modern", "deep", "neural", "networks", ",", "we", "still", "lack", "theoretically", "robust", "practical", "methods", "which", "are", "able", "to", "escape", "saddle", "points", "and", "/", "or", "sub", "-", "optimal", "local", "minima", "and", "converge", "to", "parameters", "that", "retain", "high", "testing", "performance", ".", "This", "lack", "of", "understanding", "leads", "to", "practical", "training", "challenges", ".", "Stochastic", "Gradient", "Descent", "(", "SGD", ")", "is", "currently", "the", "de", "-", "facto", "optimization", "method", "for", "training", "deep", "neural", "networks", "(", "DNNs", ")", ".", "Through", "extensive", "hyper", "-", "parameter", "tuning", ",", "SGD", "can", "avoid", "poor", "local", "optima", "and", "achieve", "good", "generalization", "ability", ".", "One", "important", "hyper", "-", "parameter", "that", "can", "significantly", "affect", "SGD", "performance", "is", "the", "weight", "initialization", ".", "For", "instance", ",", "initializing", "the", "weights", "to", "all", "zeros", "or", "all", "ones", "leads", "to", "extremely", "poor", "performance", "[", "reference", "]", ".", "Different", "approaches", "have", "been", "proposed", "for", "weight", "initialization", "such", "as", "Xavier", ",", "MSRA", ",", "Ortho", ",", "LSUV", "[", "reference", "][", "reference", "][", "reference", "][", "reference", "]", ".", "These", "are", "mostly", "agnostic", "to", "the", "model", "architecture", "and", "the", "specific", "learning", "task", ".", "Our", "work", "explores", "the", "idea", "of", "adapting", "the", "weight", "initialization", "to", "the", "optimization", "dynamics", "of", "the", "specific", "learning", "task", "at", "hand", ".", "From", "the", "Bayesian", "perspective", ",", "improved", "weight", "initialization", "can", "be", "viewed", "as", "starting", "with", "a", "better", "prior", ",", "which", "leads", "to", "a", "more", "accurate", "posterior", "and", "thus", "better", "generalization", "ability", ".", "This", "problem", "has", "been", "explored", "extensively", "in", "Bayesian", "optimization", ".", "For", "example", ",", "in", "the", "seminal", "works", "[", "reference", "][", "reference", "]", ",", "an", "adaptive", "prior", "is", "implemented", "via", "Markov", "Chain", "Monte", "Carlo", "(", "MCMC", ")", "methods", ".", "Motivated", "by", "these", "ideas", ",", "we", "incorporate", "an", "\"", "adaptive", "initialization", "\"", "for", "neural", "network", "training", "(", "see", "section", "2", "for", "details", ")", ",", "where", "we", "use", "cyclical", "batch", "size", "schedules", "to", "control", "the", "noise", "(", "or", "temperature", ")", "of", "SGD", ".", "As", "argued", "in", "[", "reference", "]", ",", "both", "learning", "rate", "and", "batch", "size", "can", "be", "used", "to", "control", "the", "noise", "of", "SGD", "but", "the", "latter", "has", "an", "advantage", "in", "that", "it", "allows", "more", "parallelization", "opportunity", "[", "reference", "]", ".", "The", "idea", "of", "using", "batch", "size", "to", "control", "the", "noise", "in", "a", "simple", "cyclical", "schedule", "was", "recently", "proposed", "in", "[", "reference", "]", ".", "Here", ",", "we", "build", "upon", "this", "work", "by", "studying", "different", "cyclical", "annealing", "strategies", "for", "a", "wide", "range", "of", "problems", ".", "Additionally", ",", "we", "discuss", "how", "this", "can", "be", "combined", "with", "a", "new", "adversarial", "regularization", "scheme", "recently", "proposed", "in", "[", "reference", "]", ",", "as", "well", "as", "prior", "work", "[", "reference", "]", "in", "order", "to", "obtain", "ensembles", "of", "models", "at", "no", "additional", "cost", ".", "In", "summary", ",", "our", "contributions", "are", "as", "follows", ":", "\u2022", "We", "explore", "different", "cyclical", "batch", "size", "(", "CBS", ")", "schedules", "for", "training", "neural", "networks", "inspired", "by", "Bayesian", "statistics", ",", "particularly", "adaptive", "MCMC", "methods", ".", "The", "CBS", "schedule", "leads", "to", "multiple", "perplexity", "improvement", "(", "up", "to", "7.91", ")", "in", "language", "modeling", "and", "minor", "improvements", "in", "natural", "language", "inference", "and", "image", "classification", ".", "Furthermore", ",", "we", "show", "that", "CBS", "schedule", "can", "alleviate", "problems", "with", "overfitting", "and", "sub", "-", "optimal", "parameter", "initialization", ".", "\u2022", "Additionally", ",", "CBS", "schedules", "require", "up", "to", "3\u00d7", "fewer", "SGD", "iterations", "due", "to", "larger", "batch", "sizes", ",", "which", "allows", "for", "more", "parallelization", "opportunity", ".", "This", "reflects", "the", "benefit", "of", "cycling", "the", "batch", "size", "instead", "of", "the", "learning", "rate", "as", "in", "prior", "work", "[", "reference", "][", "reference", "]", "\u2022", "We", "showcase", "the", "flexibility", "of", "CBS", "schedules", "for", "use", "with", "additional", "techniques", ".", "We", "propose", "a", "simple", "but", "effective", "ensembling", "method", "that", "combines", "models", "saved", "during", "different", "cycles", "at", "no", "additional", "training", "cost", ".", "In", "addition", ",", "we", "show", "that", "CBS", "schedule", "can", "be", "combined", "with", "other", "approaches", "such", "as", "the", "recently", "proposed", "adversarial", "regularization", "[", "reference", "]", "to", "yield", "further", "classification", "accuracy", "improvement", "of", "0.26", "%", ".", "section", ":", "Related", "Work", "[", "5", "]", "introduced", "Xavier", "initialization", ",", "which", "keeps", "the", "variance", "of", "input", "and", "output", "of", "all", "layers", "within", "a", "similar", "range", "in", "order", "to", "prevent", "vanishing", "or", "exploding", "values", "in", "both", "the", "forward", "and", "backward", "passes", ".", "Building", "off", "this", "idea", ",", "[", "reference", "]", "explored", "a", "new", "strategy", "known", "as", "MSRA", "to", "keep", "the", "variance", "constant", "for", "all", "convolutional", "layers", ".", "[", "reference", "]", "proposed", "an", "orthogonal", "initialization", "(", "Ortho", ")", "to", "achieve", "faster", "convergence", ",", "and", "more", "recently", ",", "[", "reference", "]", "combined", "ideas", "from", "previous", "work", "and", "showed", "that", "a", "unit", "variance", "orthogonal", "initialization", "is", "beneficial", "for", "deep", "models", ".", "[", "reference", "][", "reference", "][", "reference", "]", "show", "that", "the", "noise", "of", "SGD", "is", "controlled", "by", "the", "ratio", "of", "learning", "rate", "to", "batch", "size", ".", "The", "authors", "argued", "that", "the", "SGD", "algorithm", "can", "be", "derived", "through", "Euler", "-", "Maruyama", "discretization", "of", "a", "Stochastic", "Differential", "Equation", "(", "SDE", ")", ".", "The", "SDE", "dynamics", "are", "governed", "by", "a", "\"", "noise", "scale", "\"", "g", "\u2248", "N", "/", "B", "for", "the", "learning", "rate", ",", "N", "the", "training", "dataset", "size", ",", "and", "B", "the", "batch", "size", ".", "They", "conclude", "that", "a", "higher", "noise", "scale", "prevents", "SGD", "from", "settling", "into", "sharper", "minima", ".", "This", "result", "supports", "a", "prior", "empirical", "observation", "[", "reference", "]", "that", "under", "certain", "mild", "assumptions", "such", "as", "N", "B", ",", "the", "effect", "of", "dividing", "the", "learning", "rate", "by", "a", "constant", "factor", "is", "equivalent", "to", "that", "of", "multiplying", "the", "batch", "size", "by", "the", "same", "constant", "factor", ".", "In", "related", "work", ",", "[", "reference", "]", "applied", "this", "understanding", "and", "used", "batch", "size", "as", "a", "knob", "to", "control", "the", "noise", ",", "and", "empirically", "showed", "that", "the", "baseline", "performance", "could", "be", "matched", ".", "[", "reference", "]", "further", "explored", "how", "to", "use", "second", "-", "order", "information", "and", "adversarial", "training", "to", "control", "the", "noise", "for", "training", "large", "batch", "size", ".", "[", "reference", "][", "reference", "]", "showed", "using", "a", "statistical", "mechanics", "argument", "that", "many", "other", "hyper", "-", "parameters", "in", "neural", "network", "training", ",", "e.g.", "data", "quality", ",", "can", "also", "act", "as", "temperature", "knobs", ".", "section", ":", "Methods", "The", "goal", "of", "neural", "network", "optimization", "is", "to", "solve", "an", "empirical", "risk", "minimization", ",", "with", "a", "loss", "function", "of", "the", "form", ":", "where", "\u03b8", "is", "the", "model", "parameters", ",", "X", "is", "the", "training", "dataset", "and", "l", "(", "x", ",", "\u03b8", ")", "is", "the", "loss", "function", ".", "Here", "N", "=", "|X|", "is", "the", "cardinality", "of", "the", "training", "set", ".", "In", "SGD", ",", "a", "mini", "-", "batch", ",", "B", "\u2282", "{", "1", ",", "2", ",", "...", ",", "N", "}", "is", "used", "to", "compute", "an", "(", "unbiased", ")", "gradient", ",", "i.e.", ",", "g", "t", "=", "1", "|B|", "x\u2208B", "\u2207", "\u03b8", "l", "(", "x", ",", "\u03b8", "t", ")", ",", "and", "this", "is", "typically", "used", "to", "optimize", "(", "1", ")", "in", "the", "form", ":", "where", "\u03b7", "t", "is", "the", "learning", "rate", "(", "step", "size", ")", "at", "iteration", "t", ",", "and", "commonly", "annealed", "during", "training", ".", "By", "Bayes", "'", "Theorem", ",", "given", "the", "input", "data", ",", "X", ",", "a", "prior", "distribution", "on", "the", "model", "parameters", ",", "P", "(", "\u03b8", ")", ",", "and", "a", "likelihood", "function", ",", "P", "(", "X|\u03b8", ")", ",", "the", "posterior", "distribution", ",", "P", "(", "\u03b8|X", ")", ",", "is", ":", "From", "this", "Bayesian", "perspective", ",", "the", "goal", "of", "the", "neural", "network", "training", "is", "to", "find", "the", "Maximum", "-", "APosteriori", "(", "MAP", ")", "point", "for", "a", "given", "prior", "distribution", ".", "Note", "that", "in", "this", "context", "weight", "initialization", "and", "prior", "distribution", "are", "similar", ",", "that", "is", "a", "better", "prior", "distribution", "would", "lead", "to", "more", "informative", "posterior", ".", "In", "general", ",", "it", "may", "be", "difficult", "to", "design", "a", "better", "prior", "given", "only", "data", "and", "a", "model", "architecture", ".", "Additionally", ",", "the", "high", "dimensionality", "of", "the", "NN", "'s", "parameter", "space", "renders", "various", "approaches", "such", "as", "adaptive", "priors", "intractable", "(", "e.g.", "adaptive", "MCMC", "algorithms", "[", "reference", "][", "reference", "]", ")", ".", "Hence", ",", "we", "look", "into", "an", "adaptive", "weight", "\"", "re", "-", "initialization", "\"", "strategy", ".", "We", "start", "with", "an", "input", "prior", "(", "weight", "initialization", ")", "and", "compute", "an", "approximate", "MAP", "point", "by", "annealing", "the", "noise", "in", "SGD", ".", "Once", "we", "compute", "the", "MAP", "point", ",", "we", "use", "it", "as", "a", "new", "initialization", "of", "the", "neural", "network", "weights", ",", "and", "restart", "the", "noise", "annealing", "schedule", ".", "We", "then", "iteratively", "repeat", "this", "process", "through", "the", "training", "process", ".", "One", "approach", "to", "controlling", "the", "level", "of", "noise", "in", "SGD", "is", "via", "the", "learning", "rate", ",", "which", "is", "the", "approach", "used", "in", "[", "reference", "][", "reference", "]", ".", "However", ",", "as", "discussed", "in", "[", "reference", "][", "reference", "][", "reference", "]", ",", "the", "batch", "size", "can", "also", "be", "used", "to", "control", "SGD", "noise", ".", "The", "motivation", "for", "this", "is", "that", "larger", "batch", "sizes", "allow", "for", "parallel", "execution", "which", "can", "accelerate", "training", ".", "We", "implement", "weight", "re", "-", "initialization", "through", "cyclical", "batch", "size", "schedules", ".", "The", "SGD", "training", "process", "is", "divided", "into", "one", "or", "more", "cycles", ",", "and", "in", "single", "cycle", "we", "gradually", "increase", "the", "batch", "size", "to", "decrease", "noise", ".", "As", "the", "noise", "level", "of", "SGD", "is", "annealed", ",", "\u03b8", "will", "approaches", "a", "local", "minima", "i.e.", ",", "an", "approximate", "MAP", "point", "of", "P", "(", "\u03b8|X", ")", ".", "Then", "at", "the", "beginning", "of", "the", "subsequent", "cycle", "we", "drop", "the", "batch", "size", "back", "down", "to", "the", "initial", "value", ",", "which", "increases", "the", "noise", "in", "SGD", "and", "\"", "re", "-", "initializes", "\"", "the", "neural", "network", "parameters", "using", "the", "previous", "estimate", ".", "Several", "CBS", "schedules", "are", "shown", "in", "Fig", ".", "1", ".", "section", ":", "Results", "We", "perform", "a", "variety", "of", "experiments", "across", "different", "tasks", "and", "neural", "network", "architectures", "in", "natural", "language", "processing", "as", "well", "as", "image", "classification", ".", "We", "report", "our", "experimental", "findings", "on", "language", "tasks", "in", "section", "3.1", ",", "and", "image", "classification", "in", "section", "3.2", ".", "We", "illustrate", "that", "CBS", "schedules", "can", "alleviate", "sub", "-", "optimal", "initialization", "in", "section", "3.3", ".", "We", "follow", "the", "baseline", "training", "method", "for", "each", "task", "(", "for", "details", "please", "see", "Appendix", "A", ")", ".", "Alongside", "testing", "/", "validation", "performance", ",", "we", "also", "report", "the", "number", "of", "training", "iterations", "(", "lower", "values", "are", "preferred", ")", ".", "section", ":", "Language", "Results", "Language", "modeling", "is", "a", "challenging", "problem", "due", "to", "the", "complex", "and", "long", "-", "range", "interactions", "between", "distant", "words", "[", "reference", "]", ".", "One", "hope", "is", "that", "large", "/", "deep", "models", "might", "be", "able", "to", "capture", "these", "complex", "interactions", ",", "but", "large", "models", "easily", "overfit", "on", "these", "tasks", "and", "exhibit", "large", "gaps", "between", "training", "set", "and", "testing", "set", "performance", ".", "CBS", "schedules", "effectively", "help", "us", "avoid", "overfitting", ",", "and", "in", "addition", "snapshot", "ensembling", "enables", "even", "greater", "performance", ".", "We", "evaluate", "a", "large", "variety", "of", "CBS", "schedules", "to", "positive", "results", "as", "shown", "in", "Table", "1", ".", "Results", "are", "measured", "in", "perplexity", ",", "a", "standard", "figure", "of", "merit", "for", "evaluating", "the", "quality", "of", "language", "models", "by", "measuring", "its", "prediction", "of", "the", "empirical", "distribution", "of", "words", "(", "lower", "perplexity", "value", "is", "better", ")", ".", "As", "we", "can", "see", ",", "the", "best", "performing", "CBS", "schedules", "result", "in", "significant", "improvements", "in", "perplexity", "(", "up", "to", "7.91", ")", "over", "the", "baseline", "schedules", "and", "also", "offer", "reductions", "in", "the", "number", "of", "SGD", "training", "iterations", "(", "up", "to", "33", "%", ")", ".", "For", "example", ",", "CBS", "schedules", "achieve", "improvement", "of", "7.91", "perplexity", "improvement", "on", "WikiText", "2", "via", "CBS", "-", "1", "-", "T", "and", "reduce", "the", "SGD", "iterations", "from", "164k", "to", "111k", "via", "the", "CBS", "-", "1", "-", "A", "schedule", ".", "Notice", "that", "almost", "all", "CBS", "schedules", "outperform", "the", "baseline", "schedule", ".", "Fig", ".", "2", "shows", "the", "training", "and", "testing", "perplexity", "of", "the", "L2", "model", "on", "PTB", "and", "WikiTest", "2", "as", "trained", "via", "the", "baseline", "schedule", "along", "with", "our", "best", "CBS", "schedule", "(", "from", "Table", "1", ")", ".", "Notice", "the", "cyclical", "spikes", "in", "training", "and", "testing", "perplexity", ".", "The", "peaks", "occur", "during", "decreases", "in", "batch", "size", ",", "i.e.", ",", "increases", "in", "noise", "scale", ",", "which", "could", "help", "to", "escape", "sub", "-", "optimal", "local", "minima", ",", "and", "the", "troughs", "occur", "during", "increases", "in", "batch", "size", ",", "i.e.", ",", "decreases", "with", "noise", "scale", ".", "In", "order", "to", "support", "our", "claim", "that", "CBS", "schedules", "are", "especially", "useful", "for", "counteracting", "overfitting", ",", "we", "conducted", "additional", "language", "modeling", "experiments", "on", "models", "L1", "'", ",", "L2", "'", "with", "PTB", "and", "WT2", "which", "use", "significantly", "lower", "dropout", "(", "0.2", "and", "0.3", ")", "than", "the", "original", "L1", ",", "L2", "models", "(", "0.5", "and", "0.65", ")", ".", "Because", "these", "models", "heavily", "overfit", "the", "training", "data", ",", "we", "report", "both", "the", "final", "testing", "perplexity", "as", "well", "as", "the", "best", "testing", "perplexity", "achieve", "during", "training", ".", "As", "seen", "in", "Table", "5", "(", "in", "Appendix", "B", ")", ",", "with", "L2", "'", "CBS", "yields", "improvements", "of", "a", "staggering", "60.3", "on", "final", "testing", "perplexity", "and", "36.2", "on", "best", "testing", "perplexity", ".", "CBS", "yields", "smaller", "improvements", "on", "L1", "'", "of", "26.0", "and", "25.3", ",", "which", "are", "still", "much", "larger", "than", "the", "improvement", "achieved", "by", "CBS", "on", "L1", "and", "L2", ".", "As", "mentioned", "above", "the", "goal", "of", "every", "cycle", "is", "to", "get", "an", "approximate", "MAP", "point", ".", "A", "very", "interesting", "idea", "proposed", "in", "[", "reference", "]", "is", "to", "ensemble", "these", "MAP", "points", "by", "saving", "snapshots", "of", "the", "model", "at", "the", "end", "of", "every", "cycle", ".", "We", "follow", "that", "strategy", "with", "the", "only", "difference", "that", "we", "use", "a", "batch", "size", "cycle", "instead", "of", "cyclical", "learning", "rate", "proposed", "in", "[", "reference", "]", "due", "to", "higher", "parallelization", "opportunities", "for", "the", "former", ".", "We", "perform", "experiments", "on", "snapshot", "ensembling", "with", "the", "L2", "model", "with", "the", "respective", "best", "performing", "CBS", "schedules", "on", "PTB", "and", "WikiText", "2", "(", "CBS", "-", "1", "-", "T", "and", "CBS", "-", "1", ")", ",", "as", "well", "as", "the", "fixed", "batch", "size", "baseline", ".", "The", "CBS", "ensembles", "on", "PTB", "and", "WikiText", "2", "result", "in", "test", "set", "perplexity", "of", "76.14", "and", "88.47", ",", "outperforming", "baseline", "ensembles", "on", "both", "datasets", "(", "76.52", ",", "89.99", "respectively", ")", "and", "CBS", "single", "models", "(", "77.39", ",", "91.78", "respectively", ")", ".", "To", "further", "explore", "the", "properties", "of", "cyclical", "batch", "size", "schedules", ",", "we", "also", "evaluate", "these", "schedules", "on", "natural", "language", "inference", "tasks", ",", "as", "shown", "in", "Table", "2", ".", "In", "our", "experiments", ",", "CBS", "schedules", "do", "not", "yield", "large", "performance", "improvements", "on", "models", "like", "E1", "which", "exhibit", "smaller", "disparities", "between", "training", "and", "testing", "performance", ".", "This", "is", "in", "line", "with", "our", "limitation", "in", "that", "CBS", "is", "more", "effective", "for", "models", "which", "tend", "to", "overfit", ".", "On", "the", "other", "hand", ",", "we", "see", "a", "large", "reduction", "in", "training", "iterations", "by", "up", "to", "62", "%", "which", "is", "due", "to", "higher", "effective", "batch", "size", "used", "in", "CBS", "than", "baseline", ".", "We", "also", "test", "our", "CBS", "schedules", "on", "Cifar", "-", "10", "and", "ImageNet", ".", "Table", ".", "3", "reports", "the", "testing", "accuracy", "and", "the", "number", "of", "training", "iterations", "for", "different", "models", "on", "Cifar", "-", "10", ".", "We", "see", "that", "the", "CBS", "schedules", "match", "baseline", "performance", ",", "but", "the", "number", "of", "training", "iterations", "used", "in", "CBS", "schedules", "is", "up", "to", "2\u00d7", "fewer", ".", "section", ":", "Image", "Classification", "Results", "As", "seen", "in", "Fig", ".", "3", ",", "the", "training", "curves", "of", "CBS", "schedules", "also", "exhibit", "the", "aforementioned", "cyclical", "spikes", "both", "in", "training", "loss", "and", "testing", "accuracy", ".", "Similarly", "in", "the", "previously", "discussed", "language", "experiments", ",", "these", "spikes", "correspond", "to", "cycles", "in", "the", "CBS", "schedules", "and", "can", "be", "thought", "of", "as", "re", "-", "initializations", "of", "the", "neural", "network", "weights", ".", "We", "observe", "that", "CBS", "achieves", "similar", "performance", "to", "the", "baseline", ".", "We", "offer", "further", "support", "for", "the", "hypothesis", "that", "CBS", "schedules", "are", "more", "effective", "for", "overfitting", "neural", "networks", "with", "experiments", "on", "model", "C4", ",", "which", "achieves", "94.35", "%", "training", "accuracy", "and", "55.55", "%", "testing", "accuracy", "on", "Cifar", "-", "10", ".", "With", "CBS", "-", "15", ",", "we", "see", "90.71", "%", "training", "accuracy", "and", "56.44", "%", "testing", "accuracy", ",", "which", "is", "a", "larger", "improvement", "than", "that", "offered", "by", "CBS", "on", "convolutional", "models", "on", "Cifar", "-", "10", ".", "We", "also", "explore", "combining", "CBS", "with", "the", "recent", "adversarial", "regularization", "proposed", "by", "[", "reference", "]", ".", "Combining", "CBS", "-", "15", "on", "C2", "with", "this", "strategy", "improves", "accuracy", "to", "94.82", "%", ".", "This", "outperforms", "other", "schedules", "shown", "in", "Table", "3", ".", "Applying", "snapshot", "ensembling", "on", "C3", "trained", "with", "CBS", "-", "15", "-", "2", "leads", "to", "improved", "accuracy", "of", "93.56", "%", "as", "compared", "to", "92.58", "%", ".", "After", "ensembling", "ResNet50", "on", "Imagenet", "with", "snapshots", "from", "the", "last", "two", "cycles", ",", "the", "performance", "increases", "to", "76.401", "%", "from", "75.336", "%", ".", "section", ":", "Sub", "-", "optimal", "Initialization", "Various", "effective", "initialization", "methods", "[", "reference", "][", "reference", "][", "reference", "][", "reference", "]", "have", "been", "proposed", "previously", ";", "however", ",", "when", "presented", "with", "new", "architectures", "and", "new", "tasks", ",", "initialization", "still", "needs", "to", "be", "explored", "empirically", "and", "often", "the", "final", "performance", "varies", "greatly", "with", "different", "initializations", ".", "In", "this", "section", ",", "we", "test", "if", "CBS", "schedules", "can", "alleviate", "the", "problem", "of", "sub", "-", "optimal", "initialization", ".", "We", "test", "a", "Gaussian", "initialization", "with", "mean", "0", "and", "standard", "deviation", "0.1", "on", "an", "AlexNet", "-", "like", "model", "(", "C1", ")", ".", "The", "baseline", "(", "BL", ")", "training", "follows", "the", "same", "setting", "as", "described", "in", "Appendix", "A", "and", "achieves", "final", "accuracy", "84.27", "%", ".", "For", "CBS", ",", "we", "use", "cycle", "width", "of", "10", "with", "3", "steps", ".", "In", "particular", ",", "CBS", "1", "denotes", "a", "constant", "learning", "rate", ",", "and", "achieves", "final", "accuracy", "85.41", "%", ".", "CBS", "2", "decays", "the", "learning", "rate", "by", "a", "factor", "of", "5", "at", "epoch", "75", "and", "achieves", "final", "accuracy", "84.95", "%", ".", "We", "keep", "learning", "rate", "high", "during", "training", "because", "a", "high", "noise", "level", "helps", "\u03b8", "escape", "sub", "-", "optimal", "local", "minima", ".", "Notice", "that", "all", "CBS", "methods", "achieve", "better", "generalization", "performance", "than", "the", "baseline", ".", "section", ":", "Conclusions", "In", "this", "work", "we", "explored", "different", "cyclical", "batch", "size", "(", "CBS", ")", "schedules", "for", "training", "neural", "networks", ".", "We", "framed", "the", "motivation", "behind", "CBS", "schedules", "through", "the", "lens", "of", "Bayesian", "statistical", "methods", ",", "in", "particular", "adaptive", "MCMC", "algorithms", ",", "which", "seek", "out", "better", "estimates", "of", "the", "posterior", "starting", "with", "a", "(", "poor", ")", "prior", "distribution", ".", "In", "the", "context", "of", "neural", "network", "training", ",", "this", "translates", "to", "re", "-", "initialization", "of", "the", "weights", "via", "cycling", "between", "large", "and", "small", "batch", "sizes", "which", "control", "the", "noise", "in", "SGD", ".", "We", "show", "empirical", "results", "which", "find", "this", "cyclical", "batch", "size", "schedule", "can", "significantly", "outperform", "fixed", "batch", "size", "baselines", ",", "especially", "in", "networks", "prone", "to", "overfitting", "or", "initialized", "poorly", ",", "on", "the", "tasks", "of", "language", "modeling", ",", "natural", "language", "inference", ",", "and", "image", "classification", "with", "LSTMs", ",", "CNNs", ",", "and", "ResNets", ".", "In", "our", "language", "modeling", "experiments", ",", "we", "see", "that", "a", "wide", "variety", "of", "CBS", "schedules", "outperform", "the", "baseline", "by", "up", "to", "7.91", "perplexity", "and", "up", "to", "33", "%", "fewer", "training", "iterations", ".", "For", "natural", "language", "inference", "and", "image", "classification", "tasks", ",", "we", "observe", "a", "reduction", "in", "the", "number", "of", "training", "iterations", "of", "up", "to", "61", "%", ",", "which", "translates", "directly", "into", "reduced", "runtime", ".", "Finally", ",", "we", "demonstrate", "the", "flexibility", "of", "CBS", "as", "a", "building", "block", "for", "ensembling", "and", "adversarial", "training", "methods", ".", "Ensembling", "on", "language", "modeling", "yields", "improvements", "of", "up", "to", "11.22", "perplexity", "over", "the", "baseline", "and", "on", "image", "classification", ",", "an", "improvement", "of", "up", "to", "1.07", "%", "accuracy", ".", "Adversarial", "training", "in", "conjunction", "with", "CBS", "gives", "a", "bump", "in", "image", "classification", "accuracy", "of", "0.26", "%", ".", "section", ":", "Limitations", "We", "believe", "that", "it", "is", "very", "important", "for", "every", "work", "to", "state", "its", "limitations", "(", "in", "general", ",", "but", "in", "particular", "in", "this", "area", ")", ".", "We", "performed", "an", "extensive", "variety", "of", "experiments", "on", "different", "tasks", "in", "order", "to", "comprehensively", "test", "the", "algorithm", ".", "The", "primary", "limitation", "of", "our", "work", "is", "that", "cyclical", "batch", "size", "schedules", "introduce", "another", "hyper", "-", "parameter", "that", "requires", "manual", "tuning", ".", "We", "note", "that", "this", "is", "also", "true", "for", "cyclical", "learning", "rate", "schedules", ",", "and", "hope", "to", "address", "this", "using", "second", "order", "methods", "[", "reference", "]", "as", "part", "of", "future", "work", ".", "Furthermore", ",", "for", "well", "initialized", "models", "which", "are", "not", "prone", "to", "overfitting", ",", "single", "snapshot", "CBS", "achieves", "similar", "performance", "to", "the", "baseline", ",", "although", "the", "cyclical", "ensembling", "provides", "a", "modicum", "of", "improvement", ".", "section", ":", "A", "Training", "Details", "Here", "we", "catalogue", "details", "regarding", "all", "tasks", ",", "datasets", ",", "models", ",", "batch", "schedules", ",", "and", "other", "hyperparameters", "used", "in", "our", "experiments", ".", "In", "all", "experiments", ",", "we", "try", "to", "copy", "as", "many", "hyper", "-", "parameters", "from", "the", "original", "papers", "as", "possible", ".", "Tasks", ":", "We", "train", "networks", "to", "perform", "the", "following", "supervised", "learning", "tasks", ":", "\u2022", "Image", "classification", ".", "The", "network", "is", "trained", "to", "classify", "the", "content", "of", "images", "within", "a", "fixed", "set", "of", "object", "classes", ".", "\u2022", "Language", "modeling", ".", "The", "network", "is", "trained", "to", "predict", "the", "last", "token", "in", "a", "sequence", "of", "English", "words", ".", "\u2022", "Natural", "Language", "Inference", ".", "The", "network", "is", "trained", "to", "classify", "the", "relationship", "between", "pairs", "of", "English", "sentences", "such", "as", "that", "of", "entailment", ",", "contradiction", ",", "or", "neutral", ".", "Datasets", ":", "We", "train", "networks", "on", "the", "following", "datasets", ".", "\u2022", "Cifar", "(", "image", "classification", ")", ".", "The", "two", "Cifar", "(", "i.e.", ",", "Cifar", "-", "10", "/", "Cifar", "-", "100", ")", "datasets", "[", "reference", "]", "contain", "50k", "training", "images", "and", "10k", "testing", "images", ",", "and", "10", "/", "100", "label", "classes", ".", "\u2022", "ImageNet", "(", "image", "classification", ")", ".", "The", "ILSVRC", "2012", "classification", "dataset", "consists", "of", "1000", "label", "classes", ",", "with", "a", "total", "of", "1.2", "million", "training", "images", "and", "50", ",", "000", "validation", "images", ".", "During", "training", ",", "we", "crop", "the", "image", "to", "224", "\u00d7", "224", ".", "\u2022", "PTB", "(", "language", "modeling", ")", ".", "The", "Penn", "Tree", "Bank", "dataset", "consists", "of", "preprocessed", "and", "tokenized", "sentences", "from", "the", "Wall", "Street", "Journal", ".", "The", "training", "set", "is", "929k", "words", ",", "the", "validation", "set", "73k", "words", ",", "and", "test", "set", "82k", "words", ".", "The", "total", "vocabulary", "size", "is", "10k", ",", "and", "all", "words", "outside", "the", "vocabulary", "are", "replaced", "by", "a", "placeholder", "token", ".", "\u2022", "WikiText", "2", "(", "language", "modeling", ")", ".", "The", "Wikitext", "2", "dataset", "is", "modeled", "after", "the", "Penn", "Tree", "Bank", "dataset", "and", "consists", "of", "preprocessed", "and", "tokenized", "sentences", "from", "Wikipedia", ".", "The", "training", "set", "is", "2089k", "words", ",", "the", "validation", "set", "218k", "words", ",", "and", "the", "test", "set", "246k", "words", ".", "The", "total", "vocabulary", "size", "is", "33k", ",", "and", "all", "words", "outside", "the", "vocabulary", "are", "replaced", "by", "a", "placeholder", "token", ".", "\u2022", "SNLI", "(", "natural", "language", "inference", ")", ".", "The", "SNLI", "dataset", "[", "reference", "]", "consists", "of", "pairs", "of", "sentences", "annotated", "with", "one", "of", "three", "labels", "regarding", "textual", "entailment", "information", ":", "contradiction", ",", "neutral", ",", "or", "entailment", ".", "The", "training", "set", "contains", "550k", "pairs", ",", "and", "the", "validation", "set", "contains", "10k", "pairs", ".", "\u2022", "MultiNLI", "(", "natural", "language", "inference", ".", "The", "MultiNLI", "dataset", "[", "reference", "]", "is", "modeled", "after", "the", "SNLI", "dataset", "and", "contains", "a", "training", "set", "of", "393k", "pairs", "and", "a", "validation", "set", "of", "20k", "pairs", ".", "Model", "Architecture", ".", "We", "implement", "the", "following", "neural", "network", "architectures", ".", "\u2022", "C1", ".", "AlexNet", "-", "like", "on", "Cifar", "-", "10", "dataset", "as", "in", "[", "reference", "][", "C1", "]", ",", "trained", "on", "the", "task", "of", "image", "classification", ".", "We", "train", "for", "200", "epochs", "with", "an", "initial", "learning", "rate", "0.02", "which", "we", "decay", "by", "a", "factor", "of", "5", "at", "epoch", "30", ",", "60", ".", "In", "particular", ",", "we", "use", "initial", "learning", "rate", "0.05", "for", "cyclic", "scheduling", ".", "\u2022", "C2", ".", "WResNet", "16", "-", "4", "on", "Cifar", "-", "10", "dataset", "[", "reference", "]", ",", "trained", "on", "the", "task", "of", "image", "classification", ".", "We", "train", "for", "200", "epochs", "with", "an", "initial", "learning", "rate", "0.1", "which", "we", "decay", "by", "a", "factor", "of", "5", "at", "epoch", "60", ",", "120", ",", "and", "180", ".", "\u2022", "C3", ".", "ResNet20", "on", "Cifar", "-", "10", "dataset", "[", "reference", "]", ".", "We", "train", "it", "for", "160", "epochs", "with", "initial", "learning", "rate", "0.1", ",", "and", "decay", "a", "factor", "of", "5", "at", "epoch", "80", ",", "120", ".", "In", "particular", ",", "we", "use", "initial", "learning", "rate", "0.05", "for", "cyclic", "scheduling", ".", "\u2022", "C4", ".", "MLP3", "network", "from", "[", "reference", "]", ".", "The", "network", "consists", "of", "3", "fully", "connected", "layers", "with", "512", "units", "each", "and", "ReLU", "activations", ".", "As", "a", "baseline", ",", "we", "train", "this", "network", "with", "vanilla", "SGD", "for", "240", "epochs", "with", "a", "batch", "size", "of", "100", "and", "an", "initial", "learning", "rate", "of", "0.1", ",", "which", "is", "decayed", "by", "a", "factor", "of", "10", "at", "150", "and", "225", "epochs", ".", "\u2022", "I1", ".", "ResNet50", "on", "ImageNet", "dataset", "[", "reference", "]", ",", "trained", "on", "the", "task", "of", "image", "classification", "for", "90", "epochs", "with", "initial", "learning", "rate", "0.1", "which", "we", "decay", "by", "a", "factor", "of", "10", "at", "epoch", "30", ",", "60", "and", "80", ".", "\u2022", "L1", ".", "Medium", "Regularized", "LSTM", "[", "reference", "]", ",", "trained", "on", "the", "task", "of", "language", "modeling", ".", "We", "use", "50", "%", "dropout", "on", "non", "-", "recurrent", "connections", "and", "train", "for", "39", "epochs", "with", "initial", "learning", "rate", "of", "20", ",", "decaying", "by", "a", "factor", "of", "1.2", "every", "epoch", "after", "epoch", "6", ".", "We", "set", "a", "backpropagation", "-", "through", "-", "time", "limit", "of", "35", "steps", "and", "clip", "the", "max", "gradient", "norm", "at", "0.25", ".", "\u2022", "L2", ".", "Large", "Regularized", "LSTM", "[", "reference", "]", ",", "trained", "on", "the", "task", "of", "language", "modeling", ".", "We", "use", "65", "%", "dropout", "on", "non", "-", "recurrent", "connections", "and", "train", "for", "55", "epochs", "with", "initial", "learning", "rate", "of", "20", ",", "decaying", "by", "a", "factor", "of", "1.15", "every", "epoch", "after", "epoch", "14", ".", "We", "set", "a", "backpropagation", "-", "through", "-", "time", "limit", "of", "35", "steps", "and", "clip", "the", "max", "gradient", "norm", "at", "0.5", ".", "\u2022", "L1", "'", ",", "L2", "'", "Identical", "to", "L1", ",", "L2", "except", "for", "lower", "dropout", ":", "0.2", ",", "0.3", "respectively", ".", "Leads", "to", "significant", "overfitting", ",", "evidenced", "by", "test", "perplexity", "curve", "in", "Fig", ".", "5", ".", "\u2022", "E1", ".", "ESIM", "[", "reference", "]", ".", "We", "train", "the", "base", "ESIM", "model", "without", "the", "tree", "-", "LSTM", ",", "as", "in", "[", "reference", "]", ",", "on", "the", "task", "of", "natural", "language", "inference", "with", "ADAM", "for", "10", "epochs", "on", "MultiNLI", "and", "also", "SNLI", ".", "Training", "Schedules", ":", "We", "use", "the", "following", "batch", "size", "schedules", "\u2022", "BL", ".", "Use", "a", "fixed", "small", "batch", "size", "as", "specified", "in", "the", "original", "paper", "introducing", "the", "model", "or", "as", "is", "standard", ".", "\u2022", "CBS", "-", "k", "(-", "n", ")", ".", "Use", "a", "Cyclical", "Batch", "Size", "schedule", ",", "where", "k", "is", "the", "width", "of", "each", "step", "measured", "in", "epochs", "and", "n", "is", "the", "integer", "number", "of", "steps", "per", "cycle", ".", "When", "n", "is", "not", "specified", "it", "refers", "to", "the", "default", "value", "of", "4", ".", "At", "the", "beginning", "of", "each", "cycle", "the", "batch", "size", "is", "initialized", "to", "the", "base", "batch", "size", ",", "and", "after", "each", "step", "it", "is", "then", "doubled", ".", "\u2022", "CBS", "-", "k", "(-", "n", ")-", "A.", "Use", "an", "aggressive", "Cyclical", "Batch", "Size", "schedule", ",", "which", "is", "equivalent", "to", "the", "original", "CBS", "schedule", "except", "after", "every", "step", "the", "batch", "size", "is", "quadrupled", ".", "\u2022", "CBS", "-", "k", "(-", "n", ")-", "T.", "Use", "a", "triangular", "Cyclical", "Batch", "Size", "schedule", ",", "which", "is", "modeled", "after", "the", "triangular", "schedule", ".", "Each", "cycle", "consists", "of", "n", "steps", "doubling", "the", "batch", "size", "after", "each", "step", ",", "then", "n", "\u2212", "2", "symmetrical", "steps", "halving", "the", "batch", "size", "after", "each", "step", ".", "In", "all", "language", "modeling", "CBS", "experiments", ",", "we", "use", "an", "initial", "batch", "size", "of", "10", ",", "that", "is", ",", "half", "the", "baseline", "batch", "size", "as", "reported", "in", "the", "respective", "papers", "of", "each", "baseline", "model", "tested", ".", "The", "intuition", "behind", "starting", "with", "a", "smaller", "batch", "size", "is", "to", "introduce", "additional", "noise", "to", "help", "models", "escape", "sub", "-", "optimal", "local", "minima", ".", "For", "adversarial", "training", "used", "in", "image", "classification", ",", "we", "use", "FGSM", "method", "[", "reference", "]", "to", "generate", "adversarial", "examples", ".", "Adversarial", "training", "is", "implemented", "for", "the", "first", "half", "training", "epochs", ".", "section", ":", "B", "Additional", "Results", "This", "section", "shows", "additional", "experiment", "results", ".", "section", ":"]}