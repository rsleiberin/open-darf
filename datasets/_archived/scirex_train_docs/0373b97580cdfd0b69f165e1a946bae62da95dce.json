{"coref": {"CIFAR-10": [[145, 148], [585, 588], [1902, 1905], [1964, 1967], [1991, 1994], [2049, 2052], [2633, 2636], [2677, 2680], [2818, 2821], [2871, 2874], [2959, 2962], [2060, 2063], [2356, 2359], [2521, 2524]], "CIFAR-100": [[149, 152], [589, 592], [1906, 1910], [1968, 1971], [1995, 1999], [2627, 2630], [2638, 2642], [2711, 2715], [2750, 2753], [2822, 2826], [2875, 2878], [2963, 2967]], "ELU": [[6, 9], [95, 98], [371, 374], [375, 376], [384, 385], [406, 407], [508, 511], [522, 525], [563, 564], [1027, 1028], [1042, 1043], [1055, 1056], [1126, 1127], [1169, 1170], [1182, 1185], [1344, 1345], [1354, 1357], [1358, 1359], [1381, 1382], [1389, 1390], [1393, 1394], [1407, 1408], [1411, 1412], [1514, 1515], [1518, 1519], [1531, 1532], [1538, 1539], [1542, 1543], [1622, 1623], [1628, 1629], [1659, 1660], [1665, 1666], [1816, 1817], [1827, 1828], [1834, 1835], [1873, 1874], [1916, 1917], [2841, 2844], [2905, 2906], [2907, 2908], [991, 994], [995, 996], [1023, 1024], [1750, 1751], [2180, 2181]], "Image_Classification": [], "Percentage_correct": [], "ResNet": [[2, 5], [10, 14], [108, 110], [121, 123], [166, 170], [462, 464], [556, 558], [804, 806], [807, 808], [844, 845], [967, 969], [1179, 1181], [1342, 1343], [2838, 2840], [2850, 2852], [494, 495], [1187, 1188], [1349, 1350], [2009, 2010], [2151, 2152], [2353, 2354], [2725, 2726]], "ResNet_ELU": []}, "coref_non_salient": {"0": [[209, 210], [242, 243]], "1": [[318, 320], [624, 627], [837, 839], [864, 866], [1008, 1011]], "10": [[1979, 1981], [2014, 2016], [2345, 2347], [2390, 2392], [2981, 2983]], "11": [[847, 849], [868, 870]], "12": [[2271, 2273], [2755, 2757]], "13": [[180, 185], [200, 202]], "14": [[1240, 1241], [1246, 1247], [1251, 1252], [1626, 1627], [1663, 1664], [1831, 1832], [1877, 1878], [2237, 2238]], "15": [[362, 364], [652, 654], [671, 673]], "16": [[1254, 1255], [2117, 2119], [2127, 2128]], "17": [[816, 818], [951, 953], [988, 990]], "18": [[293, 295], [302, 304]], "19": [[2156, 2159], [2186, 2190]], "2": [[127, 128], [409, 410], [442, 443], [488, 489], [533, 534], [554, 555], [581, 582], [611, 612], [715, 716], [835, 836], [1015, 1017], [1327, 1328], [1471, 1472], [1722, 1723], [1741, 1742], [1800, 1801], [1923, 1924], [2857, 2858], [2951, 2952]], "20": [[34, 36], [459, 461], [760, 762], [820, 822]], "21": [[32, 33], [938, 939], [1190, 1191], [1942, 1943]], "22": [[67, 69], [256, 258], [447, 449], [734, 736], [1509, 1511], [1745, 1747], [2975, 2977]], "23": [[1938, 1940], [1983, 1985], [2017, 2019], [2500, 2502], [2511, 2513], [2029, 2031], [2984, 2986]], "24": [[2233, 2235]], "25": [[2241, 2242]], "26": [[2459, 2462], [1461, 1464], [1724, 1727], [2542, 2545]], "27": [[2463, 2467], [2686, 2690]], "28": [[428, 433], [634, 639], [1587, 1590], [1705, 1708]], "29": [[946, 949]], "3": [[411, 415], [677, 679], [1455, 1457], [1489, 1491], [1594, 1596], [2247, 2249], [2423, 2425], [2456, 2458], [2929, 2931]], "30": [[2198, 2201]], "31": [[829, 831]], "32": [[1112, 1113]], "33": [[1238, 1239], [1244, 1245], [1249, 1250], [1387, 1388], [1391, 1392], [1405, 1406], [1409, 1410], [1516, 1517], [1520, 1521], [1540, 1541], [1544, 1545], [1620, 1621], [1624, 1625], [1657, 1658], [1661, 1662], [1825, 1826], [1829, 1830], [1871, 1872], [1875, 1876]], "34": [[2161, 2168]], "35": [[171, 172], [195, 196], [233, 237]], "36": [[1195, 1200]], "37": [[2490, 2492]], "38": [[1207, 1209]], "39": [[1331, 1333]], "4": [[203, 206], [944, 945], [906, 907], [1304, 1305]], "40": [[272, 275], [380, 383], [527, 530], [662, 665], [999, 1002]], "41": [[1261, 1263]], "42": [[239, 241]], "43": [[641, 645]], "44": [[2123, 2126]], "45": [[2170, 2172]], "46": [[157, 159]], "47": [[1337, 1339]], "48": [[279, 281], [569, 571]], "49": [[706, 708]], "5": [[1201, 1202], [1383, 1384]], "50": [[1525, 1529]], "6": [[105, 107], [368, 370], [422, 424], [518, 520], [541, 543], [666, 668], [680, 682], [683, 684], [1256, 1258], [1368, 1370], [1642, 1644], [1608, 1610], [1700, 1702]], "7": [[76, 78], [136, 138], [724, 726], [2548, 2550], [2592, 2594], [2733, 2735], [2762, 2764], [2894, 2896]], "8": [[119, 120], [404, 405], [566, 567], [1006, 1007], [1146, 1147], [2334, 2336]], "9": [[103, 104], [420, 421], [516, 517], [539, 540], [1167, 1168], [1242, 1243], [1366, 1367]]}, "doc_id": "0373b97580cdfd0b69f165e1a946bae62da95dce", "method_subrelations": {"ResNet_ELU": [[[0, 6], "ResNet"], [[7, 10], "ELU"]]}, "n_ary_relations": [{"Material": "CIFAR-10", "Method": "ResNet_ELU", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "94.4"}, {"Material": "CIFAR-100", "Method": "ResNet_ELU", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "73.5"}], "ner": [[2, 5, "Method"], [6, 9, "Method"], [10, 14, "Method"], [32, 33, "Method"], [34, 36, "Method"], [67, 69, "Method"], [76, 78, "Metric"], [95, 98, "Method"], [103, 104, "Method"], [105, 107, "Method"], [108, 110, "Method"], [119, 120, "Task"], [121, 123, "Method"], [127, 128, "Metric"], [136, 138, "Metric"], [145, 148, "Material"], [149, 152, "Material"], [157, 159, "Task"], [166, 170, "Method"], [171, 172, "Method"], [180, 185, "Task"], [195, 196, "Method"], [200, 202, "Task"], [203, 206, "Method"], [209, 210, "Method"], [233, 237, "Method"], [239, 241, "Method"], [242, 243, "Method"], [256, 258, "Method"], [272, 275, "Task"], [279, 281, "Task"], [293, 295, "Method"], [302, 304, "Method"], [318, 320, "Method"], [362, 364, "Method"], [368, 370, "Method"], [371, 374, "Method"], [375, 376, "Method"], [380, 383, "Task"], [384, 385, "Method"], [404, 405, "Task"], [406, 407, "Method"], [409, 410, "Metric"], [411, 415, "Metric"], [420, 421, "Method"], [422, 424, "Method"], [428, 433, "Task"], [442, 443, "Metric"], [447, 449, "Method"], [459, 461, "Method"], [462, 464, "Method"], [488, 489, "Metric"], [508, 511, "Method"], [516, 517, "Method"], [518, 520, "Method"], [522, 525, "Method"], [527, 530, "Task"], [533, 534, "Metric"], [539, 540, "Method"], [541, 543, "Method"], [554, 555, "Metric"], [556, 558, "Method"], [563, 564, "Method"], [566, 567, "Task"], [569, 571, "Task"], [581, 582, "Metric"], [585, 588, "Material"], [589, 592, "Material"], [611, 612, "Metric"], [624, 627, "Method"], [634, 639, "Task"], [641, 645, "Task"], [652, 654, "Method"], [662, 665, "Task"], [666, 668, "Method"], [671, 673, "Method"], [677, 679, "Metric"], [680, 682, "Method"], [683, 684, "Method"], [706, 708, "Task"], [715, 716, "Metric"], [724, 726, "Metric"], [734, 736, "Method"], [760, 762, "Method"], [804, 806, "Method"], [807, 808, "Method"], [816, 818, "Method"], [820, 822, "Method"], [829, 831, "Metric"], [835, 836, "Metric"], [837, 839, "Method"], [844, 845, "Method"], [847, 849, "Method"], [864, 866, "Method"], [868, 870, "Method"], [944, 945, "Method"], [946, 949, "Method"], [951, 953, "Method"], [967, 969, "Method"], [988, 990, "Method"], [999, 1002, "Task"], [1006, 1007, "Task"], [1008, 1011, "Method"], [1015, 1017, "Metric"], [1027, 1028, "Method"], [1042, 1043, "Method"], [1055, 1056, "Method"], [1112, 1113, "Method"], [1126, 1127, "Method"], [1146, 1147, "Task"], [1167, 1168, "Method"], [1169, 1170, "Method"], [1179, 1181, "Method"], [1182, 1185, "Method"], [1195, 1200, "Method"], [1201, 1202, "Method"], [1207, 1209, "Method"], [1238, 1239, "Method"], [1240, 1241, "Method"], [1242, 1243, "Method"], [1244, 1245, "Method"], [1246, 1247, "Method"], [1249, 1250, "Method"], [1251, 1252, "Method"], [1254, 1255, "Method"], [1256, 1258, "Method"], [1261, 1263, "Method"], [1327, 1328, "Metric"], [1331, 1333, "Metric"], [1337, 1339, "Method"], [1342, 1343, "Method"], [1344, 1345, "Method"], [1354, 1357, "Method"], [1358, 1359, "Method"], [1366, 1367, "Method"], [1368, 1370, "Method"], [1381, 1382, "Method"], [1383, 1384, "Method"], [1387, 1388, "Method"], [1389, 1390, "Method"], [1391, 1392, "Method"], [1393, 1394, "Method"], [1405, 1406, "Method"], [1407, 1408, "Method"], [1409, 1410, "Method"], [1411, 1412, "Method"], [1455, 1457, "Metric"], [1471, 1472, "Metric"], [1489, 1491, "Metric"], [1509, 1511, "Method"], [1514, 1515, "Method"], [1516, 1517, "Method"], [1518, 1519, "Method"], [1520, 1521, "Method"], [1525, 1529, "Method"], [1531, 1532, "Method"], [1538, 1539, "Method"], [1540, 1541, "Method"], [1542, 1543, "Method"], [1544, 1545, "Method"], [1587, 1590, "Task"], [1594, 1596, "Metric"], [1620, 1621, "Method"], [1622, 1623, "Method"], [1624, 1625, "Method"], [1626, 1627, "Method"], [1628, 1629, "Method"], [1642, 1644, "Method"], [1657, 1658, "Method"], [1659, 1660, "Method"], [1661, 1662, "Method"], [1663, 1664, "Method"], [1665, 1666, "Method"], [1705, 1708, "Task"], [1722, 1723, "Metric"], [1741, 1742, "Metric"], [1745, 1747, "Method"], [1800, 1801, "Metric"], [1816, 1817, "Method"], [1825, 1826, "Method"], [1827, 1828, "Method"], [1829, 1830, "Method"], [1831, 1832, "Method"], [1834, 1835, "Method"], [1871, 1872, "Method"], [1873, 1874, "Method"], [1875, 1876, "Method"], [1877, 1878, "Method"], [1902, 1905, "Material"], [1906, 1910, "Material"], [1916, 1917, "Method"], [1923, 1924, "Metric"], [1938, 1940, "Metric"], [1964, 1967, "Material"], [1968, 1971, "Material"], [1979, 1981, "Metric"], [1983, 1985, "Metric"], [1991, 1994, "Material"], [1995, 1999, "Material"], [2014, 2016, "Metric"], [2017, 2019, "Metric"], [2049, 2052, "Material"], [2117, 2119, "Method"], [2123, 2126, "Method"], [2127, 2128, "Method"], [2156, 2159, "Method"], [2161, 2168, "Method"], [2170, 2172, "Method"], [2186, 2190, "Method"], [2198, 2201, "Method"], [2233, 2235, "Method"], [2237, 2238, "Method"], [2241, 2242, "Method"], [2247, 2249, "Metric"], [2271, 2273, "Method"], [2334, 2336, "Task"], [2345, 2347, "Metric"], [2390, 2392, "Metric"], [2423, 2425, "Metric"], [2456, 2458, "Metric"], [2459, 2462, "Method"], [2463, 2467, "Method"], [2490, 2492, "Metric"], [2500, 2502, "Metric"], [2511, 2513, "Metric"], [2548, 2550, "Metric"], [2592, 2594, "Metric"], [2627, 2630, "Material"], [2633, 2636, "Material"], [2638, 2642, "Material"], [2677, 2680, "Material"], [2686, 2690, "Method"], [2711, 2715, "Material"], [2733, 2735, "Metric"], [2750, 2753, "Material"], [2755, 2757, "Method"], [2762, 2764, "Metric"], [2818, 2821, "Material"], [2822, 2826, "Material"], [2838, 2840, "Method"], [2841, 2844, "Method"], [2850, 2852, "Method"], [2857, 2858, "Metric"], [2871, 2874, "Material"], [2875, 2878, "Material"], [2894, 2896, "Metric"], [2905, 2906, "Method"], [2907, 2908, "Method"], [2929, 2931, "Metric"], [2951, 2952, "Metric"], [2959, 2962, "Material"], [2963, 2967, "Material"], [2975, 2977, "Method"], [2981, 2983, "Metric"], [494, 495, "Method"], [906, 907, "Method"], [938, 939, "Method"], [991, 994, "Method"], [995, 996, "Method"], [1023, 1024, "Method"], [1187, 1188, "Method"], [1190, 1191, "Method"], [1304, 1305, "Method"], [1349, 1350, "Method"], [1461, 1464, "Method"], [1608, 1610, "Method"], [1700, 1702, "Method"], [1724, 1727, "Method"], [1750, 1751, "Method"], [1942, 1943, "Method"], [2009, 2010, "Method"], [2029, 2031, "Metric"], [2060, 2063, "Material"], [2151, 2152, "Method"], [2180, 2181, "Method"], [2353, 2354, "Method"], [2356, 2359, "Material"], [2521, 2524, "Material"], [2542, 2545, "Method"], [2725, 2726, "Method"], [2984, 2986, "Metric"]], "sections": [[0, 153], [153, 621], [621, 1177], [1177, 1185], [1185, 1340], [1340, 1385], [1385, 1512], [1512, 1618], [1618, 1823], [1823, 1945], [1945, 2047], [2047, 2332], [2332, 2498], [2498, 2625], [2625, 2829], [2829, 2991], [2991, 2994]], "sentences": [[0, 9], [9, 23], [23, 37], [37, 65], [65, 86], [86, 111], [111, 133], [133, 153], [153, 156], [156, 186], [186, 203], [203, 223], [223, 253], [253, 271], [271, 282], [282, 296], [296, 313], [313, 324], [324, 345], [345, 354], [354, 371], [371, 384], [384, 396], [396, 406], [406, 425], [425, 439], [439, 450], [450, 465], [465, 490], [490, 500], [500, 521], [521, 559], [559, 574], [574, 599], [599, 621], [621, 624], [624, 633], [633, 646], [646, 655], [655, 669], [669, 698], [698, 710], [710, 723], [723, 741], [741, 760], [760, 782], [782, 804], [804, 819], [819, 832], [832, 840], [840, 856], [856, 882], [882, 895], [895, 926], [926, 928], [928, 950], [950, 966], [966, 991], [991, 1018], [1018, 1055], [1055, 1067], [1067, 1084], [1084, 1100], [1100, 1124], [1124, 1140], [1140, 1158], [1158, 1160], [1160, 1173], [1173, 1174], [1174, 1176], [1176, 1177], [1177, 1185], [1185, 1189], [1189, 1215], [1215, 1227], [1227, 1238], [1238, 1260], [1260, 1275], [1275, 1292], [1292, 1307], [1307, 1314], [1314, 1340], [1340, 1345], [1345, 1371], [1371, 1373], [1373, 1385], [1385, 1394], [1394, 1405], [1405, 1413], [1413, 1415], [1415, 1427], [1427, 1440], [1440, 1453], [1453, 1473], [1473, 1492], [1492, 1512], [1512, 1521], [1521, 1533], [1533, 1546], [1546, 1548], [1548, 1559], [1559, 1574], [1574, 1591], [1591, 1603], [1603, 1618], [1618, 1631], [1631, 1632], [1632, 1633], [1633, 1647], [1647, 1669], [1669, 1671], [1671, 1682], [1682, 1715], [1715, 1729], [1729, 1748], [1748, 1769], [1769, 1774], [1774, 1786], [1786, 1806], [1806, 1808], [1808, 1823], [1823, 1837], [1837, 1838], [1838, 1839], [1839, 1841], [1841, 1842], [1842, 1844], [1844, 1859], [1859, 1871], [1871, 1879], [1879, 1891], [1891, 1911], [1911, 1930], [1930, 1945], [1945, 1948], [1948, 1972], [1972, 2000], [2000, 2024], [2024, 2047], [2047, 2053], [2053, 2079], [2079, 2097], [2097, 2110], [2110, 2120], [2120, 2142], [2142, 2149], [2149, 2173], [2173, 2191], [2191, 2217], [2217, 2243], [2243, 2268], [2268, 2280], [2280, 2300], [2300, 2314], [2314, 2332], [2332, 2336], [2336, 2338], [2338, 2373], [2373, 2401], [2401, 2419], [2419, 2435], [2435, 2438], [2438, 2444], [2444, 2447], [2447, 2468], [2468, 2482], [2482, 2498], [2498, 2502], [2502, 2504], [2504, 2537], [2537, 2559], [2559, 2574], [2574, 2595], [2595, 2597], [2597, 2620], [2620, 2621], [2621, 2622], [2622, 2625], [2625, 2631], [2631, 2658], [2658, 2681], [2681, 2703], [2703, 2705], [2705, 2728], [2728, 2758], [2758, 2779], [2779, 2781], [2781, 2801], [2801, 2827], [2827, 2829], [2829, 2832], [2832, 2853], [2853, 2868], [2868, 2907], [2907, 2921], [2921, 2932], [2932, 2968], [2968, 2991], [2991, 2994]], "words": ["document", ":", "Deep", "Residual", "Networks", "with", "Exponential", "Linear", "Unit", "Very", "deep", "convolutional", "neural", "networks", "introduced", "new", "problems", "like", "vanishing", "gradient", "and", "degradation", ".", "The", "recent", "successful", "contributions", "towards", "solving", "these", "problems", "are", "Residual", "and", "Highway", "Networks", ".", "These", "networks", "introduce", "skip", "connections", "that", "allow", "the", "information", "(", "from", "the", "input", "or", "those", "learned", "in", "earlier", "layers", ")", "to", "flow", "more", "into", "the", "deeper", "layers", ".", "These", "very", "deep", "models", "have", "lead", "to", "a", "considerable", "decrease", "in", "test", "errors", ",", "on", "benchmarks", "like", "ImageNet", "and", "COCO", ".", "In", "this", "paper", ",", "we", "propose", "the", "use", "of", "exponential", "linear", "unit", "instead", "of", "the", "combination", "of", "ReLU", "and", "Batch", "Normalization", "in", "Residual", "Networks", ".", "We", "show", "that", "this", "not", "only", "speeds", "up", "learning", "in", "Residual", "Networks", "but", "also", "improves", "the", "accuracy", "as", "the", "depth", "increases", ".", "It", "improves", "the", "test", "error", "on", "almost", "all", "data", "sets", ",", "like", "CIFAR", "-", "10", "and", "CIFAR", "-", "100", ".", "section", ":", "Introduction", "The", "Vision", "Community", "has", "been", "mesmerized", "by", "the", "effectiveness", "of", "deep", "convolutional", "neural", "networks", "(", "CNNs", ")", "that", "have", "led", "to", "a", "breakthrough", "in", "computer", "vision", "-", "related", "problems", ".", "Hence", ",", "there", "has", "been", "a", "notable", "shift", "towards", "CNNs", "in", "many", "areas", "of", "computer", "vision", ".", "Convolutional", "neural", "networks", "were", "popularized", "through", "AlexNet", "in", "2009", "and", "their", "much", "celebrated", "victory", "at", "the", "2012", "ImageNet", "competiton", ".", "After", "that", ",", "there", "have", "been", "several", "attempts", "at", "building", "deeper", "and", "deeper", "CNNs", "like", "the", "VGG", "network", "and", "GoogLeNet", "in", "2014", "which", "have", "19", "and", "22", "layers", "respectively", ".", "But", ",", "very", "deep", "models", "introduce", "problems", "like", "vanishing", "and", "exploding", "gradients", ",", "which", "hamper", "their", "convergence", ".", "The", "vanishing", "gradient", "problem", "is", "trivial", "in", "very", "deep", "networks", ".", "During", "the", "backpropagation", "phase", ",", "the", "gradients", "are", "computed", "by", "the", "chain", "rule", ".", "Multiplication", "of", "small", "numbers", "in", "the", "chain", "rule", "leads", "to", "an", "exponential", "decrease", "in", "the", "gradient", ".", "Due", "to", "this", ",", "very", "deep", "networks", "learn", "very", "slowly", ".", "Sometimes", ",", "the", "gradient", "in", "the", "earlier", "layer", "gets", "larger", "because", "derivatives", "of", "some", "activation", "functions", "can", "take", "larger", "values", ".", "This", "leads", "to", "the", "problem", "of", "exploding", "gradient", ".", "These", "problems", "have", "been", "reduced", "in", "practice", "through", "normalized", "initialization", "and", "most", "recently", ",", "Batch", "Normalization", ".", "Exponential", "linear", "unit", "(", "ELU", ")", "also", "reduces", "the", "vanishing", "gradient", "problem", ".", "ELUs", "introduce", "negative", "values", "which", "push", "the", "mean", "activation", "towards", "zero", ".", "This", "reduces", "the", "bias", "shift", "and", "speeds", "up", "learning", ".", "ELUs", "give", "better", "accuracy", "and", "learning", "speed", "-", "up", "compared", "to", "the", "combination", "of", "ReLU", "and", "Batch", "Normalization", ".", "After", "reducing", "the", "vanishing", "/", "exploding", "gradient", "problem", ",", "the", "networks", "start", "converging", ".", "However", ",", "the", "accuracy", "degrades", "in", "such", "very", "deep", "models", ".", "The", "most", "recent", "contributions", "towards", "solving", "this", "problem", "are", "Highway", "Networks", "and", "Residual", "Networks", ".", "These", "networks", "introduce", "skip", "connections", ",", "which", "allow", "information", "flow", "into", "the", "deeper", "layers", "and", "enable", "us", "to", "have", "deeper", "networks", "with", "better", "accuracy", ".", "The", "152", "-", "layer", "ResNet", "outperforms", "all", "other", "models", ".", "In", "this", "paper", ",", "we", "propose", "to", "use", "exponential", "linear", "unit", "instead", "of", "the", "combination", "of", "ReLU", "and", "Batch", "Normalization", ".", "Since", "exponential", "linear", "units", "reduce", "the", "vanishing", "gradient", "problem", "and", "give", "better", "accuracy", "compared", "to", "the", "combination", "of", "ReLU", "and", "Batch", "Normalization", ",", "we", "use", "it", "in", "our", "model", "to", "further", "increase", "the", "accuracy", "of", "Residual", "Networks", ".", "We", "also", "notice", "that", "ELU", "speeds", "up", "learning", "in", "very", "deep", "networks", "as", "well", ".", "We", "show", "that", "our", "model", "increases", "the", "accuracy", "on", "datasets", "like", "CIFAR", "-", "10", "and", "CIFAR", "-", "100", ",", "compared", "to", "the", "original", "model", ".", "It", "is", "seen", "that", "as", "the", "depth", "increases", ",", "the", "difference", "in", "accuracy", "between", "our", "model", "and", "the", "original", "model", "increases", ".", "section", ":", "Background", "Deeper", "neural", "networks", "are", "very", "difficult", "to", "train", ".", "The", "vanishing", "/", "exploding", "gradients", "problem", "impedes", "the", "convergence", "of", "deeper", "networks", ".", "This", "problem", "has", "been", "solved", "by", "normalized", "initialization", ".", "A", "notable", "recent", "contribution", "towards", "reducing", "the", "vanishing", "gradients", "problem", "is", "Batch", "Normalization", ".", "Instead", "of", "normalized", "initialization", "and", "keeping", "a", "lower", "learning", "rate", ",", "Batch", "Normalization", "makes", "normalization", "a", "part", "of", "the", "model", "and", "performs", "it", "for", "each", "mini", "-", "batch", ".", "Once", "the", "deeper", "networks", "start", "converging", ",", "a", "degradation", "problem", "occurs", ".", "Due", "to", "this", ",", "the", "accuracy", "degrades", "rapidly", "after", "it", "is", "saturated", ".", "The", "training", "error", "increases", "as", "we", "add", "more", "layers", "to", "a", "deep", "model", ",", "as", "mentioned", "in", ".", "To", "solve", "this", "problem", ",", "several", "authors", "introduced", "skip", "connections", "to", "improve", "the", "information", "flow", "across", "several", "layers", ".", "Highway", "Networks", "have", "parameterized", "skip", "connections", ",", "known", "as", "information", "highways", ",", "which", "allow", "information", "to", "flow", "unimpeded", "into", "deeper", "layers", ".", "During", "the", "training", "phase", ",", "the", "skip", "connection", "parameters", "are", "adjusted", "to", "control", "the", "amount", "of", "information", "allowed", "on", "these", "highways", ".", "Residual", "Networks", "(", "ResNets", ")", "utilize", "shortcut", "connections", "with", "the", "help", "of", "identity", "transformation", ".", "Unlike", "Highway", "Networks", ",", "these", "neither", "introduce", "extra", "parameter", "nor", "computation", "complexity", ".", "This", "improves", "the", "accuracy", "of", "deeper", "networks", ".", "With", "increasing", "depth", ",", "ResNets", "give", "better", "function", "approximation", "capabilities", "as", "they", "gain", "more", "parameters", ".", "The", "authors", "\u2019", "hypothesis", "is", "that", "the", "plain", "deeper", "networks", "give", "worse", "function", "approximation", "because", "the", "gradients", "vanish", "when", "they", "are", "propagated", "through", "many", "layers", ".", "To", "fix", "this", "problem", ",", "they", "introduce", "skip", "connections", "to", "the", "network", ".", "Formally", ",", "If", "the", "output", "of", "layer", "is", "and", "represents", "multiple", "convolutional", "transformation", "from", "layer", "to", ",", "we", "obtain", "where", "represents", "the", "identity", "function", "and", "is", "the", "default", "activation", "function", ".", "Fig", ".", "[", "reference", "]", "illustrates", "the", "basic", "building", "block", "of", "a", "Residual", "Network", "which", "consists", "of", "multiple", "convolutional", "and", "Batch", "Normalization", "layers", ".", "The", "identity", "transformation", ",", "is", "used", "to", "reduce", "the", "dimensions", "of", "to", "match", "those", "of", ".", "In", "Residual", "Networks", ",", "the", "gradients", "and", "features", "learned", "in", "earlier", "layers", "are", "passed", "back", "and", "forth", "between", "the", "layers", "via", "the", "identity", "transformations", ".", "Exponential", "Linear", "Unit", "(", "ELU", ")", "alleviates", "the", "vanishing", "gradient", "problem", "and", "also", "speeds", "up", "learning", "in", "deep", "neural", "networks", "which", "leads", "to", "higher", "classification", "accuracies", ".", "The", "exponential", "linear", "unit", "(", "ELU", ")", "is", "The", "ReLUs", "are", "non", "-", "negative", "and", "thus", "have", "mean", "activations", "larger", "than", "zero", ",", "whereas", "ELUs", "have", "negative", "values", ",", "which", "push", "the", "mean", "activations", "towards", "zero", ".", "ELUs", "saturate", "to", "a", "negative", "value", "when", "the", "input", "gets", "smaller", ".", "This", "decreases", "the", "forward", "propagated", "variation", "and", "information", ",", "which", "draws", "the", "mean", "activations", "to", "zero", ".", "Units", "with", "non", "-", "zero", "mean", "activations", "act", "as", "a", "bias", "for", "the", "next", "layer", ".", "If", "these", "units", "do", "not", "cancel", "each", "other", "out", ",", "then", "the", "learning", "causes", "a", "bias", "shift", "for", "units", "in", "the", "next", "layer", ".", "Therefore", ",", "ELUs", "decrease", "the", "bias", "shift", "as", "the", "mean", "activations", "are", "closer", "to", "zero", ".", "Less", "bias", "shift", "also", "speeds", "up", "learning", "by", "bringing", "standard", "gradient", "closer", "towards", "the", "unit", "natural", "gradient", ".", "Fig", ".", "[", "reference", "]", "shows", "the", "comparison", "of", "ReLU", "and", "ELU", "(", ")", ".", ".24", ".24", ".24", ".24", "section", ":", "Residual", "Networks", "with", "Exponential", "Linear", "Unit", "subsection", ":", "ResNet", "Architecture", "The", "Residual", "Network", "in", "is", "a", "functional", "composition", "of", "residual", "blocks", "(", "ResBlocks", ")", ",", "each", "encoding", "the", "update", "rule", "(", "[", "reference", "]", ")", ".", "Fig", "[", "reference", "]", "shows", "the", "schematic", "illustration", "of", "the", "ResBlock", ".", "In", "this", "example", ",", "consists", "of", "a", "sequence", "of", "layers", ":", "Conv", "-", "BN", "-", "ReLU", "-", "Conv", "-", "BN", ",", "where", "Conv", "and", "BN", "stands", "for", "Convolution", "and", "Batch", "Normalization", "respectively", ".", "This", "construction", "scheme", "is", "adopted", "in", "all", "our", "experiments", "while", "reproducing", "the", "results", "of", ".", "The", "function", "is", "parameterized", "by", "some", "set", "of", "parameters", ",", "which", "we", "omit", "for", "notational", "simplicity", ".", "Normally", ",", "we", "use", "64", ",", "32", "or", "16", "filters", "in", "the", "convolutional", "layers", ".", "The", "size", "of", "receptive", "field", "is", ".", "Although", "it", "does", "not", "seem", "attractive", "but", ",", "in", "practice", "it", "gives", "better", "accuracy", "without", "adding", "any", "overhead", "costs", ",", "as", "compared", "to", "plain", "networks", ".", "subsection", ":", "ResNet", "with", "ELU", "In", "comparison", "with", "the", "ResNet", "model", ",", "we", "use", "Exponential", "Linear", "Unit", "(", "ELU", ")", "in", "place", "of", "a", "combination", "of", "ReLU", "with", "Batch", "Normalization", ".", "Fig", ".", "[", "reference", "]", "illustrates", "our", "different", "experiments", "with", "ELUs", "in", "ResBlock", ".", "subsubsection", ":", "Conv", "-", "ELU", "-", "Conv", "-", "ELU", "In", "this", "model", ",", "consists", "of", "a", "sequence", "of", "layers", ":", "Conv", "-", "ELU", "-", "Conv", "-", "ELU", ".", "Fig", ".", "[", "reference", "]", "represents", "the", "basic", "building", "block", "of", "this", "experiment", ".", "We", "trained", "our", "model", "using", "the", "specification", "mentioned", "in", "[", "reference", "]", ".", "But", "we", "found", "that", "after", "few", "iterations", ",", "the", "gradients", "blew", "up", ".", "When", "the", "learning", "rate", "is", "decreased", ",", "the", "20", "-", "layer", "model", "starts", "converging", "but", "to", "very", "less", "accuracy", ".", "The", "deeper", "models", "like", "56", "and", "110", "-", "layer", "still", "do", "not", "converge", "after", "decreasing", "the", "learning", "rate", ".", "This", "model", "clearly", "fails", "as", "the", "trivial", "problem", "of", "exploding", "gradient", "can", "not", "be", "reduced", "in", "very", "deep", "models", ".", "subsubsection", ":", "ELU", "-", "Conv", "-", "ELU", "-", "Conv", "This", "is", "a", "full", "pre", "-", "activation", "unit", "ResBlock", "with", "ELU", ".", "The", "sequence", "of", "layers", "is", "ELU", "-", "Conv", "-", "ELU", "-", "Conv", ".", "Fig", ".", "[", "reference", "]", "highlights", "the", "basic", "ResBlock", "of", "this", "experiment", ".", "During", "the", "training", "of", "this", "model", "too", ",", "the", "gradients", "exploded", "after", "few", "iterations", ".", "Due", "to", "the", "exponential", "function", ",", "the", "gradients", "get", "larger", "and", "lead", "to", "exploding", "gradient", "problem", ".", "Even", "decreasing", "the", "learning", "rate", "also", "does", "not", "reduce", "this", "problem", ".", "We", "decided", "to", "add", "a", "Batch", "Normalization", "layer", "before", "Addition", "to", "control", "this", "problem", ".", "subsubsection", ":", "Conv", "-", "ELU", "-", "Conv", "-", "BN", "and", "ELU", "after", "Addition", ".23", ".23", "To", "control", "the", "exploding", "gradient", ",", "we", "added", "a", "Batch", "Normalization", "before", "addition", ".", "So", ",", "the", "sequence", "of", "layers", "in", "this", "ResBlock", "is", "Conv", "-", "ELU", "-", "Conv", "-", "BN", "and", "ELU", "after", "addition", ".", "Fig", ".", "[", "reference", "]", "represents", "the", "ResBlock", "used", "in", "this", "experiment", ".", "Thus", "in", "this", "ResBlock", ",", "the", "update", "rule", "(", "[", "reference", "]", ")", "for", "the", "layer", "is", "The", "Batch", "Normalization", "layer", "reduces", "the", "exploding", "gradient", "problem", "found", "in", "the", "previous", "two", "models", ".", "We", "found", "that", "this", "model", "gives", "better", "accuracy", "for", "20", "-", "layer", "model", ".", "However", ",", "as", "we", "increased", "the", "depth", "of", "the", "network", ",", "the", "accuracy", "degrades", "for", "the", "deeper", "models", ".", "If", "the", "ELU", "activation", "function", "is", "placed", "after", "addtion", ",", "then", "the", "mean", "activation", "of", "the", "output", "pushes", "towards", "zero", ".", "This", "could", "be", "beneficial", ".", "However", ",", "this", "forces", "each", "skip", "connection", "to", "perturb", "the", "output", ".", "This", "has", "a", "harmful", "effect", "and", "we", "found", "that", "this", "leads", "to", "degradation", "of", "accuracy", "in", "very", "deep", "ResNets", ".", "Fig", ".", "[", "reference", "]", "depicts", "the", "effects", "of", "including", "ELU", "after", "addition", "in", "this", "ResBlock", ".", "subsubsection", ":", "Conv", "-", "ELU", "-", "Conv", "-", "BN", "and", "No", "ELU", "after", "Addition", ".33", ".33", ".33", ".4", ".4", "Fig", ".", "[", "reference", "]", "gives", "an", "illustration", "of", "the", "basic", "building", "block", "of", "our", "model", ".", "Thus", "in", "our", "model", ",", "represents", "the", "following", "sequence", "of", "layers", ":", "Conv", "-", "ELU", "-", "Conv", "-", "BN", ".", "The", "update", "rule", "(", "[", "reference", "]", ")", "for", "the", "layer", "is", "This", "is", "the", "basic", "building", "block", "for", "all", "our", "experiments", "on", "CIFAR", "-", "10", "and", "CIFAR", "-", "100", "datasets", ".", "We", "show", "that", "not", "including", "ELU", "after", "addition", "does", "not", "degrade", "the", "accuracy", ",", "unlike", "the", "previous", "model", ".", "This", "ResBlock", "improves", "the", "learning", "behavior", "and", "the", "classification", "performance", "of", "the", "Residual", "Network", ".", "section", ":", "Results", "We", "empirically", "demonstrate", "the", "effectiveness", "of", "our", "model", "on", "a", "series", "of", "benchmark", "data", "sets", ":", "CIFAR", "-", "10", "and", "CIFAR", "-", "100", ".", "In", "our", "experiments", ",", "we", "compare", "the", "learning", "behavior", "and", "the", "classification", "performance", "of", "both", "the", "models", "on", "the", "CIFAR", "-", "10", "and", "CIFAR", "-", "100", "datasets", ".", "The", "experiments", "prove", "that", "our", "model", "outperforms", "the", "original", "ResNet", "model", "in", "terms", "of", "learning", "behavior", "and", "classification", "performance", "on", "both", "the", "datasets", ".", "Finally", ",", "we", "compare", "the", "classification", "performance", "of", "our", "model", "with", "other", "previously", "published", "state", "-", "of", "-", "the", "-", "art", "models", ".", "subsection", ":", "CIFAR", "-", "10", "Analysis", "The", "first", "experiment", "was", "performed", "on", "the", "CIFAR", "-", "10", "dataset", ",", "which", "consists", "of", "50k", "training", "images", "and", "10k", "test", "images", "in", "10", "classes", ".", "In", "our", "experiments", ",", "we", "performed", "training", "on", "the", "training", "set", "and", "evaluation", "on", "the", "test", "set", ".", "The", "inputs", "to", "the", "network", "are", "images", "which", "are", "color", "-", "normalized", ".", "We", "use", "a", "receptive", "field", "in", "the", "convolution", "layer", ".", "We", "use", "a", "stack", "of", "layers", "with", "convolution", "on", "the", "feature", "maps", "of", "sizes", "respectively", ",", "with", "on", "each", "feature", "map", ".", "The", "number", "of", "filters", "are", "respectively", ".", "The", "original", "ResNet", "model", "ends", "with", "a", "global", "average", "pooling", ",", "a", "10", "-", "way", "fully", "-", "connected", "layer", "and", "a", "softmax", "layer", ".", "In", "our", "model", ",", "we", "add", "an", "ELU", "activation", "function", "just", "before", "the", "global", "average", "pooling", "layer", ".", "These", "two", "models", "are", "trained", "on", "a", "AWS", "g2.2xlarge", "instance", "(", "which", "has", "a", "single", "GPU", ")", "with", "a", "mini", "batch", "-", "size", "of", "128", ".", "We", "use", "a", "weight", "decay", "of", "0.0001", "and", "a", "momentum", "of", "0.9", ",", "and", "adopt", "the", "weight", "initialization", "in", "and", "BN", "but", "with", "no", "dropout", ".", "We", "start", "with", "a", "learning", "rate", "of", "0.1", "and", "divide", "by", "10", "after", "81", "epochs", ",", "and", "again", "divide", "by", "10", "after", "122", "epochs", ".", "We", "use", "the", "data", "augmentation", "mentioned", "in", "during", "the", "training", "phase", ":", "Add", "4", "pixels", "on", "each", "side", "and", "do", "a", "random", "crop", "from", "the", "padded", "image", "or", "its", "horizontal", "flip", ".", "During", "the", "testing", "phase", ",", "we", "only", "use", "a", "color", "-", "normalized", "image", ".", "Our", "experiments", "are", "executed", "on", "20", ",", "32", ",", "44", ",", "56", "and", "110", "-", "layer", "networks", ".", "subsubsection", ":", "Learning", "Behavior", "Fig", ".", "[", "reference", "]", "shows", "the", "comparison", "of", "learning", "behaviours", "between", "our", "model", "and", "the", "original", "ResNet", "model", "on", "CIFAR", "-", "10", "dataset", "for", "20", ",", "32", ",", "44", ",", "56", "and", "110", "-", "layers", ".", "The", "graphs", "prove", "that", "for", "all", "the", "different", "number", "of", "layers", ",", "our", "model", "possesses", "a", "superior", "learning", "behavior", "and", "converges", "many", "epochs", "before", "the", "original", "model", ".", "As", "the", "depth", "of", "the", "model", "increases", ",", "our", "model", "also", "learns", "faster", "than", "the", "original", "model", ".", "The", "difference", "between", "the", "learning", "rate", "of", "these", "two", "models", "increases", "as", "the", "depth", "increases", ".", "Comparing", "Fig", ".", "[", "reference", "]", "and", "Fig", ".", "[", "reference", "]", ",", "we", "can", "easily", "notice", "the", "huge", "difference", "in", "learning", "rates", "for", "20", "-", "layer", "and", "110", "-", "layer", "models", ".", "After", "125", "epochs", ",", "both", "the", "models", "converge", "to", "almost", "the", "same", "value", ".", "But", ",", "our", "model", "has", "a", "slightly", "lower", "training", "loss", "compared", "to", "the", "original", "model", ".", "subsubsection", ":", "Classification", "Performance", "Fig", ".", "[", "reference", "]", "illustrates", "the", "comparison", "of", "classification", "performance", "between", "our", "model", "and", "the", "original", "one", "on", "CIFAR", "-", "10", "dataset", "for", "20", ",", "32", ",", "44", ",", "56", "and", "110", "layers", ".", "We", "observe", "that", "for", "the", "20", "-", "layer", "model", ",", "the", "test", "error", "is", "nearly", "the", "same", "for", "both", "the", "models", ".", "But", ",", "as", "the", "depth", "increases", ",", "our", "model", "significantly", "outperforms", "the", "original", "model", ".", "Table", "[", "reference", "]", "shows", "the", "test", "error", "for", "both", "the", "models", "from", "the", "epoch", "with", "the", "lowest", "validation", "error", ".", "Fig", ".", "[", "reference", "]", "shows", "that", "the", "gap", "between", "the", "test", "error", "of", "the", "two", "models", "increases", "as", "the", "depth", "is", "also", "increased", ".", ".33", ".33", ".33", ".4", ".4", "subsection", ":", "CIFAR", "-", "100", "Analysis", "Similar", "to", "CIFAR", "-", "10", ",", "the", "CIFAR", "-", "100", "dataset", "also", "contains", "images", "with", "the", "same", "train", "-", "test", "split", ",", "but", "from", "100", "classes", ".", "For", "both", "the", "original", "model", "and", "our", "model", ",", "the", "experimental", "settings", "are", "exactly", "the", "same", "as", "those", "of", "CIFAR", "-", "10", ".", "We", "trained", "only", "for", "the", "110", "-", "layer", "models", "as", "it", "gives", "us", "state", "-", "of", "-", "the", "-", "art", "results", ".", "Fig", ".", "[", "reference", "]", "shows", "that", "for", "CIFAR", "-", "100", "dataset", "as", "well", ",", "our", "model", "learns", "faster", "than", "the", "original", "ResNet", "model", ".", "The", "original", "model", "yields", "a", "test", "error", "of", "27.23", "%", ",", "which", "is", "already", "state", "-", "of", "-", "the", "-", "art", "in", "CIFAR", "-", "100", "with", "standard", "data", "augmentation", ".", "Our", "model", "reduces", "the", "test", "error", "to", "26.55", "%", "and", "is", "again", "one", "of", "the", "best", "published", "single", "model", "performances", ".", "Fig", ".", "[", "reference", "]", "shows", "that", "the", "test", "error", "of", "our", "model", "is", "much", "lower", "from", "the", "starting", "epoch", "itself", ".", "Table", "[", "reference", "]", "shows", "the", "comparison", "of", "our", "result", "with", "other", "previously", "published", "results", "on", "the", "CIFAR", "-", "10", "and", "CIFAR", "-", "100", "datasets", ".", ".23", ".23", "section", ":", "Conclusions", "In", "this", "paper", ",", "we", "introduce", "Residual", "Networks", "with", "exponential", "linear", "units", "which", "learn", "faster", "than", "the", "current", "Residual", "Networks", ".", "They", "also", "give", "better", "accuracy", "than", "the", "original", "ones", "when", "the", "depth", "is", "increased", ".", "On", "datasets", "like", "CIFAR", "-", "10", "and", "CIFAR", "-", "100", ",", "we", "improve", "beyond", "the", "current", "state", "-", "of", "-", "the", "-", "art", "in", "terms", "of", "test", "error", ",", "while", "also", "learning", "faster", "than", "these", "models", "using", "ELUs", ".", "ELUs", "push", "the", "mean", "activations", "towards", "zero", "as", "they", "introduce", "small", "negative", "values", ".", "This", "reduces", "the", "bias", "shift", "and", "increases", "the", "learning", "speed", ".", "Our", "experiments", "show", "that", "not", "only", "does", "our", "model", "have", "superior", "learning", "behavior", ",", "but", "it", "also", "provides", "better", "accuracy", "as", "compared", "to", "the", "current", "model", "on", "CIFAR", "-", "10", "and", "CIFAR", "-", "100", "datasets", ".", "This", "enables", "the", "researchers", "to", "use", "very", "deep", "models", "and", "also", "increase", "their", "learning", "behavior", "and", "classification", "performance", "at", "the", "same", "time", ".", "bibliography", ":", "References"]}