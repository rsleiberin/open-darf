{"coref": {"Accuracy": [[4744, 4745], [4829, 4831], [5657, 5658]], "Citeseer": [[3230, 3231], [3255, 3256], [3444, 3445], [4688, 4689], [4898, 4899], [5052, 5054]], "Cora": [[3228, 3229], [3253, 3254], [3442, 3443], [4686, 4687], [5050, 5051], [4885, 4886], [5080, 5081]], "Node_Classification": [[61, 63], [86, 88], [813, 816], [836, 838], [912, 914], [923, 925], [2153, 2155], [2241, 2245], [3306, 3308], [3434, 3436], [3675, 3677], [4674, 4676], [4708, 4710], [4716, 4718], [4802, 4804], [5056, 5058], [5402, 5404], [5734, 5736], [27, 29], [221, 223], [2127, 2129], [2150, 2152], [2412, 2414], [2839, 2841], [2989, 2991], [3128, 3130], [4681, 4683], [5008, 5010], [5129, 5131], [5296, 5298], [5452, 5454], [5644, 5646]], "Pubmed": [[3232, 3233], [3257, 3258], [3446, 3447], [4900, 4902], [4670, 4671], [4690, 4691], [5347, 5348]], "alpha-LoNGAE": [[1673, 1674], [1534, 1535], [1586, 1587], [2130, 2131], [2791, 2792], [2813, 2814], [2931, 2932], [3965, 3966], [4052, 4053], [4087, 4088], [4117, 4118], [4151, 4152], [4183, 4184], [4366, 4367], [4653, 4654], [4813, 4814], [4872, 4873], [4917, 4918], [4937, 4938], [4992, 4993], [5028, 5029], [5036, 5037], [5062, 5063], [5138, 5139], [5283, 5284], [5340, 5341], [5449, 5450]]}, "coref_non_salient": {"0": [[402, 404], [419, 421]], "1": [[451, 453], [5568, 5570]], "10": [[53, 57], [150, 154], [185, 186], [245, 247], [445, 446], [801, 805], [1463, 1464], [1734, 1735], [2001, 2002], [2320, 2321], [2400, 2404], [4904, 4908], [5388, 5392], [5725, 5729], [2828, 2832]], "100": [[2558, 2560]], "101": [[5467, 5471]], "102": [[389, 393]], "103": [[5048, 5049]], "104": [[3004, 3011]], "105": [[394, 398]], "106": [[2334, 2337]], "107": [[1449, 1451]], "108": [[3772, 3774]], "109": [[2515, 2519]], "11": [[1847, 1852], [2097, 2101]], "110": [[2733, 2734], [2741, 2742], [2848, 2849], [4046, 4047], [4125, 4126], [4158, 4159], [4187, 4188], [3316, 3317], [3976, 3977], [5149, 5150], [5166, 5167]], "111": [[2538, 2539], [2888, 2889]], "112": [[1407, 1409], [1965, 1967]], "113": [[537, 539]], "114": [[311, 315]], "115": [[2087, 2090]], "116": [[2728, 2732]], "117": [[432, 433]], "118": [[626, 627]], "119": [[5571, 5573]], "12": [[2602, 2604], [2968, 2971]], "120": [[2900, 2903]], "121": [[206, 208]], "122": [[3768, 3771]], "123": [[196, 200], [258, 262], [660, 664], [5477, 5481], [5772, 5776]], "124": [[416, 418]], "125": [[3857, 3860]], "126": [[1648, 1650]], "127": [[224, 225], [373, 374], [942, 943], [2884, 2885], [3027, 3028], [3078, 3079], [3184, 3185], [4912, 4913], [341, 342], [883, 884]], "128": [[2897, 2899]], "129": [[1240, 1244]], "13": [[2185, 2187], [4705, 4707]], "130": [[1670, 1672]], "131": [[2876, 2878]], "132": [[3088, 3092]], "133": [[1765, 1766]], "134": [[1859, 1863]], "135": [[763, 765]], "136": [[1304, 1307]], "137": [[1737, 1739]], "138": [[2534, 2537]], "139": [[3565, 3569]], "14": [[1374, 1376], [2939, 2942]], "140": [[3994, 3996]], "141": [[2573, 2577]], "142": [[1873, 1875]], "143": [[399, 401]], "144": [[2623, 2625]], "145": [[145, 149], [2294, 2298]], "146": [[3381, 3382], [3199, 3200], [3240, 3241], [4373, 4374], [4411, 4412]], "147": [[434, 435]], "148": [[3461, 3462]], "149": [[772, 776]], "15": [[2684, 2685], [2690, 2691]], "150": [[2455, 2456]], "151": [[356, 362]], "152": [[3073, 3077]], "153": [[422, 423]], "154": [[448, 450]], "155": [[1536, 1540]], "156": [[2501, 2505]], "157": [[2881, 2883]], "158": [[1390, 1399]], "159": [[2159, 2169]], "16": [[377, 379], [691, 693], [1082, 1084], [3159, 3161], [3283, 3285], [4200, 4202], [4501, 4503], [5504, 5506]], "160": [[2546, 2548]], "17": [[1319, 1321], [2779, 2783], [3883, 3887], [5183, 5187], [5685, 5689]], "18": [[1777, 1786], [1900, 1902]], "19": [[2525, 2527], [4204, 4206], [2720, 2722]], "2": [[1422, 1423], [2205, 2207], [2678, 2679], [3931, 3932], [3935, 3937], [4040, 4041], [5120, 5121], [5134, 5136]], "20": [[1459, 1460], [3847, 3850]], "21": [[766, 768], [1719, 1720], [5507, 5508]], "22": [[2905, 2907], [2935, 2937], [3000, 3002], [3041, 3043], [4881, 4883], [4890, 4891], [5076, 5078]], "23": [[4530, 4531], [4564, 4565]], "24": [[3602, 3604], [3780, 3782], [3802, 3803]], "25": [[4588, 4589], [4726, 4727], [5046, 5047]], "26": [[3983, 3984], [4018, 4019], [4056, 4057], [4122, 4123], [4155, 4156], [5142, 5143]], "27": [[3267, 3270], [3335, 3338], [3939, 3942], [4065, 4068], [3234, 3237], [4128, 4131]], "28": [[3383, 3384], [3202, 3203], [3242, 3243], [4375, 4376], [4423, 4424]], "29": [[2686, 2687], [2693, 2694]], "3": [[1571, 1575], [2668, 2670]], "30": [[1920, 1922], [2102, 2104]], "31": [[3323, 3325], [4179, 4181]], "32": [[621, 622], [751, 752]], "33": [[5195, 5197]], "34": [[3722, 3723], [3758, 3759]], "35": [[3147, 3149], [3330, 3333]], "36": [[1452, 1454], [1651, 1653], [3905, 3907], [5099, 5101], [5179, 5181], [5363, 5365]], "37": [[17, 20], [127, 130], [2424, 2427], [2488, 2491], [2785, 2787], [5378, 5380]], "38": [[2251, 2254], [5326, 5329]], "39": [[34, 36], [65, 67], [348, 352]], "4": [[2139, 2143], [2920, 2927]], "40": [[4572, 4575], [4824, 4827], [4851, 4854], [4927, 4930]], "41": [[318, 320], [3761, 3762]], "42": [[3534, 3535], [3776, 3777], [5743, 5746]], "43": [[3271, 3272], [3339, 3341], [3943, 3944], [4070, 4071], [3219, 3220], [4147, 4148]], "44": [[1276, 1280], [1411, 1413]], "45": [[1465, 1466], [2322, 2323], [3115, 3118], [3909, 3910], [5381, 5382]], "46": [[2680, 2681], [2688, 2689]], "47": [[806, 807], [1474, 1475], [4995, 4996], [5410, 5411], [4921, 4922], [4933, 4934]], "48": [[4326, 4327], [4525, 4526], [4334, 4335], [4562, 4563]], "49": [[3726, 3729]], "5": [[963, 964], [3176, 3179], [4505, 4508], [4609, 4612], [4636, 4639]], "50": [[40, 42], [5395, 5397]], "51": [[2982, 2983], [3412, 3413], [5043, 5044]], "52": [[2610, 2611]], "53": [[3822, 3824]], "54": [[1331, 1336], [1945, 1947], [3458, 3460], [3641, 3643], [5096, 5098], [5369, 5371], [5384, 5386], [5635, 5637]], "55": [[4386, 4387], [4476, 4477]], "56": [[3854, 3856]], "57": [[5700, 5706]], "58": [[676, 678], [783, 785], [868, 870], [917, 919], [930, 932], [1270, 1272], [2712, 2714]], "59": [[5, 8], [188, 191]], "6": [[21, 23], [58, 60], [83, 85], [142, 144], [215, 217], [459, 461], [810, 812], [832, 835], [907, 909], [920, 922], [1166, 1168], [1170, 1172], [1229, 1231], [1247, 1249], [1541, 1543], [1577, 1579], [1757, 1759], [2115, 2117], [2406, 2408], [2615, 2617], [2647, 2649], [2736, 2738], [2805, 2807], [2964, 2966], [3122, 3124], [3301, 3303], [3369, 3371], [3431, 3433], [3732, 3734], [3799, 3801], [3828, 3830], [4189, 4191], [4213, 4215], [4351, 4353], [4509, 4511], [4657, 4659], [5022, 5024], [5122, 5124], [5199, 5201], [5399, 5401], [5638, 5640], [5731, 5733], [703, 705], [1196, 1198], [1237, 1239], [1822, 1824], [2833, 2835], [3657, 3659], [4109, 4111], [4362, 4364], [4404, 4406], [4472, 4474], [4623, 4625], [5005, 5007], [5269, 5271]], "60": [[900, 902], [3980, 3982], [4316, 4318]], "61": [[2594, 2599], [2674, 2676]], "62": [[4323, 4325]], "63": [[3385, 3386], [3206, 3207], [3244, 3245], [4377, 4378], [4425, 4426], [4460, 4461]], "64": [[4527, 4529]], "65": [[5254, 5256]], "66": [[2978, 2981]], "67": [[2446, 2448]], "68": [[3863, 3865]], "69": [[5174, 5177]], "7": [[9, 10], [956, 957], [1013, 1014], [1427, 1428], [1517, 1518], [1722, 1723], [2196, 2197], [2331, 2332], [2378, 2379], [2531, 2532], [2748, 2749], [4281, 4282]], "70": [[3466, 3471]], "71": [[454, 457], [1867, 1869]], "72": [[3923, 3925], [5161, 5164]], "73": [[5157, 5160]], "74": [[5565, 5567]], "75": [[3717, 3721]], "76": [[78, 80], [841, 843]], "77": [[139, 141], [2493, 2495]], "78": [[3818, 3820]], "79": [[3988, 3992]], "8": [[1287, 1288], [1290, 1291], [1298, 1300]], "80": [[3530, 3533]], "81": [[424, 426], [2561, 2563]], "82": [[2911, 2919]], "83": [[2541, 2542], [2661, 2662], [4207, 4208], [4370, 4371], [4384, 4385], [2528, 2529], [2564, 2565], [2631, 2632], [3344, 3345], [4390, 4391], [4438, 4439], [4605, 4606]], "84": [[2555, 2557], [2715, 2717]], "85": [[1732, 1733], [1741, 1742]], "86": [[3390, 3391]], "87": [[4838, 4841]], "88": [[1654, 1668]], "89": [[3550, 3553], [4339, 4345]], "9": [[337, 338], [3894, 3896], [5215, 5217]], "90": [[3141, 3143]], "91": [[3838, 3840]], "92": [[3059, 3062]], "93": [[5352, 5354]], "94": [[2866, 2869]], "95": [[624, 625]], "96": [[3421, 3427]], "97": [[1401, 1404]], "98": [[3572, 3575]], "99": [[1880, 1882]]}, "doc_id": "2e4c06dd00c4c09ad5ac6be883cc66c19d88ea79", "method_subrelations": {"alpha-LoNGAE": [[[0, 12], "alpha-LoNGAE"]]}, "n_ary_relations": [{"Material": "Citeseer", "Method": "alpha-LoNGAE", "Metric": "Accuracy", "Task": "Node_Classification", "score": "71.60%"}, {"Material": "Cora", "Method": "alpha-LoNGAE", "Metric": "Accuracy", "Task": "Node_Classification", "score": "78.30%"}, {"Material": "Pubmed", "Method": "alpha-LoNGAE", "Metric": "Accuracy", "Task": "Node_Classification", "score": "79.40%"}], "ner": [[5, 8, "Task"], [9, 10, "Method"], [17, 20, "Task"], [21, 23, "Task"], [34, 36, "Method"], [40, 42, "Method"], [53, 57, "Task"], [58, 60, "Task"], [61, 63, "Task"], [65, 67, "Method"], [78, 80, "Method"], [83, 85, "Task"], [86, 88, "Task"], [127, 130, "Task"], [139, 141, "Task"], [142, 144, "Task"], [145, 149, "Task"], [150, 154, "Task"], [185, 186, "Task"], [188, 191, "Task"], [196, 200, "Task"], [206, 208, "Task"], [215, 217, "Task"], [224, 225, "Task"], [245, 247, "Task"], [258, 262, "Task"], [311, 315, "Method"], [318, 320, "Method"], [337, 338, "Metric"], [348, 352, "Method"], [356, 362, "Method"], [373, 374, "Task"], [377, 379, "Method"], [389, 393, "Task"], [394, 398, "Task"], [399, 401, "Task"], [402, 404, "Task"], [416, 418, "Task"], [419, 421, "Task"], [422, 423, "Task"], [424, 426, "Task"], [432, 433, "Material"], [434, 435, "Material"], [445, 446, "Task"], [448, 450, "Task"], [451, 453, "Task"], [454, 457, "Task"], [459, 461, "Task"], [537, 539, "Task"], [621, 622, "Task"], [624, 625, "Metric"], [626, 627, "Metric"], [660, 664, "Task"], [676, 678, "Method"], [691, 693, "Method"], [751, 752, "Task"], [763, 765, "Metric"], [766, 768, "Metric"], [772, 776, "Method"], [783, 785, "Method"], [801, 805, "Task"], [806, 807, "Task"], [810, 812, "Task"], [813, 816, "Task"], [832, 835, "Task"], [836, 838, "Task"], [841, 843, "Method"], [868, 870, "Method"], [900, 902, "Metric"], [907, 909, "Task"], [912, 914, "Task"], [917, 919, "Method"], [920, 922, "Task"], [923, 925, "Task"], [930, 932, "Method"], [942, 943, "Task"], [956, 957, "Method"], [963, 964, "Method"], [1013, 1014, "Method"], [1082, 1084, "Method"], [1166, 1168, "Task"], [1170, 1172, "Task"], [1229, 1231, "Task"], [1240, 1244, "Method"], [1247, 1249, "Task"], [1270, 1272, "Method"], [1276, 1280, "Method"], [1287, 1288, "Method"], [1290, 1291, "Method"], [1298, 1300, "Method"], [1304, 1307, "Method"], [1319, 1321, "Method"], [1331, 1336, "Method"], [1374, 1376, "Method"], [1390, 1399, "Method"], [1401, 1404, "Method"], [1407, 1409, "Method"], [1411, 1413, "Method"], [1422, 1423, "Task"], [1427, 1428, "Method"], [1449, 1451, "Method"], [1452, 1454, "Method"], [1459, 1460, "Method"], [1463, 1464, "Task"], [1465, 1466, "Task"], [1474, 1475, "Task"], [1517, 1518, "Method"], [1536, 1540, "Method"], [1541, 1543, "Task"], [1571, 1575, "Method"], [1577, 1579, "Task"], [1648, 1650, "Method"], [1651, 1653, "Method"], [1654, 1668, "Task"], [1670, 1672, "Metric"], [1673, 1674, "Method"], [1719, 1720, "Metric"], [1722, 1723, "Method"], [1732, 1733, "Task"], [1734, 1735, "Task"], [1737, 1739, "Task"], [1741, 1742, "Task"], [1757, 1759, "Task"], [1765, 1766, "Method"], [1777, 1786, "Metric"], [1847, 1852, "Method"], [1859, 1863, "Method"], [1867, 1869, "Task"], [1873, 1875, "Task"], [1880, 1882, "Task"], [1900, 1902, "Metric"], [1920, 1922, "Method"], [1945, 1947, "Method"], [1965, 1967, "Method"], [2001, 2002, "Task"], [2087, 2090, "Method"], [2097, 2101, "Method"], [2102, 2104, "Method"], [2115, 2117, "Task"], [2139, 2143, "Task"], [2153, 2155, "Task"], [2159, 2169, "Task"], [2185, 2187, "Task"], [2196, 2197, "Method"], [2205, 2207, "Task"], [2241, 2245, "Task"], [2251, 2254, "Method"], [2294, 2298, "Task"], [2320, 2321, "Task"], [2322, 2323, "Task"], [2331, 2332, "Method"], [2334, 2337, "Method"], [2378, 2379, "Method"], [2400, 2404, "Task"], [2406, 2408, "Task"], [2424, 2427, "Task"], [2446, 2448, "Method"], [2455, 2456, "Method"], [2488, 2491, "Task"], [2493, 2495, "Task"], [2501, 2505, "Method"], [2515, 2519, "Method"], [2525, 2527, "Method"], [2531, 2532, "Method"], [2534, 2537, "Method"], [2538, 2539, "Method"], [2541, 2542, "Method"], [2546, 2548, "Task"], [2555, 2557, "Task"], [2558, 2560, "Task"], [2561, 2563, "Task"], [2573, 2577, "Method"], [2594, 2599, "Method"], [2602, 2604, "Method"], [2610, 2611, "Method"], [2615, 2617, "Task"], [2623, 2625, "Task"], [2647, 2649, "Task"], [2661, 2662, "Method"], [2668, 2670, "Method"], [2674, 2676, "Method"], [2678, 2679, "Task"], [2680, 2681, "Method"], [2684, 2685, "Method"], [2686, 2687, "Method"], [2688, 2689, "Method"], [2690, 2691, "Method"], [2693, 2694, "Method"], [2712, 2714, "Method"], [2715, 2717, "Task"], [2728, 2732, "Method"], [2733, 2734, "Method"], [2736, 2738, "Task"], [2741, 2742, "Method"], [2748, 2749, "Method"], [2779, 2783, "Method"], [2785, 2787, "Task"], [2805, 2807, "Task"], [2848, 2849, "Method"], [2866, 2869, "Method"], [2876, 2878, "Method"], [2881, 2883, "Method"], [2884, 2885, "Task"], [2888, 2889, "Method"], [2897, 2899, "Method"], [2900, 2903, "Task"], [2905, 2907, "Method"], [2911, 2919, "Method"], [2920, 2927, "Task"], [2935, 2937, "Method"], [2939, 2942, "Method"], [2964, 2966, "Task"], [2968, 2971, "Method"], [2978, 2981, "Method"], [2982, 2983, "Method"], [3000, 3002, "Method"], [3004, 3011, "Method"], [3027, 3028, "Task"], [3041, 3043, "Method"], [3059, 3062, "Method"], [3073, 3077, "Method"], [3078, 3079, "Task"], [3088, 3092, "Method"], [3115, 3118, "Task"], [3122, 3124, "Task"], [3141, 3143, "Method"], [3147, 3149, "Task"], [3159, 3161, "Method"], [3176, 3179, "Method"], [3184, 3185, "Task"], [3228, 3229, "Material"], [3230, 3231, "Material"], [3232, 3233, "Material"], [3253, 3254, "Material"], [3255, 3256, "Material"], [3257, 3258, "Material"], [3267, 3270, "Material"], [3271, 3272, "Material"], [3283, 3285, "Method"], [3301, 3303, "Task"], [3306, 3308, "Task"], [3323, 3325, "Metric"], [3330, 3333, "Task"], [3335, 3338, "Material"], [3339, 3341, "Material"], [3369, 3371, "Task"], [3381, 3382, "Material"], [3383, 3384, "Material"], [3385, 3386, "Material"], [3390, 3391, "Material"], [3421, 3427, "Metric"], [3431, 3433, "Task"], [3434, 3436, "Task"], [3442, 3443, "Material"], [3444, 3445, "Material"], [3446, 3447, "Material"], [3458, 3460, "Method"], [3461, 3462, "Method"], [3466, 3471, "Method"], [3530, 3533, "Task"], [3534, 3535, "Task"], [3550, 3553, "Metric"], [3565, 3569, "Method"], [3572, 3575, "Method"], [3602, 3604, "Method"], [3641, 3643, "Method"], [3675, 3677, "Task"], [3717, 3721, "Method"], [3722, 3723, "Method"], [3726, 3729, "Method"], [3732, 3734, "Task"], [3758, 3759, "Method"], [3761, 3762, "Method"], [3768, 3771, "Task"], [3772, 3774, "Task"], [3776, 3777, "Task"], [3780, 3782, "Method"], [3799, 3801, "Task"], [3802, 3803, "Method"], [3818, 3820, "Method"], [3822, 3824, "Method"], [3828, 3830, "Task"], [3838, 3840, "Method"], [3847, 3850, "Method"], [3854, 3856, "Method"], [3857, 3860, "Task"], [3863, 3865, "Metric"], [3883, 3887, "Method"], [3894, 3896, "Metric"], [3905, 3907, "Method"], [3909, 3910, "Task"], [3923, 3925, "Method"], [3931, 3932, "Task"], [3935, 3937, "Task"], [3939, 3942, "Material"], [3943, 3944, "Material"], [3980, 3982, "Metric"], [3983, 3984, "Metric"], [3988, 3992, "Metric"], [3994, 3996, "Task"], [4018, 4019, "Metric"], [4040, 4041, "Task"], [4046, 4047, "Method"], [4056, 4057, "Metric"], [4065, 4068, "Material"], [4070, 4071, "Material"], [4122, 4123, "Metric"], [4125, 4126, "Method"], [4155, 4156, "Metric"], [4158, 4159, "Method"], [4179, 4181, "Metric"], [4187, 4188, "Method"], [4189, 4191, "Task"], [4200, 4202, "Method"], [4204, 4206, "Method"], [4207, 4208, "Method"], [4213, 4215, "Task"], [4281, 4282, "Method"], [4316, 4318, "Metric"], [4323, 4325, "Metric"], [4326, 4327, "Metric"], [4339, 4345, "Metric"], [4351, 4353, "Task"], [4370, 4371, "Method"], [4384, 4385, "Method"], [4386, 4387, "Method"], [4476, 4477, "Method"], [4501, 4503, "Method"], [4505, 4508, "Method"], [4509, 4511, "Task"], [4525, 4526, "Metric"], [4527, 4529, "Metric"], [4530, 4531, "Metric"], [4564, 4565, "Metric"], [4572, 4575, "Method"], [4588, 4589, "Method"], [4609, 4612, "Method"], [4636, 4639, "Method"], [4657, 4659, "Task"], [4674, 4676, "Task"], [4686, 4687, "Material"], [4688, 4689, "Material"], [4705, 4707, "Task"], [4708, 4710, "Task"], [4716, 4718, "Task"], [4726, 4727, "Method"], [4744, 4745, "Metric"], [4802, 4804, "Task"], [4824, 4827, "Method"], [4829, 4831, "Metric"], [4838, 4841, "Method"], [4851, 4854, "Method"], [4881, 4883, "Method"], [4890, 4891, "Method"], [4898, 4899, "Material"], [4900, 4902, "Material"], [4904, 4908, "Task"], [4912, 4913, "Task"], [4927, 4930, "Method"], [4995, 4996, "Task"], [5022, 5024, "Task"], [5046, 5047, "Method"], [5048, 5049, "Method"], [5050, 5051, "Material"], [5052, 5054, "Material"], [5056, 5058, "Task"], [5076, 5078, "Method"], [5096, 5098, "Method"], [5099, 5101, "Method"], [5120, 5121, "Task"], [5122, 5124, "Task"], [5134, 5136, "Task"], [5142, 5143, "Metric"], [5157, 5160, "Method"], [5161, 5164, "Method"], [5174, 5177, "Task"], [5179, 5181, "Method"], [5183, 5187, "Method"], [5195, 5197, "Method"], [5199, 5201, "Task"], [5215, 5217, "Metric"], [5254, 5256, "Metric"], [5326, 5329, "Method"], [5352, 5354, "Metric"], [5363, 5365, "Method"], [5369, 5371, "Method"], [5378, 5380, "Task"], [5381, 5382, "Task"], [5384, 5386, "Method"], [5388, 5392, "Task"], [5395, 5397, "Method"], [5399, 5401, "Task"], [5402, 5404, "Task"], [5410, 5411, "Task"], [5467, 5471, "Method"], [5477, 5481, "Task"], [5504, 5506, "Method"], [5507, 5508, "Metric"], [5565, 5567, "Task"], [5568, 5570, "Task"], [5571, 5573, "Task"], [5635, 5637, "Method"], [5638, 5640, "Task"], [5657, 5658, "Metric"], [5685, 5689, "Method"], [5700, 5706, "Method"], [5725, 5729, "Task"], [5731, 5733, "Task"], [5734, 5736, "Task"], [5743, 5746, "Task"], [5772, 5776, "Task"], [27, 29, "Task"], [221, 223, "Task"], [341, 342, "Task"], [703, 705, "Task"], [883, 884, "Task"], [1196, 1198, "Task"], [1237, 1239, "Task"], [1534, 1535, "Method"], [1586, 1587, "Method"], [1822, 1824, "Task"], [2127, 2129, "Task"], [2130, 2131, "Method"], [2150, 2152, "Task"], [2412, 2414, "Task"], [2528, 2529, "Method"], [2564, 2565, "Method"], [2631, 2632, "Method"], [2720, 2722, "Method"], [2791, 2792, "Method"], [2813, 2814, "Method"], [2828, 2832, "Task"], [2833, 2835, "Task"], [2839, 2841, "Task"], [2931, 2932, "Method"], [2989, 2991, "Task"], [3128, 3130, "Task"], [3199, 3200, "Material"], [3202, 3203, "Material"], [3206, 3207, "Material"], [3219, 3220, "Material"], [3234, 3237, "Material"], [3240, 3241, "Material"], [3242, 3243, "Material"], [3244, 3245, "Material"], [3316, 3317, "Method"], [3344, 3345, "Method"], [3412, 3413, "Method"], [3657, 3659, "Task"], [3965, 3966, "Method"], [3976, 3977, "Method"], [4052, 4053, "Method"], [4087, 4088, "Method"], [4109, 4111, "Task"], [4117, 4118, "Method"], [4128, 4131, "Material"], [4147, 4148, "Material"], [4151, 4152, "Method"], [4183, 4184, "Method"], [4334, 4335, "Metric"], [4362, 4364, "Task"], [4366, 4367, "Method"], [4373, 4374, "Material"], [4375, 4376, "Material"], [4377, 4378, "Material"], [4390, 4391, "Method"], [4404, 4406, "Task"], [4411, 4412, "Material"], [4423, 4424, "Material"], [4425, 4426, "Material"], [4438, 4439, "Method"], [4460, 4461, "Material"], [4472, 4474, "Task"], [4562, 4563, "Metric"], [4605, 4606, "Method"], [4623, 4625, "Task"], [4653, 4654, "Method"], [4670, 4671, "Material"], [4681, 4683, "Task"], [4690, 4691, "Material"], [4813, 4814, "Method"], [4872, 4873, "Method"], [4885, 4886, "Material"], [4917, 4918, "Method"], [4921, 4922, "Task"], [4933, 4934, "Task"], [4937, 4938, "Method"], [4992, 4993, "Method"], [5005, 5007, "Task"], [5008, 5010, "Task"], [5028, 5029, "Method"], [5036, 5037, "Method"], [5043, 5044, "Method"], [5062, 5063, "Method"], [5080, 5081, "Material"], [5129, 5131, "Task"], [5138, 5139, "Method"], [5149, 5150, "Method"], [5166, 5167, "Method"], [5269, 5271, "Task"], [5283, 5284, "Method"], [5296, 5298, "Task"], [5340, 5341, "Method"], [5347, 5348, "Material"], [5449, 5450, "Method"], [5452, 5454, "Task"], [5644, 5646, "Task"]], "sections": [[0, 154], [154, 915], [915, 1164], [1164, 2122], [2122, 2417], [2417, 3093], [3093, 3150], [3150, 3451], [3451, 3926], [3926, 5084], [5084, 5624], [5624, 5777], [5777, 5802], [5802, 5805]], "sentences": [[0, 10], [10, 30], [30, 64], [64, 103], [103, 131], [131, 139], [139, 154], [154, 157], [157, 176], [176, 201], [201, 227], [227, 257], [257, 286], [286, 321], [321, 344], [344, 375], [375, 408], [408, 410], [410, 436], [436, 496], [496, 526], [526, 580], [580, 597], [597, 643], [643, 665], [665, 687], [687, 780], [780, 817], [817, 858], [858, 886], [886, 915], [915, 925], [925, 952], [952, 963], [963, 971], [971, 1006], [1006, 1030], [1030, 1061], [1061, 1078], [1078, 1121], [1121, 1150], [1150, 1164], [1164, 1168], [1168, 1191], [1191, 1224], [1224, 1247], [1247, 1268], [1268, 1292], [1292, 1337], [1337, 1373], [1373, 1387], [1387, 1405], [1405, 1424], [1424, 1452], [1452, 1484], [1484, 1501], [1501, 1515], [1515, 1541], [1541, 1546], [1546, 1580], [1580, 1588], [1588, 1600], [1600, 1631], [1631, 1669], [1669, 1705], [1705, 1715], [1715, 1732], [1732, 1760], [1760, 1767], [1767, 1804], [1804, 1826], [1826, 1853], [1853, 1864], [1864, 1888], [1888, 1905], [1905, 1943], [1943, 1960], [1960, 2000], [2000, 2030], [2030, 2065], [2065, 2105], [2105, 2122], [2122, 2129], [2129, 2153], [2153, 2188], [2188, 2208], [2208, 2240], [2240, 2263], [2263, 2279], [2279, 2293], [2293, 2324], [2324, 2392], [2392, 2417], [2417, 2421], [2421, 2449], [2449, 2474], [2474, 2506], [2506, 2541], [2541, 2564], [2564, 2610], [2610, 2626], [2626, 2656], [2656, 2688], [2688, 2703], [2703, 2739], [2739, 2761], [2761, 2810], [2810, 2842], [2842, 2886], [2886, 2904], [2904, 2928], [2928, 2953], [2953, 2963], [2963, 2985], [2985, 2999], [2999, 3038], [3038, 3067], [3067, 3093], [3093, 3097], [3097, 3131], [3131, 3150], [3150, 3155], [3155, 3186], [3186, 3239], [3239, 3252], [3252, 3265], [3265, 3277], [3277, 3278], [3278, 3279], [3279, 3309], [3309, 3342], [3342, 3389], [3389, 3409], [3409, 3451], [3451, 3455], [3455, 3478], [3478, 3499], [3499, 3511], [3511, 3536], [3536, 3565], [3565, 3582], [3582, 3605], [3605, 3629], [3629, 3654], [3654, 3674], [3674, 3692], [3692, 3715], [3715, 3758], [3758, 3775], [3775, 3798], [3798, 3821], [3821, 3832], [3832, 3843], [3843, 3851], [3851, 3867], [3867, 3897], [3897, 3926], [3926, 3931], [3931, 3954], [3954, 3979], [3979, 4016], [4016, 4023], [4023, 4042], [4042, 4043], [4043, 4079], [4079, 4113], [4113, 4145], [4145, 4174], [4174, 4189], [4189, 4221], [4221, 4241], [4241, 4275], [4275, 4315], [4315, 4329], [4329, 4346], [4346, 4360], [4360, 4388], [4388, 4423], [4423, 4445], [4445, 4457], [4457, 4476], [4476, 4482], [4482, 4492], [4492, 4517], [4517, 4559], [4559, 4580], [4580, 4602], [4602, 4627], [4627, 4652], [4652, 4673], [4673, 4701], [4701, 4719], [4719, 4744], [4744, 4761], [4761, 4774], [4774, 4784], [4784, 4805], [4805, 4829], [4829, 4832], [4832, 4836], [4836, 4855], [4855, 4867], [4867, 4903], [4903, 4904], [4904, 4931], [4931, 4983], [4983, 5021], [5021, 5055], [5055, 5083], [5083, 5084], [5084, 5087], [5087, 5132], [5132, 5152], [5152, 5198], [5198, 5218], [5218, 5228], [5228, 5257], [5257, 5282], [5282, 5299], [5299, 5305], [5305, 5335], [5335, 5358], [5358, 5383], [5383, 5410], [5410, 5438], [5438, 5466], [5466, 5494], [5494, 5516], [5516, 5543], [5543, 5561], [5561, 5571], [5571, 5591], [5591, 5624], [5624, 5627], [5627, 5671], [5671, 5716], [5716, 5747], [5747, 5777], [5777, 5780], [5780, 5802], [5802, 5805]], "words": ["document", ":", "Learning", "to", "Make", "Predictions", "on", "Graphs", "with", "Autoencoders", "We", "examine", "two", "fundamental", "tasks", "associated", "with", "graph", "representation", "learning", ":", "link", "prediction", "and", "semi", "-", "supervised", "node", "classification", ".", "We", "present", "a", "novel", "autoencoder", "architecture", "capable", "of", "learning", "a", "joint", "representation", "of", "both", "local", "graph", "structure", "and", "available", "node", "features", "for", "the", "multi", "-", "task", "learning", "of", "link", "prediction", "and", "node", "classification", ".", "Our", "autoencoder", "architecture", "is", "efficiently", "trained", "end", "-", "to", "-", "end", "in", "a", "single", "learning", "stage", "to", "simultaneously", "perform", "link", "prediction", "and", "node", "classification", ",", "whereas", "previous", "related", "methods", "require", "multiple", "training", "steps", "that", "are", "difficult", "to", "optimize", ".", "We", "provide", "a", "comprehensive", "empirical", "evaluation", "of", "our", "models", "on", "nine", "benchmark", "graph", "-", "structured", "datasets", "and", "demonstrate", "significant", "improvement", "over", "related", "methods", "for", "graph", "representation", "learning", ".", "Reference", "code", "and", "data", "are", "available", "at", ".", "network", "embedding", ",", "link", "prediction", ",", "semi", "-", "supervised", "learning", ",", "multi", "-", "task", "learning", "section", ":", "Introduction", "A", "s", "the", "world", "is", "becoming", "increasingly", "interconnected", ",", "graph", "-", "structured", "data", "are", "also", "growing", "in", "ubiquity", ".", "In", "this", "work", ",", "we", "examine", "the", "task", "of", "learning", "to", "make", "predictions", "on", "graphs", "for", "a", "broad", "range", "of", "real", "-", "world", "applications", ".", "Specifically", ",", "we", "study", "two", "canonical", "subtasks", "associated", "with", "graph", "-", "structured", "datasets", ":", "link", "prediction", "and", "semi", "-", "supervised", "node", "classification", "(", "LPNC", ")", ".", "A", "graph", "is", "a", "partially", "observed", "set", "of", "edges", "and", "nodes", "(", "or", "vertices", ")", ",", "and", "the", "learning", "task", "is", "to", "predict", "the", "labels", "for", "edges", "and", "nodes", ".", "In", "real", "-", "world", "applications", ",", "the", "input", "graph", "is", "a", "network", "with", "nodes", "representing", "unique", "entities", ",", "and", "edges", "representing", "relationships", "(", "or", "links", ")", "between", "entities", ".", "Further", ",", "the", "labels", "of", "nodes", "and", "edges", "in", "a", "graph", "are", "often", "correlated", ",", "exhibiting", "complex", "relational", "structures", "that", "violate", "the", "general", "assumption", "of", "independent", "and", "identical", "distribution", "fundamental", "in", "traditional", "machine", "learning", ".", "Therefore", ",", "models", "capable", "of", "exploiting", "topological", "structures", "of", "graphs", "have", "been", "shown", "to", "achieve", "superior", "predictive", "performances", "on", "many", "LPNC", "tasks", ".", "We", "present", "a", "novel", "densely", "connected", "autoencoder", "architecture", "capable", "of", "learning", "a", "shared", "representation", "of", "latent", "node", "embeddings", "from", "both", "local", "graph", "topology", "and", "available", "explicit", "node", "features", "for", "LPNC", ".", "The", "resulting", "autoencoder", "models", "are", "useful", "for", "many", "applications", "across", "multiple", "domains", ",", "including", "analysis", "of", "metabolic", "networks", "for", "drug", "-", "target", "interaction", ",", "bibliographic", "networks", ",", "social", "networks", "such", "as", "Facebook", "(", "\u201c", "People", "You", "May", "Know", "\u201d", ")", ",", "terrorist", "networks", ",", "communication", "networks", ",", "cybersecurity", ",", "recommender", "systems", ",", "and", "knowledge", "bases", "such", "as", "DBpedia", "and", "Wikidata", ".", "There", "are", "a", "number", "of", "technical", "challenges", "associated", "with", "learning", "to", "make", "meaningful", "predictions", "on", "complex", "graphs", ":", "Extreme", "class", "imbalance", ":", "in", "link", "prediction", ",", "the", "number", "of", "known", "present", "(", "positive", ")", "edges", "is", "often", "significantly", "less", "than", "the", "number", "of", "known", "absent", "(", "negative", ")", "edges", ",", "making", "it", "difficult", "to", "reliably", "learn", "from", "rare", "examples", ";", "Learn", "from", "complex", "graph", "structures", ":", "edges", "may", "be", "directed", "or", "undirected", ",", "weighted", "or", "unweighted", ",", "highly", "sparse", "in", "occurrence", ",", "and", "/", "or", "consisting", "of", "multiple", "types", ".", "A", "useful", "model", "should", "be", "versatile", "to", "address", "a", "variety", "of", "graph", "types", ",", "including", "bipartite", "graphs", ";", "Incorporate", "side", "information", ":", "nodes", "(", "and", "maybe", "edges", ")", "are", "sometimes", "described", "by", "a", "set", "of", "features", ",", "called", "side", "information", ",", "that", "could", "encode", "information", "complementary", "to", "topological", "features", "of", "the", "input", "graph", ".", "Such", "explicit", "data", "on", "nodes", "and", "edges", "are", "not", "always", "readily", "available", "and", "are", "considered", "optional", ".", "A", "useful", "model", "should", "be", "able", "to", "incorporate", "optional", "side", "information", "about", "nodes", "and", "/", "or", "edges", ",", "whenever", "available", ",", "to", "potentially", "improve", "predictive", "performance", ";", "Efficiency", "and", "scalability", ":", "real", "-", "world", "graph", "datasets", "contain", "large", "numbers", "of", "nodes", "and", "/", "or", "edges", ".", "It", "is", "essential", "for", "a", "model", "to", "be", "memory", "and", "computationally", "efficient", "to", "achieve", "practical", "utility", "on", "real", "-", "world", "applications", ".", "Our", "contribution", "in", "this", "work", "is", "a", "simple", ",", "yet", "versatile", "autoencoder", "architecture", "that", "addresses", "all", "of", "the", "above", "technical", "challenges", ".", "We", "demonstrate", "that", "our", "autoencoder", "models", ":", "1", ")", "can", "handle", "extreme", "class", "imbalance", "common", "in", "link", "prediction", "problems", ";", "2", ")", "can", "learn", "expressive", "latent", "features", "for", "nodes", "from", "topological", "structures", "of", "sparse", ",", "bipartite", "graphs", "that", "may", "have", "directed", "and", "/", "or", "weighted", "edges", ";", "3", ")", "is", "flexible", "to", "incorporate", "explicit", "side", "features", "about", "nodes", "as", "an", "optional", "component", "to", "improve", "predictive", "performance", ";", "and", "4", ")", "utilize", "extensive", "parameter", "sharing", "to", "reduce", "memory", "footprint", "and", "computational", "complexity", ",", "while", "leveraging", "available", "GPU", "-", "based", "implementations", "for", "increased", "scalability", ".", "Further", ",", "the", "autoencoder", "architecture", "has", "the", "novelty", "of", "being", "efficiently", "trained", "end", "-", "to", "-", "end", "for", "the", "joint", ",", "multi", "-", "task", "learning", "(", "MTL", ")", "of", "both", "link", "prediction", "and", "node", "classification", "tasks", ".", "To", "the", "best", "of", "our", "knowledge", ",", "this", "is", "the", "first", "architecture", "capable", "of", "performing", "simultaneous", "link", "prediction", "and", "node", "classification", "in", "a", "single", "learning", "stage", ",", "whereas", "previous", "related", "methods", "require", "multiple", "training", "stages", "that", "are", "difficult", "to", "optimize", ".", "Lastly", ",", "we", "conduct", "a", "comprehensive", "evaluation", "of", "the", "proposed", "autoencoder", "architecture", "on", "nine", "challenging", "benchmark", "graph", "-", "structured", "datasets", "comprising", "a", "wide", "range", "of", "LPNC", "applications", ".", "Numerical", "experiments", "validate", "the", "efficacy", "of", "our", "models", "by", "showing", "significant", "improvement", "on", "multiple", "evaluation", "measures", "over", "related", "methods", "designed", "for", "link", "prediction", "and", "/", "or", "node", "classification", ".", "section", ":", "Autoencoder", "Architecture", "for", "Link", "Prediction", "and", "Node", "Classification", "We", "now", "characterize", "our", "proposed", "autoencoder", "architecture", ",", "schematically", "depicted", "in", "Figure", "[", "reference", "]", ",", "for", "LPNC", "and", "formalize", "the", "notation", "used", "in", "this", "paper", ".", "The", "input", "to", "the", "autoencoder", "is", "a", "graph", "of", "nodes", ".", "Graph", "is", "represented", "by", "its", "adjacency", "matrix", ".", "For", "a", "partially", "observed", "graph", ",", ",", "where", "denotes", "a", "known", "present", "positive", "edge", ",", "denotes", "a", "known", "absent", "negative", "edge", ",", "and", "unk", "denotes", "an", "unknown", "status", "(", "missing", "or", "unobserved", ")", "edge", ".", "In", "general", ",", "the", "input", "to", "the", "autoencoder", "can", "be", "directed", "or", "undirected", ",", "weighted", "or", "unweighted", ",", "and", "/", "or", "bipartite", "graphs", ".", "However", ",", "for", "the", "remainder", "of", "this", "paper", "and", "throughout", "the", "numerical", "experiments", ",", "we", "assume", "undirected", "and", "symmetric", "graphs", "with", "binary", "edges", "to", "maintain", "parity", "with", "previous", "related", "work", ".", "Optionally", ",", "we", "are", "given", "a", "matrix", "of", "available", "explicit", "node", "features", ",", "i.e.", "side", "information", ".", "The", "aim", "of", "the", "autoencoder", "model", "is", "to", "learn", "a", "set", "of", "low", "-", "dimensional", "latent", "variables", "for", "the", "nodes", "that", "can", "produce", "an", "approximate", "reconstruction", "output", "such", "that", "the", "error", "between", "and", "is", "minimized", ",", "thereby", "preserving", "the", "global", "graph", "structure", ".", "In", "this", "paper", ",", "we", "use", "capital", "variables", "(", "e.g.", ",", ")", "to", "denote", "matrices", "and", "lower", "-", "case", "variables", "(", "e.g.", ",", ")", "to", "denote", "row", "vectors", ".", "For", "example", ",", "we", "use", "to", "mean", "the", "th", "row", "of", "the", "matrix", ".", "subsection", ":", "Link", "Prediction", "Research", "on", "link", "prediction", "attempts", "to", "answer", "the", "principal", "question", ":", "given", "two", "entities", ",", "should", "there", "be", "a", "connection", "between", "them", "?", "We", "focus", "on", "the", "structural", "link", "prediction", "problem", ",", "where", "the", "task", "is", "to", "compute", "the", "likelihood", "that", "an", "unobserved", "or", "missing", "edge", "exists", "between", "two", "nodes", "in", "a", "partially", "observed", "graph", ".", "For", "a", "comprehensive", "survey", "on", "link", "prediction", ",", "to", "include", "structural", "and", "temporal", "link", "prediction", "using", "unsupervised", "and", "supervised", "models", ",", "see", ".", "Link", "Prediction", "from", "Graph", "Topology", "Let", "be", "an", "adjacency", "vector", "of", "that", "contains", "the", "local", "neighborhood", "of", "the", "th", "node", ".", "Our", "proposed", "autoencoder", "architecture", "comprises", "a", "set", "of", "non", "-", "linear", "transformations", "on", "summarized", "in", "two", "component", "parts", ":", "encoder", ",", "and", "decoder", ".", "We", "stack", "two", "layers", "of", "the", "encoder", "part", "to", "derive", "-", "dimensional", "latent", "feature", "representation", "of", "the", "th", "node", ",", "and", "then", "stack", "two", "layers", "of", "the", "decoder", "part", "to", "obtain", "an", "approximate", "reconstruction", "output", ",", "resulting", "in", "a", "four", "-", "layer", "autoencoder", "architecture", ".", "Note", "that", "is", "highly", "sparse", ",", "with", "up", "to", "90", "percent", "of", "the", "edges", "missing", "at", "random", "in", "some", "of", "our", "experiments", ",", "and", "the", "dense", "reconstructed", "output", "contains", "the", "predictions", "for", "the", "missing", "edges", ".", "The", "hidden", "representations", "for", "the", "encoder", "and", "decoder", "parts", "are", "computed", "as", "follows", ":", "The", "choice", "of", "non", "-", "linear", ",", "element", "-", "wise", "activation", "function", "is", "the", "rectified", "linear", "unit", ".", "The", "last", "decoder", "layer", "computes", "a", "linear", "transformation", "to", "score", "the", "missing", "links", "as", "part", "of", "the", "reconstruction", ".", "We", "constrain", "the", "autoencoder", "to", "be", "symmetrical", "with", "shared", "parameters", "for", "between", "the", "encoder", "and", "decoder", "parts", ",", "resulting", "in", "almost", "fewer", "parameters", "than", "an", "unconstrained", "architecture", ".", "Parameter", "sharing", "is", "a", "powerful", "form", "of", "regularization", "that", "helps", "improve", "learning", "and", "generalization", ",", "and", "is", "also", "the", "main", "motivation", "for", "MTL", ",", "first", "explored", "in", "and", "most", "recently", "in", ".", "Notice", "the", "bias", "units", "do", "not", "share", "parameters", ",", "and", ",", "are", "transposed", "copies", "of", ",", ".", "For", "brevity", "of", "notation", ",", "we", "summarize", "the", "parameters", "to", "be", "learned", "in", ".", "Since", "our", "autoencoder", "learns", "node", "embeddings", "from", "local", "neighborhood", "structures", "of", "the", "graph", ",", "we", "refer", "to", "it", "as", "LoNGAE", "for", "Local", "Neighborhood", "Graph", "Autoencoder", ".", "Link", "Prediction", "with", "Node", "Features", "Optionally", ",", "if", "a", "matrix", "of", "explicit", "node", "features", "is", "available", ",", "then", "we", "concatenate", "to", "obtain", "an", "augmented", "adjacency", "matrix", "and", "perform", "the", "above", "encoder", "-", "decoder", "transformations", "on", "for", "link", "prediction", ".", "We", "refer", "to", "this", "variant", "as", "LoNGAE", ".", "Notice", "the", "augmented", "adjacency", "matrix", "is", "no", "longer", "square", "and", "symmetric", ".", "The", "intuition", "behind", "the", "concatenation", "of", "node", "features", "is", "to", "enable", "a", "shared", "representation", "of", "both", "graph", "and", "node", "features", "throughout", "the", "autoencoding", "transformations", "by", "way", "of", "the", "tied", "parameters", ".", "This", "idea", "draws", "inspiration", "from", "recent", "work", "by", "Vukoti\u0107", "et", "al", ".", ",", "where", "they", "successfully", "applied", "symmetrical", "autoencoders", "with", "parameter", "sharing", "for", "multi", "-", "modal", "and", "cross", "-", "modal", "representation", "learning", "of", "textual", "and", "visual", "features", ".", "The", "training", "complexity", "of", "LoNGAE", "is", ",", "where", "is", "the", "number", "of", "nodes", ",", "is", "the", "dimensionality", "of", "node", "features", ",", "is", "the", "size", "of", "the", "hidden", "layer", ",", "and", "is", "the", "number", "of", "iterations", ".", "In", "practice", ",", ",", ",", "and", "are", "independent", "of", ".", "Thus", ",", "the", "overall", "complexity", "of", "the", "autoencoder", "is", ",", "linear", "in", "the", "number", "of", "nodes", ".", "Inference", "and", "Learning", "During", "the", "forward", "pass", ",", "or", "inference", ",", "the", "model", "takes", "as", "input", "an", "adjacency", "vector", "and", "computes", "its", "reconstructed", "output", "for", "link", "prediction", ".", "The", "parameters", "are", "learned", "via", "backpropagation", ".", "During", "the", "backward", "pass", ",", "we", "estimate", "by", "minimizing", "the", "Masked", "Balanced", "Cross", "-", "Entropy", "(", "MBCE", ")", "loss", ",", "which", "only", "allows", "for", "the", "contributions", "of", "those", "parameters", "associated", "with", "observed", "edges", ",", "as", "in", ".", "Moreover", ",", "can", "exhibit", "extreme", "class", "imbalance", "between", "known", "present", "and", "absent", "links", ",", "as", "is", "common", "in", "link", "prediction", "problems", ".", "We", "handle", "class", "imbalance", "by", "defining", "a", "weighting", "factor", "to", "be", "used", "as", "a", "multiplier", "for", "the", "positive", "class", "in", "the", "cross", "-", "entropy", "loss", "formulation", ".", "This", "approach", "is", "referred", "to", "as", "balanced", "cross", "-", "entropy", ".", "Other", "approaches", "to", "class", "imbalance", "include", "optimizing", "for", "a", "ranking", "loss", "and", "the", "recent", "work", "on", "focal", "loss", "by", "Lin", "et", "al", ".", ".", "For", "a", "single", "example", "and", "its", "reconstructed", "output", ",", "we", "compute", "the", "MBCE", "loss", "as", "follows", ":", "Here", ",", "is", "the", "balanced", "cross", "-", "entropy", "loss", "with", "weighting", "factor", ",", "is", "the", "sigmoid", "function", ",", "is", "the", "Hadamard", "(", "element", "-", "wise", ")", "product", ",", "and", "is", "the", "boolean", "function", ":", "if", ",", "else", ".", "The", "same", "autoencoder", "architecture", "can", "be", "applied", "to", "a", "row", "vector", "in", "the", "augmented", "adjacency", "matrix", ".", "However", ",", "at", "the", "final", "decoder", "layer", ",", "we", "slice", "the", "reconstruction", "into", "two", "outputs", ":", "corresponding", "to", "the", "reconstructed", "example", "in", "the", "original", "adjacency", "matrix", ",", "and", "corresponding", "to", "the", "reconstructed", "example", "in", "the", "matrix", "of", "node", "features", ".", "During", "learning", ",", "we", "optimize", "on", "the", "concatenation", "of", "graph", "topology", "and", "side", "node", "features", ",", "but", "compute", "the", "losses", "for", "the", "reconstructed", "outputs", "separately", "with", "different", "loss", "functions", ".", "The", "motivation", "behind", "this", "design", "is", "to", "maintain", "flexibility", "to", "handle", "different", "input", "formats", ";", "the", "input", "is", "usually", "binary", ",", "but", "the", "input", "can", "be", "binary", ",", "real", "-", "valued", ",", "or", "both", ".", "In", "this", "work", ",", "we", "enforce", "both", "inputs", "to", "be", "in", "the", "range", "for", "simplicity", "and", "improved", "performance", ",", "and", "compute", "the", "augmented", "MBCE", "loss", "as", "follows", ":", "where", "is", "the", "standard", "cross", "-", "entropy", "loss", "with", "sigmoid", "function", ".", "At", "inference", "time", ",", "we", "use", "the", "reconstructed", "output", "for", "link", "prediction", "and", "disregard", "the", "output", ".", "subsection", ":", "Semi", "-", "Supervised", "Node", "Classification", "The", "LoNGAE", "model", "can", "also", "be", "used", "to", "perform", "efficient", "information", "propagation", "on", "graphs", "for", "the", "task", "of", "semi", "-", "supervised", "node", "classification", ".", "Node", "classification", "is", "the", "task", "of", "predicting", "the", "labels", "or", "types", "of", "entities", "in", "a", "graph", ",", "such", "as", "the", "types", "of", "molecules", "in", "a", "metabolic", "network", "or", "document", "categories", "in", "a", "citation", "network", ".", "For", "a", "given", "augmented", "adjacency", "vector", ",", "the", "autoencoder", "learns", "the", "corresponding", "node", "embeddings", "to", "obtain", "an", "optimal", "reconstruction", ".", "Intuitively", ",", "encodes", "a", "vector", "of", "latent", "features", "derived", "from", "the", "concatenation", "of", "both", "graph", "and", "node", "features", ",", "and", "can", "be", "used", "to", "predict", "the", "label", "of", "the", "th", "node", ".", "For", "multi", "-", "class", "classification", ",", "we", "can", "decode", "using", "the", "softmax", "activation", "function", "to", "learn", "a", "probability", "distribution", "over", "node", "labels", ".", "More", "precisely", ",", "we", "predict", "node", "labels", "via", "the", "following", "transformation", ":", ",", "where", "and", ".", "In", "many", "applications", ",", "only", "a", "small", "fraction", "of", "the", "nodes", "are", "labeled", ".", "For", "semi", "-", "supervised", "learning", ",", "it", "is", "advantageous", "to", "utilize", "unlabeled", "examples", "in", "conjunction", "with", "labeled", "instances", "to", "better", "capture", "the", "underlying", "data", "patterns", "for", "improved", "learning", "and", "generalization", ".", "We", "achieve", "this", "by", "jointly", "training", "the", "autoencoder", "with", "a", "masked", "softmax", "classifier", "to", "collectively", "learn", "node", "labels", "from", "minimizing", "their", "combined", "losses", ":", "where", "is", "the", "set", "of", "node", "labels", ",", "if", "node", "belongs", "to", "class", ",", "is", "the", "softmax", "probability", "that", "node", "belongs", "to", "class", ",", "is", "the", "loss", "defined", "for", "the", "autoencoder", ",", "and", "the", "boolean", "function", "if", "node", "has", "a", "label", ",", "otherwise", ".", "Notice", "in", "this", "configuration", ",", "we", "can", "perform", "multi", "-", "task", "learning", "for", "both", "link", "prediction", "and", "semi", "-", "supervised", "node", "classification", ",", "simultaneously", ".", "section", ":", "Related", "Work", "The", "field", "of", "graph", "representation", "learning", "is", "seeing", "a", "resurgence", "of", "research", "interest", "in", "recent", "years", ",", "driven", "in", "part", "by", "the", "latest", "advances", "in", "deep", "learning", ".", "The", "aim", "is", "to", "learn", "a", "mapping", "that", "encodes", "the", "input", "graph", "into", "low", "-", "dimensional", "feature", "embeddings", "while", "preserving", "its", "original", "global", "structure", ".", "Hamilton", "et", "al", ".", "succinctly", "articulate", "the", "diverse", "set", "of", "previously", "proposed", "approaches", "for", "graph", "representation", "learning", ",", "or", "graph", "embedding", ",", "as", "belonging", "within", "a", "unified", "encoder", "-", "decoder", "framework", ".", "In", "this", "section", ",", "we", "summarize", "three", "classes", "of", "encoder", "-", "decoder", "models", "most", "related", "to", "our", "work", ":", "matrix", "factorization", "(", "MF", ")", ",", "autoencoders", ",", "and", "graph", "convolutional", "networks", "(", "GCNs", ")", ".", "MF", "has", "its", "roots", "in", "dimensionality", "reduction", "and", "gained", "popularity", "with", "extensive", "applications", "in", "collaborative", "filtering", "(", "CF", ")", "and", "recommender", "systems", ".", "MF", "models", "take", "an", "input", "matrix", ",", "learn", "a", "shared", "linear", "latent", "representation", "for", "rows", "(", ")", "and", "columns", "(", ")", "during", "an", "encoder", "step", ",", "and", "then", "use", "a", "bilinear", "(", "pairwise", ")", "decoder", "based", "on", "the", "inner", "product", "to", "produce", "a", "reconstructed", "matrix", ".", "CF", "is", "mathematically", "similar", "to", "link", "prediction", ",", "where", "the", "goal", "is", "essentially", "matrix", "completion", ".", "Menon", "and", "Elkan", "proposed", "an", "MF", "model", "capable", "of", "incorporating", "side", "information", "about", "nodes", "and", "/", "or", "edges", "to", "demonstrate", "strong", "link", "prediction", "results", "on", "several", "challenging", "network", "datasets", ".", "Other", "recent", "approaches", "similar", "to", "MF", "that", "learn", "node", "embeddings", "via", "some", "encoder", "transformation", "and", "then", "use", "a", "bilinear", "decoder", "for", "the", "reconstruction", "include", "DeepWalk", "and", "its", "variants", "LINE", "and", "node2vec", ".", "DeepWalk", ",", "LINE", ",", "and", "node2vec", "do", "not", "support", "external", "node", "/", "edge", "features", ".", "Our", "work", "is", "inspired", "by", "recent", "successful", "applications", "of", "autoencoder", "architectures", "for", "collaborative", "filtering", "that", "outperform", "popular", "matrix", "factorization", "methods", ",", "and", "is", "related", "to", "Structural", "Deep", "Network", "Embedding", "(", "SDNE", ")", "for", "link", "prediction", ".", "Similar", "to", "SDNE", ",", "our", "models", "rely", "on", "the", "autoencoder", "to", "learn", "non", "-", "linear", "node", "embeddings", "from", "local", "graph", "neighborhoods", ".", "However", ",", "our", "models", "have", "several", "important", "distinctions", ":", "1", ")", "we", "leverage", "extensive", "parameter", "sharing", "between", "the", "encoder", "and", "decoder", "parts", "to", "enhance", "representation", "learning", ";", "2", ")", "our", "LoNGAE", "model", "can", "optionally", "concatenate", "side", "node", "features", "to", "the", "adjacency", "matrix", "for", "improved", "link", "prediction", "performance", ";", "and", "3", ")", "the", "LoNGAE", "model", "can", "be", "trained", "end", "-", "to", "-", "end", "in", "a", "single", "stage", "for", "multi", "-", "task", "learning", "of", "link", "prediction", "and", "semi", "-", "supervised", "node", "classification", ".", "On", "the", "other", "hand", ",", "training", "SDNE", "requires", "multiple", "steps", "that", "are", "difficult", "to", "jointly", "optimize", ":", "i", ")", "pre", "-", "training", "via", "a", "deep", "belief", "network", ";", "and", "ii", ")", "utilizing", "a", "separate", "downstream", "classifier", "on", "top", "of", "node", "embeddings", "for", "LPNC", ".", "Lastly", ",", "GCNs", "are", "a", "recent", "class", "of", "algorithms", "based", "on", "convolutional", "encoders", "for", "learning", "node", "embeddings", ".", "The", "GCN", "model", "is", "motivated", "by", "a", "localized", "first", "-", "order", "approximation", "of", "spectral", "convolutions", "for", "layer", "-", "wise", "information", "propagation", "on", "graphs", ".", "Similar", "to", "our", "LoNGAE", "model", ",", "the", "GCN", "model", "can", "learn", "hidden", "layer", "representations", "that", "encode", "both", "local", "graph", "structure", "and", "features", "of", "nodes", ".", "The", "choice", "of", "the", "decoder", "depends", "on", "the", "task", ".", "For", "link", "prediction", ",", "the", "bilinear", "inner", "product", "is", "used", "in", "the", "context", "of", "the", "variational", "graph", "autoencoder", "(", "VGAE", ")", ".", "For", "semi", "-", "supervised", "node", "classification", ",", "the", "softmax", "activation", "function", "is", "employed", ".", "The", "GCN", "model", "provides", "an", "end", "-", "to", "-", "end", "learning", "framework", "that", "scales", "linearly", "in", "the", "number", "of", "graph", "edges", "and", "has", "been", "shown", "to", "achieve", "strong", "LPNC", "results", "on", "a", "number", "of", "graph", "-", "structured", "datasets", ".", "However", ",", "the", "GCN", "model", "has", "a", "drawback", "of", "being", "memory", "intensive", "because", "it", "is", "trained", "on", "the", "full", "dataset", "using", "batch", "gradient", "descent", "for", "every", "training", "iteration", ".", "We", "show", "that", "our", "models", "outperform", "GCN", "-", "based", "models", "for", "LPNC", "while", "consuming", "a", "constant", "memory", "budget", "by", "way", "of", "mini", "-", "batch", "training", ".", "section", ":", "Experimental", "Design", "In", "this", "section", ",", "we", "expound", "our", "protocol", "for", "the", "empirical", "evaluation", "of", "our", "models", "\u2019", "capability", "for", "learning", "and", "generalization", "on", "the", "tasks", "of", "link", "prediction", "and", "semi", "-", "supervised", "node", "classification", ".", "Secondarily", ",", "we", "also", "present", "results", "of", "the", "models", "\u2019", "representation", "capacity", "on", "the", "task", "of", "network", "reconstruction", ".", "subsection", ":", "Datasets", "and", "Baselines", "We", "evaluate", "our", "proposed", "autoencoder", "models", "on", "nine", "graph", "-", "structured", "datasets", ",", "spanning", "multiple", "application", "domains", ",", "from", "which", "previous", "graph", "embedding", "methods", "have", "achieved", "strong", "results", "for", "LPNC", ".", "The", "datasets", "are", "summarized", "in", "Table", "[", "reference", "]", "and", "include", "networks", "for", "Protein", "interactions", ",", "Metabolic", "pathways", ",", "military", "Conflict", "between", "countries", ",", "the", "U.S.", "PowerGrid", ",", "collaboration", "between", "users", "on", "the", "BlogCatalog", "social", "website", ",", "and", "publication", "citations", "from", "the", "Cora", ",", "Citeseer", ",", "Pubmed", ",", "Arxiv", "-", "GRQC", "databases", ".", "{", "Protein", ",", "Metabolic", ",", "Conflict", ",", "PowerGrid", "}", "are", "reported", "in", ".", "{", "Cora", ",", "Citeseer", ",", "Pubmed", "}", "are", "from", "and", "reported", "in", ".", "And", "{", "Arxiv", "-", "GRQC", ",", "BlogCatalog", "}", "are", "reported", "in", ".", "width=0.5", "width=0.5", "We", "empirically", "compare", "our", "autoencoder", "models", "against", "four", "strong", "baselines", "summarized", "in", "Table", "[", "reference", "]", ",", "which", "were", "designed", "specifically", "for", "link", "prediction", "and", "/", "or", "node", "classification", ".", "We", "begin", "our", "empirical", "evaluation", "with", "the", "SDNE", "baseline", ",", "where", "we", "compare", "the", "representation", "capacity", "of", "our", "models", "on", "the", "network", "reconstruction", "task", "using", "the", "Arxiv", "-", "GRQC", "and", "BlogCatalog", "datasets", ".", "For", "the", "MF", "baseline", ",", "we", "closely", "follow", "the", "experimental", "protocol", "in", ",", "where", "we", "randomly", "sample", "10", "percent", "of", "the", "observed", "links", "for", "training", "and", "evaluate", "link", "prediction", "performance", "on", "the", "other", "disjoint", "90", "percent", "for", "the", "{", "Protein", ",", "Metabolic", ",", "Conflict", "}", "datasets", ".", "For", "PowerGrid", ",", "we", "use", "90", "percent", "of", "observed", "links", "for", "training", "and", "evaluate", "on", "the", "remaining", "10", "percent", ".", "And", "for", "the", "VGAE", "and", "GCN", "baselines", ",", "we", "use", "the", "same", "train", "/", "validation", "/", "test", "segments", "described", "in", "and", "for", "link", "prediction", "and", "node", "classification", ",", "respectively", ",", "on", "the", "{", "Cora", ",", "Citeseer", ",", "Pubmed", "}", "citation", "networks", ".", "subsection", ":", "Implementation", "Details", "We", "implement", "the", "autoencoder", "architecture", "using", "Keras", "on", "top", "of", "the", "GPU", "-", "enabled", "TensorFlow", "backend", ",", "along", "with", "several", "additional", "details", ".", "The", "diagonal", "elements", "of", "the", "adjacency", "matrix", "are", "set", "to", "with", "the", "interpretation", "that", "every", "node", "is", "connected", "to", "itself", ".", "We", "impute", "missing", "or", "unk", "elements", "in", "the", "adjacency", "matrix", "with", ".", "Note", "that", "imputed", "edges", "are", "not", "observed", "elements", "in", "the", "adjacency", "matrix", "and", "hence", "do", "not", "contribute", "to", "the", "masked", "loss", "computations", "during", "training", ".", "We", "are", "free", "to", "impute", "any", "values", "for", "the", "missing", "edges", ",", "but", "through", "cross", "-", "validation", "we", "found", "that", "the", "uniform", "value", "of", "produces", "the", "best", "results", ".", "Hyper", "-", "parameter", "tuning", "is", "performed", "via", "cross", "-", "validation", "or", "on", "the", "available", "validation", "set", ".", "Key", "hyper", "-", "parameters", "include", "mini", "-", "batch", "size", ",", "dimensionality", "of", "the", "hidden", "layers", ",", "and", "the", "percentage", "of", "dropout", "regularization", ".", "In", "general", ",", "we", "strive", "to", "keep", "a", "similar", "set", "of", "hyper", "-", "parameters", "across", "datasets", "to", "highlight", "the", "consistency", "of", "our", "models", ".", "In", "all", "experiments", ",", "the", "dimensionality", "of", "the", "hidden", "layers", "in", "the", "autoencoder", "architecture", "is", "fixed", "at", "-", "256", "-", "128", "-", "256", "-", ".", "For", "reconstruction", "and", "link", "prediction", ",", "we", "train", "for", "50", "epochs", "using", "mini", "-", "batch", "size", "of", "8", "samples", ".", "For", "node", "classification", ",", "we", "train", "for", "100", "epochs", "using", "mini", "-", "batch", "size", "of", "64", "samples", ".", "We", "utilize", "early", "stopping", "as", "a", "form", "of", "regularization", "in", "time", "when", "the", "model", "shows", "signs", "of", "overfitting", "on", "the", "validation", "set", ".", "We", "apply", "mean", "-", "variance", "normalization", "(", "MVN", ")", "after", "each", "ReLU", "activation", "layer", "to", "help", "improve", "link", "prediction", "performance", ",", "where", "it", "compensates", "for", "noise", "between", "train", "and", "test", "instances", "by", "normalizing", "the", "activations", "to", "have", "zero", "mean", "and", "unit", "variance", ".", "MVN", "enables", "efficient", "learning", "and", "has", "been", "shown", "effective", "in", "cardiac", "semantic", "segmentation", "and", "speech", "recognition", ".", "During", "training", ",", "we", "apply", "dropout", "regularization", "throughout", "the", "architecture", "to", "mitigate", "overfitting", ",", "depending", "on", "the", "sparsity", "of", "the", "input", "graph", ".", "For", "link", "prediction", ",", "dropout", "is", "also", "applied", "at", "the", "input", "layer", "to", "produce", "an", "effect", "similar", "to", "using", "a", "denoising", "autoencoder", ".", "This", "denoising", "technique", "was", "previously", "employed", "for", "link", "prediction", "in", ".", "We", "initialize", "weights", "according", "to", "the", "Xavier", "scheme", "described", "in", ".", "We", "do", "not", "apply", "weight", "decay", "regularization", ".", "We", "employ", "the", "Adam", "algorithm", "for", "gradient", "descent", "optimization", "with", "a", "fixed", "learning", "rate", "of", ".", "As", "part", "of", "our", "experimental", "design", ",", "we", "also", "performed", "experiments", "without", "parameter", "sharing", "between", "the", "encoder", "and", "decoder", "parts", "of", "the", "architecture", "and", "found", "severely", "degraded", "predictive", "performance", ".", "This", "observation", "is", "consistent", "with", "prior", "findings", "that", "parameter", "sharing", "helps", "improve", "generalization", "by", "providing", "additional", "regularization", "to", "mitigate", "the", "adverse", "effects", "of", "overfitting", "and", "enhance", "representation", "learning", ".", "subsection", ":", "Results", "and", "Analysis", "Reconstruction", "Results", "of", "the", "reconstruction", "task", "for", "the", "Arxiv", "-", "GRQC", "and", "BlogCatalog", "network", "datasets", "are", "illustrated", "in", "Figure", "[", "reference", "]", ".", "In", "this", "experiment", ",", "we", "compare", "the", "results", "obtained", "by", "our", "LoNGAE", "model", "to", "those", "obtained", "by", "the", "related", "autoencoder", "-", "based", "SDNE", "model", ".", "The", "evaluation", "metric", "is", "precision@", ",", "which", "is", "a", "rank", "-", "based", "measure", "used", "in", "information", "retrieval", "and", "is", "defined", "as", "the", "proportion", "of", "retrieved", "edges", "/", "links", "in", "the", "top", "-", "set", "that", "are", "relevant", ".", "We", "use", "precision@", "to", "evaluate", "the", "model", "\u2019s", "ability", "to", "retrieve", "edges", "known", "to", "be", "present", "(", "positive", "edges", ")", "as", "part", "of", "the", "reconstruction", ".", "width=0.8", "In", "comparison", "to", "SDNE", ",", "we", "show", "that", "our", "LoNGAE", "model", "achieves", "better", "precision@", "performance", "for", "all", "values", ",", "up", "to", "for", "Arxiv", "-", "GRQC", "and", "for", "BlogCatalog", ",", "when", "trained", "on", "the", "complete", "datasets", ".", "We", "also", "systematically", "test", "the", "capacity", "of", "the", "LoNGAE", "model", "to", "reconstruct", "the", "original", "networks", "when", "up", "to", "80", "percent", "of", "the", "edges", "are", "randomly", "removed", ",", "akin", "to", "the", "link", "prediction", "task", ".", "We", "show", "that", "the", "LoNGAE", "model", "only", "gets", "worse", "precision@", "performance", "than", "SDNE", "on", "the", "Arxiv", "-", "GRQC", "dataset", "when", "more", "than", "40", "percent", "of", "the", "edges", "are", "missing", "at", "random", ".", "On", "the", "BlogCatalog", "dataset", ",", "the", "LoNGAE", "model", "achieves", "better", "precision@", "performance", "than", "SDNE", "for", "large", "values", "even", "when", "80", "percent", "of", "the", "edges", "are", "missing", "at", "random", ".", "This", "experiment", "demonstrates", "the", "superior", "representation", "capacity", "of", "our", "LoNGAE", "model", "compared", "to", "SDNE", ".", "Link", "Prediction", "Table", "[", "reference", "]", "shows", "the", "comparison", "between", "our", "autoencoder", "models", "and", "the", "matrix", "factorization", "(", "MF", ")", "model", "proposed", "in", "for", "link", "prediction", "with", "and", "without", "node", "features", ".", "Recall", "that", "our", "goal", "is", "to", "recover", "the", "statuses", "of", "the", "missing", "or", "unknown", "links", "in", "the", "input", "graph", ".", "As", "part", "of", "the", "experimental", "design", ",", "we", "pretend", "that", "a", "randomly", "selected", "set", "of", "elements", "in", "the", "adjacency", "matrix", "are", "missing", "and", "collect", "their", "indices", "to", "be", "used", "as", "a", "validation", "set", ".", "Our", "task", "is", "to", "train", "the", "autoencoder", "to", "produce", "a", "set", "of", "predictions", ",", "a", "list", "of", "ones", "and", "zeros", ",", "on", "those", "missing", "indices", "and", "see", "how", "well", "the", "model", "performs", "when", "compared", "to", "the", "ground", "-", "truth", ".", "The", "evaluation", "metric", "is", "the", "area", "under", "the", "ROC", "curve", "(", "AUC", ")", ".", "Results", "are", "reported", "as", "mean", "AUC", "and", "standard", "deviation", "over", "10", "-", "fold", "cross", "-", "validation", ".", "The", "datasets", "under", "consideration", "for", "link", "prediction", "exhibit", "varying", "degrees", "of", "class", "imbalance", ".", "For", "featureless", "link", "prediction", ",", "our", "LoNGAE", "model", "marginally", "outperforms", "MF", "on", "{", "Protein", ",", "Metabolic", ",", "Conflict", "}", "and", "is", "significantly", "better", "than", "MF", "on", "PowerGrid", ".", "Consistent", "with", "MF", "results", ",", "we", "observe", "that", "incorporating", "external", "node", "features", "provides", "a", "boost", "in", "link", "prediction", "accuracy", ",", "especially", "for", "the", "Protein", "dataset", "where", "we", "achieve", "a", "6", "percent", "increase", "in", "performance", ".", "Metabolic", "and", "Conflict", "also", "come", "with", "external", "edge", "features", ",", "which", "were", "exploited", "by", "the", "MF", "model", "for", "further", "performance", "gains", ".", "We", "leave", "the", "task", "of", "combining", "edge", "features", "for", "future", "work", ".", "Each", "node", "in", "Conflict", "only", "has", "three", "features", ",", "which", "are", "unable", "to", "significantly", "boost", "link", "prediction", "accuracy", ".", "PowerGrid", "does", "not", "have", "node", "features", "so", "there", "are", "no", "results", "for", "the", "respective", "rows", ".", "Table", "[", "reference", "]", "summarizes", "the", "performances", "between", "our", "autoencoder", "models", "and", "related", "graph", "embedding", "methods", "for", "link", "prediction", "with", "and", "without", "node", "features", ".", "Following", "the", "protocol", "described", "in", ",", "we", "report", "AUC", "and", "average", "precision", "(", "AP", ")", "scores", "for", "each", "model", "on", "the", "held", "-", "out", "test", "set", "containing", "10", "percent", "of", "randomly", "sampled", "positive", "links", "and", "the", "same", "number", "of", "negative", "links", ".", "We", "show", "mean", "AUC", "and", "AP", "with", "standard", "error", "over", "10", "runs", "with", "random", "weight", "initializations", "on", "fixed", "data", "splits", ".", "Results", "for", "the", "baseline", "methods", "are", "taken", "from", "Kipf", "and", "Welling", ",", "where", "we", "pick", "the", "best", "performing", "models", "for", "comparison", ".", "Similar", "to", "the", "MF", "model", ",", "the", "graph", "embedding", "methods", "that", "can", "combine", "side", "node", "features", "always", "produce", "a", "boost", "in", "link", "prediction", "accuracy", ".", "In", "this", "comparison", ",", "we", "significantly", "outperform", "the", "best", "graph", "embedding", "methods", "by", "as", "much", "as", "10", "percent", ",", "with", "and", "without", "node", "features", ".", "Our", "LoNGAE", "model", "achieves", "competitive", "link", "prediction", "performance", "when", "compared", "against", "the", "best", "model", "presented", "in", "on", "the", "Pubmed", "dataset", ".", "width=0.9", "Node", "Classification", "Results", "of", "semi", "-", "supervised", "node", "classification", "for", "the", "{", "Cora", ",", "Citeseer", ",", "Pubmed", "}", "datasets", "are", "summarized", "in", "Table", "[", "reference", "]", ".", "In", "this", "context", "of", "citation", "networks", ",", "node", "classification", "is", "equivalent", "to", "the", "task", "of", "document", "classification", ".", "We", "closely", "follow", "the", "experimental", "setup", "of", "Kipf", "and", "Welling", ",", "where", "we", "use", "their", "provided", "train", "/", "validation", "/", "test", "splits", "for", "evaluation", ".", "Accuracy", "performance", "is", "measured", "on", "the", "held", "-", "out", "test", "set", "of", "1", ",", "000", "examples", ".", "We", "tune", "hyper", "-", "parameters", "on", "the", "validation", "set", "of", "500", "examples", ".", "The", "train", "set", "only", "contains", "20", "examples", "per", "class", ".", "All", "methods", "use", "the", "complete", "adjacency", "matrix", ",", "and", "available", "node", "features", ",", "to", "learn", "latent", "embeddings", "for", "node", "classification", ".", "For", "comparison", ",", "we", "train", "and", "test", "our", "LoNGAE", "model", "on", "the", "same", "data", "splits", "over", "10", "runs", "with", "random", "weight", "initializations", "and", "report", "mean", "accuracy", ".", "Kipf", "and", "Welling", "report", "their", "mean", "GCN", "and", "ICA", "results", "on", "the", "same", "data", "splits", "over", "100", "runs", "with", "random", "weight", "initializations", ".", "The", "other", "baseline", "methods", "are", "taken", "from", "Yang", "et", "al", ".", ".", "In", "this", "comparison", ",", "our", "LoNGAE", "model", "achieves", "competitive", "performance", "when", "compared", "against", "the", "GCN", "model", "on", "the", "Cora", "dataset", ",", "but", "outperforms", "GCN", "and", "all", "other", "baseline", "methods", "on", "the", "Citeseer", "and", "Pubmed", "datasets", ".", "width=0.5", "Multi", "-", "task", "Learning", "Lastly", ",", "we", "report", "LPNC", "results", "obtained", "by", "our", "LoNGAE", "model", "in", "the", "MTL", "setting", "over", "10", "runs", "with", "random", "weight", "initializations", ".", "In", "the", "MTL", "scenario", ",", "the", "LoNGAE", "model", "takes", "as", "input", "an", "incomplete", "graph", "with", "10", "percent", "of", "the", "positive", "edges", ",", "and", "the", "same", "number", "of", "negative", "edges", ",", "missing", "at", "random", "and", "all", "available", "node", "features", "to", "simultaneously", "produce", "predictions", "for", "the", "missing", "edges", "and", "labels", "for", "the", "nodes", ".", "Table", "[", "reference", "]", "shows", "the", "efficacy", "of", "the", "LoNGAE", "model", "for", "MTL", "when", "compared", "against", "the", "best", "performing", "task", "-", "specific", "link", "prediction", "and", "node", "classification", "models", ",", "which", "require", "the", "complete", "adjacency", "matrix", "as", "input", ".", "For", "link", "prediction", ",", "multi", "-", "task", "LoNGAE", "achieves", "competitive", "performance", "against", "task", "-", "specific", "LoNGAE", ",", "and", "significantly", "outperforms", "the", "best", "VGAE", "model", "from", "Kipf", "and", "Welling", "on", "Cora", "and", "Citeseer", "datasets", ".", "For", "node", "classification", ",", "multi", "-", "task", "LoNGAE", "is", "the", "best", "performing", "model", "across", "the", "board", ",", "only", "trailing", "behind", "the", "GCN", "model", "on", "the", "Cora", "dataset", ".", "width=0.5", "section", ":", "Discussion", "In", "our", "experiments", ",", "we", "show", "that", "a", "simple", "autoencoder", "architecture", "with", "parameter", "sharing", "consistently", "outperforms", "previous", "related", "methods", "on", "a", "range", "of", "challenging", "graph", "-", "structured", "benchmarks", "for", "three", "separate", "tasks", ":", "reconstruction", ",", "link", "prediction", ",", "and", "semi", "-", "supervised", "node", "classification", ".", "For", "the", "reconstruction", "task", ",", "our", "LoNGAE", "model", "achieves", "superior", "precision@", "performance", "when", "compared", "to", "the", "related", "SDNE", "model", ".", "Although", "both", "models", "leverage", "a", "deep", "autoencoder", "architecture", "for", "graph", "representation", "learning", ",", "the", "SDNE", "model", "lacks", "several", "key", "implementations", "necessary", "for", "enhanced", "representation", "capacity", ",", "namely", "parameter", "sharing", "between", "the", "encoder", "-", "decoder", "parts", "and", "end", "-", "to", "-", "end", "training", "of", "deep", "architectures", ".", "For", "link", "prediction", ",", "we", "observe", "that", "combining", "available", "node", "features", "always", "produces", "a", "significant", "boost", "in", "predictive", "performance", ".", "This", "observation", "was", "previously", "reported", "in", ",", "among", "others", ".", "Intuitively", ",", "we", "expect", "topological", "graph", "features", "provide", "complementary", "information", "not", "present", "in", "the", "node", "features", ",", "and", "the", "combination", "of", "both", "feature", "sets", "should", "improve", "predictive", "power", ".", "Although", "explicit", "node", "features", "may", "not", "always", "be", "readily", "available", ",", "a", "link", "prediction", "model", "capable", "of", "incorporating", "optional", "side", "information", "has", "broader", "applicability", ".", "Our", "LoNGAE", "model", "also", "performs", "favorably", "well", "on", "the", "task", "of", "semi", "-", "supervised", "node", "classification", ".", "The", "model", "is", "capable", "of", "encoding", "non", "-", "linear", "node", "embeddings", "from", "both", "local", "graph", "structure", "and", "explicit", "node", "features", ",", "which", "can", "be", "decoded", "by", "a", "softmax", "activation", "function", "to", "yield", "accurate", "node", "labels", ".", "The", "efficacy", "of", "the", "proposed", "LoNGAE", "model", "is", "evident", "especially", "on", "the", "Pubmed", "dataset", ",", "where", "the", "label", "rate", "is", "only", "0.003", ".", "This", "efficacy", "is", "attributed", "to", "parameter", "sharing", "being", "used", "in", "the", "autoencoder", "architecture", ",", "which", "provides", "regularization", "to", "help", "improve", "representation", "learning", "and", "generalization", ".", "Our", "autoencoder", "architecture", "naturally", "supports", "multi", "-", "task", "learning", ",", "where", "a", "joint", "representation", "for", "both", "link", "prediction", "and", "node", "classification", "is", "enabled", "via", "parameter", "sharing", ".", "MTL", "aims", "to", "exploit", "commonalities", "and", "differences", "across", "multiple", "tasks", "to", "find", "a", "shared", "representation", "that", "can", "result", "in", "improved", "performance", "for", "each", "task", "-", "specific", "metric", ".", "In", "this", "work", ",", "we", "show", "that", "our", "multi", "-", "task", "LoNGAE", "model", "improves", "node", "classification", "accuracy", "by", "learning", "to", "predict", "missing", "edges", "at", "the", "same", "time", ".", "Our", "multi", "-", "task", "model", "has", "broad", "practical", "utility", "to", "address", "real", "-", "world", "applications", "where", "the", "input", "graphs", "may", "have", "both", "missing", "edges", "and", "node", "labels", ".", "Finally", ",", "we", "address", "one", "major", "limitation", "associated", "with", "our", "autoencoder", "models", "having", "complexity", "scale", "linearly", "in", "the", "number", "of", "nodes", ".", "Hamilton", "et", "al", ".", "express", "that", "the", "complexity", "in", "nodes", "may", "limit", "the", "utility", "of", "the", "models", "on", "massive", "graphs", "with", "hundreds", "of", "millions", "of", "nodes", ".", "In", "practice", ",", "we", "would", "implement", "our", "models", "to", "leverage", "data", "parallelism", "across", "commodity", "CPU", "and", "/", "or", "GPU", "resources", "for", "effective", "distributed", "learning", "on", "massive", "graphs", ".", "Data", "parallelism", "is", "possible", "because", "our", "models", "learn", "node", "embeddings", "from", "each", "row", "vector", "of", "the", "adjacency", "matrix", "independently", ".", "Nevertheless", ",", "the", "area", "of", "improvement", "in", "future", "work", "is", "to", "take", "advantage", "of", "the", "sparsity", "of", "edges", "in", "the", "graphs", "to", "scale", "our", "models", "linearly", "in", "the", "number", "of", "observed", "edges", ".", "section", ":", "Conclusion", "In", "this", "work", ",", "we", "presented", "a", "new", "autoencoder", "architecture", "for", "link", "prediction", "and", "semi", "-", "supervised", "node", "classification", ",", "and", "showed", "that", "the", "resulting", "models", "outperform", "related", "methods", "in", "accuracy", "performance", "on", "a", "range", "of", "real", "-", "world", "graph", "-", "structured", "datasets", ".", "The", "success", "of", "our", "models", "is", "primarily", "attributed", "to", "extensive", "parameter", "sharing", "between", "the", "encoder", "and", "decoder", "parts", "of", "the", "architecture", ",", "coupled", "with", "the", "capability", "to", "learn", "expressive", "non", "-", "linear", "latent", "node", "representations", "from", "both", "local", "graph", "neighborhoods", "and", "explicit", "node", "features", ".", "Further", ",", "our", "novel", "architecture", "is", "capable", "of", "simultaneous", "multi", "-", "task", "learning", "of", "both", "link", "prediction", "and", "node", "classification", "in", "one", "efficient", "end", "-", "to", "-", "end", "training", "stage", ".", "Our", "work", "provides", "a", "useful", "framework", "to", "make", "accurate", "and", "meaningful", "predictions", "on", "a", "diverse", "set", "of", "complex", "graph", "structures", "for", "a", "wide", "range", "of", "real", "-", "world", "applications", ".", "section", ":", "Acknowledgment", "The", "author", "thanks", "Edward", "Raff", "and", "Jared", "Sylvester", "for", "insightful", "discussions", ",", "and", "gracious", "reviewers", "for", "constructive", "feedback", "on", "the", "paper", ".", "bibliography", ":", "References"]}