{"coref": {"Accuracy": [[607, 608], [732, 733], [2609, 2610], [2974, 2975], [3008, 3009], [3040, 3041], [3196, 3197], [3340, 3341], [3500, 3501], [3541, 3542], [3551, 3552], [3593, 3594], [4309, 4310], [3161, 3162], [3234, 3235], [3830, 3831], [3862, 3863], [4078, 4079]], "CoNLL_2003__English_": [[4127, 4130], [4319, 4321]], "F1": [[4037, 4041], [4119, 4122], [4148, 4151], [4220, 4223], [4239, 4242], [4097, 4100]], "IMDb": [], "MR": [[3737, 3740], [4316, 4318], [2910, 2912], [3664, 3666], [3702, 3704], [3909, 3911], [4001, 4003], [4491, 4493]], "Named_Entity_Recognition__NER_": [[3976, 3977], [4084, 4085]], "Part-Of-Speech_Tagging": [[3972, 3975], [4063, 4065]], "Penn_Treebank": [], "S-LSTM": [[0, 4], [430, 433], [438, 441], [602, 605], [744, 745], [780, 781], [832, 835], [917, 920], [936, 939], [978, 981], [1000, 1003], [1030, 1033], [1704, 1708], [1748, 1751], [2010, 2013], [2048, 2051], [2128, 2131], [2213, 2216], [2294, 2297], [2316, 2319], [2422, 2425], [2627, 2630], [2753, 2756], [2919, 2922], [2926, 2929], [2976, 2979], [3042, 3045], [3085, 3087], [3091, 3094], [3144, 3147], [3163, 3164], [3324, 3327], [3398, 3401], [3517, 3520], [3545, 3548], [3575, 3578], [3598, 3601], [3605, 3608], [3637, 3640], [3708, 3711], [3718, 3721], [3748, 3751], [3775, 3778], [3807, 3810], [3832, 3835], [3894, 3897], [4009, 4012], [4114, 4117], [4191, 4194], [4290, 4293], [4341, 4344], [4358, 4361], [4431, 4434], [4468, 4471], [4502, 4505], [4547, 4550], [4560, 4563], [4597, 4600], [4611, 4614], [4664, 4667]], "Sentiment_Analysis": []}, "coref_non_salient": {"0": [[209, 211], [283, 284], [661, 662], [1075, 1076], [4669, 4671]], "1": [[3351, 3353], [3684, 3686], [3689, 3691], [3881, 3883]], "10": [[110, 113], [1660, 1666], [1698, 1701]], "11": [[121, 123], [159, 161]], "12": [[325, 329], [4565, 4568]], "13": [[3941, 3948], [4182, 4187]], "14": [[61, 63], [1374, 1376]], "15": [[769, 770], [3471, 3472], [3555, 3556], [3764, 3765]], "16": [[2026, 2029], [2178, 2181], [3752, 3755], [4154, 4160], [3823, 3826]], "17": [[766, 768], [1838, 1841]], "18": [[197, 199], [891, 894], [4674, 4676]], "19": [[1087, 1089], [1115, 1117]], "2": [[3415, 3420], [3533, 3537], [3846, 3851], [3873, 3878], [4508, 4513], [4514, 4519]], "20": [[2809, 2812], [2814, 2815]], "21": [[652, 653], [45, 46], [427, 428], [637, 638], [670, 671], [687, 688], [888, 889], [1026, 1027], [1336, 1337], [1404, 1405], [1558, 1559], [1657, 1658], [1713, 1714], [1830, 1831], [2954, 2955], [3217, 3218], [3346, 3347], [4633, 4634]], "22": [[1510, 1512], [1970, 1972]], "23": [[170, 171], [219, 220], [463, 464], [610, 611], [748, 749], [2006, 2007], [2014, 2015], [2084, 2085], [2308, 2309], [2631, 2632], [2757, 2758], [2923, 2924], [3328, 3329], [3336, 3337], [3367, 3368], [3512, 3513], [3573, 3574], [3596, 3597], [3610, 3611], [3635, 3636], [3712, 3713], [3819, 3820], [3898, 3899], [4007, 4008], [4137, 4138], [4162, 4163], [4345, 4346], [4367, 4368], [4474, 4475], [4506, 4507], [4583, 4584], [4601, 4602], [1328, 1329], [1611, 1612], [1836, 1837], [2617, 2618], [3113, 3114], [3387, 3388], [3952, 3953], [4143, 4144]], "24": [[2797, 2798], [3111, 3112]], "25": [[3543, 3544]], "26": [[4273, 4278]], "27": [[3525, 3527], [3766, 3768]], "28": [[2545, 2548]], "29": [[2867, 2871]], "3": [[48, 50], [162, 164], [444, 446], [782, 784], [878, 880], [1155, 1157], [4569, 4571], [4624, 4626]], "30": [[2818, 2820]], "31": [[1767, 1769]], "32": [[4382, 4386]], "33": [[3617, 3619]], "34": [[4034, 4036]], "35": [[3646, 3649]], "36": [[865, 866], [3589, 3590]], "37": [[3980, 3985]], "38": [[852, 856], [1011, 1015], [1563, 1567], [1753, 1757]], "39": [[4621, 4623]], "4": [[2534, 2536], [2570, 2572], [2657, 2659], [3650, 3652], [3939, 3941], [3967, 3970], [3990, 3992], [4030, 4032]], "40": [[89, 94], [596, 600], [2760, 2765], [4590, 4595]], "41": [[1194, 1196], [1242, 1246]], "42": [[3852, 3859]], "43": [[2663, 2665]], "44": [[10, 14], [165, 169]], "45": [[4364, 4365]], "46": [[4645, 4648]], "47": [[984, 986], [3514, 3516], [3557, 3559], [4551, 4553]], "48": [[1036, 1040]], "49": [[4480, 4482], [4498, 4501]], "5": [[5, 7], [19, 21], [995, 997]], "50": [[2861, 2863]], "51": [[1637, 1641]], "52": [[3529, 3532]], "53": [[253, 255]], "54": [[1553, 1555]], "55": [[2772, 2776]], "56": [[3986, 3989], [4263, 4266]], "57": [[1056, 1059]], "58": [[664, 668]], "59": [[818, 819]], "6": [[477, 479], [2366, 2368], [2988, 2991], [3211, 3214]], "60": [[2824, 2825]], "61": [[1550, 1551]], "62": [[268, 270]], "63": [[902, 903]], "64": [[261, 264]], "65": [[792, 794]], "66": [[859, 861]], "67": [[1460, 1465]], "68": [[2275, 2279]], "69": [[716, 718]], "7": [[987, 989], [3441, 3443], [3493, 3498]], "70": [[2735, 2738]], "71": [[710, 712]], "72": [[2725, 2726]], "73": [[681, 683]], "74": [[1047, 1052]], "75": [[812, 817]], "76": [[584, 589]], "77": [[863, 864]], "78": [[3017, 3019]], "79": [[1080, 1083]], "8": [[899, 901], [3562, 3565]], "80": [[4231, 4236]], "81": [[1004, 1009]], "82": [[3890, 3893], [4428, 4430]], "83": [[191, 193]], "84": [[947, 952]], "85": [[2848, 2850]], "86": [[2175, 2177]], "87": [[1063, 1066]], "88": [[139, 142]], "89": [[1093, 1096]], "9": [[590, 592], [704, 706], [2532, 2533], [2538, 2539], [2633, 2634], [3602, 3603], [3658, 3659]], "90": [[1152, 1154]], "91": [[1126, 1128]], "92": [[2728, 2732]], "93": [[2580, 2582]], "94": [[1330, 1333]], "95": [[2804, 2805]], "96": [[203, 205], [698, 700]]}, "doc_id": "3e79a574d776c46bbe6d34f41b1e83b5d0f698f2", "method_subrelations": {"S-LSTM": [[[0, 6], "S-LSTM"]]}, "n_ary_relations": [{"Material": "CoNLL_2003__English_", "Method": "S-LSTM", "Metric": "F1", "Task": "Named_Entity_Recognition__NER_", "score": "91.57"}, {"Material": "IMDb", "Method": "S-LSTM", "Metric": "Accuracy", "Task": "Sentiment_Analysis", "score": "87.15"}, {"Material": "MR", "Method": "S-LSTM", "Metric": "Accuracy", "Task": "Sentiment_Analysis", "score": "76.2"}, {"Material": "Penn_Treebank", "Method": "S-LSTM", "Metric": "Accuracy", "Task": "Part-Of-Speech_Tagging", "score": "97.55"}], "ner": [[0, 4, "Method"], [5, 7, "Task"], [10, 14, "Method"], [19, 21, "Task"], [48, 50, "Task"], [61, 63, "Method"], [89, 94, "Task"], [110, 113, "Method"], [121, 123, "Method"], [139, 142, "Method"], [159, 161, "Method"], [162, 164, "Task"], [165, 169, "Method"], [170, 171, "Method"], [191, 193, "Task"], [197, 199, "Task"], [203, 205, "Task"], [209, 211, "Task"], [219, 220, "Method"], [253, 255, "Metric"], [261, 264, "Task"], [268, 270, "Method"], [283, 284, "Task"], [325, 329, "Method"], [430, 433, "Method"], [438, 441, "Method"], [444, 446, "Task"], [463, 464, "Method"], [477, 479, "Task"], [584, 589, "Method"], [590, 592, "Task"], [596, 600, "Task"], [602, 605, "Method"], [607, 608, "Metric"], [610, 611, "Method"], [652, 653, "Method"], [661, 662, "Task"], [664, 668, "Method"], [681, 683, "Method"], [698, 700, "Task"], [704, 706, "Task"], [710, 712, "Task"], [716, 718, "Method"], [732, 733, "Metric"], [744, 745, "Method"], [748, 749, "Method"], [766, 768, "Task"], [769, 770, "Method"], [780, 781, "Method"], [782, 784, "Task"], [792, 794, "Method"], [812, 817, "Method"], [818, 819, "Method"], [832, 835, "Method"], [852, 856, "Method"], [859, 861, "Metric"], [863, 864, "Task"], [865, 866, "Method"], [878, 880, "Task"], [891, 894, "Task"], [899, 901, "Method"], [902, 903, "Task"], [917, 920, "Method"], [936, 939, "Method"], [947, 952, "Method"], [978, 981, "Method"], [984, 986, "Method"], [987, 989, "Method"], [995, 997, "Task"], [1000, 1003, "Method"], [1004, 1009, "Method"], [1011, 1015, "Method"], [1030, 1033, "Method"], [1036, 1040, "Method"], [1047, 1052, "Method"], [1056, 1059, "Task"], [1063, 1066, "Task"], [1075, 1076, "Task"], [1080, 1083, "Method"], [1087, 1089, "Method"], [1093, 1096, "Task"], [1115, 1117, "Method"], [1126, 1128, "Method"], [1152, 1154, "Method"], [1155, 1157, "Task"], [1194, 1196, "Method"], [1242, 1246, "Method"], [1330, 1333, "Method"], [1374, 1376, "Method"], [1460, 1465, "Method"], [1510, 1512, "Method"], [1550, 1551, "Method"], [1553, 1555, "Method"], [1563, 1567, "Method"], [1637, 1641, "Method"], [1660, 1666, "Method"], [1698, 1701, "Method"], [1704, 1708, "Method"], [1748, 1751, "Method"], [1753, 1757, "Method"], [1767, 1769, "Method"], [1838, 1841, "Task"], [1970, 1972, "Method"], [2006, 2007, "Method"], [2010, 2013, "Method"], [2014, 2015, "Method"], [2026, 2029, "Method"], [2048, 2051, "Method"], [2084, 2085, "Method"], [2128, 2131, "Method"], [2175, 2177, "Task"], [2178, 2181, "Method"], [2213, 2216, "Method"], [2275, 2279, "Metric"], [2294, 2297, "Method"], [2308, 2309, "Method"], [2316, 2319, "Method"], [2366, 2368, "Task"], [2422, 2425, "Method"], [2532, 2533, "Task"], [2534, 2536, "Task"], [2538, 2539, "Task"], [2545, 2548, "Method"], [2570, 2572, "Task"], [2580, 2582, "Method"], [2609, 2610, "Metric"], [2627, 2630, "Method"], [2631, 2632, "Method"], [2633, 2634, "Task"], [2657, 2659, "Task"], [2663, 2665, "Method"], [2725, 2726, "Task"], [2728, 2732, "Method"], [2735, 2738, "Method"], [2753, 2756, "Method"], [2757, 2758, "Method"], [2760, 2765, "Task"], [2772, 2776, "Method"], [2797, 2798, "Method"], [2804, 2805, "Method"], [2809, 2812, "Method"], [2814, 2815, "Method"], [2818, 2820, "Method"], [2824, 2825, "Method"], [2848, 2850, "Method"], [2861, 2863, "Metric"], [2867, 2871, "Metric"], [2919, 2922, "Method"], [2923, 2924, "Method"], [2926, 2929, "Method"], [2974, 2975, "Metric"], [2976, 2979, "Method"], [2988, 2991, "Task"], [3008, 3009, "Metric"], [3017, 3019, "Metric"], [3040, 3041, "Metric"], [3042, 3045, "Method"], [3085, 3087, "Method"], [3091, 3094, "Method"], [3111, 3112, "Method"], [3144, 3147, "Method"], [3163, 3164, "Method"], [3196, 3197, "Metric"], [3211, 3214, "Task"], [3324, 3327, "Method"], [3328, 3329, "Method"], [3336, 3337, "Method"], [3340, 3341, "Metric"], [3351, 3353, "Metric"], [3367, 3368, "Method"], [3398, 3401, "Method"], [3415, 3420, "Method"], [3441, 3443, "Method"], [3471, 3472, "Method"], [3493, 3498, "Method"], [3500, 3501, "Metric"], [3512, 3513, "Method"], [3514, 3516, "Method"], [3517, 3520, "Method"], [3525, 3527, "Task"], [3529, 3532, "Method"], [3533, 3537, "Method"], [3541, 3542, "Metric"], [3543, 3544, "Metric"], [3545, 3548, "Method"], [3551, 3552, "Metric"], [3555, 3556, "Method"], [3557, 3559, "Method"], [3562, 3565, "Method"], [3573, 3574, "Method"], [3575, 3578, "Method"], [3589, 3590, "Method"], [3593, 3594, "Metric"], [3596, 3597, "Method"], [3598, 3601, "Method"], [3602, 3603, "Task"], [3605, 3608, "Method"], [3610, 3611, "Method"], [3617, 3619, "Method"], [3635, 3636, "Method"], [3637, 3640, "Method"], [3646, 3649, "Method"], [3650, 3652, "Task"], [3658, 3659, "Task"], [3684, 3686, "Metric"], [3689, 3691, "Metric"], [3708, 3711, "Method"], [3712, 3713, "Method"], [3718, 3721, "Method"], [3737, 3740, "Material"], [3748, 3751, "Method"], [3752, 3755, "Method"], [3764, 3765, "Method"], [3766, 3768, "Task"], [3775, 3778, "Method"], [3807, 3810, "Method"], [3819, 3820, "Method"], [3832, 3835, "Method"], [3846, 3851, "Method"], [3852, 3859, "Method"], [3873, 3878, "Method"], [3881, 3883, "Metric"], [3890, 3893, "Metric"], [3894, 3897, "Method"], [3898, 3899, "Method"], [3939, 3941, "Task"], [3941, 3948, "Method"], [3967, 3970, "Task"], [3972, 3975, "Task"], [3976, 3977, "Task"], [3980, 3985, "Method"], [3986, 3989, "Method"], [3990, 3992, "Task"], [4007, 4008, "Method"], [4009, 4012, "Method"], [4030, 4032, "Task"], [4034, 4036, "Metric"], [4037, 4041, "Metric"], [4063, 4065, "Task"], [4084, 4085, "Task"], [4114, 4117, "Method"], [4119, 4122, "Metric"], [4127, 4130, "Material"], [4137, 4138, "Method"], [4148, 4151, "Metric"], [4154, 4160, "Method"], [4162, 4163, "Method"], [4182, 4187, "Method"], [4191, 4194, "Method"], [4220, 4223, "Metric"], [4231, 4236, "Method"], [4239, 4242, "Metric"], [4263, 4266, "Method"], [4273, 4278, "Method"], [4290, 4293, "Method"], [4309, 4310, "Metric"], [4316, 4318, "Material"], [4319, 4321, "Material"], [4341, 4344, "Method"], [4345, 4346, "Method"], [4358, 4361, "Method"], [4364, 4365, "Metric"], [4367, 4368, "Method"], [4382, 4386, "Task"], [4428, 4430, "Metric"], [4431, 4434, "Method"], [4468, 4471, "Method"], [4474, 4475, "Method"], [4480, 4482, "Metric"], [4498, 4501, "Metric"], [4502, 4505, "Method"], [4506, 4507, "Method"], [4508, 4513, "Method"], [4514, 4519, "Method"], [4547, 4550, "Method"], [4551, 4553, "Method"], [4560, 4563, "Method"], [4565, 4568, "Method"], [4569, 4571, "Task"], [4583, 4584, "Method"], [4590, 4595, "Task"], [4597, 4600, "Method"], [4601, 4602, "Method"], [4611, 4614, "Method"], [4621, 4623, "Method"], [4624, 4626, "Task"], [4645, 4648, "Method"], [4664, 4667, "Method"], [4669, 4671, "Task"], [4674, 4676, "Task"], [45, 46, "Method"], [427, 428, "Method"], [637, 638, "Method"], [670, 671, "Method"], [687, 688, "Method"], [888, 889, "Method"], [1026, 1027, "Method"], [1328, 1329, "Method"], [1336, 1337, "Method"], [1404, 1405, "Method"], [1558, 1559, "Method"], [1611, 1612, "Method"], [1657, 1658, "Method"], [1713, 1714, "Method"], [1830, 1831, "Method"], [1836, 1837, "Method"], [2617, 2618, "Method"], [2910, 2912, "Material"], [2954, 2955, "Method"], [3113, 3114, "Method"], [3161, 3162, "Metric"], [3217, 3218, "Method"], [3234, 3235, "Metric"], [3346, 3347, "Method"], [3387, 3388, "Method"], [3664, 3666, "Material"], [3702, 3704, "Material"], [3823, 3826, "Method"], [3830, 3831, "Metric"], [3862, 3863, "Metric"], [3909, 3911, "Material"], [3952, 3953, "Method"], [4001, 4003, "Material"], [4078, 4079, "Metric"], [4097, 4100, "Metric"], [4143, 4144, "Method"], [4491, 4493, "Material"], [4633, 4634, "Method"]], "sections": [[0, 7], [7, 118], [118, 648], [648, 1201], [1201, 1325], [1325, 1702], [1702, 2002], [2002, 2521], [2521, 2747], [2747, 2903], [2903, 3653], [3653, 3934], [3934, 4295], [4295, 4554], [4554, 4677], [4677, 4679], [4679, 4694], [4694, 4696]], "sentences": [[0, 7], [7, 10], [10, 22], [22, 41], [41, 61], [61, 86], [86, 118], [118, 121], [121, 133], [133, 157], [157, 215], [215, 228], [228, 265], [265, 289], [289, 317], [317, 321], [321, 334], [334, 366], [366, 396], [396, 416], [416, 436], [436, 453], [453, 472], [472, 499], [499, 513], [513, 551], [551, 574], [574, 593], [593, 622], [622, 648], [648, 652], [652, 683], [683, 712], [712, 769], [769, 795], [795, 825], [825, 829], [829, 865], [865, 898], [898, 936], [936, 947], [947, 978], [978, 998], [998, 1016], [1016, 1030], [1030, 1047], [1047, 1067], [1067, 1070], [1070, 1097], [1097, 1111], [1111, 1141], [1141, 1173], [1173, 1201], [1201, 1204], [1204, 1271], [1271, 1296], [1296, 1307], [1307, 1325], [1325, 1329], [1329, 1361], [1361, 1382], [1382, 1401], [1401, 1409], [1409, 1439], [1439, 1440], [1440, 1455], [1455, 1513], [1513, 1550], [1550, 1556], [1556, 1573], [1573, 1601], [1601, 1602], [1602, 1610], [1610, 1624], [1624, 1635], [1635, 1660], [1660, 1691], [1691, 1702], [1702, 1708], [1708, 1724], [1724, 1732], [1732, 1736], [1736, 1748], [1748, 1771], [1771, 1782], [1782, 1784], [1784, 1786], [1786, 1797], [1797, 1827], [1827, 1852], [1852, 1861], [1861, 1885], [1885, 1899], [1899, 1915], [1915, 1924], [1924, 1944], [1944, 1945], [1945, 1962], [1962, 1979], [1979, 2002], [2002, 2007], [2007, 2025], [2025, 2082], [2082, 2137], [2137, 2151], [2151, 2171], [2171, 2193], [2193, 2210], [2210, 2240], [2240, 2261], [2261, 2265], [2265, 2290], [2290, 2310], [2310, 2314], [2314, 2341], [2341, 2369], [2369, 2384], [2384, 2393], [2393, 2403], [2403, 2414], [2414, 2420], [2420, 2432], [2432, 2465], [2465, 2482], [2482, 2509], [2509, 2521], [2521, 2525], [2525, 2537], [2537, 2549], [2549, 2569], [2569, 2589], [2589, 2591], [2591, 2619], [2619, 2635], [2635, 2642], [2642, 2654], [2654, 2656], [2656, 2681], [2681, 2695], [2695, 2709], [2709, 2724], [2724, 2747], [2747, 2750], [2750, 2766], [2766, 2781], [2781, 2786], [2786, 2797], [2797, 2799], [2799, 2809], [2809, 2813], [2813, 2824], [2824, 2842], [2842, 2872], [2872, 2886], [2886, 2894], [2894, 2903], [2903, 2907], [2907, 2925], [2925, 2944], [2944, 2966], [2966, 2992], [2992, 3022], [3022, 3039], [3039, 3072], [3072, 3081], [3081, 3111], [3111, 3129], [3129, 3132], [3132, 3156], [3156, 3175], [3175, 3206], [3206, 3221], [3221, 3256], [3256, 3296], [3296, 3324], [3324, 3330], [3330, 3363], [3363, 3383], [3383, 3395], [3395, 3436], [3436, 3471], [3471, 3487], [3487, 3521], [3521, 3545], [3545, 3560], [3560, 3566], [3566, 3589], [3589, 3613], [3613, 3641], [3641, 3653], [3653, 3659], [3659, 3681], [3681, 3695], [3695, 3714], [3714, 3726], [3726, 3762], [3762, 3775], [3775, 3792], [3792, 3828], [3828, 3852], [3852, 3889], [3889, 3914], [3914, 3934], [3934, 3941], [3941, 3978], [3978, 4013], [4013, 4033], [4033, 4062], [4062, 4083], [4083, 4104], [4104, 4139], [4139, 4161], [4161, 4188], [4188, 4204], [4204, 4256], [4256, 4267], [4267, 4295], [4295, 4298], [4298, 4334], [4334, 4353], [4353, 4369], [4369, 4387], [4387, 4419], [4419, 4454], [4454, 4486], [4486, 4508], [4508, 4534], [4534, 4554], [4554, 4557], [4557, 4585], [4585, 4627], [4627, 4649], [4649, 4657], [4657, 4677], [4677, 4679], [4679, 4682], [4682, 4694], [4694, 4696]], "words": ["Sentence", "-", "State", "LSTM", "for", "Text", "Representation", "section", ":", "Abstract", "Bi", "-", "directional", "LSTMs", "are", "a", "powerful", "tool", "for", "text", "representation", ".", "On", "the", "other", "hand", ",", "they", "have", "been", "shown", "to", "suffer", "various", "limitations", "due", "to", "their", "sequential", "nature", ".", "We", "investigate", "an", "alternative", "LSTM", "structure", "for", "encoding", "text", ",", "which", "consists", "of", "a", "parallel", "state", "for", "each", "word", ".", "Recurrent", "steps", "are", "used", "to", "perform", "local", "and", "global", "information", "exchange", "between", "words", "simultaneously", ",", "rather", "than", "incremental", "reading", "of", "a", "sequence", "of", "words", ".", "Results", "on", "various", "classification", "and", "sequence", "labelling", "benchmarks", "show", "that", "the", "proposed", "model", "has", "strong", "representation", "power", ",", "giving", "highly", "competitive", "performances", "compared", "to", "stacked", "BiLSTM", "models", "with", "similar", "parameter", "numbers", ".", "section", ":", "Introduction", "Neural", "models", "have", "become", "the", "dominant", "approach", "in", "the", "NLP", "literature", ".", "Compared", "to", "handcrafted", "indicator", "features", ",", "neural", "sentence", "representations", "are", "less", "sparse", ",", "and", "more", "flexible", "in", "encoding", "intricate", "syntactic", "and", "semantic", "information", ".", "Among", "various", "neural", "networks", "for", "encoding", "sentences", ",", "bi", "-", "directional", "LSTMs", "(", "BiLSTM", ")", "[", "reference", "]", "have", "been", "a", "dominant", "method", ",", "giving", "state", "-", "of", "-", "the", "-", "art", "results", "in", "language", "modelling", "[", "reference", "]", ",", "machine", "translation", "[", "reference", "]", ",", "syntactic", "parsing", "[", "reference", "]", "and", "question", "answering", "[", "reference", "]", ".", "Despite", "their", "success", ",", "BiLSTMs", "have", "been", "shown", "to", "suffer", "several", "limitations", ".", "For", "example", ",", "their", "inherently", "sequential", "nature", "endows", "computation", "non", "-", "parallel", "within", "the", "same", "sentence", "[", "reference", "]", ",", "which", "can", "lead", "to", "a", "computational", "bottleneck", ",", "hindering", "their", "use", "in", "the", "in", "-", "dustry", ".", "In", "addition", ",", "local", "ngrams", ",", "which", "have", "been", "shown", "a", "highly", "useful", "source", "of", "contextual", "information", "for", "NLP", ",", "are", "not", "explicitly", "modelled", "[", "reference", "]", ".", "Finally", ",", "sequential", "information", "flow", "leads", "to", "relatively", "weaker", "power", "in", "capturing", "longrange", "dependencies", ",", "which", "results", "in", "lower", "performance", "in", "encoding", "longer", "sentences", "[", "reference", "]", ".", "We", "investigate", "an", "alternative", "recurrent", "neural", "network", "structure", "for", "addressing", "these", "issues", ".", "As", "shown", "in", "Figure", "1", ",", "the", "main", "idea", "is", "to", "model", "the", "hidden", "states", "of", "all", "words", "simultaneously", "at", "each", "recurrent", "step", ",", "rather", "than", "one", "word", "at", "a", "time", ".", "In", "particular", ",", "we", "view", "the", "whole", "sentence", "as", "a", "single", "state", ",", "which", "consists", "of", "sub", "-", "states", "for", "individual", "words", "and", "an", "overall", "sentence", "-", "level", "state", ".", "To", "capture", "local", "and", "non", "-", "local", "contexts", ",", "states", "are", "updated", "recurrently", "by", "exchanging", "information", "between", "each", "other", ".", "Consequently", ",", "we", "refer", "to", "our", "model", "as", "sentence", "-", "state", "LSTM", ",", "or", "S", "-", "LSTM", "in", "short", ".", "Empirically", ",", "S", "-", "LSTM", "can", "give", "effective", "sentence", "encoding", "after", "3", "-", "6", "recurrent", "steps", ".", "In", "contrast", ",", "the", "number", "of", "recurrent", "steps", "necessary", "for", "BiLSTM", "scales", "with", "the", "size", "of", "the", "sentence", ".", "At", "each", "recurrent", "step", ",", "information", "exchange", "is", "conducted", "between", "consecutive", "words", "in", "the", "sentence", ",", "and", "between", "the", "sentence", "-", "level", "state", "and", "each", "word", ".", "In", "particular", ",", "each", "word", "receives", "information", "from", "its", "predecessor", "and", "successor", "simultaneously", ".", "From", "an", "initial", "state", "without", "information", "exchange", ",", "each", "word", "-", "level", "state", "can", "obtain", "3", "-", "gram", ",", "5", "-", "gram", "and", "7", "-", "gram", "information", "after", "1", ",", "2", "and", "3", "recurrent", "steps", ",", "respectively", ".", "Being", "connected", "with", "every", "word", ",", "the", "sentence", "-", "level", "state", "vector", "serves", "to", "exchange", "non", "-", "local", "information", "with", "each", "word", ".", "In", "addition", ",", "it", "can", "also", "be", "used", "as", "a", "global", "sentence", "-", "level", "representation", "for", "classification", "tasks", ".", "Results", "on", "both", "classification", "and", "sequence", "labelling", "show", "that", "S", "-", "LSTM", "gives", "better", "accuracies", "compared", "to", "BiLSTM", "using", "the", "same", "number", "of", "parameters", ",", "while", "being", "faster", ".", "We", "release", "our", "code", "and", "models", "at", "https:", "//", "github.com", "/", "leuchine", "/", "S", "-", "LSTM", ",", "which", "include", "all", "baselines", "and", "the", "final", "model", ".", "section", ":", "Related", "Work", "LSTM", "[", "reference", "]", "showed", "its", "early", "potentials", "in", "NLP", "when", "a", "neural", "machine", "translation", "system", "that", "leverages", "LSTM", "source", "encoding", "gave", "highly", "competitive", "results", "compared", "to", "the", "best", "SMT", "models", "[", "reference", "]", ".", "LSTM", "encoders", "have", "since", "been", "explored", "for", "other", "tasks", ",", "including", "syntactic", "parsing", "[", "reference", "]", ",", "text", "classification", "[", "reference", "]", "and", "machine", "reading", "[", "reference", "]", ".", "Bidirectional", "extensions", "have", "become", "a", "standard", "configuration", "for", "achieving", "state", "-", "of", "-", "the", "-", "art", "accuracies", "among", "various", "tasks", "[", "reference", "][", "reference", "][", "reference", "]", ".", "SLSTMs", "are", "similar", "to", "BiLSTMs", "in", "their", "recurrent", "bi", "-", "directional", "message", "flow", "between", "words", ",", "but", "different", "in", "the", "design", "of", "state", "transition", ".", "CNNs", "[", "reference", "]", ")", "also", "allow", "better", "parallelisation", "compared", "to", "LSTMs", "for", "sentence", "encoding", "[", "reference", "]", ",", "thanks", "to", "parallelism", "among", "convolution", "filters", ".", "On", "the", "other", "hand", ",", "convolution", "features", "embody", "only", "fix", "-", "sized", "local", "ngram", "information", ",", "whereas", "sentence", "-", "level", "feature", "aggregation", "via", "pooling", "can", "lead", "to", "loss", "of", "information", "[", "reference", "]", ".", "In", "contrast", ",", "S", "-", "LSTM", "uses", "a", "global", "sentence", "-", "level", "node", "to", "assemble", "and", "back", "-", "distribute", "local", "information", "in", "the", "recurrent", "state", "transition", "process", ",", "suffering", "less", "information", "loss", "compared", "to", "pooling", ".", "Attention", "[", "reference", "]", "has", "recently", "been", "explored", "as", "a", "standalone", "method", "for", "sentence", "encoding", ",", "giving", "competitive", "results", "compared", "to", "Bi", "-", "LSTM", "encoders", "for", "neural", "machine", "translation", "[", "reference", "]", ".", "The", "attention", "mechanism", "allows", "parallelisation", ",", "and", "can", "play", "a", "similar", "role", "to", "the", "sentence", "-", "level", "state", "in", "S", "-", "LSTMs", ",", "which", "uses", "neural", "gates", "to", "integrate", "word", "-", "level", "information", "compared", "to", "hierarchical", "attention", ".", "S", "-", "LSTM", "further", "allows", "local", "communication", "between", "neighbouring", "words", ".", "Hierarchical", "stacking", "of", "CNN", "layers", "[", "reference", "][", "reference", "][", "reference", "][", "reference", "]", "allows", "better", "interaction", "between", "non", "-", "local", "components", "in", "a", "sentence", "via", "incremental", "levels", "of", "abstraction", ".", "S", "-", "LSTM", "is", "similar", "to", "hierarchical", "attention", "and", "stacked", "CNN", "in", "this", "respect", ",", "incrementally", "refining", "sentence", "representations", ".", "However", ",", "S", "-", "LSTM", "models", "hierarchical", "encoding", "of", "sentence", "structure", "as", "a", "recurrent", "state", "transition", "process", ".", "In", "nature", ",", "our", "work", "belongs", "to", "the", "family", "of", "LSTM", "sentence", "representations", ".", "S", "-", "LSTM", "is", "inspired", "by", "message", "passing", "over", "graphs", "[", "reference", "][", "reference", "]", ")", ".", "Graph", "-", "structure", "neural", "models", "have", "been", "used", "for", "computer", "program", "verification", "[", "reference", "]", "and", "image", "object", "detection", "[", "reference", "]", ".", "The", "closest", "previous", "work", "in", "NLP", "includes", "the", "use", "of", "convolutional", "neural", "networks", "[", "reference", "]", "and", "DAG", "LSTMs", "[", "reference", "]", "for", "modelling", "syntactic", "structures", ".", "Compared", "to", "our", "work", ",", "their", "motivations", "and", "network", "structures", "are", "highly", "different", ".", "In", "particular", ",", "the", "DAG", "LSTM", "of", "[", "reference", "]", "is", "a", "natural", "extension", "of", "tree", "LSTM", "[", "reference", "]", ",", "and", "is", "sequential", "rather", "than", "parallel", "in", "nature", ".", "To", "our", "knowledge", ",", "we", "are", "the", "first", "to", "investigate", "a", "graph", "RNN", "for", "encoding", "sentences", ",", "proposing", "parallel", "graph", "states", "for", "integrating", "word", "-", "level", "and", "sentence", "-", "level", "information", ".", "In", "this", "perspective", ",", "our", "contribution", "is", "similar", "to", "that", "of", "[", "reference", "]", "and", "[", "reference", "]", "in", "introducing", "a", "neural", "representation", "to", "the", "NLP", "literature", ".", "section", ":", "Model", "Given", "a", "sentence", "s", "=", "w", "1", ",", "w", "2", ",", ".", ".", ".", ",", "w", "n", ",", "where", "w", "i", "represents", "the", "ith", "word", "and", "n", "is", "the", "sentence", "length", ",", "our", "goal", "is", "to", "find", "a", "neural", "representation", "of", "s", ",", "which", "consists", "of", "a", "hidden", "vector", "h", "i", "for", "each", "input", "word", "w", "i", ",", "and", "a", "global", "sentence", "-", "level", "hidden", "vector", "g.", "Here", "h", "i", "represents", "syntactic", "and", "semantic", "features", "for", "w", "i", "under", "the", "sentential", "context", ",", "while", "g", "represents", "features", "for", "the", "whole", "sentence", ".", "Following", "previous", "work", ",", "we", "additionally", "add", "s", "and", "/", "s", "to", "the", "two", "ends", "of", "the", "sentence", "as", "w", "0", "and", "w", "n", "+", "1", ",", "respectively", ".", "section", ":", "Baseline", "BiLSTM", "The", "baseline", "BiLSTM", "model", "consists", "of", "two", "LSTM", "components", ",", "which", "process", "the", "input", "in", "the", "forward", "left", "-", "to", "-", "right", "and", "the", "backward", "rightto", "-", "left", "directions", ",", "respectively", ".", "In", "each", "direction", ",", "the", "reading", "of", "input", "words", "is", "modelled", "as", "a", "recurrent", "process", "with", "a", "single", "hidden", "state", ".", "Given", "an", "initial", "value", ",", "the", "state", "changes", "its", "value", "recurrently", ",", "each", "time", "consuming", "an", "incoming", "word", ".", "Take", "the", "forward", "LSTM", "component", "for", "example", ".", "Denoting", "the", "initial", "state", "as", "\u2212", "\u2192", "h", "0", ",", "which", "is", "a", "model", "parameter", ",", "the", "recurrent", "state", "transition", "step", "for", "calculating", "\u2212", "\u2192", "h", "1", ",", ".", ".", ".", ",", "\u2212", "\u2192", "h", "n", "+", "1", "is", "defined", "as", "follows", "[", "reference", "]", ":", "where", "x", "t", "denotes", "the", "word", "representation", "of", "w", "t", ";", "i", "t", ",", "o", "t", ",", "f", "t", "and", "u", "t", "represent", "the", "values", "of", "an", "input", "gate", ",", "an", "output", "gate", ",", "a", "forget", "gate", "and", "an", "actual", "input", "at", "time", "step", "t", ",", "respectively", ",", "which", "controls", "the", "information", "flow", "for", "a", "recurrent", "cell", "\u2212", "\u2192", "c", "t", "and", "the", "state", "vector", "\u2212", "\u2192", "h", "t", ";", "W", "x", ",", "U", "x", "and", "b", "x", "(", "x", "\u2208", "{", "i", ",", "o", ",", "f", ",", "u", "}", ")", "are", "model", "parameters", ".", "\u03c3", "is", "the", "sigmoid", "function", ".", "The", "backward", "LSTM", "component", "follows", "the", "same", "recurrent", "state", "transition", "process", "as", "described", "in", "Eq", "1", ".", "Starting", "from", "an", "initial", "state", "h", "n", "+", "1", ",", "which", "is", "a", "model", "parameter", ",", "it", "reads", "the", "input", "x", "n", ",", "x", "n\u22121", ",", ".", ".", ".", ",", "x", "0", ",", "changing", "its", "value", "to", "The", "BiLSTM", "model", "uses", "the", "concatenated", "value", "of", "\u2212", "\u2192", "h", "t", "and", "\u2190", "\u2212", "h", "t", "as", "the", "hidden", "vector", "for", "w", "t", ":", "A", "single", "hidden", "vector", "representation", "g", "of", "the", "whole", "input", "sentence", "can", "be", "obtained", "using", "the", "final", "state", "values", "of", "the", "two", "LSTM", "components", ":", "Stacked", "BiLSTM", "Multiple", "layers", "of", "BiLTMs", "can", "be", "stacked", "for", "increased", "representation", "power", ",", "where", "the", "hidden", "vectors", "of", "a", "lower", "layer", "are", "used", "as", "inputs", "for", "an", "upper", "layer", ".", "Different", "model", "parameters", "are", "used", "in", "each", "stacked", "BiLSTM", "layer", ".", "section", ":", "Sentence", "-", "State", "LSTM", "Formally", ",", "an", "S", "-", "LSTM", "state", "at", "time", "step", "t", "can", "be", "denoted", "by", ":", "which", "consists", "of", "a", "sub", "state", "h", "t", "i", "for", "each", "word", "w", "i", "and", "a", "sentence", "-", "level", "sub", "state", "g", "t", ".", "S", "-", "LSTM", "uses", "a", "recurrent", "state", "transition", "process", "to", "model", "information", "exchange", "between", "sub", "states", ",", "which", "enriches", "state", "representations", "incrementally", ".", "For", "the", "initial", "state", "H", "0", ",", "we", "set", "h", "0", "i", "=", "g", "0", "=", "h", "0", ",", "where", "h", "0", "is", "a", "parameter", ".", "The", "state", "transition", "from", "H", "t\u22121", "to", "H", "t", "consists", "of", "sub", "state", "transitions", "from", "h", "t\u22121", "i", "to", "h", "t", "i", "and", "from", "g", "t\u22121", "to", "g", "t", ".", "We", "take", "an", "LSTM", "structure", "similar", "to", "the", "baseline", "BiLSTM", "for", "modelling", "state", "transition", ",", "using", "a", "recurrent", "cell", "c", "t", "i", "for", "each", "w", "i", "and", "a", "cell", "c", "t", "g", "for", "g.", "As", "shown", "in", "Figure", "1", ",", "the", "value", "of", "each", "h", "t", "i", "is", "computed", "based", "on", "the", "values", "of", "x", "i", ",", "h", "i", "+", "1", "and", "g", "t\u22121", ",", "together", "with", "their", "corresponding", "cell", "values", ":", "where", "\u03be", "t", "i", "is", "the", "concatenation", "of", "hidden", "vectors", "of", "a", "context", "window", ",", "and", "where", "f", "t", "0", ",", ".", ".", ".", ",", "f", "t", "n", "+", "1", "and", "f", "t", "g", "are", "gates", "controlling", "information", "from", "c", "t\u22121", "0", ",", ".", ".", ".", ",", "c", "t\u22121", "n", "+", "1", "and", "c", "t\u22121", "g", ",", "respectively", ",", "which", "are", "normalised", ".", "o", "t", "is", "an", "output", "gate", "from", "the", "recurrent", "cell", "c", "t", "g", "to", "g", "t", ".", "W", "x", ",", "U", "x", "and", "b", "x", "(", "x", "\u2208", "{", "g", ",", "f", ",", "o", "}", ")", "are", "model", "parameters", ".", "section", ":", "Contrast", "with", "BiLSTM", "The", "difference", "between", "S", "-", "LSTM", "and", "BiLSTM", "can", "be", "understood", "with", "respect", "to", "their", "recurrent", "states", ".", "While", "BiL", "-", "STM", "uses", "only", "one", "state", "in", "each", "direction", "to", "represent", "the", "subsequence", "from", "the", "beginning", "to", "a", "certain", "word", ",", "S", "-", "LSTM", "uses", "a", "structural", "state", "to", "represent", "the", "full", "sentence", ",", "which", "consists", "of", "a", "sentence", "-", "level", "sub", "state", "and", "n", "+", "2", "word", "-", "level", "sub", "states", ",", "simultaneously", ".", "Different", "from", "BiLSTMs", ",", "for", "which", "h", "t", "at", "different", "time", "steps", "are", "used", "to", "represent", "w", "0", ",", ".", ".", ".", ",", "w", "n", "+", "1", ",", "respectively", ",", "the", "word", "-", "level", "states", "h", "t", "i", "and", "sentence", "-", "level", "state", "g", "t", "of", "S", "-", "LSTMs", "directly", "correspond", "to", "the", "goal", "outputs", "h", "i", "and", "g", ",", "as", "introduced", "in", "the", "beginning", "of", "this", "section", ".", "As", "t", "increases", "from", "0", ",", "h", "t", "i", "and", "g", "t", "are", "enriched", "with", "increasingly", "deeper", "context", "information", ".", "From", "the", "perspective", "of", "information", "flow", ",", "BiL", "-", "STM", "passes", "information", "from", "one", "end", "of", "the", "sentence", "to", "the", "other", ".", "As", "a", "result", ",", "the", "number", "of", "time", "steps", "scales", "with", "the", "size", "of", "the", "input", ".", "In", "contrast", ",", "S", "-", "LSTM", "allows", "bi", "-", "directional", "information", "flow", "at", "each", "word", "simultaneously", ",", "and", "additionally", "between", "the", "sentence", "-", "level", "state", "and", "every", "wordlevel", "state", ".", "At", "each", "step", ",", "each", "h", "i", "captures", "an", "increasing", "larger", "ngram", "context", ",", "while", "additionally", "communicating", "globally", "to", "all", "other", "h", "j", "via", "g.", "The", "optimal", "number", "of", "recurrent", "steps", "is", "decided", "by", "the", "end", "-", "task", "performance", ",", "and", "does", "not", "necessarily", "scale", "with", "the", "sentence", "size", ".", "As", "a", "result", ",", "S", "-", "LSTM", "can", "potentially", "be", "both", "more", "efficient", "and", "more", "accurate", "compared", "with", "BiLSTMs", ".", "Increasing", "window", "size", ".", "By", "default", "S", "-", "LSTM", "exchanges", "information", "only", "between", "neighbouring", "words", ",", "which", "can", "be", "seen", "as", "adopting", "a", "1", "-", "word", "window", "on", "each", "side", ".", "The", "window", "size", "can", "be", "extended", "to", "2", ",", "3", "or", "more", "words", "in", "order", "to", "allow", "more", "communication", "in", "a", "state", "transition", ",", "expediting", "information", "exchange", ".", "To", "this", "end", ",", "we", "modify", "Eq", "2", ",", "integrating", "additional", "context", "words", "to", "\u03be", "t", "i", ",", "with", "extended", "gates", "and", "cells", ".", "For", "example", ",", "with", "a", "window", "size", "of", "2", ",", "We", "study", "the", "effectiveness", "of", "window", "size", "in", "our", "experiments", ".", "Additional", "sentence", "-", "level", "nodes", ".", "By", "default", "S", "-", "LSTM", "uses", "one", "sentence", "-", "level", "node", ".", "One", "way", "of", "enriching", "the", "parameter", "space", "is", "to", "add", "more", "sentence", "-", "level", "nodes", ",", "each", "communicating", "with", "word", "-", "level", "nodes", "in", "the", "same", "way", "as", "described", "by", "Eq", "3", ".", "In", "addition", ",", "different", "sentence", "-", "level", "nodes", "can", "communicate", "with", "each", "other", "during", "state", "transition", ".", "When", "one", "sentence", "-", "level", "node", "is", "used", "for", "classification", "outputs", ",", "the", "other", "sentencelevel", "node", "can", "serve", "as", "hidden", "memory", "units", ",", "or", "latent", "features", ".", "We", "study", "the", "effectiveness", "of", "multiple", "sentence", "-", "level", "nodes", "empirically", ".", "section", ":", "Task", "settings", "We", "consider", "two", "task", "settings", ",", "namely", "classification", "and", "sequence", "labelling", ".", "For", "classification", ",", "g", "is", "fed", "to", "a", "softmax", "classification", "layer", ":", "where", "y", "is", "the", "probability", "distribution", "of", "output", "class", "labels", "and", "W", "c", "and", "b", "c", "are", "model", "parameters", ".", "For", "sequence", "labelling", ",", "each", "h", "i", "can", "be", "used", "as", "feature", "representation", "for", "a", "corresponding", "word", "w", "i", ".", "External", "attention", "It", "has", "been", "shown", "that", "summation", "of", "hidden", "states", "using", "attention", "[", "reference", "][", "reference", "]", "give", "better", "accuracies", "compared", "to", "using", "the", "end", "states", "of", "BiLSTMs", ".", "We", "study", "the", "influence", "of", "attention", "on", "both", "S", "-", "LSTM", "and", "BiLSTM", "for", "classification", ".", "In", "particular", ",", "additive", "attention", "(", "Bahdanau", "Here", "W", "\u03b1", ",", "u", "and", "b", "\u03b1", "are", "model", "parameters", ".", "External", "CRF", "For", "sequential", "labelling", ",", "we", "use", "a", "CRF", "layer", "on", "top", "of", "the", "hidden", "vectors", "h", "1", ",", "h", "2", ",", ".", ".", ".", ",", "h", "n", "for", "calculating", "the", "conditional", "probabilities", "of", "label", "sequences", "[", "reference", "]", ":", "where", "W", "y", "i\u22121", ",", "y", "i", "s", "and", "b", "y", "i\u22121", ",", "y", "i", "s", "are", "parameters", "specific", "to", "two", "consecutive", "labels", "y", "i\u22121", "and", "y", "i", ".", "For", "training", ",", "standard", "log", "-", "likelihood", "loss", "is", "used", "with", "L", "2", "regularization", "given", "a", "set", "of", "gold", "-", "standard", "instances", ".", "section", ":", "Experiments", "We", "empirically", "compare", "S", "-", "LSTMs", "and", "BiLSTMs", "on", "different", "classification", "and", "sequence", "labelling", "tasks", ".", "All", "experiments", "are", "conducted", "using", "a", "GeForce", "GTX", "1080", "GPU", "with", "8", "GB", "memory", ".", "[", "reference", "]", ")", ".", "Statistics", "of", "the", "four", "datasets", "are", "shown", "in", "Table", "1", ".", "Hyperparameters", ".", "We", "initialise", "word", "embeddings", "using", "GloVe", "[", "reference", "]", ")", "300", "dimensional", "embeddings", ".", "1", "Embeddings", "are", "finetuned", "during", "model", "training", "for", "all", "tasks", ".", "Dropout", "[", "reference", "]", ")", "is", "applied", "to", "embedding", "hidden", "states", ",", "with", "a", "rate", "of", "0.5", ".", "All", "models", "are", "optimised", "using", "the", "Adam", "optimizer", "(", "Kingma", "and", "Ba", ",", "2014", ")", ",", "with", "an", "initial", "learning", "rate", "of", "0.001", "and", "a", "decay", "rate", "of", "0.97", ".", "Gradients", "are", "clipped", "at", "3", "and", "a", "batch", "size", "of", "10", "is", "adopted", ".", "Sentences", "with", "similar", "lengths", "are", "batched", "together", ".", "The", "L2", "regularization", "parameter", "is", "set", "to", "0.001", ".", "section", ":", "Development", "Experiments", "We", "use", "the", "movie", "review", "development", "data", "to", "investigate", "different", "configurations", "of", "S", "-", "LSTMs", "and", "BiLSTMs", ".", "For", "S", "-", "LSTMs", ",", "the", "default", "configuration", "uses", "s", "and", "/", "s", "words", "for", "augmenting", "words", "Hyperparameters", ":", "Table", "2", "shows", "the", "development", "results", "of", "various", "S", "-", "LSTM", "settings", ",", "where", "Time", "refers", "to", "training", "time", "per", "epoch", ".", "Without", "the", "sentence", "-", "level", "node", ",", "the", "accuracy", "of", "S", "-", "LSTM", "drops", "to", "81.76", "%", ",", "demonstrating", "the", "necessity", "of", "global", "information", "exchange", ".", "Adding", "one", "additional", "sentence", "-", "level", "node", "as", "described", "in", "Section", "3.2", "does", "not", "lead", "to", "accuracy", "improvements", ",", "although", "the", "number", "of", "parameters", "and", "decoding", "time", "increase", "accordingly", ".", "As", "a", "result", ",", "we", "use", "only", "1", "sentence", "-", "level", "node", "for", "the", "remaining", "experiments", ".", "The", "accuracies", "of", "S", "-", "LSTM", "increases", "as", "the", "hidden", "layer", "size", "for", "each", "node", "increases", "from", "100", "to", "300", ",", "but", "does", "not", "further", "increase", "when", "the", "size", "increases", "beyond", "300", ".", "We", "fix", "the", "hidden", "size", "to", "300", "accordingly", ".", "Without", "using", "s", "and", "/", "s", ",", "the", "performance", "of", "S", "-", "LSTM", "drops", "from", "82.64", "%", "to", "82.36", "%", ",", "showing", "the", "effectiveness", "of", "having", "these", "additional", "nodes", ".", "Hyperparameters", "for", "BiLSTM", "models", "are", "also", "set", "according", "to", "the", "development", "data", ",", "which", "we", "omit", "here", ".", "State", "transition", ".", "In", "Table", "2", ",", "the", "number", "of", "recurrent", "state", "transition", "steps", "of", "S", "-", "LSTM", "is", "decided", "according", "to", "the", "best", "development", "performance", ".", "Figure", "2", "draws", "the", "development", "accuracies", "of", "SLSTMs", "with", "various", "window", "sizes", "against", "the", "number", "of", "recurrent", "steps", ".", "As", "can", "be", "seen", "from", "the", "figure", ",", "when", "the", "number", "of", "time", "steps", "increases", "from", "1", "to", "11", ",", "the", "accuracies", "generally", "increase", ",", "before", "reaching", "a", "maximum", "value", ".", "This", "shows", "the", "effectiveness", "of", "recurrent", "information", "exchange", "in", "S", "-", "LSTM", "state", "transition", ".", "On", "the", "other", "hand", ",", "no", "significant", "differences", "are", "observed", "on", "the", "peak", "accuracies", "given", "by", "different", "window", "sizes", ",", "although", "a", "larger", "window", "size", "(", "e.g.", "4", ")", "generally", "results", "in", "faster", "plateauing", ".", "This", "can", "be", "be", "explained", "by", "the", "intuition", "that", "information", "exchange", "between", "distant", "nodes", "can", "be", "achieved", "using", "more", "recurrent", "steps", "under", "a", "smaller", "window", "size", ",", "as", "can", "be", "achieved", "using", "fewer", "steps", "under", "a", "larger", "window", "size", ".", "Considering", "efficiency", ",", "we", "choose", "a", "window", "size", "of", "1", "for", "the", "remaining", "experiments", ",", "setting", "the", "number", "of", "recurrent", "steps", "to", "9", "according", "to", "Figure", "2", ".", "S", "-", "LSTM", "vs", "BiLSTM", ":", "As", "shown", "in", "Table", "3", ",", "BiLSTM", "gives", "significantly", "better", "accuracies", "compared", "to", "uni", "-", "directional", "LSTM", "2", ",", "with", "the", "training", "time", "per", "epoch", "growing", "from", "67", "seconds", "to", "106", "seconds", ".", "Stacking", "2", "layers", "of", "BiLSTM", "gives", "further", "improvements", "to", "development", "results", ",", "with", "a", "larger", "time", "of", "207", "seconds", ".", "3", "layers", "of", "stacked", "BiLSTM", "does", "not", "further", "improve", "the", "results", ".", "In", "contrast", ",", "S", "-", "LSTM", "gives", "a", "development", "result", "of", "82.64", "%", ",", "which", "is", "significantly", "better", "compared", "to", "2", "-", "layer", "stacked", "BiLSTM", ",", "with", "a", "smaller", "number", "of", "model", "parameters", "and", "a", "shorter", "time", "of", "65", "seconds", ".", "We", "additionally", "make", "comparisons", "with", "stacked", "CNNs", "and", "hierarchical", "attention", "[", "reference", "]", ",", "shown", "in", "Table", "3", "(", "the", "CNN", "and", "Transformer", "rows", ")", ",", "where", "N", "indicates", "the", "number", "of", "attention", "layers", ".", "CNN", "is", "the", "most", "efficient", "among", "all", "models", "compared", ",", "with", "the", "smallest", "model", "size", ".", "On", "the", "other", "hand", ",", "a", "3", "-", "layer", "stacked", "CNN", "gives", "an", "accuracy", "of", "81.46", "%", ",", "which", "is", "also", "the", "lowest", "compared", "with", "BiLSTM", ",", "hierarchical", "attention", "and", "S", "-", "LSTM", ".", "The", "best", "performance", "of", "hierarchical", "attention", "is", "between", "single", "-", "layer", "and", "two", "-", "layer", "BiLSTMs", "in", "terms", "of", "both", "accuracy", "and", "efficiency", ".", "S", "-", "LSTM", "gives", "significantly", "better", "accuracies", "compared", "with", "both", "CNN", "and", "hierarchical", "attention", ".", "Influence", "of", "external", "attention", "mechanism", ".", "Table", "3", "additionally", "shows", "the", "results", "of", "BiLSTM", "and", "S", "-", "LSTM", "when", "external", "attention", "is", "used", "as", "described", "in", "Section", "3.3", ".", "Attention", "leads", "to", "improved", "accuracies", "for", "both", "BiLSTM", "and", "S", "-", "LSTM", "in", "classification", ",", "with", "S", "-", "LSTM", "still", "outperforming", "BiLSTM", "significantly", ".", "The", "result", "suggests", "that", "external", "techniques", "such", "as", "attention", "can", "play", "orthogonal", "roles", "compared", "with", "internal", "recurrent", "structures", ",", "therefore", "benefiting", "both", "BiLSTMs", "and", "S", "-", "LSTMs", ".", "Similar", "observations", "are", "found", "using", "external", "CRF", "layers", "for", "sequence", "labelling", ".", "section", ":", "Final", "Results", "for", "Classification", "The", "final", "results", "on", "the", "movie", "review", "and", "rich", "text", "classification", "datasets", "are", "shown", "in", "Tables", "4", "and", "5", ",", "respectively", ".", "In", "addition", "to", "training", "time", "per", "epoch", ",", "test", "times", "are", "additionally", "reported", ".", "We", "use", "the", "best", "settings", "on", "the", "movie", "review", "development", "dataset", "for", "both", "S", "-", "LSTMs", "and", "BiLSTMs", ".", "The", "step", "number", "for", "S", "-", "LSTMs", "is", "set", "to", "9", ".", "As", "shown", "in", "Table", "4", ",", "the", "final", "results", "on", "the", "movie", "review", "dataset", "are", "consistent", "with", "the", "development", "results", ",", "where", "S", "-", "LSTM", "outperforms", "BiL", "-", "STM", "significantly", ",", "with", "a", "faster", "speed", ".", "Observations", "on", "CNN", "and", "hierarchical", "attention", "are", "consistent", "with", "the", "development", "results", ".", "S", "-", "LSTM", "also", "gives", "highly", "competitive", "results", "when", "compared", "with", "existing", "methods", "in", "the", "literature", ".", "As", "shown", "in", "Table", "5", ",", "among", "the", "16", "datasets", "of", "[", "reference", "]", ",", "S", "-", "LSTM", "gives", "the", "best", "results", "on", "12", ",", "compared", "with", "BiLSTM", "and", "2", "layered", "BiL", "-", "STM", "models", ".", "The", "average", "accuracy", "of", "S", "-", "LSTM", "is", "85.6", "%", ",", "significantly", "higher", "compared", "with", "84.9", "%", "by", "2", "-", "layer", "stacked", "BiLSTM", ".", "3", "-", "layer", "stacked", "BiL", "-", "STM", "gives", "an", "average", "accuracy", "of", "84.57", "%", ",", "which", "is", "lower", "compared", "to", "a", "2", "-", "layer", "stacked", "BiLSTM", ",", "with", "a", "training", "time", "per", "epoch", "of", "423.6", "seconds", ".", "The", "relative", "speed", "advantage", "of", "S", "-", "LSTM", "over", "BiLSTM", "is", "larger", "on", "the", "16", "datasets", "as", "compared", "to", "the", "movie", "review", "test", "test", ".", "This", "is", "because", "the", "average", "length", "of", "inputs", "is", "larger", "on", "the", "16", "datasets", "(", "see", "Section", "4.5", ")", ".", "section", ":", "Final", "Results", "for", "Sequence", "Labelling", "Bi", "-", "directional", "RNN", "-", "CRF", "structures", ",", "and", "in", "particular", "BiLSTM", "-", "CRFs", ",", "have", "achieved", "the", "state", "of", "the", "art", "in", "the", "literature", "for", "sequence", "labelling", "tasks", ",", "including", "POS", "-", "tagging", "and", "NER", ".", "We", "compare", "S", "-", "LSTM", "-", "CRF", "with", "BiLSTM", "-", "CRF", "for", "sequence", "labelling", ",", "using", "the", "same", "settings", "as", "decided", "on", "the", "movie", "review", "development", "experiments", "for", "both", "BiLSTMs", "and", "S", "-", "LSTMs", ".", "For", "the", "latter", ",", "we", "decide", "the", "number", "of", "recurrent", "steps", "on", "the", "respective", "development", "sets", "for", "sequence", "labelling", ".", "The", "POS", "accuracies", "and", "NER", "F1", "-", "scores", "against", "the", "number", "of", "recurrent", "steps", "are", "shown", "in", "Figure", "3", "(", "a", ")", "and", "(", "b", ")", ",", "respectively", ".", "For", "POS", "tagging", ",", "the", "best", "step", "number", "is", "set", "to", "7", ",", "with", "a", "development", "accuracy", "of", "97.58", "%", ".", "For", "NER", ",", "the", "step", "number", "is", "set", "to", "9", ",", "with", "a", "development", "F1", "-", "score", "of", "94.98", "%", ".", "As", "can", "be", "seen", "in", "(", "Table", "7", ")", ",", "S", "-", "LSTM", "gives", "an", "F1", "-", "score", "of", "91.57", "%", "on", "the", "CoNLL", "test", "set", ",", "which", "is", "significantly", "better", "compared", "with", "BiLSTMs", ".", "Stacking", "more", "layers", "of", "BiLSTMs", "leads", "to", "slightly", "better", "F1", "-", "scores", "compared", "with", "a", "single", "-", "layer", "BiL", "-", "STM", ".", "Our", "BiLSTM", "results", "are", "comparable", "to", "the", "results", "reported", "by", "[", "reference", "]", "and", "[", "reference", "]", ",", "who", "also", "use", "bidirectional", "RNN", "-", "CRF", "structures", ".", "In", "contrast", ",", "S", "-", "LSTM", "gives", "the", "best", "reported", "results", "under", "the", "same", "settings", ".", "In", "the", "second", "section", "of", "Table", "7", "learning", "using", "additional", "language", "model", "objectives", ",", "obtaining", "an", "F", "-", "score", "of", "86.26", "%", ";", "[", "reference", "]", "leverage", "character", "-", "level", "language", "models", ",", "obtaining", "an", "F", "-", "score", "of", "91.93", "%", ",", "which", "is", "the", "current", "best", "result", "on", "the", "dataset", ".", "All", "the", "three", "models", "are", "based", "on", "BiLSTM", "-", "CRF", ".", "On", "the", "other", "hand", ",", "these", "semi", "-", "supervised", "learning", "techniques", "are", "orthogonal", "to", "our", "work", ",", "and", "can", "potentially", "be", "used", "for", "S", "-", "LSTM", "also", ".", "section", ":", "Analysis", "Figure", "4", "(", "a", ")", "and", "(", "b", ")", "show", "the", "accuracies", "against", "the", "sentence", "length", "on", "the", "movie", "review", "and", "CoNLL", "datasets", ",", "respectively", ",", "where", "test", "samples", "are", "binned", "in", "batches", "of", "80", ".", "We", "find", "that", "the", "performances", "of", "both", "S", "-", "LSTM", "and", "BiLSTM", "decrease", "as", "the", "sentence", "length", "increases", ".", "On", "the", "other", "hand", ",", "S", "-", "LSTM", "demonstrates", "relatively", "better", "robustness", "compared", "to", "BiLSTMs", ".", "This", "confirms", "our", "intuition", "that", "a", "sentence", "-", "level", "node", "can", "facilitate", "better", "non", "-", "local", "communication", ".", "these", "comparisons", ",", "we", "mix", "all", "training", "instances", ",", "order", "them", "by", "the", "size", ",", "and", "put", "them", "into", "10", "equal", "groups", ",", "the", "medium", "sentence", "lengths", "of", "which", "are", "shown", ".", "As", "can", "be", "seen", "from", "the", "figure", ",", "the", "speed", "advantage", "of", "S", "-", "LSTM", "is", "larger", "when", "the", "size", "of", "the", "input", "text", "increases", ",", "thanks", "to", "a", "fixed", "number", "of", "recurrent", "steps", ".", "Similar", "to", "hierarchical", "attention", "[", "reference", "]", ",", "there", "is", "a", "relative", "disadvantage", "of", "S", "-", "LSTM", "in", "comparison", "with", "BiLSTM", ",", "which", "is", "that", "the", "memory", "consumption", "is", "relatively", "larger", ".", "For", "example", ",", "over", "the", "movie", "review", "development", "set", ",", "the", "actual", "GPU", "memory", "consumption", "by", "S", "-", "LSTM", ",", "BiLSTM", ",", "2", "-", "layer", "stacked", "BiLSTM", "and", "4", "-", "layer", "stacked", "BiLSTM", "are", "252", "M", ",", "89", "M", ",", "146", "M", "and", "253", "M", ",", "respectively", ".", "This", "is", "due", "to", "the", "fact", "that", "computation", "is", "performed", "in", "parallel", "by", "S", "-", "LSTM", "and", "hierarchical", "attention", ".", "section", ":", "Conclusion", "We", "have", "investigated", "S", "-", "LSTM", ",", "a", "recurrent", "neural", "network", "for", "encoding", "sentences", ",", "which", "offers", "richer", "contextual", "information", "exchange", "with", "more", "parallelism", "compared", "to", "BiLSTMs", ".", "Results", "on", "a", "range", "of", "classification", "and", "sequence", "labelling", "tasks", "show", "that", "S", "-", "LSTM", "outperforms", "BiLSTMs", "using", "the", "same", "number", "of", "parameters", ",", "demonstrating", "that", "S", "-", "LSTM", "can", "be", "a", "useful", "addition", "to", "the", "neural", "toolbox", "for", "encoding", "sentences", ".", "The", "structural", "nature", "in", "S", "-", "LSTM", "states", "allows", "straightforward", "extension", "to", "tree", "structures", ",", "resulting", "in", "highly", "parallelisable", "tree", "LSTMs", ".", "We", "leave", "such", "investigation", "to", "future", "work", ".", "Next", "directions", "also", "include", "the", "investigation", "of", "S", "-", "LSTM", "to", "more", "NLP", "tasks", ",", "such", "as", "machine", "translation", ".", "section", ":", "section", ":", "Acknowledge", "We", "thank", "the", "anonymous", "reviewers", "for", "their", "constructive", "and", "thoughtful", "comments", ".", "section", ":"]}