{"coref": {"CIFAR-10": [[194, 197], [871, 874], [3587, 3590], [3898, 3901], [3912, 3915], [4178, 4181], [4185, 4189], [4432, 4436], [4501, 4505], [4526, 4529], [4546, 4549], [4573, 4576]], "CIFAR-100": [[198, 201], [875, 878], [3591, 3594], [3903, 3906], [4182, 4185], [4577, 4580], [4494, 4497]], "DSN": [[2, 6], [8, 12], [13, 14], [577, 581], [582, 583], [807, 808], [918, 919], [922, 926], [938, 942], [943, 944], [2247, 2248], [2254, 2255], [2361, 2362], [3659, 3660], [3785, 3786], [3961, 3962], [4078, 4079], [4174, 4175], [4326, 4327], [4367, 4368], [4379, 4380], [4416, 4417], [4483, 4484], [4564, 4565], [4728, 4732], [4733, 4734], [840, 841], [844, 845], [2269, 2270], [3577, 3578], [3738, 3739], [3807, 3808], [3811, 3812], [4047, 4048], [4052, 4053], [4085, 4086], [4090, 4091], [4094, 4095], [4104, 4105], [4148, 4149], [4302, 4303], [4586, 4587]], "Image_Classification": [[39, 40], [77, 78], [267, 269], [540, 541], [1256, 1257], [4533, 4535]], "MNIST": [[192, 193], [869, 870], [3585, 3586], [3895, 3896], [3952, 3953], [3964, 3965], [3980, 3981]], "Percentage_correct": [], "Percentage_error": [], "SVHN": [[203, 204], [880, 881], [3595, 3596], [3909, 3910], [4600, 4601]]}, "coref_non_salient": {"0": [[2350, 2354], [2560, 2564], [2591, 2594], [4759, 4762]], "1": [[468, 470], [2444, 2447]], "10": [[57, 61], [490, 492], [4101, 4103]], "11": [[270, 272], [296, 298]], "12": [[1328, 1329], [1395, 1397], [1402, 1404], [1967, 1968], [2249, 2251], [3145, 3147], [4306, 4307]], "13": [[139, 145], [441, 444], [708, 715], [724, 727], [2459, 2462]], "14": [[280, 282], [1540, 1542]], "15": [[4060, 4066], [4080, 4084]], "16": [[437, 438], [2463, 2464], [3688, 3690]], "17": [[2272, 2273], [2595, 2596], [3404, 3405], [3615, 3617]], "18": [[100, 101], [385, 386], [2166, 2171], [4684, 4685]], "19": [[382, 384], [4358, 4360]], "2": [[305, 307], [2379, 2380]], "20": [[261, 264], [779, 781], [4745, 4747]], "21": [[151, 154], [654, 657]], "22": [[23, 25], [626, 628], [4742, 4744]], "23": [[3699, 3701], [3712, 3714], [4385, 4387], [4454, 4456]], "24": [[4710, 4713]], "25": [[3775, 3777]], "26": [[1970, 1972], [3514, 3516]], "27": [[18, 20], [1887, 1888], [3706, 3708], [3882, 3884], [4108, 4110], [4130, 4132], [736, 738], [911, 913], [1512, 1514]], "28": [[4314, 4316]], "29": [[1320, 1322], [3419, 3422]], "3": [[753, 754], [1187, 1189]], "30": [[446, 448], [3916, 3918], [4119, 4120], [4310, 4312], [4681, 4683], [4707, 4709]], "31": [[769, 771], [772, 776]], "32": [[482, 484], [664, 666], [1412, 1413], [2358, 2359], [2682, 2684], [3339, 3341], [3551, 3553], [4351, 4353]], "33": [[1489, 1491]], "34": [[815, 816], [962, 964], [974, 975], [1605, 1606], [1621, 1622], [1775, 1777], [1820, 1822], [2062, 2064], [3800, 3801]], "35": [[3977, 3979]], "36": [[899, 900], [3926, 3927], [4272, 4274]], "37": [[2513, 2517]], "38": [[4627, 4629]], "39": [[3634, 3636], [3715, 3717]], "4": [[802, 803], [1283, 1285], [1642, 1644], [1723, 1725], [2245, 2246], [2295, 2298], [4172, 4173], [4371, 4372], [4381, 4382], [4492, 4493]], "40": [[785, 787], [820, 821], [959, 960], [1602, 1603]], "41": [[3664, 3665]], "42": [[1610, 1611], [1623, 1624], [3798, 3799]], "43": [[2043, 2045], [2176, 2177], [2555, 2556]], "44": [[1271, 1273], [3017, 3019], [3671, 3673], [3768, 3770]], "45": [[1974, 1976]], "46": [[3387, 3391]], "47": [[439, 440], [901, 902], [4705, 4706]], "48": [[278, 279], [398, 399]], "49": [[2588, 2590]], "5": [[1379, 1381], [2366, 2367], [3124, 3126]], "50": [[3637, 3640]], "51": [[2779, 2784]], "52": [[1367, 1369]], "53": [[4221, 4224], [4670, 4673]], "54": [[1124, 1131]], "55": [[852, 855], [3819, 3822], [4037, 4040], [4152, 4155]], "56": [[1301, 1303], [2104, 2107], [2144, 2148]], "57": [[408, 411]], "58": [[4116, 4118]], "59": [[47, 49], [218, 220], [1051, 1053], [2394, 2397], [2453, 2456], [2491, 2494]], "6": [[287, 295], [566, 569]], "60": [[53, 56], [1493, 1499]], "61": [[1158, 1160]], "62": [[1674, 1676]], "63": [[4376, 4378]], "64": [[1738, 1740], [2755, 2758], [2765, 2769]], "65": [[3763, 3765]], "66": [[1959, 1961]], "67": [[412, 414]], "68": [[904, 905]], "69": [[69, 70]], "7": [[389, 390], [423, 424], [457, 458], [570, 571], [638, 641], [976, 977], [2518, 2519], [3869, 3870]], "70": [[426, 429]], "71": [[2205, 2208]], "72": [[2369, 2371]], "73": [[4439, 4441]], "74": [[402, 404], [759, 761]], "75": [[528, 530]], "76": [[2180, 2182]], "77": [[1191, 1193]], "78": [[98, 99]], "79": [[953, 957]], "8": [[82, 83], [1017, 1019], [1030, 1032], [1062, 1064]], "80": [[4674, 4675]], "81": [[553, 555]], "82": [[2194, 2199]], "83": [[221, 226]], "84": [[323, 325]], "85": [[1663, 1666]], "86": [[239, 241]], "87": [[4476, 4478]], "88": [[741, 743], [2719, 2721]], "89": [[848, 851], [3815, 3818], [4067, 4070]], "9": [[2263, 2265], [4169, 4171]], "90": [[3778, 3782]], "91": [[1445, 1448]], "92": [[1778, 1779]], "93": [[2688, 2691]], "94": [[2692, 2695]], "95": [[3392, 3396]], "96": [[4032, 4036]]}, "doc_id": "06b4d8409837dce9d6eb919efd1debdaecc40d01", "method_subrelations": {"DSN": [[[0, 3], "DSN"]]}, "n_ary_relations": [{"Material": "CIFAR-10", "Method": "DSN", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "91.8"}, {"Material": "CIFAR-100", "Method": "DSN", "Metric": "Percentage_correct", "Task": "Image_Classification", "score": "65.4"}, {"Material": "MNIST", "Method": "DSN", "Metric": "Percentage_error", "Task": "Image_Classification", "score": "0.4"}, {"Material": "SVHN", "Method": "DSN", "Metric": "Percentage_error", "Task": "Image_Classification", "score": 1.92}], "ner": [[2, 6, "Method"], [8, 12, "Method"], [13, 14, "Method"], [18, 20, "Metric"], [23, 25, "Method"], [39, 40, "Task"], [47, 49, "Method"], [53, 56, "Method"], [57, 61, "Method"], [69, 70, "Method"], [77, 78, "Task"], [82, 83, "Method"], [98, 99, "Method"], [100, 101, "Task"], [139, 145, "Method"], [151, 154, "Method"], [192, 193, "Material"], [194, 197, "Material"], [198, 201, "Material"], [203, 204, "Material"], [218, 220, "Method"], [221, 226, "Method"], [239, 241, "Method"], [261, 264, "Method"], [267, 269, "Task"], [270, 272, "Task"], [278, 279, "Method"], [280, 282, "Method"], [287, 295, "Task"], [296, 298, "Task"], [305, 307, "Task"], [323, 325, "Method"], [382, 384, "Method"], [385, 386, "Task"], [389, 390, "Method"], [402, 404, "Method"], [408, 411, "Task"], [412, 414, "Task"], [423, 424, "Method"], [426, 429, "Task"], [437, 438, "Method"], [439, 440, "Method"], [441, 444, "Method"], [446, 448, "Method"], [457, 458, "Method"], [468, 470, "Method"], [482, 484, "Metric"], [490, 492, "Method"], [528, 530, "Method"], [540, 541, "Task"], [553, 555, "Method"], [566, 569, "Task"], [570, 571, "Method"], [577, 581, "Method"], [582, 583, "Method"], [626, 628, "Method"], [638, 641, "Method"], [654, 657, "Method"], [664, 666, "Metric"], [708, 715, "Method"], [724, 727, "Method"], [741, 743, "Metric"], [753, 754, "Method"], [759, 761, "Method"], [769, 771, "Task"], [772, 776, "Task"], [779, 781, "Method"], [785, 787, "Method"], [802, 803, "Method"], [807, 808, "Method"], [815, 816, "Method"], [820, 821, "Method"], [848, 851, "Method"], [852, 855, "Method"], [869, 870, "Material"], [871, 874, "Material"], [875, 878, "Material"], [880, 881, "Material"], [899, 900, "Method"], [901, 902, "Method"], [904, 905, "Method"], [918, 919, "Method"], [922, 926, "Method"], [938, 942, "Method"], [943, 944, "Method"], [953, 957, "Method"], [959, 960, "Method"], [962, 964, "Method"], [974, 975, "Method"], [976, 977, "Method"], [1017, 1019, "Method"], [1030, 1032, "Method"], [1051, 1053, "Method"], [1062, 1064, "Method"], [1124, 1131, "Method"], [1158, 1160, "Metric"], [1187, 1189, "Method"], [1191, 1193, "Method"], [1256, 1257, "Task"], [1271, 1273, "Method"], [1283, 1285, "Method"], [1301, 1303, "Method"], [1320, 1322, "Method"], [1328, 1329, "Metric"], [1367, 1369, "Method"], [1379, 1381, "Method"], [1395, 1397, "Metric"], [1402, 1404, "Metric"], [1412, 1413, "Metric"], [1445, 1448, "Task"], [1489, 1491, "Method"], [1493, 1499, "Method"], [1540, 1542, "Method"], [1602, 1603, "Method"], [1605, 1606, "Method"], [1610, 1611, "Method"], [1621, 1622, "Method"], [1623, 1624, "Method"], [1642, 1644, "Method"], [1663, 1666, "Metric"], [1674, 1676, "Metric"], [1723, 1725, "Method"], [1738, 1740, "Task"], [1775, 1777, "Method"], [1778, 1779, "Method"], [1820, 1822, "Method"], [1887, 1888, "Metric"], [1959, 1961, "Task"], [1967, 1968, "Metric"], [1970, 1972, "Metric"], [1974, 1976, "Metric"], [2043, 2045, "Task"], [2062, 2064, "Method"], [2104, 2107, "Method"], [2144, 2148, "Method"], [2166, 2171, "Task"], [2176, 2177, "Task"], [2180, 2182, "Metric"], [2194, 2199, "Method"], [2205, 2208, "Method"], [2245, 2246, "Method"], [2247, 2248, "Method"], [2249, 2251, "Metric"], [2254, 2255, "Method"], [2263, 2265, "Metric"], [2272, 2273, "Method"], [2295, 2298, "Method"], [2350, 2354, "Method"], [2358, 2359, "Metric"], [2361, 2362, "Method"], [2366, 2367, "Method"], [2369, 2371, "Task"], [2379, 2380, "Task"], [2394, 2397, "Method"], [2444, 2447, "Method"], [2453, 2456, "Method"], [2459, 2462, "Method"], [2463, 2464, "Method"], [2491, 2494, "Method"], [2513, 2517, "Method"], [2518, 2519, "Method"], [2555, 2556, "Task"], [2560, 2564, "Method"], [2588, 2590, "Method"], [2591, 2594, "Method"], [2595, 2596, "Method"], [2682, 2684, "Metric"], [2688, 2691, "Method"], [2692, 2695, "Method"], [2719, 2721, "Metric"], [2755, 2758, "Task"], [2765, 2769, "Task"], [2779, 2784, "Task"], [3017, 3019, "Method"], [3124, 3126, "Method"], [3145, 3147, "Metric"], [3339, 3341, "Metric"], [3387, 3391, "Method"], [3392, 3396, "Method"], [3404, 3405, "Method"], [3419, 3422, "Method"], [3514, 3516, "Metric"], [3551, 3553, "Metric"], [3585, 3586, "Material"], [3587, 3590, "Material"], [3591, 3594, "Material"], [3595, 3596, "Material"], [3615, 3617, "Method"], [3634, 3636, "Metric"], [3637, 3640, "Metric"], [3659, 3660, "Method"], [3664, 3665, "Metric"], [3671, 3673, "Method"], [3688, 3690, "Method"], [3699, 3701, "Method"], [3706, 3708, "Metric"], [3712, 3714, "Method"], [3715, 3717, "Metric"], [3763, 3765, "Method"], [3768, 3770, "Method"], [3775, 3777, "Method"], [3778, 3782, "Method"], [3785, 3786, "Method"], [3798, 3799, "Method"], [3800, 3801, "Method"], [3815, 3818, "Method"], [3819, 3822, "Method"], [3869, 3870, "Method"], [3882, 3884, "Metric"], [3895, 3896, "Material"], [3898, 3901, "Material"], [3903, 3906, "Material"], [3909, 3910, "Material"], [3912, 3915, "Material"], [3916, 3918, "Method"], [3926, 3927, "Method"], [3961, 3962, "Method"], [3977, 3979, "Method"], [4032, 4036, "Method"], [4037, 4040, "Method"], [4060, 4066, "Method"], [4067, 4070, "Method"], [4078, 4079, "Method"], [4080, 4084, "Method"], [4101, 4103, "Method"], [4108, 4110, "Metric"], [4116, 4118, "Method"], [4119, 4120, "Method"], [4130, 4132, "Metric"], [4152, 4155, "Method"], [4169, 4171, "Metric"], [4172, 4173, "Method"], [4174, 4175, "Method"], [4178, 4181, "Material"], [4182, 4185, "Material"], [4185, 4189, "Material"], [4221, 4224, "Method"], [4272, 4274, "Method"], [4310, 4312, "Method"], [4314, 4316, "Method"], [4326, 4327, "Method"], [4351, 4353, "Metric"], [4358, 4360, "Method"], [4367, 4368, "Method"], [4371, 4372, "Method"], [4376, 4378, "Metric"], [4379, 4380, "Method"], [4381, 4382, "Method"], [4385, 4387, "Method"], [4416, 4417, "Method"], [4432, 4436, "Material"], [4439, 4441, "Method"], [4454, 4456, "Method"], [4476, 4478, "Method"], [4483, 4484, "Method"], [4492, 4493, "Method"], [4501, 4505, "Material"], [4526, 4529, "Material"], [4533, 4535, "Task"], [4546, 4549, "Material"], [4564, 4565, "Method"], [4573, 4576, "Material"], [4577, 4580, "Material"], [4627, 4629, "Task"], [4670, 4673, "Method"], [4674, 4675, "Method"], [4681, 4683, "Method"], [4684, 4685, "Task"], [4705, 4706, "Method"], [4707, 4709, "Method"], [4710, 4713, "Method"], [4728, 4732, "Method"], [4733, 4734, "Method"], [4742, 4744, "Method"], [4745, 4747, "Method"], [4759, 4762, "Method"], [398, 399, "Method"], [736, 738, "Metric"], [840, 841, "Method"], [844, 845, "Method"], [911, 913, "Metric"], [1512, 1514, "Metric"], [2269, 2270, "Method"], [3577, 3578, "Method"], [3738, 3739, "Method"], [3807, 3808, "Method"], [3811, 3812, "Method"], [3952, 3953, "Material"], [3964, 3965, "Material"], [3980, 3981, "Material"], [4047, 4048, "Method"], [4052, 4053, "Method"], [4085, 4086, "Method"], [4090, 4091, "Method"], [4094, 4095, "Method"], [4104, 4105, "Method"], [4148, 4149, "Method"], [4302, 4303, "Method"], [4306, 4307, "Metric"], [4494, 4497, "Material"], [4586, 4587, "Method"], [4600, 4601, "Material"]], "sections": [[0, 206], [206, 920], [920, 1001], [1001, 1438], [1438, 2348], [2348, 2894], [2894, 3221], [3221, 3305], [3305, 3360], [3360, 3570], [3570, 3950], [3950, 4176], [4176, 4589], [4589, 4714], [4714, 4772], [4772, 4839], [4839, 4842]], "sentences": [[0, 6], [6, 32], [32, 50], [50, 56], [56, 112], [112, 147], [147, 159], [159, 206], [206, 209], [209, 242], [242, 273], [273, 317], [317, 387], [387, 405], [405, 432], [432, 485], [485, 495], [495, 515], [515, 542], [542, 559], [559, 601], [601, 629], [629, 642], [642, 658], [658, 695], [695, 706], [706, 718], [718, 748], [748, 762], [762, 772], [772, 782], [782, 804], [804, 831], [831, 857], [857, 882], [882, 906], [906, 920], [920, 926], [926, 946], [946, 969], [969, 1001], [1001, 1004], [1004, 1038], [1038, 1100], [1100, 1138], [1138, 1195], [1195, 1215], [1215, 1269], [1269, 1286], [1286, 1304], [1304, 1326], [1326, 1357], [1357, 1438], [1438, 1441], [1441, 1473], [1473, 1486], [1486, 1519], [1519, 1547], [1547, 1645], [1645, 1657], [1657, 1701], [1701, 1755], [1755, 1758], [1758, 1803], [1803, 1827], [1827, 1847], [1847, 1857], [1857, 1863], [1863, 1907], [1907, 1927], [1927, 1962], [1962, 1977], [1977, 2037], [2037, 2084], [2084, 2108], [2108, 2151], [2151, 2157], [2157, 2191], [2191, 2214], [2214, 2232], [2232, 2266], [2266, 2310], [2310, 2328], [2328, 2334], [2334, 2348], [2348, 2354], [2354, 2372], [2372, 2401], [2401, 2408], [2408, 2419], [2419, 2441], [2441, 2465], [2465, 2487], [2487, 2500], [2500, 2565], [2565, 2616], [2616, 2639], [2639, 2651], [2651, 2656], [2656, 2658], [2658, 2679], [2679, 2702], [2702, 2707], [2707, 2733], [2733, 2798], [2798, 2823], [2823, 2837], [2837, 2865], [2865, 2876], [2876, 2891], [2891, 2894], [2894, 2896], [2896, 2911], [2911, 2931], [2931, 2937], [2937, 2944], [2944, 2960], [2960, 2966], [2966, 2977], [2977, 3008], [3008, 3023], [3023, 3034], [3034, 3062], [3062, 3066], [3066, 3095], [3095, 3117], [3117, 3127], [3127, 3167], [3167, 3182], [3182, 3204], [3204, 3221], [3221, 3223], [3223, 3268], [3268, 3284], [3284, 3305], [3305, 3307], [3307, 3318], [3318, 3348], [3348, 3360], [3360, 3362], [3362, 3417], [3417, 3425], [3425, 3438], [3438, 3468], [3468, 3517], [3517, 3542], [3542, 3570], [3570, 3573], [3573, 3597], [3597, 3613], [3613, 3631], [3631, 3648], [3648, 3684], [3684, 3695], [3695, 3715], [3715, 3736], [3736, 3754], [3754, 3766], [3766, 3785], [3785, 3802], [3802, 3834], [3834, 3871], [3871, 3920], [3920, 3936], [3936, 3950], [3950, 3953], [3953, 3980], [3980, 4009], [4009, 4042], [4042, 4090], [4090, 4103], [4103, 4122], [4122, 4136], [4136, 4158], [4158, 4162], [4162, 4176], [4176, 4185], [4185, 4194], [4194, 4216], [4216, 4225], [4225, 4271], [4271, 4291], [4291, 4301], [4301, 4326], [4326, 4361], [4361, 4388], [4388, 4407], [4407, 4464], [4464, 4479], [4479, 4494], [4494, 4513], [4513, 4538], [4538, 4550], [4550, 4566], [4566, 4576], [4576, 4589], [4589, 4595], [4595, 4601], [4601, 4621], [4621, 4652], [4652, 4663], [4663, 4677], [4677, 4694], [4694, 4703], [4703, 4714], [4714, 4717], [4717, 4748], [4748, 4758], [4758, 4772], [4772, 4775], [4775, 4802], [4802, 4826], [4826, 4839], [4839, 4842]], "words": ["document", ":", "Deeply", "-", "Supervised", "Nets", "Our", "proposed", "deeply", "-", "supervised", "nets", "(", "DSN", ")", "method", "simultaneously", "minimizes", "classification", "error", "while", "making", "the", "learning", "process", "of", "hidden", "layers", "direct", "and", "transparent", ".", "We", "make", "an", "attempt", "to", "boost", "the", "classification", "performance", "by", "studying", "a", "new", "formulation", "in", "deep", "networks", ".", "Three", "aspects", "in", "convolutional", "neural", "networks", "(", "CNN", ")", "style", "architectures", "are", "being", "looked", "at", ":", "(", "1", ")", "transparency", "of", "the", "intermediate", "layers", "to", "the", "overall", "classification", ";", "(", "2", ")", "discriminativeness", "and", "robustness", "of", "learned", "features", ",", "especially", "in", "the", "early", "layers", ";", "(", "3", ")", "effectiveness", "in", "training", "due", "to", "the", "presence", "of", "the", "exploding", "and", "vanishing", "gradients", ".", "We", "introduce", "\u201c", "companion", "objective", "\u201d", "to", "the", "individual", "hidden", "layers", ",", "in", "addition", "to", "the", "overall", "objective", "at", "the", "output", "layer", "(", "a", "different", "strategy", "to", "layer", "-", "wise", "pre", "-", "training", ")", ".", "We", "extend", "techniques", "from", "stochastic", "gradient", "methods", "to", "analyze", "our", "algorithm", ".", "The", "advantage", "of", "our", "method", "is", "evident", "and", "our", "experimental", "result", "on", "benchmark", "datasets", "shows", "significant", "performance", "gain", "over", "existing", "methods", "(", "e.g.", "all", "state", "-", "of", "-", "the", "-", "art", "results", "on", "MNIST", ",", "CIFAR", "-", "10", ",", "CIFAR", "-", "100", ",", "and", "SVHN", ")", ".", "section", ":", "Introduction", "Much", "attention", "has", "been", "given", "to", "a", "resurgence", "of", "neural", "networks", ",", "deep", "learning", "(", "DL", ")", "in", "particular", ",", "which", "can", "be", "of", "unsupervised", ",", "supervised", ",", "or", "a", "hybrid", "form", ".", "Significant", "performance", "gain", "has", "been", "observed", ",", "especially", "in", "the", "presence", "of", "large", "amount", "of", "training", "data", ",", "when", "deep", "learning", "techniques", "are", "used", "for", "image", "classification", "and", "speech", "recognition", ".", "On", "the", "one", "hand", ",", "hierarchical", "and", "recursive", "networks", "have", "demonstrated", "great", "promise", "in", "automatically", "learning", "thousands", "or", "even", "millions", "of", "features", "for", "pattern", "recognition", ";", "on", "the", "other", "hand", "concerns", "about", "deep", "learning", "have", "been", "raised", "and", "many", "fundamental", "questions", "remain", "open", ".", "Some", "potential", "problems", "with", "the", "current", "DL", "frameworks", "include", ":", "reduced", "transparency", "and", "discriminativeness", "of", "the", "features", "learned", "at", "hidden", "layers", ";", "training", "difficulty", "due", "to", "exploding", "and", "vanishing", "gradients", ";", "lack", "of", "a", "thorough", "mathematical", "understanding", "about", "the", "algorithmic", "behavior", ",", "despite", "of", "some", "attempts", "made", "on", "the", "theoretical", "side", ";", "dependence", "on", "the", "availability", "of", "large", "amount", "of", "training", "data", ";", "complexity", "of", "manual", "tuning", "during", "training", ".", "Nevertheless", ",", "DL", "is", "capable", "of", "automatically", "learning", "and", "fusing", "rich", "hierarchical", "features", "in", "an", "integrated", "framework", ".", "Recent", "activities", "in", "open", "-", "sourcing", "and", "experience", "sharing", "have", "also", "greatly", "helped", "the", "adopting", "and", "advancing", "of", "DL", "in", "the", "machine", "learning", "community", "and", "beyond", ".", "Several", "techniques", ",", "such", "as", "dropout", ",", "dropconnect", ",", "pre", "-", "training", ",", "and", "data", "augmentation", ",", "have", "been", "proposed", "to", "enhance", "the", "performance", "of", "DL", "from", "various", "angles", ",", "in", "addition", "to", "a", "variety", "of", "engineering", "tricks", "used", "to", "fine", "-", "tune", "feature", "scale", ",", "step", "size", ",", "and", "convergence", "rate", ".", "Features", "learned", "automatically", "by", "the", "CNN", "algorithm", "are", "intuitive", ".", "Some", "portion", "of", "features", ",", "especially", "for", "those", "in", "the", "early", "layers", ",", "also", "demonstrate", "certain", "degree", "of", "opacity", ".", "This", "finding", "is", "also", "consistent", "with", "an", "observation", "that", "different", "initializations", "of", "the", "feature", "learning", "at", "the", "early", "layers", "make", "negligible", "difference", "to", "the", "final", "classification", ".", "In", "addition", ",", "the", "presence", "of", "vanishing", "gradients", "also", "makes", "the", "DL", "training", "slow", "and", "ineffective", ".", "In", "this", "paper", ",", "we", "address", "the", "feature", "learning", "problem", "in", "DL", "by", "presenting", "a", "new", "algorithm", ",", "deeply", "-", "supervised", "nets", "(", "DSN", ")", ",", "which", "enforces", "direct", "and", "early", "supervision", "for", "both", "the", "hidden", "layers", "and", "the", "output", "layer", ".", "We", "introduce", "companion", "objective", "to", "the", "individual", "hidden", "layers", ",", "which", "is", "used", "as", "an", "additional", "constraint", "(", "or", "a", "new", "regularization", ")", "to", "the", "learning", "process", ".", "Our", "new", "formulation", "significantly", "enhances", "the", "performance", "of", "existing", "supervised", "DL", "methods", ".", "We", "also", "make", "an", "attempt", "to", "provide", "justification", "for", "our", "formulation", "using", "stochastic", "gradient", "techniques", ".", "We", "show", "an", "improvement", "of", "the", "convergence", "rate", "of", "the", "proposed", "method", "over", "standard", "ones", ",", "assuming", "local", "strong", "convexity", "of", "the", "optimization", "function", "(", "a", "very", "loose", "assumption", "but", "pointing", "to", "a", "promising", "direction", ")", ".", "Several", "existing", "approaches", "are", "particularly", "worth", "mentioning", "and", "comparing", "with", ".", "In", ",", "layer", "-", "wise", "supervised", "pre", "-", "training", "is", "performed", ".", "Our", "proposed", "method", "does", "not", "perform", "pre", "-", "training", "and", "it", "emphasizes", "the", "importance", "of", "minimizing", "the", "output", "classification", "error", "while", "reducing", "the", "prediction", "error", "of", "each", "individual", "layer", ".", "This", "is", "important", "as", "the", "backpropagation", "is", "performed", "altogether", "in", "an", "integrated", "framework", ".", "In", ",", "label", "information", "is", "used", "for", "unsupervised", "learning", ".", "Semi", "-", "supervised", "learning", "is", "carried", "in", "deep", "learning", ".", "In", ",", "an", "SVM", "classifier", "is", "used", "for", "the", "output", "layer", ",", "instead", "of", "the", "standard", "softmax", "function", "in", "the", "CNN", ".", "Our", "framework", "(", "DSN", ")", ",", "with", "the", "choice", "of", "using", "SVM", ",", "softmax", "or", "other", "classifiers", ",", "emphasizes", "the", "direct", "supervision", "of", "each", "intermediate", "layer", ".", "In", "the", "experiments", ",", "we", "show", "consistent", "improvement", "of", "DSN", "-", "SVM", "and", "DSN", "-", "Softmax", "over", "CNN", "-", "SVM", "and", "CNN", "-", "Softmax", "respectively", ".", "We", "observe", "all", "state", "-", "of", "-", "the", "-", "art", "results", "on", "MNIST", ",", "CIFAR", "-", "10", ",", "CIFAR", "-", "100", ",", "and", "SVHN", ".", "It", "is", "also", "worth", "mentioning", "that", "our", "formulation", "is", "inclusive", "to", "various", "techniques", "proposed", "recently", "such", "as", "averaging", ",", "dropconnect", ",", "and", "Maxout", ".", "We", "expect", "to", "see", "more", "classification", "error", "reduction", "with", "careful", "engineering", "for", "DSN", ".", "section", ":", "Deeply", "-", "Supervised", "Nets", "In", "this", "section", ",", "we", "give", "the", "main", "formulation", "of", "the", "proposed", "deeply", "-", "supervised", "nets", "(", "DSN", ")", ".", "We", "focus", "on", "building", "our", "infrastructure", "around", "supervised", "CNN", "style", "frameworks", "by", "introducing", "classifier", ",", "e.g.", "SVM", "model", ",", "to", "each", "layer", ".", "An", "early", "attempt", "to", "combine", "SVM", "with", "DL", "was", "made", "in", ",", "which", "however", "has", "a", "different", "motivation", "with", "ours", "and", "only", "studies", "the", "output", "layer", "with", "some", "preliminary", "experimental", "results", ".", "subsection", ":", "Motivation", "We", "are", "motivated", "by", "the", "following", "simple", "observation", ":", "in", "general", ",", "a", "discriminative", "classifier", "trained", "on", "highly", "discriminative", "features", "will", "display", "better", "performance", "than", "a", "discriminative", "classifier", "trained", "on", "less", "discriminative", "features", ".", "If", "the", "features", "in", "question", "are", "the", "hidden", "layer", "feature", "maps", "of", "a", "deep", "network", ",", "this", "observation", "means", "that", "the", "performance", "of", "a", "discriminative", "classifier", "trained", "using", "these", "hidden", "layer", "feature", "maps", "can", "serve", "as", "a", "proxy", "for", "the", "quality", "/", "discriminativeness", "of", "those", "hidden", "layer", "feature", "maps", ",", "and", "further", "to", "the", "quality", "of", "the", "upper", "layer", "feature", "maps", ".", "By", "making", "appropriate", "use", "of", "this", "feature", "quality", "feedback", "at", "each", "hidden", "layer", "of", "the", "network", ",", "we", "are", "able", "to", "directly", "influence", "the", "hidden", "layer", "weight", "/", "filter", "update", "process", "to", "favor", "highly", "discriminative", "feature", "maps", ".", "This", "is", "a", "source", "of", "supervision", "that", "acts", "deep", "within", "the", "network", "at", "each", "layer", ";", "when", "our", "proxy", "for", "feature", "quality", "is", "good", ",", "we", "expect", "to", "much", "more", "rapidly", "approach", "the", "region", "of", "good", "features", "than", "would", "be", "the", "case", "if", "we", "had", "to", "rely", "on", "the", "gradual", "backpropagation", "from", "the", "output", "layer", "alone", ".", "We", "also", "expect", "to", "alleviate", "the", "common", "problem", "of", "having", "gradients", "that", "\u201c", "explode", "\u201d", "or", "\u201c", "vanish", "\u201d", ".", "One", "concern", "with", "a", "direct", "pursuit", "of", "feature", "discriminativeness", "at", "all", "hidden", "layers", "is", "that", "this", "might", "interfere", "with", "the", "overall", "network", "performance", ",", "since", "it", "is", "ultimately", "the", "feature", "maps", "at", "the", "output", "layer", "which", "are", "used", "for", "the", "final", "classification", ";", "our", "experimental", "results", "indicate", "that", "this", "is", "not", "the", "case", ".", "Our", "basic", "network", "architecture", "will", "be", "similar", "to", "the", "standard", "one", "used", "in", "the", "CNN", "framework", ".", "Our", "additional", "deep", "feedback", "is", "brought", "in", "by", "associating", "a", "companion", "local", "output", "with", "each", "hidden", "layer", ".", "We", "may", "think", "of", "this", "companion", "local", "output", "as", "analogous", "to", "the", "final", "output", "that", "a", "truncated", "network", "would", "have", "produced", ".", "Backpropagation", "of", "error", "now", "proceeds", "as", "usual", ",", "with", "the", "crucial", "difference", "that", "we", "now", "backpropagate", "not", "only", "from", "the", "final", "layer", "but", "also", "simultaneously", "from", "our", "local", "companion", "output", ".", "The", "empirical", "result", "suggests", "the", "following", "main", "properties", "of", "the", "companion", "objective", ":", "(", "1", ")", "it", "acts", "as", "a", "kind", "of", "feature", "regularization", "(", "although", "an", "unusual", "one", ")", ",", "which", "leads", "to", "significant", "reduction", "to", "the", "testing", "error", "but", "not", "necessarily", "to", "the", "train", "error", ";", "(", "2", ")", "it", "results", "in", "faster", "convergence", ",", "especially", "in", "presence", "of", "small", "training", "data", "(", "see", "Figure", "(", "[", "reference", "]", ")", "for", "an", "illustration", "on", "a", "running", "example", ")", ".", "subsection", ":", "Formulation", "We", "focus", "on", "the", "supervised", "learning", "case", "and", "let", "be", "our", "set", "of", "input", "training", "data", "where", "sample", "denotes", "the", "raw", "input", "data", "and", "is", "the", "corresponding", "groundtruth", "label", "for", "sample", ".", "We", "drop", "for", "notational", "simplicity", ",", "since", "each", "sample", "is", "considered", "independently", ".", "The", "goal", "of", "deep", "nets", ",", "specifically", "convolutional", "neural", "networks", "(", "CNN", ")", ",", "is", "to", "learn", "layers", "of", "filters", "and", "weights", "for", "the", "minimization", "of", "classification", "error", "at", "the", "output", "layer", ".", "Here", ",", "we", "absorb", "the", "bias", "term", "into", "the", "weight", "parameters", "and", "do", "not", "differentiate", "weights", "from", "filters", "and", "denote", "a", "recursive", "function", "for", "each", "layer", "as", ":", "denotes", "the", "total", "number", "of", "layers", ";", "are", "the", "filters", "/", "weights", "to", "be", "learned", ";", "is", "the", "feature", "map", "produced", "at", "layer", ";", "refers", "to", "the", "convolved", "/", "filtered", "responses", "on", "the", "previous", "feature", "map", ";", "is", "a", "pooling", "function", "on", ";", "Combining", "all", "layers", "of", "weights", "gives", "Now", "we", "introduce", "a", "set", "of", "classifiers", ",", "e.g.", "SVM", "(", "other", "classifiers", "like", "Softmax", "can", "be", "applied", "and", "we", "will", "show", "results", "using", "both", "SVM", "and", "Softmax", "in", "the", "experiments", ")", ",", "one", "for", "each", "hidden", "layer", ",", "in", "addition", "to", "the", "in", "the", "standard", "CNN", "framework", ".", "We", "denote", "the", "as", "the", "SVM", "weights", "for", "the", "output", "layer", ".", "Thus", ",", "we", "build", "our", "overall", "combined", "objective", "function", "as", ":", "where", "and", "We", "name", "as", "the", "overall", "loss", "(", "output", "layer", ")", "and", "as", "the", "companion", "loss", "(", "hidden", "layers", ")", ",", "which", "are", "both", "squared", "hinge", "losses", "of", "the", "prediction", "errors", ".", "The", "above", "formulation", "can", "be", "understood", "intuitively", ":", "in", "addition", "to", "learning", "convolution", "kernels", "and", "weights", ",", ",", "as", "in", "the", "standard", "CNN", "model", ",", "enforcing", "a", "constraint", "at", "each", "hidden", "layer", "for", "directly", "making", "a", "good", "label", "prediction", "gives", "a", "strong", "push", "for", "having", "discriminative", "and", "sensible", "features", "at", "each", "individual", "layer", ".", "In", "eqn", ".", "(", "[", "reference", "]", ")", ",", "and", "are", "respectively", "the", "margin", "and", "squared", "hinge", "loss", "of", "the", "SVM", "classifier", "(", "L2SVM", ")", "at", "the", "output", "layer", "(", "we", "omit", "the", "balance", "term", "in", "front", "of", "the", "hinge", "for", "notational", "simplicity", ")", ";", "in", "eqn", ".", "(", "[", "reference", "]", ")", ",", "and", "are", "respectively", "the", "margin", "and", "squared", "hinge", "loss", "of", "the", "SVM", "classifier", "at", "each", "hidden", "layer", ".", "Note", "that", "for", "each", ",", "the", "directly", "depends", "on", ",", "which", "is", "dependent", "on", "up", "to", "the", "th", "layer", ".", "depends", "on", ",", "which", "is", "decided", "by", "the", "entire", ".", "The", "second", "term", "in", "eqn", ".", "(", "[", "reference", "]", ")", "often", "goes", "to", "zero", "during", "the", "course", "of", "training", ";", "this", "way", ",", "the", "overall", "goal", "of", "producing", "good", "classification", "of", "the", "output", "layer", "is", "not", "altered", "and", "the", "companion", "objective", "just", "acts", "as", "a", "proxy", "or", "regularization", ".", "This", "is", "achieved", "by", "having", "as", "a", "threshold", "(", "a", "hyper", "parameter", ")", "in", "the", "second", "term", "of", "eqn", ".", "(", "[", "reference", "]", ")", "with", "a", "hinge", "loss", ":", "once", "the", "overall", "value", "of", "the", "hidden", "layer", "reaches", "or", "is", "below", ",", "it", "vanishes", "and", "no", "longer", "plays", "role", "in", "the", "learning", "process", ".", "balances", "the", "importance", "of", "the", "error", "in", "the", "output", "objective", "and", "the", "companion", "objective", ".", "In", "addition", ",", "we", "could", "use", "a", "simple", "decay", "function", "as", "to", "enforce", "the", "second", "term", "to", "vanish", "after", "certain", "number", "of", "iterations", ",", "where", "is", "the", "epoch", "step", "and", "is", "the", "total", "number", "of", "epochs", "(", "wheather", "or", "not", "to", "have", "the", "decay", "on", "might", "vary", "in", "different", "experiments", "although", "the", "differences", "may", "not", "be", "very", "big", ")", ".", "To", "summarize", ",", "we", "describe", "this", "optimization", "problem", "as", "follows", ":", "we", "want", "to", "learn", "filters", "/", "weights", "for", "the", "entire", "network", "such", "that", "an", "SVM", "classifier", "trained", "on", "the", "output", "feature", "maps", "(", "that", "depend", "on", "those", "filters", "/", "features", ")", "will", "display", "good", "performance", ".", "We", "seek", "this", "output", "performance", "while", "also", "requiring", "some", "\u201c", "satisfactory", "\u201d", "level", "of", "performance", "on", "the", "part", "of", "the", "hidden", "layer", "classifiers", ".", "We", "are", "saying", ":", "restrict", "attention", "to", "the", "parts", "of", "feature", "space", "that", ",", "when", "considered", "at", "the", "internal", "layers", ",", "lead", "to", "highly", "discriminative", "hidden", "layer", "feature", "maps", "(", "as", "measured", "via", "our", "proxy", "of", "hidden", "-", "layer", "classifier", "performance", ")", ".", "The", "main", "difference", "between", "eqn", ".", "(", "[", "reference", "]", ")", "and", "previous", "attempts", "in", "layer", "-", "wise", "supervised", "training", "is", "that", "we", "perform", "the", "optimization", "altogether", "with", "a", "robust", "measure", "(", "or", "regularization", ")", "of", "the", "hidden", "layer", ".", "For", "example", ",", "greedy", "layer", "-", "wise", "pretraining", "was", "performed", "as", "either", "initialization", "or", "fine", "-", "tuning", "which", "results", "in", "some", "overfitting", ".", "The", "state", "-", "of", "-", "the", "-", "art", "benchmark", "results", "demonstrate", "the", "particular", "advantage", "of", "our", "formulation", ".", "As", "shown", "in", "Figure", "[", "reference", "]", "(", "c", ")", ",", "indeed", "both", "CNN", "and", "DSN", "reach", "training", "error", "near", "zero", "but", "DSN", "demonstrates", "a", "clear", "advantage", "of", "having", "a", "better", "generalization", "capability", ".", "To", "train", "the", "DSN", "model", "using", "SGD", ",", "the", "gradients", "of", "the", "objective", "function", "w.r.t", "the", "parameters", "in", "the", "model", "are", ":", "The", "gradient", "w.r.t", "just", "follows", "the", "conventional", "CNN", "based", "model", "plus", "the", "gradient", "that", "directly", "comes", "from", "the", "hidden", "layer", "supervision", ".", "Next", ",", "we", "provide", "more", "discussions", "to", "and", "try", "to", "understand", "intuitively", "about", "our", "formulation", ",", "eqn", ".", "(", "[", "reference", "]", ")", ".", "For", "ease", "of", "reference", ",", "we", "write", "this", "objective", "function", "as", "where", "and", ".", "subsection", ":", "Stochastic", "Gradient", "Descent", "View", "We", "focus", "on", "the", "convergence", "advantage", "of", "DSN", ",", "instead", "of", "the", "regularization", "to", "the", "generalization", "aspect", ".", "In", "addition", "to", "the", "present", "problem", "in", "CNN", "where", "learned", "features", "are", "not", "always", "intuitive", "and", "discriminative", ",", "the", "difficulty", "of", "training", "deep", "neural", "networks", "has", "been", "discussed", ".", "As", "we", "can", "observe", "from", "eqn", ".", "(", "[", "reference", "]", ")", "and", "(", "[", "reference", "]", ")", ",", "the", "change", "of", "the", "bottom", "layer", "weights", "get", "propagated", "through", "layers", "of", "functions", ",", "leading", "to", "exploding", "or", "vanishing", "gradients", ".", "Various", "techniques", "and", "parameter", "tuning", "tricks", "have", "been", "proposed", "to", "better", "train", "deep", "neural", "networks", ",", "such", "as", "pre", "-", "training", "and", "dropout", ".", "Here", "we", "provide", "a", "somewhat", "loose", "analysis", "to", "our", "proposed", "formulation", ",", "in", "a", "hope", "to", "understand", "its", "advantage", "in", "effectiveness", ".", "The", "objective", "function", "in", "deep", "neural", "networks", "is", "highly", "non", "-", "convex", ".", "Here", "we", "make", "the", "following", "assumptions", "/", "observations", ":", "(", "1", ")", "the", "objective", "/", "energy", "function", "of", "DL", "observes", "a", "large", "\u201c", "flat", "\u201d", "area", "around", "the", "\u201c", "optimal", "\u201d", "solution", "where", "any", "result", "has", "a", "similar", "performance", ";", "locally", "we", "still", "assume", "a", "convex", "(", "or", "even", "-", "strongly", "convex", ")", "function", "whose", "optimization", "is", "often", "performed", "with", "stochastic", "gradient", "descent", "algorithm", ".", "The", "definition", "of", "-", "strongly", "convex", "is", "standard", ":", "A", "function", "is", "-", "strongly", "convex", "if", "and", "any", "subgradient", "at", ",", "and", "the", "update", "rule", "in", "Stochastic", "Gradient", "Descent", "(", "SGD", ")", "at", "step", "is", ",", "where", "refers", "to", "the", "step", "rate", "and", "helps", "to", "project", "onto", "the", "space", "of", ".", "Let", "be", "the", "optimum", "solution", ",", "upper", "bounds", "for", "and", "in", "for", "the", "strongly", "convex", "function", ",", "and", "for", "convex", "function", "in", ".", "Here", "we", "make", "an", "attempt", "to", "understand", "the", "convergence", "of", "eqn", ".", "(", "[", "reference", "]", ")", "w.r.t", ".", ",", "due", "to", "the", "presence", "of", "large", "area", "of", "flat", "function", "shown", "in", "Figure", "(", "[", "reference", "]", ".b", ")", ".", "In", ",", "a", "convergence", "rate", "is", "given", "for", "the", "M", "-", "estimators", "with", "locally", "convex", "function", "with", "compositional", "loss", "and", "regularization", "terms", ".", "Both", "terms", "in", "eqn", ".", "(", "[", "reference", "]", ")", "here", "refer", "to", "the", "same", "class", "label", "prediction", "error", ",", "a", "reason", "for", "calling", "the", "second", "term", "as", "companion", "objective", ".", "Our", "motivation", "is", "two", "-", "fold", ":", "(", "1", ")", "encourage", "the", "features", "learned", "at", "each", "layer", "to", "be", "directly", "discriminative", "for", "class", "label", "prediction", ",", "while", "keeping", "the", "ultimate", "goal", "of", "minimizing", "class", "label", "prediction", "at", "the", "output", "layer", ";", "(", "2", ")", "alleviate", "the", "exploding", "and", "vanishing", "gradients", "problem", "as", "each", "layer", "now", "has", "a", "direct", "supervision", "from", "the", "ground", "truth", "labels", ".", "One", "might", "raise", "a", "concern", "that", "learning", "highly", "discriminative", "intermediate", "stage", "filters", "may", "not", "necessarily", "lead", "to", "the", "best", "prediction", "at", "the", "output", "layer", ".", "An", "illustration", "can", "been", "seen", "in", "Figure", "(", "[", "reference", "]", ".b", ")", ".", "Next", ",", "we", "give", "a", "loose", "theoretical", "analysis", "to", "our", "framework", ",", "which", "is", "also", "validated", "by", "comprehensive", "experimental", "studies", "with", "overwhelming", "advantages", "over", "the", "existing", "methods", ".", "We", "name", "as", "the", "-", "feasible", "set", "for", "a", "function", ".", "First", "we", "show", "that", "a", "feasible", "solution", "for", "leads", "to", "a", "feasible", "one", "to", ".", "That", "is", ":", "theorem", ":", "if", "\u2225w", "(", "m", ")", "\u22252", "+", "\u2113", "((", "^W", "(", "1", ")", ",", "..", ",", "^W", "(", "m", ")),", "w", "(", "m", "))", "\u2264\u03b3", "then", "there", "exists", "(", "^W", "(", "1", ")", ",", "..", ",", "^W", "(", "m", ")", ",", "..", ",", "^W", "(", "m\u2032", ")", ")", "such", "that", "\u2225w", "(", "m\u2032", ")", "\u22252", "+", "\u2113", "((", "^W", "(", "1", ")", ",", "..", ",", "^W", "(", "m", ")", "..", ",", "^W", "(", "m\u2032", ")),", "w", "(", "m\u2032", "))", "\u2264\u03b3", ".", "Note", "that", "we", "drop", "the", ">", "W", "(", "j", "),", "jm", "since", "the", "filters", "above", "layer", "m", "do", "not", "participate", "in", "the", "computation", "for", "the", "objective", "function", "of", "this", "layer", ".", "As", "we", "can", "see", "from", "an", "illustration", "of", "our", "network", "architecture", "shown", "in", "fig", ".", "(", "[", "reference", "]", ".a", ")", ",", "for", "such", "that", ".", "Then", "there", "is", "a", "trivial", "solution", "for", "the", "network", "for", "every", "layer", "up", "to", ",", "we", "let", "and", ",", "meaning", "that", "the", "filters", "will", "be", "identity", "matrices", ".", "This", "results", "in", ".", "Lemma", "[", "reference", "]", "shows", "that", "a", "good", "solution", "for", "is", "also", "a", "good", "one", "for", ",", "but", "it", "may", "not", "be", "the", "case", "the", "other", "way", "around", ".", "That", "is", ":", "a", "that", "makes", "small", "may", "not", "necessarily", "produce", "discriminative", "features", "for", "the", "hidden", "layers", "to", "have", "a", "small", ".", "However", ",", "can", "be", "viewed", "as", "a", "regularization", "term", ".", "Since", "observes", "a", "very", "flat", "area", "near", "even", "zero", "on", "the", "training", "data", "and", "it", "is", "ultimately", "the", "test", "error", "that", "we", "really", "care", "about", ",", "we", "thus", "only", "focus", "on", "the", ",", ",", "which", "makes", "both", "and", "small", ".", "Therefore", ",", "it", "is", "not", "unreasonable", "to", "assume", "that", "and", "share", "the", "same", "optimal", ".", "Let", "and", "be", "strongly", "convex", "around", ",", "and", ",", "with", "and", ",", "where", "and", "are", "the", "subgradients", "for", "and", "at", "respectively", ".", "It", "can", "be", "directly", "seen", "that", "is", "also", "strongly", "convex", "and", "for", "subgradient", "of", "at", ",", ".", "theorem", ":", "Suppose", "\u2264\u2062E", "[", "\u2225^gpt\u22252", "]", "G2", "and", "\u2264\u2062E", "[", "\u2225^gqt\u22252", "]", "G2", ",", "and", "we", "use", "the", "update", "rule", "of", "=", "W", "+", "t1\u2062\u03a0W", "(-", "Wt\u2062\u03b7t", "(+", "^gpt^gqt", ")", ")", "where", "=", "\u2062E", "[", "^gpt", "]", "gpt", "and", "=", "\u2062E", "[", "^gqt", "]", "gqt", ".", "If", "we", "use", "=", "\u03b7t\u2062", "/", "1", "(+", "\u03bb1\u03bb2", ")", "t", ",", "then", "at", "time", "stamp", "T", "Since", ",", "it", "can", "be", "directly", "seen", "that", "Based", "on", "lemma", "1", "in", ",", "this", "upper", "bound", "directly", "holds", ".", "theorem", ":", "Following", "the", "assumptions", "in", "lemma", ",", "but", "now", "we", "assume", "=", "\u03b7t", "/", "1", "t", "since", "\u03bb1", "and", "\u03bb2", "are", "not", "always", "readily", "available", ",", "then", "started", "from", "\u2264\u2225", "-", "W1W\u22c6\u22252D", "the", "convergence", "rate", "is", "bounded", "by", "Let", ",", "we", "have", "Thus", ",", "Therefore", ",", "with", ",", "With", "being", "small", ",", "we", "have", "theorem", ":", "Let", "\u2062P", "(", "W", ")", "be", "\u03bb1", "-", "strongly", "convex", "and", "\u2062Q", "(", "W", ")", "be", "\u03bb2", "-", "strongly", "convex", "near", "optimal", "W\u22c6", "and", "denote", "WT", "(", "F", ")", "and", "WT", "(", "P", ")", "as", "the", "solution", "after", "T", "iterations", "when", "applying", "SGD", "on", "\u2062F", "(", "W", ")", "and", "\u2062P", "(", "W", ")", "respectively", ".", "Then", "our", "deeply", "supervised", "framework", "in", "eqn", ".", "(", ")", "improves", "the", "the", "speed", "over", "using", "top", "layer", "only", "by", "=", "\u2062E", "[", "\u2225", "-", "WT", "(", "P", ")", "W\u22c6\u22252", "]", "\u2062E", "[", "\u2225", "-", "WT", "(", "F", ")", "W\u22c6\u22252", "]", "\u2062\u0398", "(+", "1\u03bb22\u03bb12", "),", "=\u2062when\u03b7t\u2062", "/", "1\u03bbt", ",", "\u2062and", "=", "\u2062E", "[", "\u2225", "-", "WT", "(", "P", ")", "W\u22c6\u22252", "]", "\u2062E", "[", "\u2225", "-", "WT", "(", "F", ")", "W\u22c6\u22252", "]", "\u2062\u0398", "(", "e\u2062ln", "(", "T", ")", "\u03bb2", "),", "=\u2062when\u03b7t", "/", "1", "t", "Lemma", "[", "reference", "]", "shows", "the", "compatibility", "of", "the", "companion", "objective", "of", "w.r.t", "the", "output", "objective", ".", "The", "first", "equation", "can", "be", "directly", "derived", "from", "lemma", "[", "reference", "]", "and", "the", "second", "equation", "can", "be", "seen", "from", "lemma", "[", "reference", "]", ".", "In", "general", "which", "leads", "to", "a", "great", "improvement", "in", "convergence", "speed", "and", "the", "constraints", "in", "each", "hidden", "layer", "also", "helps", "to", "learning", "filters", "which", "are", "directly", "discriminative", ".", "section", ":", "Experiments", "We", "evaluate", "the", "proposed", "DSN", "method", "on", "four", "standard", "benchmark", "datasets", ":", "MNIST", ",", "CIFAR", "-", "10", ",", "CIFAR", "-", "100", "and", "SVHN", ".", "We", "follow", "a", "common", "training", "protocol", "used", "by", "Krizhevsky", "et", "al", ".", "in", "all", "experiments", ".", "We", "use", "SGD", "solver", "with", "mini", "-", "batch", "size", "of", "at", "a", "fixed", "constant", "momentum", "value", "of", ".", "Initial", "value", "for", "learning", "rate", "and", "weight", "decay", "factor", "is", "determined", "based", "on", "the", "validation", "set", ".", "For", "a", "fair", "comparison", "and", "clear", "illustration", "of", "the", "effectiveness", "of", "DSN", ",", "we", "match", "the", "complexity", "of", "our", "model", "with", "that", "in", "network", "architectures", "used", "in", "and", "to", "have", "a", "comparable", "number", "of", "parameters", ".", "We", "also", "incorporate", "two", "dropout", "layers", "with", "dropout", "rate", "at", ".", "Companion", "objective", "at", "the", "convolutional", "layers", "is", "imposed", "to", "backpropagate", "the", "classification", "error", "guidance", "to", "the", "underlying", "convolutional", "layers", ".", "Learning", "rates", "are", "annealed", "during", "training", "by", "a", "factor", "of", "according", "to", "an", "epoch", "schedule", "determined", "on", "the", "validation", "set", ".", "The", "proposed", "DSN", "framework", "is", "not", "difficult", "to", "train", "and", "there", "are", "no", "particular", "engineering", "tricks", "adopted", ".", "Our", "system", "is", "built", "on", "top", "of", "widely", "used", "Caffe", "infrastructure", ".", "For", "the", "network", "architecture", "setup", ",", "we", "adopted", "the", "mlpconv", "layer", "and", "global", "averaged", "pooling", "scheme", "introduced", "in", ".", "DSN", "can", "be", "equipped", "with", "different", "types", "of", "loss", "functions", ",", "such", "as", "Softmax", "and", "SVM", ".", "We", "show", "performance", "boost", "of", "DSN", "-", "SVM", "and", "DSN", "-", "Softmax", "over", "CNN", "-", "SVM", "and", "CNN", "-", "Softmax", "respectively", "(", "see", "Figure", "(", "[", "reference", "]", ".a", ")", ")", ".", "The", "performance", "gain", "is", "more", "evident", "in", "presence", "of", "small", "training", "data", "(", "see", "Figure", "(", "[", "reference", "]", ".b", ")", ")", ";", "this", "might", "partially", "ease", "the", "burden", "of", "requiring", "large", "training", "data", "for", "DL", ".", "Overall", ",", "we", "observe", "state", "-", "of", "-", "the", "-", "art", "classification", "error", "in", "all", "four", "datasets", "(", "without", "data", "augmentation", ")", ",", "for", "MINIST", ",", "for", "CIFAR", "-", "10", ",", "for", "CIFAR", "-", "100", ",", "and", "for", "SVHN", "(", "for", "CIFAR", "-", "10", "with", "data", "augmentation", ")", ".", "All", "results", "are", "achieved", "without", "using", "averaging", ",", "which", "is", "not", "exclusive", "to", "our", "method", ".", "Figure", "(", "[", "reference", "]", ")", "gives", "an", "illustration", "of", "some", "learned", "features", ".", "subsection", ":", "MNIST", "We", "first", "validate", "the", "effectiveness", "of", "the", "proposed", "DSN", "on", "the", "MNIST", "handwritten", "digits", "classification", "task", ",", "a", "widely", "and", "extensively", "adopted", "benchmark", "in", "machine", "learning", ".", "MNIST", "dataset", "consists", "of", "images", "of", "10", "different", "classes", "(", "0", "to", "9", ")", "of", "size", "with", "60", ",", "000", "training", "samples", "and", "10", ",", "000", "test", "samples", ".", "Figure", "[", "reference", "]", "(", "a", ")", "and", "(", "b", ")", "show", "results", "from", "four", "methods", ",", "namely", ":", "(", "1", ")", "conventional", "CNN", "with", "softmax", "loss", "(", "CNN", "-", "Softmax", ")", ",", "(", "2", ")", "the", "proposed", "DSN", "with", "softmax", "loss", "(", "DSN", "-", "Softmax", ")", ",", "(", "3", ")", "CNN", "with", "max", "-", "margin", "objective", "(", "CNN", "-", "SVM", ")", ",", "and", "(", "4", ")", "the", "proposed", "DSN", "with", "max", "-", "margin", "objective", "(", "DSN", "-", "SVM", ")", ".", "DSN", "-", "Softmax", "and", "DSN", "-", "SVM", "outperform", "both", "their", "competing", "CNN", "algorithms", "(", "DSN", "-", "SVM", "shows", "classification", "error", "of", "under", "a", "single", "model", "without", "data", "whitening", "and", "augmentation", ")", ".", "Figure", "[", "reference", "]", "(", "b", ")", "shows", "classification", "error", "of", "the", "competing", "methods", "when", "trained", "w.r.t", ".", "varying", "sizes", "of", "training", "samples", "(", "gain", "of", "DSN", "-", "SVM", "over", "CNN", "-", "Softmax", "at", "samples", ".", "Figure", "[", "reference", "]", "(", "c", ")", "shows", "a", "comparison", "of", "generalization", "error", "between", "CNN", "and", "DSN", ".", "subsection", ":", "CIFAR", "-", "10", "and", "CIFAR", "-", "100", "CIFAR", "-", "10", "dataset", "consists", "of", "color", "images", ".", "A", "total", "number", "of", "60", ",", "000", "images", "are", "split", "into", "50", ",", "000", "training", "and", "10", ",", "000", "testing", "images", ".", "The", "dataset", "is", "preprocessed", "by", "global", "contrast", "normalization", ".", "To", "compare", "our", "results", "with", "the", "previous", "state", "-", "of", "-", "the", "-", "art", ",", "in", "this", "case", ",", "we", "also", "augmented", "the", "dataset", "by", "zero", "padding", "4", "pixels", "on", "each", "side", ",", "then", "do", "corner", "cropping", "and", "random", "flipping", "on", "the", "fly", "during", "training", ".", "No", "model", "averaging", "is", "done", "at", "the", "test", "phase", "and", "we", "only", "crop", "the", "center", "of", "a", "test", "sample", ".", "Table", "(", "[", "reference", "]", ")", "shows", "our", "result", ".", "Our", "DSN", "model", "achieved", "an", "error", "rates", "of", "without", "data", "augmentation", "and", "with", "data", "agumentation", "(", "the", "best", "known", "result", "to", "our", "knowledge", ")", ".", "DSN", "also", "provides", "added", "robustness", "to", "hyperparameter", "choice", ",", "in", "that", "the", "early", "layers", "are", "guided", "with", "direct", "classification", "loss", ",", "leading", "to", "a", "faster", "convergence", "rate", "and", "relieved", "burden", "on", "heavy", "hyperparameter", "tuning", ".", "We", "also", "compared", "the", "gradients", "in", "DSN", "and", "those", "in", "CNN", ",", "observing", "times", "greater", "gradient", "variance", "of", "DSN", "over", "CNN", "in", "the", "first", "convolutional", "layer", ".", "This", "is", "consistent", "with", "an", "observation", "in", ",", "and", "the", "assumptions", "and", "motivations", "we", "make", "in", "this", "work", ".", "To", "see", "what", "the", "features", "have", "been", "learned", "in", "DSN", "vs.", "CNN", ",", "we", "select", "one", "example", "image", "from", "each", "of", "the", "ten", "categories", "of", "CIFAR", "-", "10", "dataset", ",", "run", "one", "forward", "pass", ",", "and", "show", "the", "feature", "maps", "learned", "from", "the", "first", "(", "bottom", ")", "convolutional", "layer", "in", "Figure", "(", "[", "reference", "]", ")", ".", "Only", "the", "top", "30", "%", "activations", "are", "shown", "in", "each", "of", "the", "feature", "maps", ".", "Feature", "maps", "learned", "by", "DSN", "show", "to", "be", "more", "intuitive", "than", "those", "by", "CNN", ".", "CIFAR", "-", "100", "dataset", "is", "similar", "to", "CIFAR", "-", "10", "dataset", ",", "except", "that", "it", "has", "100", "classes", ".", "The", "number", "of", "images", "for", "each", "class", "is", "then", "instead", "of", "as", "in", "CIFAR", "-", "10", ",", "which", "makes", "the", "classification", "task", "more", "challenging", ".", "We", "use", "the", "same", "network", "settings", "as", "in", "CIFAR", "-", "10", ".", "Table", "(", "[", "reference", "]", ")", "shows", "previous", "best", "results", "and", "is", "reported", "by", "DSN", ".", "The", "performance", "boost", "consistently", "shown", "on", "both", "CIFAR", "-", "10", "and", "CIFAR", "-", "100", "again", "demonstrates", "the", "advantage", "of", "the", "DSN", "method", ".", "subsection", ":", "Street", "View", "House", "Numbers", "Street", "View", "House", "Numbers", "(", "SVHN", ")", "dataset", "consists", "of", "digits", "for", "training", ",", "digits", "for", "testing", ",", "and", "extra", "training", "samples", "on", "color", "images", ".", "We", "followed", "the", "previous", "works", "for", "data", "preparation", ",", "namely", ":", "we", "select", "400", "samples", "per", "class", "from", "the", "training", "set", "and", "200", "samples", "per", "class", "from", "the", "extra", "set", ".", "The", "remaining", "598", ",", "388", "images", "are", "used", "for", "training", ".", "We", "followed", "to", "preprocess", "the", "dataset", "by", "Local", "Contrast", "Normalization", "(", "LCN", ")", ".", "We", "do", "not", "do", "data", "augmentation", "in", "training", "and", "use", "only", "a", "single", "model", "in", "testing", ".", "Table", "[", "reference", "]", "shows", "recent", "comparable", "results", ".", "Note", "that", "Dropconnect", "uses", "data", "augmentation", "and", "multiple", "model", "voting", ".", "section", ":", "Conclusions", "In", "this", "paper", ",", "we", "have", "presented", "a", "new", "formulation", ",", "deeply", "-", "supervised", "nets", "(", "DSN", ")", ",", "attempting", "to", "make", "a", "more", "transparent", "learning", "process", "for", "deep", "learning", ".", "Evident", "performance", "enhancement", "over", "existing", "approaches", "has", "been", "obtained", ".", "A", "stochastic", "gradient", "view", "also", "sheds", "light", "to", "the", "understanding", "of", "our", "formulation", ".", "section", ":", "Acknowledgments", "This", "work", "is", "supported", "by", "NSF", "award", "IIS", "-", "1216528", "(", "IIS", "-", "1360566", ")", "and", "NSF", "award", "IIS", "-", "0844566", "(", "IIS", "-", "1360568", ")", ".", "We", "thank", "Min", "Lin", ",", "Naiyan", "Wang", ",", "Baoyuan", "Wang", ",", "Jingdong", "Wang", ",", "Liwei", "Wang", ",", "and", "David", "Wipf", "for", "help", "discussions", ".", "We", "are", "greatful", "for", "the", "generous", "donation", "of", "the", "GPUs", "by", "NVIDIA", ".", "bibliography", ":", "References"]}