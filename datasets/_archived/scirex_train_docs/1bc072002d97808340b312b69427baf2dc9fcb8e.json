{"coref": {"AUC": [[3199, 3203], [3204, 3205], [3208, 3210], [3285, 3286], [3624, 3626], [4028, 4029], [4208, 4210]], "Click-Through_Rate_Prediction": [[253, 256], [259, 260], [379, 385], [741, 743], [814, 816], [843, 846], [928, 931], [1100, 1102], [1243, 1245], [1265, 1266], [1352, 1353], [1588, 1590], [1776, 1778], [2353, 2355], [3189, 3191], [4509, 4511], [16, 19], [85, 86], [591, 592]], "Company_": [], "Criteo": [], "FNN": [[969, 974], [975, 976], [989, 990], [1608, 1614], [1615, 1616], [1726, 1732], [1733, 1734], [1738, 1739], [2461, 2462], [2791, 2792], [3102, 3108], [3167, 3168], [3238, 3239], [3290, 3291], [3316, 3317], [4138, 4139], [4218, 4219], [4312, 4313], [4319, 4320], [4361, 4362], [4369, 4370], [2382, 2383]], "Log_Loss": [], "iPinYou": [[2850, 2852]]}, "coref_non_salient": {"0": [[950, 952], [1062, 1064], [1270, 1272], [1297, 1299]], "1": [[93, 95], [397, 398], [433, 435], [3063, 3065]], "10": [[193, 194], [2502, 2503], [2688, 2689], [3242, 3243]], "100": [[531, 534]], "101": [[568, 570]], "102": [[2698, 2700]], "103": [[2075, 2076]], "104": [[2332, 2336]], "105": [[307, 309]], "106": [[1763, 1767]], "107": [[619, 621]], "108": [[2071, 2074]], "109": [[365, 366]], "11": [[2291, 2293], [2696, 2697]], "110": [[2127, 2131]], "111": [[407, 410]], "112": [[3450, 3452]], "113": [[674, 676]], "114": [[411, 414]], "115": [[2813, 2815]], "116": [[4552, 4554]], "117": [[2561, 2565]], "118": [[1034, 1037], [2555, 2558], [3153, 3156], [3340, 3343], [3479, 3482]], "119": [[1602, 1604]], "12": [[625, 627], [717, 719], [810, 812], [847, 850], [964, 967], [1325, 1327], [1504, 1507]], "120": [[3580, 3582]], "121": [[1394, 1397], [638, 641]], "122": [[3784, 3789]], "123": [[1999, 2002]], "124": [[1452, 1454], [1490, 1492]], "125": [[1826, 1829]], "126": [[272, 274]], "127": [[360, 364]], "128": [[279, 281]], "129": [[34, 36]], "13": [[1747, 1749], [2117, 2119], [4309, 4311]], "130": [[726, 730]], "131": [[687, 689]], "132": [[1040, 1047]], "133": [[631, 633], [1388, 1390]], "134": [[992, 997]], "135": [[3843, 3846]], "136": [[3938, 3940]], "137": [[10, 13]], "14": [[38, 40], [283, 285], [302, 304], [1146, 1148], [1158, 1161]], "15": [[4112, 4114], [4183, 4185], [4595, 4597]], "16": [[4005, 4007], [4081, 4083], [4180, 4182], [4247, 4249], [4279, 4281], [4354, 4356], [4372, 4374]], "17": [[2005, 2008], [2318, 2320], [2733, 2735]], "18": [[248, 250], [4405, 4410]], "19": [[1263, 1264], [215, 216], [672, 673], [856, 857], [1379, 1380], [1410, 1411], [1434, 1435], [1951, 1952], [2262, 2263], [2324, 2325], [2467, 2468], [2516, 2517], [2528, 2529], [2601, 2602], [2623, 2624], [2674, 2675], [3026, 3027], [3070, 3071], [3428, 3429], [3439, 3440], [3919, 3920], [3942, 3943], [4001, 4002], [4065, 4066], [4087, 4088], [4396, 4397], [4469, 4470], [4476, 4477], [4556, 4557]], "2": [[1067, 1071], [1992, 1994]], "20": [[2540, 2544], [3131, 3135], [4460, 4464]], "21": [[634, 636], [1350, 1351], [1391, 1393]], "22": [[2803, 2804], [3992, 3993], [4039, 4040], [4045, 4046], [4056, 4057]], "23": [[4439, 4444]], "24": [[2774, 2777], [2788, 2790], [3980, 3982], [4194, 4196]], "25": [[978, 983], [1618, 1623], [2430, 2435], [3120, 3125]], "26": [[1709, 1711], [3975, 3977], [4115, 4117], [4436, 4438], [4498, 4500]], "27": [[257, 258], [21, 22]], "28": [[386, 387], [391, 392], [585, 586], [733, 734], [1702, 1703], [3055, 3056], [3218, 3219]], "29": [[189, 192], [1461, 1464], [2498, 2501]], "3": [[984, 985], [1018, 1019], [1624, 1625], [2436, 2437], [2444, 2445], [2459, 2460], [2727, 2728], [3169, 3170], [3240, 3241], [3292, 3293], [3357, 3358], [4140, 4141], [4220, 4221], [4274, 4275], [4299, 4300], [4363, 4364], [4379, 4380], [4445, 4451], [2474, 2475], [2761, 2762], [4031, 4032]], "30": [[196, 200], [1465, 1470]], "31": [[1496, 1499], [2337, 2339], [2751, 2754]], "32": [[1831, 1833], [3516, 3518]], "33": [[183, 185], [500, 502], [998, 1000], [1276, 1278], [1743, 1745], [1875, 1877], [1953, 1955], [3082, 3084]], "34": [[3550, 3552], [3558, 3560]], "35": [[2708, 2710]], "36": [[1251, 1253], [4592, 4593]], "37": [[186, 187], [503, 504], [2283, 2284]], "38": [[4349, 4350]], "39": [[818, 820], [1416, 1418]], "4": [[1440, 1442], [3952, 3954]], "40": [[141, 144], [857, 860], [1021, 1024], [1357, 1360], [3372, 3375], [3649, 3652], [4397, 4400]], "41": [[1548, 1552]], "42": [[695, 698], [3861, 3863], [3871, 3873], [4171, 4173], [4190, 4192]], "43": [[3835, 3838], [3890, 3892]], "44": [[3949, 3951]], "45": [[4422, 4432]], "46": [[3234, 3235], [3263, 3264], [3299, 3300]], "47": [[2416, 2419]], "48": [[2217, 2220]], "49": [[472, 476], [3086, 3090]], "5": [[1455, 1457], [1493, 1495]], "50": [[4453, 4456]], "51": [[4561, 4565]], "52": [[2766, 2767], [2827, 2828]], "53": [[2157, 2160]], "54": [[2375, 2380]], "55": [[4543, 4545]], "56": [[3365, 3367]], "57": [[1048, 1051], [2577, 2580], [3157, 3160], [3336, 3339], [3483, 3486]], "58": [[2264, 2266], [2690, 2692]], "59": [[494, 495], [3078, 3081]], "6": [[2, 4], [442, 443], [937, 939], [1446, 1447], [2816, 2818]], "60": [[1279, 1280], [1300, 1301], [1956, 1957], [2124, 2125], [2154, 2155], [2237, 2238], [3236, 3237], [3257, 3258], [3301, 3302], [3314, 3315], [3331, 3332], [2063, 2064], [2186, 2187], [2250, 2251], [2327, 2328], [2385, 2386], [2397, 2398]], "61": [[428, 432], [1203, 1207], [1635, 1639], [2968, 2972]], "62": [[2344, 2349]], "63": [[1027, 1033]], "64": [[275, 277], [350, 352]], "65": [[3996, 3999]], "66": [[2287, 2290], [3409, 3412]], "67": [[31, 33], [269, 271]], "68": [[2189, 2193]], "69": [[4334, 4337], [2482, 2485]], "7": [[4036, 4038], [4047, 4048]], "70": [[700, 705]], "71": [[541, 542]], "72": [[616, 618]], "73": [[3653, 3655]], "74": [[28, 30], [266, 268]], "75": [[2194, 2195]], "76": [[2525, 2527]], "77": [[1939, 1941]], "78": [[1331, 1334]], "79": [[1510, 1513]], "8": [[201, 202], [2510, 2511], [2694, 2695], [3136, 3141], [3244, 3245]], "80": [[2505, 2509]], "81": [[3801, 3804]], "82": [[401, 403], [1186, 1188], [3059, 3061]], "83": [[527, 530]], "84": [[177, 180]], "85": [[353, 355]], "86": [[714, 716]], "87": [[1285, 1288]], "88": [[3443, 3445]], "89": [[404, 406]], "9": [[145, 146], [168, 169], [861, 862], [1361, 1362], [1382, 1383], [1540, 1541], [1586, 1587], [2227, 2228], [4401, 4402], [4480, 4481]], "90": [[1121, 1125]], "91": [[1155, 1157]], "92": [[543, 545]], "93": [[1055, 1058]], "94": [[1398, 1399], [1554, 1555], [642, 643]], "95": [[954, 958]], "96": [[376, 378]], "97": [[315, 317]], "98": [[917, 921]], "99": [[4106, 4107]]}, "doc_id": "1bc072002d97808340b312b69427baf2dc9fcb8e", "method_subrelations": {"FNN": [[[0, 3], "FNN"]]}, "n_ary_relations": [{"Material": "Company_", "Method": "FNN", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.8683"}, {"Material": "Company_", "Method": "FNN", "Metric": "Log_Loss", "Task": "Click-Through_Rate_Prediction", "score": "0.02629"}, {"Material": "Criteo", "Method": "FNN", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.7963"}, {"Material": "Criteo", "Method": "FNN", "Metric": "Log_Loss", "Task": "Click-Through_Rate_Prediction", "score": "0.45738"}, {"Material": "iPinYou", "Method": "FNN", "Metric": "AUC", "Task": "Click-Through_Rate_Prediction", "score": "0.7619"}], "ner": [[2, 4, "Task"], [10, 13, "Task"], [28, 30, "Task"], [31, 33, "Task"], [34, 36, "Task"], [38, 40, "Task"], [93, 95, "Method"], [141, 144, "Method"], [145, 146, "Method"], [168, 169, "Method"], [177, 180, "Method"], [183, 185, "Method"], [186, 187, "Method"], [189, 192, "Method"], [193, 194, "Method"], [196, 200, "Method"], [201, 202, "Method"], [248, 250, "Task"], [253, 256, "Task"], [257, 258, "Task"], [259, 260, "Task"], [266, 268, "Task"], [269, 271, "Task"], [272, 274, "Task"], [275, 277, "Task"], [279, 281, "Task"], [283, 285, "Task"], [302, 304, "Task"], [307, 309, "Method"], [315, 317, "Method"], [350, 352, "Task"], [353, 355, "Task"], [360, 364, "Task"], [365, 366, "Task"], [376, 378, "Method"], [379, 385, "Task"], [386, 387, "Metric"], [397, 398, "Method"], [401, 403, "Method"], [404, 406, "Method"], [407, 410, "Method"], [411, 414, "Method"], [428, 432, "Method"], [433, 435, "Method"], [442, 443, "Task"], [472, 476, "Method"], [494, 495, "Task"], [500, 502, "Method"], [503, 504, "Method"], [527, 530, "Method"], [531, 534, "Method"], [541, 542, "Method"], [543, 545, "Method"], [568, 570, "Method"], [616, 618, "Method"], [619, 621, "Task"], [625, 627, "Method"], [631, 633, "Task"], [634, 636, "Task"], [674, 676, "Method"], [687, 689, "Method"], [695, 698, "Method"], [700, 705, "Task"], [714, 716, "Method"], [717, 719, "Method"], [726, 730, "Metric"], [741, 743, "Task"], [810, 812, "Method"], [814, 816, "Task"], [818, 820, "Method"], [843, 846, "Task"], [847, 850, "Method"], [857, 860, "Method"], [861, 862, "Method"], [917, 921, "Method"], [928, 931, "Task"], [937, 939, "Task"], [950, 952, "Method"], [954, 958, "Method"], [964, 967, "Method"], [969, 974, "Method"], [975, 976, "Method"], [978, 983, "Method"], [984, 985, "Method"], [989, 990, "Method"], [992, 997, "Method"], [998, 1000, "Method"], [1018, 1019, "Method"], [1021, 1024, "Method"], [1027, 1033, "Method"], [1034, 1037, "Method"], [1040, 1047, "Method"], [1048, 1051, "Method"], [1055, 1058, "Method"], [1062, 1064, "Method"], [1067, 1071, "Method"], [1100, 1102, "Task"], [1121, 1125, "Metric"], [1146, 1148, "Task"], [1155, 1157, "Task"], [1158, 1161, "Task"], [1186, 1188, "Method"], [1203, 1207, "Method"], [1243, 1245, "Task"], [1251, 1253, "Metric"], [1263, 1264, "Task"], [1265, 1266, "Task"], [1270, 1272, "Method"], [1276, 1278, "Method"], [1279, 1280, "Method"], [1285, 1288, "Task"], [1297, 1299, "Method"], [1300, 1301, "Method"], [1325, 1327, "Method"], [1331, 1334, "Task"], [1350, 1351, "Task"], [1352, 1353, "Task"], [1357, 1360, "Method"], [1361, 1362, "Method"], [1382, 1383, "Method"], [1388, 1390, "Task"], [1391, 1393, "Task"], [1394, 1397, "Task"], [1398, 1399, "Task"], [1416, 1418, "Method"], [1440, 1442, "Method"], [1446, 1447, "Task"], [1452, 1454, "Method"], [1455, 1457, "Method"], [1461, 1464, "Method"], [1465, 1470, "Method"], [1490, 1492, "Method"], [1493, 1495, "Method"], [1496, 1499, "Method"], [1504, 1507, "Method"], [1510, 1513, "Method"], [1540, 1541, "Method"], [1548, 1552, "Method"], [1554, 1555, "Task"], [1586, 1587, "Method"], [1588, 1590, "Task"], [1602, 1604, "Method"], [1608, 1614, "Method"], [1615, 1616, "Method"], [1618, 1623, "Method"], [1624, 1625, "Method"], [1635, 1639, "Method"], [1709, 1711, "Method"], [1726, 1732, "Method"], [1733, 1734, "Method"], [1738, 1739, "Method"], [1743, 1745, "Method"], [1747, 1749, "Method"], [1763, 1767, "Method"], [1776, 1778, "Task"], [1826, 1829, "Metric"], [1831, 1833, "Method"], [1875, 1877, "Method"], [1939, 1941, "Method"], [1953, 1955, "Method"], [1956, 1957, "Method"], [1992, 1994, "Method"], [1999, 2002, "Method"], [2005, 2008, "Metric"], [2071, 2074, "Method"], [2075, 2076, "Method"], [2117, 2119, "Method"], [2124, 2125, "Method"], [2127, 2131, "Method"], [2154, 2155, "Method"], [2157, 2160, "Method"], [2189, 2193, "Method"], [2194, 2195, "Task"], [2217, 2220, "Task"], [2227, 2228, "Method"], [2237, 2238, "Method"], [2264, 2266, "Method"], [2283, 2284, "Method"], [2287, 2290, "Method"], [2291, 2293, "Method"], [2318, 2320, "Metric"], [2332, 2336, "Method"], [2337, 2339, "Method"], [2344, 2349, "Metric"], [2353, 2355, "Task"], [2375, 2380, "Method"], [2416, 2419, "Task"], [2430, 2435, "Method"], [2436, 2437, "Method"], [2444, 2445, "Method"], [2459, 2460, "Method"], [2461, 2462, "Method"], [2498, 2501, "Method"], [2502, 2503, "Method"], [2505, 2509, "Method"], [2510, 2511, "Method"], [2525, 2527, "Task"], [2540, 2544, "Method"], [2555, 2558, "Method"], [2561, 2565, "Method"], [2577, 2580, "Method"], [2688, 2689, "Method"], [2690, 2692, "Method"], [2694, 2695, "Method"], [2696, 2697, "Method"], [2698, 2700, "Method"], [2708, 2710, "Metric"], [2727, 2728, "Method"], [2733, 2735, "Metric"], [2751, 2754, "Method"], [2766, 2767, "Method"], [2774, 2777, "Method"], [2788, 2790, "Method"], [2791, 2792, "Method"], [2803, 2804, "Method"], [2813, 2815, "Method"], [2816, 2818, "Task"], [2827, 2828, "Method"], [2850, 2852, "Material"], [2968, 2972, "Method"], [3059, 3061, "Method"], [3063, 3065, "Method"], [3078, 3081, "Task"], [3082, 3084, "Method"], [3086, 3090, "Method"], [3102, 3108, "Method"], [3120, 3125, "Method"], [3131, 3135, "Method"], [3136, 3141, "Method"], [3153, 3156, "Method"], [3157, 3160, "Method"], [3167, 3168, "Method"], [3169, 3170, "Method"], [3189, 3191, "Task"], [3199, 3203, "Metric"], [3204, 3205, "Metric"], [3208, 3210, "Metric"], [3234, 3235, "Method"], [3236, 3237, "Method"], [3238, 3239, "Method"], [3240, 3241, "Method"], [3242, 3243, "Method"], [3244, 3245, "Method"], [3257, 3258, "Method"], [3263, 3264, "Method"], [3285, 3286, "Metric"], [3290, 3291, "Method"], [3292, 3293, "Method"], [3299, 3300, "Method"], [3301, 3302, "Method"], [3314, 3315, "Method"], [3316, 3317, "Method"], [3331, 3332, "Method"], [3336, 3339, "Method"], [3340, 3343, "Method"], [3357, 3358, "Method"], [3365, 3367, "Method"], [3372, 3375, "Method"], [3409, 3412, "Method"], [3443, 3445, "Metric"], [3450, 3452, "Metric"], [3479, 3482, "Method"], [3483, 3486, "Method"], [3550, 3552, "Method"], [3580, 3582, "Task"], [3624, 3626, "Metric"], [3649, 3652, "Method"], [3653, 3655, "Method"], [3784, 3789, "Method"], [3801, 3804, "Method"], [3835, 3838, "Method"], [3843, 3846, "Metric"], [3861, 3863, "Method"], [3871, 3873, "Method"], [3890, 3892, "Method"], [3938, 3940, "Method"], [3949, 3951, "Task"], [3952, 3954, "Method"], [3975, 3977, "Method"], [3980, 3982, "Method"], [3992, 3993, "Method"], [3996, 3999, "Task"], [4005, 4007, "Metric"], [4028, 4029, "Metric"], [4036, 4038, "Method"], [4039, 4040, "Method"], [4045, 4046, "Method"], [4047, 4048, "Method"], [4056, 4057, "Method"], [4081, 4083, "Metric"], [4106, 4107, "Method"], [4112, 4114, "Metric"], [4115, 4117, "Method"], [4138, 4139, "Method"], [4140, 4141, "Method"], [4171, 4173, "Method"], [4180, 4182, "Metric"], [4183, 4185, "Metric"], [4190, 4192, "Method"], [4194, 4196, "Method"], [4208, 4210, "Metric"], [4218, 4219, "Method"], [4220, 4221, "Method"], [4247, 4249, "Metric"], [4274, 4275, "Method"], [4279, 4281, "Metric"], [4299, 4300, "Method"], [4309, 4311, "Method"], [4312, 4313, "Method"], [4319, 4320, "Method"], [4334, 4337, "Method"], [4349, 4350, "Task"], [4354, 4356, "Metric"], [4361, 4362, "Method"], [4363, 4364, "Method"], [4369, 4370, "Method"], [4372, 4374, "Metric"], [4379, 4380, "Method"], [4397, 4400, "Method"], [4401, 4402, "Method"], [4405, 4410, "Task"], [4422, 4432, "Task"], [4436, 4438, "Method"], [4439, 4444, "Method"], [4445, 4451, "Method"], [4453, 4456, "Method"], [4480, 4481, "Method"], [4498, 4500, "Method"], [4509, 4511, "Task"], [4543, 4545, "Method"], [4552, 4554, "Task"], [4561, 4565, "Method"], [4592, 4593, "Metric"], [4595, 4597, "Metric"], [16, 19, "Task"], [21, 22, "Task"], [85, 86, "Task"], [215, 216, "Task"], [391, 392, "Metric"], [585, 586, "Metric"], [591, 592, "Task"], [638, 641, "Task"], [642, 643, "Task"], [672, 673, "Task"], [733, 734, "Metric"], [856, 857, "Task"], [1379, 1380, "Task"], [1410, 1411, "Task"], [1434, 1435, "Task"], [1702, 1703, "Metric"], [1951, 1952, "Task"], [2063, 2064, "Method"], [2186, 2187, "Method"], [2250, 2251, "Method"], [2262, 2263, "Task"], [2324, 2325, "Task"], [2327, 2328, "Method"], [2382, 2383, "Method"], [2385, 2386, "Method"], [2397, 2398, "Method"], [2467, 2468, "Task"], [2474, 2475, "Method"], [2482, 2485, "Method"], [2516, 2517, "Task"], [2528, 2529, "Task"], [2601, 2602, "Task"], [2623, 2624, "Task"], [2674, 2675, "Task"], [2761, 2762, "Method"], [3026, 3027, "Task"], [3055, 3056, "Metric"], [3070, 3071, "Task"], [3218, 3219, "Metric"], [3428, 3429, "Task"], [3439, 3440, "Task"], [3516, 3518, "Method"], [3558, 3560, "Method"], [3919, 3920, "Task"], [3942, 3943, "Task"], [4001, 4002, "Task"], [4031, 4032, "Method"], [4065, 4066, "Task"], [4087, 4088, "Task"], [4396, 4397, "Task"], [4460, 4464, "Method"], [4469, 4470, "Task"], [4476, 4477, "Task"], [4556, 4557, "Task"]], "sections": [[0, 245], [245, 1117], [1117, 1584], [1584, 1724], [1724, 2428], [2428, 2764], [2764, 2835], [2835, 2838], [2838, 3221], [3221, 3363], [3363, 3578], [3578, 3936], [3936, 4118], [4118, 4384], [4384, 4604], [4604, 4607]], "sentences": [[0, 10], [10, 41], [41, 82], [82, 106], [106, 130], [130, 165], [165, 196], [196, 204], [204, 218], [218, 245], [245, 248], [248, 282], [282, 305], [305, 350], [350, 389], [389, 433], [433, 472], [472, 497], [497, 519], [519, 531], [531, 546], [546, 562], [562, 579], [579, 611], [611, 625], [625, 649], [649, 712], [712, 735], [735, 800], [800, 832], [832, 853], [853, 882], [882, 922], [922, 959], [959, 987], [987, 1015], [1015, 1059], [1059, 1082], [1082, 1117], [1117, 1121], [1121, 1149], [1149, 1180], [1180, 1208], [1208, 1229], [1229, 1267], [1267, 1276], [1276, 1300], [1300, 1325], [1325, 1357], [1357, 1382], [1382, 1401], [1401, 1437], [1437, 1500], [1500, 1545], [1545, 1584], [1584, 1593], [1593, 1627], [1627, 1640], [1640, 1690], [1690, 1724], [1724, 1735], [1735, 1750], [1750, 1761], [1761, 1811], [1811, 1820], [1820, 1844], [1844, 1865], [1865, 1902], [1902, 1932], [1932, 1986], [1986, 2020], [2020, 2040], [2040, 2060], [2060, 2095], [2095, 2114], [2114, 2154], [2154, 2174], [2174, 2196], [2196, 2240], [2240, 2279], [2279, 2298], [2298, 2321], [2321, 2358], [2358, 2373], [2373, 2392], [2392, 2428], [2428, 2438], [2438, 2456], [2456, 2474], [2474, 2519], [2519, 2592], [2592, 2630], [2630, 2649], [2649, 2663], [2663, 2679], [2679, 2711], [2711, 2729], [2729, 2764], [2764, 2767], [2767, 2784], [2784, 2823], [2823, 2835], [2835, 2838], [2838, 2842], [2842, 2844], [2844, 2872], [2872, 2890], [2890, 2907], [2907, 2917], [2917, 2967], [2967, 2986], [2986, 3002], [3002, 3020], [3020, 3046], [3046, 3048], [3048, 3082], [3082, 3102], [3102, 3120], [3120, 3162], [3162, 3184], [3184, 3186], [3186, 3207], [3207, 3221], [3221, 3225], [3225, 3254], [3254, 3284], [3284, 3307], [3307, 3333], [3333, 3363], [3363, 3367], [3367, 3407], [3407, 3423], [3423, 3447], [3447, 3474], [3474, 3514], [3514, 3529], [3529, 3541], [3541, 3563], [3563, 3578], [3578, 3582], [3582, 3627], [3627, 3645], [3645, 3687], [3687, 3746], [3746, 3761], [3761, 3798], [3798, 3834], [3834, 3847], [3847, 3882], [3882, 3915], [3915, 3924], [3924, 3936], [3936, 3940], [3940, 3974], [3974, 4004], [4004, 4021], [4021, 4041], [4041, 4053], [4053, 4118], [4118, 4123], [4123, 4197], [4197, 4222], [4222, 4250], [4250, 4263], [4263, 4282], [4282, 4294], [4294, 4331], [4331, 4351], [4351, 4368], [4368, 4384], [4384, 4387], [4387, 4418], [4418, 4471], [4471, 4485], [4485, 4517], [4517, 4533], [4533, 4566], [4566, 4604], [4604, 4607]], "words": ["document", ":", "Deep", "Learning", "over", "Multi", "-", "field", "Categorical", "Data", "Predicting", "user", "responses", ",", "such", "as", "click", "-", "through", "rate", "and", "conversion", "rate", ",", "are", "critical", "in", "many", "web", "applications", "including", "web", "search", ",", "personalised", "recommendation", ",", "and", "online", "advertising", ".", "Different", "from", "continuous", "raw", "features", "that", "we", "usually", "found", "in", "the", "image", "and", "audio", "domains", ",", "the", "input", "features", "in", "web", "space", "are", "always", "of", "multi", "-", "field", "and", "are", "mostly", "discrete", "and", "categorical", "while", "their", "dependencies", "are", "little", "known", ".", "Major", "user", "response", "prediction", "models", "have", "to", "either", "limit", "themselves", "to", "linear", "models", "or", "require", "manually", "building", "up", "high", "-", "order", "combination", "features", ".", "The", "former", "loses", "the", "ability", "of", "exploring", "feature", "interactions", ",", "while", "the", "latter", "results", "in", "a", "heavy", "computation", "in", "the", "large", "feature", "space", ".", "To", "tackle", "the", "issue", ",", "we", "propose", "two", "novel", "models", "using", "deep", "neural", "networks", "(", "DNNs", ")", "to", "automatically", "learn", "effective", "patterns", "from", "categorical", "feature", "interactions", "and", "make", "predictions", "of", "users", "\u2019", "ad", "clicks", ".", "To", "get", "our", "DNNs", "efficiently", "work", ",", "we", "propose", "to", "leverage", "three", "feature", "transformation", "methods", ",", "i.e.", ",", "factorisation", "machines", "(", "FMs", ")", ",", "restricted", "Boltzmann", "machines", "(", "RBMs", ")", "and", "denoising", "auto", "-", "encoders", "(", "DAEs", ")", ".", "This", "paper", "presents", "the", "structure", "of", "our", "models", "and", "their", "efficient", "training", "algorithms", ".", "The", "large", "-", "scale", "experiments", "with", "real", "-", "world", "data", "demonstrate", "that", "our", "methods", "work", "better", "than", "major", "state", "-", "of", "-", "the", "-", "art", "models", ".", "section", ":", "Introduction", "User", "response", "(", "e.g.", ",", "click", "-", "through", "or", "conversion", ")", "prediction", "plays", "a", "critical", "part", "in", "many", "web", "applications", "including", "web", "search", ",", "recommender", "systems", ",", "sponsored", "search", ",", "and", "display", "advertising", ".", "In", "online", "advertising", ",", "for", "instance", ",", "the", "ability", "of", "targeting", "individual", "users", "is", "the", "key", "advantage", "compared", "to", "traditional", "offline", "advertising", ".", "All", "these", "targeting", "techniques", ",", "essentially", ",", "rely", "on", "the", "system", "function", "of", "predicting", "whether", "a", "specific", "user", "will", "think", "the", "potential", "ad", "is", "\u201c", "relevant", "\u201d", ",", "i.e.", ",", "the", "probability", "that", "the", "user", "in", "a", "certain", "context", "will", "click", "a", "given", "ad", ".", "Sponsored", "search", ",", "contextual", "advertising", ",", "and", "the", "recently", "emerged", "real", "-", "time", "bidding", "(", "RTB", ")", "display", "advertising", "all", "heavily", "rely", "on", "the", "ability", "of", "learned", "models", "to", "predict", "ad", "click", "-", "through", "rates", "(", "CTR", ")", ".", "The", "applied", "CTR", "estimation", "models", "today", "are", "mostly", "linear", ",", "ranging", "from", "logistic", "regression", "and", "naive", "Bayes", "to", "FTRL", "logistic", "regression", "and", "Bayesian", "probit", "regression", ",", "all", "of", "which", "are", "based", "on", "a", "huge", "number", "of", "sparse", "features", "with", "one", "-", "hot", "encoding", ".", "Linear", "models", "have", "advantages", "of", "easy", "implementation", ",", "efficient", "learning", "but", "relative", "low", "performance", "because", "of", "the", "failure", "of", "learning", "the", "non", "-", "trivial", "patterns", "to", "catch", "the", "interactions", "between", "the", "assumed", "(", "conditionally", ")", "independent", "raw", "features", ".", "Non", "-", "linear", "models", ",", "on", "the", "other", "hand", ",", "are", "able", "to", "utilise", "different", "feature", "combinations", "and", "thus", "could", "potentially", "improve", "estimation", "performance", ".", "For", "example", ",", "factorisation", "machines", "(", "FMs", ")", "map", "the", "user", "and", "item", "binary", "features", "into", "a", "low", "dimensional", "continuous", "space", ".", "And", "the", "feature", "interaction", "is", "automatically", "explored", "via", "vector", "inner", "product", ".", "Gradient", "boosting", "trees", "automatically", "learn", "feature", "combinations", "while", "growing", "each", "decision", "/", "regression", "tree", ".", "However", ",", "these", "models", "can", "not", "make", "use", "of", "all", "possible", "combinations", "of", "different", "features", ".", "In", "addition", ",", "many", "models", "require", "feature", "engineering", "that", "manually", "designs", "what", "the", "inputs", "should", "be", ".", "Another", "problem", "of", "the", "mainstream", "ad", "CTR", "estimation", "models", "is", "that", "most", "prediction", "models", "have", "shallow", "structures", "and", "have", "limited", "expression", "to", "model", "the", "underlying", "patterns", "from", "complex", "and", "massive", "data", ".", "As", "a", "result", ",", "their", "data", "modelling", "and", "generalisation", "ability", "is", "still", "restricted", ".", "Deep", "learning", "has", "become", "successful", "in", "computer", "vision", ",", "speech", "recognition", ",", "and", "natural", "language", "processing", "(", "NLP", ")", "during", "recent", "five", "years", ".", "As", "visual", ",", "aural", ",", "and", "textual", "signals", "are", "known", "to", "be", "spatially", "and", "/", "or", "temporally", "correlated", ",", "the", "newly", "introduced", "unsupervised", "training", "on", "deep", "structures", "would", "be", "able", "to", "explore", "such", "local", "dependency", "and", "establish", "a", "dense", "representation", "of", "the", "feature", "space", ",", "making", "neural", "network", "models", "effective", "in", "learning", "high", "-", "order", "features", "directly", "from", "the", "raw", "feature", "input", ".", "With", "such", "learning", "ability", ",", "deep", "learning", "would", "be", "a", "good", "candidate", "to", "estimate", "online", "user", "response", "rate", "such", "as", "ad", "CTR", ".", "However", ",", "most", "input", "features", "in", "CTR", "estimation", "are", "of", "multi", "-", "field", "and", "are", "discrete", "categorical", "features", ",", "e.g.", ",", "the", "user", "location", "city", "(", "London", ",", "Paris", ")", ",", "device", "type", "(", "PC", ",", "Mobile", ")", ",", "ad", "category", "(", "Sports", ",", "Electronics", ")", "etc", ".", ",", "and", "their", "local", "dependencies", "(", "thus", "the", "sparsity", "in", "the", "feature", "space", ")", "are", "unknown", ".", "Therefore", ",", "it", "is", "of", "great", "interest", "to", "see", "how", "deep", "learning", "improves", "the", "CTR", "estimation", "via", "learning", "feature", "representation", "on", "such", "large", "-", "scale", "multi", "-", "field", "discrete", "categorical", "features", ".", "To", "our", "best", "knowledge", ",", "there", "is", "no", "previous", "literature", "of", "ad", "CTR", "estimation", "using", "deep", "learning", "methods", "thus", "far", ".", "In", "addition", ",", "training", "deep", "neural", "networks", "(", "DNNs", ")", "on", "a", "large", "input", "feature", "space", "requires", "tuning", "a", "huge", "number", "of", "parameters", ",", "which", "is", "computationally", "expensive", ".", "For", "instance", ",", "unlike", "image", "and", "audio", "cases", ",", "we", "have", "about", "1", "million", "binary", "input", "features", "and", "100", "hidden", "units", "in", "the", "first", "layer", ";", "then", "it", "requires", "100", "million", "links", "to", "build", "the", "first", "layer", "neural", "network", ".", "In", "this", "paper", ",", "we", "take", "ad", "CTR", "estimation", "as", "a", "working", "example", "to", "study", "deep", "learning", "over", "a", "large", "multi", "-", "field", "categorical", "feature", "space", "by", "using", "embedding", "methods", "in", "both", "supervised", "and", "unsupervised", "fashions", ".", "We", "introduce", "two", "types", "of", "deep", "learning", "models", ",", "called", "Factorisation", "Machine", "supported", "Neural", "Network", "(", "FNN", ")", "and", "Sampling", "-", "based", "Neural", "Network", "(", "SNN", ")", ".", "Specifically", ",", "FNN", "with", "a", "supervised", "-", "learning", "embedding", "layer", "using", "factorisation", "machines", "is", "proposed", "to", "efficiently", "reduce", "the", "dimension", "from", "sparse", "features", "to", "dense", "continuous", "features", ".", "The", "second", "model", "SNN", "is", "a", "deep", "neural", "network", "powered", "by", "a", "sampling", "-", "based", "restricted", "Boltzmann", "machine", "(", "SNN", "-", "RBM", ")", "or", "a", "sampling", "-", "based", "denoising", "auto", "-", "encoder", "(", "SNN", "-", "DAE", ")", "with", "a", "proposed", "negative", "sampling", "method", ".", "Based", "on", "the", "embedding", "layer", ",", "we", "build", "multiple", "layers", "neural", "nets", "with", "full", "connections", "to", "explore", "non", "-", "trivial", "data", "patterns", ".", "Our", "experiments", "on", "multiple", "real", "-", "world", "advertisers", "\u2019", "ad", "click", "data", "have", "demonstrated", "the", "consistent", "improvement", "of", "CTR", "estimation", "from", "our", "proposed", "models", "over", "the", "state", "-", "of", "-", "the", "-", "art", "ones", ".", "section", ":", "Related", "Work", "Click", "-", "through", "rate", ",", "defined", "as", "the", "probability", "of", "the", "ad", "click", "from", "a", "specific", "user", "on", "a", "displayed", "ad", ",", "is", "essential", "in", "online", "advertising", ".", "In", "order", "to", "maximise", "revenue", "and", "user", "satisfaction", ",", "online", "advertising", "platforms", "must", "predict", "the", "expected", "user", "behaviour", "for", "each", "displayed", "ad", "and", "maximise", "the", "expectation", "that", "users", "will", "click", ".", "The", "majority", "of", "current", "models", "use", "logistic", "regression", "based", "on", "a", "set", "of", "sparse", "binary", "features", "converted", "from", "the", "original", "categorical", "features", "via", "one", "-", "hot", "encoding", ".", "Heavy", "engineering", "efforts", "are", "needed", "to", "design", "features", "such", "as", "locations", ",", "top", "unigrams", ",", "combination", "features", ",", "etc", ".", ".", "Embedding", "very", "large", "feature", "vector", "into", "low", "-", "dimensional", "vector", "spaces", "is", "useful", "for", "prediction", "task", "as", "it", "reduces", "the", "data", "and", "model", "complexity", "and", "improves", "both", "the", "effectiveness", "and", "the", "efficiency", "of", "the", "training", "and", "prediction", ".", "Various", "methods", "of", "embedding", "architectures", "have", "been", "proposed", ".", "Factorisation", "machine", "(", "FM", ")", ",", "originally", "proposed", "for", "collaborative", "filtering", "recommendation", ",", "is", "regarded", "as", "one", "of", "the", "most", "successful", "embedding", "models", ".", "FM", "naturally", "has", "the", "capability", "of", "estimating", "interactions", "between", "any", "two", "features", "via", "mapping", "them", "into", "vectors", "in", "a", "low", "-", "rank", "latent", "space", ".", "Deep", "Learning", "is", "a", "branch", "of", "artificial", "intelligence", "research", "that", "attempts", "to", "develop", "the", "techniques", "that", "will", "allow", "computers", "to", "handle", "complex", "tasks", "such", "as", "recognition", "and", "prediction", "at", "high", "performance", ".", "Deep", "neural", "networks", "(", "DNNs", ")", "are", "able", "to", "extract", "the", "hidden", "structures", "and", "intrinsic", "patterns", "at", "different", "levels", "of", "abstractions", "from", "training", "data", ".", "DNNs", "have", "been", "successfully", "applied", "in", "computer", "vision", ",", "speech", "recognition", "and", "natural", "language", "processing", "(", "NLP", ")", ".", "Furthermore", ",", "with", "the", "help", "of", "unsupervised", "pre", "-", "training", ",", "we", "can", "get", "good", "feature", "representation", "which", "guides", "the", "learning", "towards", "basins", "of", "attraction", "of", "minima", "that", "support", "better", "generalisation", "from", "the", "training", "data", ".", "Usually", ",", "these", "deep", "models", "have", "two", "stages", "in", "learning", ":", "the", "first", "stage", "performs", "model", "initialisation", "via", "unsupervised", "learning", "(", "i.e.", ",", "the", "restricted", "Boltzmann", "machine", "or", "stacked", "denoising", "auto", "-", "encoders", ")", "to", "make", "the", "model", "catch", "the", "input", "data", "distribution", ";", "the", "second", "stage", "involves", "a", "fine", "tuning", "of", "the", "initialised", "model", "via", "supervised", "learning", "with", "back", "-", "propagation", ".", "The", "novelty", "of", "our", "deep", "learning", "models", "lies", "in", "the", "first", "layer", "initialisation", ",", "where", "the", "input", "raw", "features", "are", "high", "dimensional", "and", "sparse", "binary", "features", "converted", "from", "the", "raw", "categorical", "features", ",", "which", "makes", "it", "hard", "to", "train", "traditional", "DNNs", "in", "large", "scale", ".", "Compared", "with", "the", "word", "-", "embedding", "techniques", "used", "in", "NLP", ",", "our", "models", "deal", "with", "more", "general", "multi", "-", "field", "categorical", "features", "without", "any", "assumed", "data", "structures", "such", "as", "word", "alignment", "and", "letter", "-", "n", "-", "gram", "etc", ".", "section", ":", "DNNs", "for", "CTR", "Estimation", "given", "Categorical", "Features", "In", "this", "section", ",", "we", "discuss", "the", "two", "proposed", "DNN", "architectures", "in", "detail", ",", "namely", "Factorisation", "-", "machine", "supported", "Neural", "Networks", "(", "FNN", ")", "and", "Sampling", "-", "based", "Neural", "Networks", "(", "SNN", ")", ".", "The", "input", "categorical", "features", "are", "field", "-", "wise", "one", "-", "hot", "encoded", ".", "For", "each", "field", ",", "e.g.", ",", "city", ",", "there", "are", "multiple", "units", ",", "each", "of", "which", "represents", "a", "specific", "value", "of", "this", "field", ",", "e.g.", ",", "city", "=", "London", ",", "and", "there", "is", "only", "one", "positive", "(", "1", ")", "unit", ",", "while", "all", "others", "are", "negative", "(", "0", ")", ".", "The", "encoded", "features", ",", "denoted", "as", ",", "are", "the", "input", "of", "many", "CTR", "estimation", "models", "as", "well", "as", "our", "DNN", "models", ",", "as", "depicted", "at", "the", "bottom", "layer", "of", "Figure", "[", "reference", "]", ".", "subsection", ":", "Factorisation", "-", "machine", "supported", "Neural", "Networks", "(", "FNN", ")", "Our", "first", "model", "FNN", "is", "based", "on", "the", "factorisation", "machine", "as", "the", "bottom", "layer", ".", "The", "network", "structure", "is", "shown", "in", "Figure", "[", "reference", "]", ".", "With", "a", "top", "-", "down", "description", ",", "the", "output", "unit", "is", "a", "real", "number", "as", "predicted", "CTR", ",", "i.e.", ",", "the", "probability", "of", "a", "specific", "user", "clicking", "a", "given", "ad", "in", "a", "certain", "context", ":", "where", "is", "the", "logistic", "activation", "function", ",", ",", "and", "as", "input", "for", "this", "layer", ".", "The", "calculation", "of", "is", "where", ",", ",", "and", ".", "We", "choose", "as", "it", "has", "optimal", "empirical", "learning", "performance", "than", "other", "activation", "functions", ",", "as", "will", "be", "discussed", "in", "Section", "[", "reference", "]", ".", "Similarly", ",", "where", ",", "and", ".", "where", "is", "a", "global", "scalar", "parameter", "and", "is", "the", "number", "of", "fields", "in", "total", ".", "is", "a", "parameter", "vectors", "for", "the", "-", "th", "field", "in", "factorisation", "machines", ":", "where", "and", "are", "starting", "and", "ending", "feature", "indexes", "of", "the", "-", "th", "field", ",", "and", "is", "the", "input", "vector", "as", "described", "at", "beginning", ".", "All", "weights", "are", "initialised", "with", "the", "bias", "term", "and", "vector", "respectively", "(", "e.g.", ",", "is", "initialised", "by", ",", "is", "initialised", "by", ",", "is", "initialised", "by", ",", "etc", ".", ")", ".", "In", "this", "way", ",", "vector", "of", "the", "first", "layer", "is", "initialised", "as", "shown", "in", "Figure", "[", "reference", "]", "via", "training", "a", "factorisation", "machine", "(", "FM", ")", ":", "where", "each", "feature", "is", "assigned", "with", "a", "bias", "weight", "and", "a", "-", "dimensional", "vector", "and", "the", "feature", "interaction", "is", "modelled", "as", "their", "vectors", "\u2019", "inner", "product", ".", "In", "this", "way", ",", "the", "above", "neural", "nets", "can", "learn", "more", "efficiently", "from", "factorisation", "machine", "representation", "so", "that", "the", "computational", "complexity", "problem", "of", "the", "high", "-", "dimensional", "binary", "inputs", "has", "been", "naturally", "bypassed", ".", "Different", "hidden", "layers", "can", "be", "regarded", "as", "different", "internal", "functions", "capturing", "different", "forms", "of", "representations", "of", "the", "data", "instance", ".", "For", "this", "reason", ",", "this", "model", "has", "more", "abilities", "of", "catching", "intrinsic", "data", "patterns", "and", "leads", "to", "better", "performance", ".", "The", "idea", "using", "FM", "in", "the", "bottom", "layer", "is", "ignited", "by", "Convolutional", "Neural", "Networks", "(", "CNNs", ")", ",", "which", "exploit", "spatially", "local", "correlation", "by", "enforcing", "a", "local", "connectivity", "pattern", "between", "neurons", "of", "adjacent", "layers", ".", "Similarly", ",", "the", "inputs", "of", "hidden", "layer", "1", "are", "connected", "to", "the", "input", "units", "of", "a", "specific", "field", ".", "Also", ",", "the", "bottom", "layer", "is", "not", "fully", "connected", "as", "FM", "performs", "a", "field", "-", "wise", "training", "for", "one", "-", "hot", "sparse", "encoded", "input", ",", "allowing", "local", "sparsity", ",", "illustrated", "as", "the", "dash", "lines", "in", "Figure", "[", "reference", "]", ".", "FM", "learns", "good", "structural", "data", "representation", "in", "the", "latent", "space", ",", "helpful", "for", "any", "further", "model", "to", "build", "on", ".", "A", "subtle", "difference", ",", "though", ",", "appears", "between", "the", "product", "rule", "of", "FM", "and", "the", "sum", "rule", "of", "DNN", "for", "combination", ".", "However", ",", "according", "to", ",", "if", "the", "observational", "discriminatory", "information", "is", "highly", "ambiguous", "(", "which", "is", "true", "in", "our", "case", "for", "ad", "click", "behaviour", ")", ",", "the", "posterior", "weights", "(", "from", "DNN", ")", "will", "not", "deviate", "dramatically", "from", "the", "prior", "(", "FM", ")", ".", "Furthermore", ",", "the", "weights", "in", "hidden", "layers", "(", "except", "the", "FM", "layer", ")", "are", "initialised", "by", "layer", "-", "wise", "RBM", "pre", "-", "training", "using", "contrastive", "divergence", ",", "which", "effectively", "preserves", "the", "information", "in", "input", "dataset", "as", "detailed", "in", ".", "The", "initial", "weights", "for", "FMs", "are", "trained", "by", "stochastic", "gradient", "descent", "(", "SGD", ")", ",", "as", "detailed", "in", ".", "Note", "that", "we", "only", "need", "to", "update", "weights", "which", "connect", "to", "the", "positive", "input", "units", ",", "which", "largely", "reduces", "the", "computational", "complexity", ".", "After", "pre", "-", "training", "of", "the", "FM", "and", "upper", "layers", ",", "supervised", "fine", "-", "tuning", "(", "back", "propagation", ")", "is", "applied", "to", "minimise", "loss", "function", "of", "cross", "entropy", ":", "where", "is", "the", "predicted", "CTR", "in", "Eq", ".", "(", "[", "reference", "]", ")", "and", "is", "the", "binary", "click", "ground", "-", "truth", "label", ".", "Using", "the", "chain", "rule", "of", "back", "propagation", ",", "the", "FNN", "weights", "including", "FM", "weights", "can", "be", "efficiently", "updated", ".", "For", "example", ",", "we", "update", "FM", "layer", "weights", "via", "Due", "to", "the", "fact", "that", "the", "majority", "entries", "of", "are", "0", ",", "we", "can", "accelerate", "fine", "-", "tuning", "by", "updating", "weights", "linking", "to", "positive", "units", "only", ".", "subsection", ":", "Sampling", "-", "based", "Neural", "Networks", "(", "SNN", ")", "The", "structure", "of", "the", "second", "model", "SNN", "is", "shown", "in", "Figure", "[", "reference", "]", "(", "a", ")", ".", "The", "difference", "between", "SNN", "and", "FNN", "lies", "in", "the", "structure", "and", "training", "method", "in", "the", "bottom", "layer", ".", "SNN", "\u2019s", "bottom", "layer", "is", "fully", "connected", "with", "sigmoid", "activation", "function", ":", "To", "initialise", "the", "weights", "of", "the", "bottom", "layer", ",", "we", "tried", "both", "restricted", "Boltzmann", "machine", "(", "RBM", ")", "and", "denoising", "auto", "-", "encoder", "(", "DAE", ")", "in", "the", "pre", "-", "training", "stage", ".", "In", "order", "to", "deal", "with", "the", "computational", "problem", "of", "training", "large", "sparse", "one", "-", "hot", "encoding", "data", ",", "we", "propose", "a", "sampling", "-", "based", "RBM", "(", "Figure", "[", "reference", "]", "(", "b", ")", ",", "denoted", "as", "SNN", "-", "RBM", ")", "and", "a", "sampling", "-", "based", "DAE", "in", "(", "Figure", "[", "reference", "]", "(", "c", ")", ",", "denoted", "as", "SNN", "-", "DAE", ")", "to", "efficiently", "calculate", "the", "initial", "weights", "of", "the", "bottom", "layer", ".", "Instead", "of", "modelling", "the", "whole", "feature", "set", "for", "each", "training", "instance", "set", ",", "for", "each", "feature", "field", ",", "e.g.", ",", "city", ",", "there", "is", "only", "one", "positive", "value", "feature", "for", "each", "training", "instance", ",", "e.g.", ",", "city", "=", "London", ",", "we", "sample", "negative", "units", ",", "e.g.", ",", "city", "=", "Paris", "when", ",", "randomly", "with", "value", "0", ".", "Black", "units", "in", "Figure", "[", "reference", "]", "(", "b", ")", "and", "[", "reference", "]", "(", "c", ")", "are", "unsampled", "and", "thus", "ignored", "when", "pre", "-", "training", "the", "data", "instance", ".", "With", "the", "sampled", "units", ",", "we", "can", "train", "an", "RBM", "via", "contrastive", "divergence", "and", "a", "DAE", "via", "SGD", "with", "unsupervised", "approaches", "to", "largely", "reduce", "the", "data", "dimension", "with", "high", "recovery", "performance", ".", "The", "real", "-", "value", "dense", "vector", "is", "used", "as", "the", "input", "of", "the", "further", "layers", "in", "SNN", ".", "In", "this", "way", ",", "computational", "complexity", "can", "be", "dramatically", "reduced", "and", ",", "in", "turn", ",", "initial", "weights", "can", "be", "calculated", "quickly", "and", "back", "-", "propagation", "is", "then", "performed", "to", "fine", "-", "tune", "SNN", "model", ".", "subsection", ":", "Regularisation", "To", "prevent", "overfitting", ",", "the", "widely", "used", "L2", "regularisation", "term", "is", "added", "to", "the", "loss", "function", ".", "For", "example", ",", "the", "L2", "regularisation", "for", "FNN", "in", "Figure", "[", "reference", "]", "is", "On", "the", "other", "hand", ",", "dropout", "is", "a", "technique", "which", "becomes", "a", "popular", "and", "effective", "regularisation", "technique", "for", "deep", "learning", "during", "the", "recent", "years", ".", "We", "also", "implement", "this", "regularisation", "and", "compare", "them", "in", "our", "experiment", ".", "section", ":", "Experiment", "subsection", ":", "Experiment", "Setup", "Data", ".", "We", "evaluate", "our", "models", "based", "on", "iPinYou", "dataset", ",", "a", "public", "real", "-", "world", "display", "ad", "dataset", "with", "each", "ad", "display", "information", "and", "corresponding", "user", "click", "feedback", ".", "The", "data", "logs", "are", "organised", "by", "different", "advertisers", "and", "in", "a", "row", "-", "per", "-", "record", "format", ".", "There", "are", "19.50", "M", "data", "instances", "with", "14.79", "K", "positive", "label", "(", "click", ")", "in", "total", ".", "The", "features", "for", "each", "data", "instance", "are", "all", "categorical", ".", "Feature", "examples", "in", "the", "ad", "log", "data", "are", "user", "agent", ",", "partially", "masked", "IP", ",", "region", ",", "city", ",", "ad", "exchange", ",", "domain", ",", "URL", ",", "ad", "slot", "ID", ",", "ad", "slot", "visibility", ",", "ad", "slot", "size", ",", "ad", "slot", "format", ",", "creative", "ID", ",", "user", "tags", ",", "etc", ".", "After", "one", "-", "hot", "encoding", ",", "the", "number", "of", "binary", "features", "is", "937.67", "K", "in", "the", "whole", "dataset", ".", "We", "feed", "each", "compared", "model", "with", "these", "binary", "-", "feature", "data", "instances", "and", "the", "user", "click", "(", "1", ")", "and", "non", "-", "click", "(", "0", ")", "feedback", "as", "the", "ground", "-", "truth", "labels", ".", "In", "our", "experiments", ",", "we", "use", "training", "data", "from", "advertiser", "1458", ",", "2259", ",", "2261", ",", "2997", ",", "3386", "and", "the", "whole", "dataset", ",", "respectively", ".", "Models", ".", "We", "compare", "the", "performance", "of", "the", "following", "CTR", "estimation", "models", ":", "Logistic", "Regression", "is", "a", "linear", "model", "with", "simple", "implementation", "and", "fast", "training", "speed", ",", "which", "is", "widely", "used", "in", "online", "advertising", "estimation", ".", "Factorisation", "Machine", "is", "a", "non", "-", "linear", "model", "able", "to", "estimate", "feature", "interactions", "even", "in", "problems", "with", "huge", "sparsity", ".", "Factorisation", "-", "machine", "supported", "Neural", "Network", "is", "our", "proposed", "model", "as", "described", "in", "Section", "[", "reference", "]", ".", "Sampling", "-", "based", "Neural", "Network", "is", "also", "our", "proposed", "model", "with", "sampling", "-", "based", "RBM", "and", "DAE", "pre", "-", "training", "methods", "for", "the", "first", "layer", "in", "Section", "[", "reference", "]", ",", "denoted", "as", "SNN", "-", "RBM", "and", "SNN", "-", "DAE", "respectively", ".", "Our", "experiment", "code", "of", "both", "FNN", "and", "SNN", "is", "implemented", "with", "TheanoTheano", ":", "http:", "//", "deeplearning.net", "/", "software", "/", "theano", "/", ".", "Metric", ".", "To", "measure", "the", "CTR", "estimation", "performance", "of", "each", "model", ",", "we", "employ", "the", "area", "under", "ROC", "curve", "(", "AUC", ")", ".", "The", "AUC", "metric", "is", "a", "widely", "used", "measure", "for", "evaluating", "the", "CTR", "performance", ".", "subsection", ":", "Performance", "Comparison", "Table", "[", "reference", "]", "shows", "the", "results", "that", "compare", "LR", ",", "FM", ",", "FNN", "and", "SNN", "with", "RBM", "and", "DAE", "on", "5", "different", "advertisers", "and", "the", "whole", "dataset", ".", "We", "observe", "that", "FM", "is", "not", "significantly", "better", "than", "LR", ",", "which", "means", "2", "-", "order", "combination", "features", "might", "not", "be", "good", "enough", "to", "catch", "the", "underlying", "data", "patterns", ".", "The", "AUC", "performance", "of", "the", "proposed", "FNN", "and", "SNN", "is", "better", "than", "the", "performance", "of", "LR", "and", "FM", "on", "all", "tested", "datasets", ".", "Based", "on", "the", "latent", "structure", "learned", "by", "FM", ",", "FNN", "further", "learns", "effective", "patterns", "between", "these", "latent", "features", "and", "provides", "a", "consistent", "improvement", "over", "FM", ".", "The", "performance", "of", "SNN", "-", "DAE", "and", "SNN", "-", "RBM", "is", "generally", "consistent", ",", "i.e.", ",", "the", "relative", "order", "of", "the", "results", "of", "the", "SNN", "are", "almost", "the", "same", ".", "subsection", ":", "Hyperparameter", "Tuning", "Due", "to", "the", "fact", "that", "deep", "neural", "networks", "involve", "many", "implementation", "details", "and", "need", "to", "tune", "a", "fairly", "large", "number", "of", "hyper", "-", "parameters", ",", "following", "details", "show", "how", "we", "implement", "our", "models", "and", "tune", "hyperparameters", "in", "the", "models", ".", "We", "use", "stochastic", "gradient", "descent", "to", "learn", "most", "of", "our", "parameters", "for", "all", "proposed", "models", ".", "Regarding", "selecting", "the", "number", "of", "training", "epochs", ",", "we", "use", "early", "stopping", ",", "i.e.", ",", "the", "training", "stops", "when", "the", "validation", "error", "increases", ".", "We", "try", "different", "learning", "rate", "from", "1", ",", "0.1", ",", "0.01", ",", "0.001", "to", "0.0001", "and", "choose", "the", "one", "with", "optimal", "performance", "on", "the", "validation", "dataset", ".", "For", "negative", "unit", "sampling", "of", "SNN", "-", "RBM", "and", "SNN", "-", "DAE", ",", "we", "try", "the", "negative", "sample", "number", "and", "per", "field", "as", "described", "in", "Section", "[", "reference", "]", ",", "and", "find", "produces", "the", "best", "results", "in", "most", "situations", ".", "For", "the", "activation", "functions", "in", "both", "models", "on", "the", "hidden", "layers", "(", "as", "Eqs", ".", "(", "[", "reference", "]", ")", "and", "(", "[", "reference", "]", ")", ")", ",", "we", "try", "linear", "function", ",", "sigmoid", "function", "and", "tanh", "function", ",", "and", "find", "the", "result", "of", "tanh", "function", "is", "optimal", ".", "This", "might", "be", "because", "the", "hyperbolic", "tangent", "often", "converges", "faster", "than", "the", "sigmoid", "function", ".", "subsection", ":", "Architecture", "Selection", "In", "our", "models", ",", "we", "investigate", "architectures", "with", "3", ",", "4", "and", "5", "hidden", "layers", "by", "fixing", "all", "layer", "sizes", "and", "find", "the", "architecture", "with", "3", "hidden", "layers", "(", "i.e.", ",", "5", "layers", "in", "total", ")", "is", "the", "best", "in", "terms", "of", "AUC", "performance", ".", "However", ",", "the", "range", "of", "choosing", "their", "layer", "sizes", "is", "exponential", "in", "the", "number", "of", "hidden", "layers", ".", "Suppose", "there", "is", "a", "deep", "neural", "network", "with", "hidden", "layers", "and", "each", "of", "the", "hidden", "layers", "is", "trained", "with", "a", "range", "of", "hidden", "units", "from", "100", "to", "500", "with", "increments", "of", "100", ",", "thus", "there", "are", "models", "in", "total", "to", "compare", ".", "Instead", "of", "trying", "all", "combinations", "of", "hidden", "units", ",", "in", "our", "experiment", "we", "use", "another", "strategy", "by", "starting", "tuning", "the", "different", "hidden", "layer", "sizes", "with", "the", "same", "number", "of", "hidden", "units", "in", "all", "three", "hidden", "layers", "since", "the", "architecture", "with", "equal", "-", "size", "hidden", "layers", "is", "empirically", "better", "than", "the", "architecture", "with", "increasing", "width", "or", "decreasing", "width", "in", ".", "For", "this", "reason", ",", "we", "start", "tuning", "layer", "sizes", "with", "equal", "hidden", "layer", "sizes", ".", "In", "fact", ",", "apart", "from", "increasing", ",", "constant", ",", "decreasing", "layer", "sizes", ",", "there", "is", "a", "more", "effective", "structure", ",", "which", "is", "the", "diamond", "shape", "of", "neural", "networks", ",", "as", "shown", "in", "Figure", "[", "reference", "]", ".", "We", "compare", "our", "diamond", "shape", "network", "with", "other", "three", "shapes", "of", "networks", "and", "tune", "the", "total", "number", "of", "total", "hidden", "units", "on", "two", "different", "datasets", "shown", "in", "Figures", "[", "reference", "]", "and", "[", "reference", "]", ".", "The", "diamond", "shape", "architecture", "outperforms", "others", "in", "almost", "all", "layer", "size", "settings", ".", "The", "reason", "why", "this", "diamond", "shape", "works", "might", "be", "because", "this", "special", "shape", "of", "neural", "network", "has", "certain", "constraint", "to", "the", "capacity", "of", "the", "neural", "network", ",", "which", "provides", "better", "generalisation", "on", "test", "sets", ".", "On", "the", "other", "hand", ",", "the", "performance", "of", "diamond", "architecture", "picks", "at", "the", "total", "hidden", "unit", "size", "of", "600", ",", "i.e.", ",", "the", "combination", "of", "(", "200", ",", "300", ",", "100", ")", ".", "This", "depends", "on", "the", "training", "data", "observation", "numbers", ".", "Too", "many", "hidden", "units", "against", "a", "limited", "dataset", "could", "cause", "overfitting", ".", "subsection", ":", "Regularisation", "Comparison", "Neural", "network", "training", "algorithms", "are", "very", "sensitive", "to", "the", "overfitting", "problem", "since", "deep", "networks", "have", "multiple", "non", "-", "linear", "layers", ",", "which", "makes", "them", "very", "expressive", "models", "that", "can", "learn", "very", "complicated", "functions", ".", "For", "DNN", "models", ",", "we", "compared", "L2", "regularisation", "(", "Eq", ".", "(", "[", "reference", "]", ")", ")", "and", "dropout", "for", "preventing", "complex", "co", "-", "adaptations", "on", "the", "training", "data", ".", "The", "dropout", "rate", "implemented", "in", "this", "experiment", "refers", "to", "the", "probability", "of", "each", "unit", "being", "active", ".", "Figure", "[", "reference", "]", "shows", "the", "compared", "AUC", "performance", "of", "SNN", "-", "RBM", "regularised", "by", "L2", "norm", "and", "dropout", ".", "It", "is", "obvious", "that", "dropout", "outperforms", "L2", "in", "all", "compared", "settings", ".", "The", "reason", "why", "dropout", "is", "more", "effective", "is", "that", "when", "feeding", "each", "training", "case", ",", "each", "hidden", "unit", "is", "stochastically", "excluded", "from", "the", "network", "with", "a", "probability", "of", "dropout", "rate", ",", "i.e.", ",", "each", "training", "case", "can", "be", "regarded", "as", "a", "new", "model", "and", "these", "models", "are", "averaged", "as", "a", "special", "case", "of", "bagging", ",", "which", "effectively", "improves", "the", "generalisation", "ability", "of", "DNN", "models", ".", "subsection", ":", "Analysis", "of", "Parameters", "As", "a", "summary", "of", "Sections", "[", "reference", "]", "and", "[", "reference", "]", ",", "for", "both", "FNN", "and", "SNN", ",", "there", "are", "two", "important", "parameters", "which", "should", "be", "tuned", "to", "make", "the", "model", "more", "effective", ":", "(", "i", ")", "the", "parameters", "of", "layer", "size", "decide", "the", "architecture", "of", "the", "neural", "network", "and", "(", "ii", ")", "the", "parameter", "of", "dropout", "rate", "changes", "generalisation", "ability", "on", "all", "datasets", "compared", "to", "neural", "networks", "just", "with", "L2", "regularisation", ".", "Figures", "[", "reference", "]", "and", "[", "reference", "]", "show", "how", "the", "AUC", "performance", "changes", "with", "the", "increasing", "of", "dropout", "in", "both", "FNN", "and", "SNN", ".", "We", "can", "find", "that", "there", "is", "an", "upward", "trend", "of", "performance", "in", "both", "models", "at", "the", "beginning", "and", "then", "drop", "sharply", "with", "continuous", "decreasing", "of", "dropout", "rate", ".", "The", "distinction", "between", "two", "models", "is", "the", "different", "sensitivities", "of", "the", "dropout", ".", "From", "Figure", "[", "reference", "]", ",", "we", "can", "see", "the", "model", "SNN", "is", "sensitive", "to", "the", "dropout", "rate", ".", "This", "might", "be", "caused", "by", "the", "connectivities", "in", "the", "bottom", "layer", ".", "The", "bottom", "layer", "of", "the", "SNN", "is", "fully", "connected", "with", "the", "input", "vector", "while", "the", "bottom", "layer", "for", "FNN", "is", "partially", "connected", "and", "thus", "the", "FNN", "is", "more", "robust", "when", "some", "hidden", "units", "are", "dropped", "out", ".", "Furthermore", ",", "the", "sigmoid", "activation", "function", "tend", "to", "more", "effective", "than", "the", "linear", "activation", "function", "in", "terms", "of", "dropout", ".", "Therefore", ",", "the", "dropout", "rates", "at", "the", "best", "performance", "of", "FNN", "and", "SNN", "are", "quite", "different", ".", "For", "FNN", "the", "optimal", "dropout", "rate", "is", "around", "0.8", "while", "for", "SNN", "is", "about", "0.99", ".", "section", ":", "Conclusion", "In", "this", "paper", ",", "we", "investigated", "the", "potential", "of", "training", "deep", "neural", "networks", "(", "DNNs", ")", "to", "predict", "users", "\u2019", "ad", "click", "response", "based", "on", "multi", "-", "field", "categorical", "features", ".", "To", "deal", "with", "the", "computational", "complexity", "problem", "of", "high", "-", "dimensional", "discrete", "categorical", "features", ",", "we", "proposed", "two", "DNN", "models", ":", "field", "-", "wise", "feature", "embedding", "with", "supervised", "factorisation", "machine", "pre", "-", "training", ",", "and", "fully", "connected", "DNN", "with", "field", "-", "wise", "sampling", "-", "based", "RBM", "and", "DAE", "unsupervised", "pre", "-", "training", ".", "These", "architectures", "and", "pre", "-", "training", "algorithms", "make", "our", "DNNs", "trained", "very", "efficiently", ".", "Comprehensive", "experiments", "on", "a", "public", "real", "-", "world", "dataset", "verifies", "that", "the", "proposed", "DNN", "models", "successfully", "learn", "the", "underlying", "data", "patterns", "and", "provide", "superior", "CTR", "estimation", "performance", "than", "other", "compared", "models", ".", "The", "proposed", "models", "are", "very", "general", "and", "could", "enable", "a", "wide", "range", "of", "future", "works", ".", "For", "example", ",", "the", "model", "performance", "can", "be", "improved", "by", "momentum", "methods", "in", "that", "it", "suffices", "for", "handling", "the", "curvature", "problems", "in", "DNN", "training", "objectives", "without", "using", "complex", "second", "-", "order", "methods", ".", "In", "addition", ",", "the", "partial", "connection", "in", "the", "bottom", "layer", "could", "be", "extended", "to", "higher", "hidden", "layers", "as", "partial", "connectivities", "have", "many", "advantages", "such", "as", "lower", "complexity", ",", "higher", "generalisation", "ability", "and", "more", "similar", "to", "human", "brain", ".", "bibliography", ":", "References"]}