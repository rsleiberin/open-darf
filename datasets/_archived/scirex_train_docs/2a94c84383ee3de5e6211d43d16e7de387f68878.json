{"coref": {"Bounding_Box_AP": [[1288, 1290], [1291, 1292], [4884, 4889], [4890, 4891], [4910, 4912], [5186, 5187], [5225, 5226], [5284, 5285], [5317, 5318], [5813, 5814], [6240, 6241], [6283, 6284], [1300, 1301], [4896, 4897], [4925, 4926], [4928, 4929], [4932, 4933], [5291, 5292], [5440, 5441], [5454, 5455], [5647, 5648], [6114, 6115]], "COCO": [[142, 145], [456, 457], [1158, 1161], [4322, 4323], [161, 162], [1285, 1286], [3974, 3975], [4124, 4125], [4784, 4785], [5045, 5046], [6063, 6064], [6133, 6134], [6180, 6181], [6369, 6370]], "FPN": [[0, 3], [98, 101], [102, 103], [118, 119], [1114, 1117], [1118, 1119], [1167, 1168], [1265, 1266], [1395, 1396], [2034, 2037], [2072, 2075], [2117, 2118], [2946, 2949], [3091, 3092], [3473, 3474], [3497, 3500], [3557, 3558], [4313, 4314], [4627, 4628], [4865, 4866], [5038, 5039], [5099, 5100], [5263, 5264], [5630, 5631], [5863, 5864], [6018, 6019], [6349, 6350], [6358, 6359], [6418, 6419], [6495, 6496], [6835, 6836], [6974, 6977], [5062, 5063], [5945, 5946], [6665, 6666], [7002, 7003]], "Faster_R-CNN": [[98, 101], [122, 127], [616, 620], [1114, 1117], [1313, 1317], [1721, 1725], [1796, 1797], [2072, 2075], [2105, 2109], [2901, 2905], [3501, 3505], [3505, 3509], [3536, 3540], [3764, 3768], [4858, 4862], [5033, 5037], [5050, 5054], [5133, 5137], [5265, 5269], [5393, 5397], [5421, 5425], [5520, 5524], [5547, 5552], [5559, 5563], [5597, 5601], [5798, 5803], [5841, 5845], [5857, 5861], [1230, 1234], [3687, 3691], [5613, 5617], [5948, 5952], [6037, 6041]], "Faster_R-CNN___FPN": [], "Object_Detection": [[4, 6], [19, 21], [188, 193], [1279, 1281], [1519, 1521], [2909, 2911], [3965, 3967], [4853, 4855], [4880, 4882], [5853, 5855], [6373, 6374], [6410, 6412], [6993, 6995]]}, "coref_non_salient": {"0": [[530, 532], [1376, 1380], [1422, 1424], [5872, 5874], [5889, 5891], [5934, 5936], [5937, 5939], [5954, 5956]], "1": [[1330, 1332], [6761, 6764]], "10": [[2879, 2881], [4486, 4488]], "100": [[659, 664]], "101": [[826, 828]], "102": [[2876, 2878], [6888, 6890]], "103": [[7634, 7636]], "104": [[1571, 1572], [1573, 1574]], "105": [[83, 89]], "106": [[607, 609]], "107": [[4006, 4007]], "108": [[4692, 4694]], "109": [[6737, 6738], [7077, 7078], [7118, 7119], [7178, 7179], [7242, 7243], [7486, 7487]], "11": [[1687, 1688], [2957, 2965]], "110": [[4081, 4084], [4840, 4843], [5968, 5971], [5795, 5798], [5991, 5994]], "111": [[7509, 7512]], "112": [[556, 558], [1588, 1590]], "113": [[3879, 3880]], "114": [[16, 18]], "115": [[4110, 4111]], "116": [[1718, 1720]], "117": [[33, 35], [4354, 4356], [4648, 4650], [4655, 4657], [5515, 5517], [6961, 6963]], "118": [[6791, 6794]], "119": [[667, 669]], "12": [[2119, 2122], [6393, 6395], [6421, 6423], [6969, 6971], [6980, 6983]], "120": [[1814, 1815]], "121": [[3812, 3817]], "122": [[1269, 1271], [4127, 4129]], "123": [[1937, 1940]], "124": [[3521, 3526]], "125": [[717, 719]], "126": [[977, 982]], "127": [[6329, 6331]], "128": [[1537, 1540]], "129": [[2386, 2387]], "13": [[4117, 4119], [4771, 4774]], "130": [[6958, 6960]], "131": [[338, 341]], "132": [[6322, 6325]], "133": [[3771, 3775]], "134": [[2987, 2991]], "135": [[1557, 1564]], "136": [[6445, 6448]], "137": [[5867, 5868]], "138": [[1318, 1319], [2187, 2188]], "139": [[2164, 2167]], "14": [[3084, 3089], [5335, 5339]], "140": [[3008, 3011]], "141": [[4867, 4877]], "142": [[1459, 1462]], "143": [[5976, 5979]], "144": [[6848, 6849]], "145": [[2232, 2234]], "146": [[1004, 1010]], "147": [[463, 467]], "148": [[1665, 1670]], "149": [[7519, 7521]], "15": [[1854, 1855], [7054, 7056]], "150": [[2084, 2087]], "151": [[6748, 6749]], "152": [[6986, 6991]], "153": [[1578, 1580], [1933, 1935]], "154": [[6083, 6087]], "155": [[1869, 1872]], "156": [[1642, 1646]], "157": [[1960, 1961]], "158": [[1360, 1362]], "159": [[27, 31]], "16": [[451, 452], [3908, 3909]], "160": [[1836, 1837]], "161": [[767, 771]], "162": [[1913, 1916]], "163": [[2576, 2580]], "164": [[3020, 3021]], "165": [[460, 462]], "166": [[1479, 1482]], "167": [[3916, 3918]], "17": [[9, 11], [218, 220], [222, 224], [638, 640], [1388, 1390], [6268, 6270], [6865, 6867]], "18": [[5929, 5931], [5941, 5943], [6147, 6151]], "19": [[1125, 1128], [1785, 1788], [1925, 1926], [1964, 1965]], "2": [[1623, 1626], [1660, 1663], [1730, 1733], [3942, 3945], [6196, 6200], [5078, 5081], [5150, 5153], [6107, 6110]], "20": [[490, 492], [524, 526], [889, 891], [948, 950], [2941, 2943], [3575, 3577], [3584, 3586], [3643, 3645], [4384, 4386], [5330, 5332], [6516, 6518], [7164, 7166]], "21": [[1401, 1402], [1633, 1634], [1754, 1755], [3410, 3411], [5389, 5390], [5491, 5492], [5923, 5924], [6353, 6354], [6686, 6687], [6695, 6696], [6718, 6719], [6768, 6769], [6785, 6786]], "22": [[1339, 1340], [1756, 1757]], "23": [[204, 206], [864, 867]], "24": [[2154, 2157], [6504, 6507], [6554, 6557], [7049, 7053], [7555, 7558], [7711, 7715]], "25": [[1758, 1762], [6869, 6874]], "26": [[6543, 6545], [6670, 6672], [7402, 7404], [7571, 7573]], "27": [[3868, 3871], [7528, 7531], [7565, 7568]], "28": [[655, 657], [1599, 1603], [1609, 1611], [6941, 6943]], "29": [[4247, 4249], [5001, 5003], [6101, 6103], [7663, 7665], [7677, 7679]], "3": [[3032, 3036], [6449, 6455]], "30": [[5206, 5208], [6589, 6590], [6684, 6685], [7239, 7240], [7256, 7257], [7289, 7290], [7311, 7312], [7391, 7392], [7503, 7504], [7585, 7586]], "31": [[928, 932], [2444, 2446], [2475, 2479], [4388, 4390]], "32": [[2594, 2597], [2629, 2632]], "33": [[3014, 3017], [7560, 7562]], "34": [[1920, 1921], [6742, 6743], [6428, 6429], [6438, 6439], [7016, 7017]], "35": [[2092, 2093], [2890, 2891], [2950, 2951], [2951, 2952], [3080, 3081], [3464, 3465], [4120, 4121], [4267, 4268], [4311, 4312], [4358, 4359], [4726, 4727], [4776, 4777], [5097, 5098], [5138, 5139], [5368, 5369], [5557, 5558], [5595, 5596], [5839, 5840], [6609, 6610], [2969, 2970], [4446, 4447], [5501, 5502]], "36": [[933, 935], [2480, 2482]], "37": [[6511, 6512], [7045, 7046], [7709, 7710]], "38": [[5173, 5175]], "39": [[6601, 6602], [6692, 6693]], "4": [[1505, 1509], [1652, 1655], [4729, 4732]], "40": [[1694, 1698], [2100, 2104], [3595, 3599]], "41": [[1272, 1273], [4133, 4134], [6674, 6675], [6728, 6729], [1337, 1338], [4130, 4131], [4143, 4144], [4146, 4147], [4150, 4151], [4172, 4173], [4175, 4176], [4339, 4340], [4630, 4631], [6645, 6646], [6648, 6649], [6698, 6699], [6709, 6710], [6776, 6777]], "42": [[3527, 3528], [3620, 3621], [3668, 3669], [3725, 3726], [3852, 3853], [5162, 5163], [5469, 5470]], "43": [[2723, 2727]], "44": [[7347, 7348]], "45": [[6188, 6191]], "46": [[728, 729], [1864, 1865]], "47": [[7741, 7744]], "48": [[1823, 1826], [6375, 6377]], "49": [[5591, 5594]], "5": [[4758, 4760], [6316, 6318]], "50": [[5878, 5882], [5901, 5905]], "51": [[4856, 4857], [614, 615], [3941, 3942], [5077, 5078], [5149, 5150], [6106, 6107]], "52": [[3259, 3260], [3288, 3289], [3296, 3297], [3313, 3314], [4901, 4902]], "53": [[6509, 6510], [7594, 7595]], "54": [[1261, 1264], [2895, 2899]], "55": [[2767, 2769], [6464, 6465]], "56": [[74, 76], [1179, 1183]], "57": [[5732, 5733]], "58": [[111, 113], [6859, 6862]], "59": [[1927, 1929]], "6": [[1842, 1843], [1956, 1959]], "60": [[3872, 3873], [3904, 3905], [3922, 3923], [5211, 5212], [5234, 5235]], "61": [[4051, 4053]], "62": [[3651, 3657]], "63": [[330, 332], [1615, 1617]], "64": [[3018, 3019], [3884, 3885], [1517, 1518], [2997, 2998], [4060, 4061]], "65": [[4216, 4217], [4316, 4317], [7648, 7649]], "66": [[4085, 4089], [6070, 6074]], "67": [[4545, 4550], [4557, 4561]], "68": [[2390, 2391], [3836, 3837]], "69": [[4211, 4214], [4960, 4962], [7650, 7652]], "7": [[2999, 3002], [3776, 3779], [3886, 3890]], "70": [[230, 233], [305, 308], [468, 471], [1094, 1097], [1978, 1981], [2731, 2734], [3439, 3442]], "71": [[2647, 2649], [4401, 4403]], "72": [[2236, 2238]], "73": [[1811, 1813]], "74": [[497, 502], [648, 653]], "75": [[61, 64], [368, 371]], "76": [[372, 373], [391, 392], [1581, 1582], [1649, 1650], [1685, 1686], [1794, 1795], [6891, 6892]], "77": [[3253, 3258]], "78": [[3592, 3594]], "79": [[6336, 6338]], "8": [[355, 357], [403, 404], [720, 722]], "80": [[4496, 4500]], "81": [[6914, 6920]], "82": [[3514, 3519], [5067, 5071], [5341, 5346]], "83": [[5473, 5477]], "84": [[4360, 4361], [4746, 4747]], "85": [[5573, 5575]], "86": [[6467, 6469]], "87": [[2568, 2571]], "88": [[215, 217]], "89": [[724, 727]], "9": [[1522, 1525], [1944, 1946], [6379, 6381]], "90": [[1831, 1832]], "91": [[1618, 1619]], "92": [[3445, 3448]], "93": [[333, 334]], "94": [[4103, 4109]], "95": [[7738, 7740]], "96": [[1551, 1553]], "97": [[2508, 2513], [2544, 2547]], "98": [[6399, 6402]], "99": [[2088, 2091]]}, "doc_id": "2a94c84383ee3de5e6211d43d16e7de387f68878", "method_subrelations": {"Faster_R-CNN___FPN": [[[0, 12], "Faster_R-CNN"], [[15, 18], "FPN"]]}, "n_ary_relations": [{"Material": "COCO", "Method": "Faster_R-CNN___FPN", "Metric": "Bounding_Box_AP", "Task": "Object_Detection", "score": "36.2"}], "ner": [[0, 3, "Method"], [4, 6, "Task"], [9, 11, "Method"], [16, 18, "Method"], [19, 21, "Task"], [27, 31, "Method"], [33, 35, "Method"], [61, 64, "Method"], [74, 76, "Method"], [83, 89, "Task"], [98, 101, "Method"], [102, 103, "Method"], [111, 113, "Method"], [118, 119, "Method"], [122, 127, "Method"], [142, 145, "Material"], [188, 193, "Task"], [204, 206, "Task"], [215, 217, "Task"], [218, 220, "Method"], [222, 224, "Method"], [230, 233, "Method"], [305, 308, "Method"], [330, 332, "Method"], [333, 334, "Method"], [338, 341, "Method"], [355, 357, "Task"], [368, 371, "Method"], [372, 373, "Method"], [391, 392, "Method"], [403, 404, "Task"], [451, 452, "Material"], [456, 457, "Material"], [460, 462, "Task"], [463, 467, "Method"], [468, 471, "Method"], [490, 492, "Method"], [497, 502, "Method"], [524, 526, "Method"], [530, 532, "Metric"], [556, 558, "Method"], [607, 609, "Method"], [616, 620, "Method"], [638, 640, "Method"], [648, 653, "Method"], [655, 657, "Method"], [659, 664, "Method"], [667, 669, "Method"], [717, 719, "Method"], [720, 722, "Task"], [724, 727, "Method"], [728, 729, "Method"], [767, 771, "Method"], [826, 828, "Method"], [864, 867, "Task"], [889, 891, "Method"], [928, 932, "Method"], [933, 935, "Method"], [948, 950, "Method"], [977, 982, "Method"], [1004, 1010, "Method"], [1094, 1097, "Method"], [1114, 1117, "Method"], [1118, 1119, "Method"], [1125, 1128, "Task"], [1158, 1161, "Material"], [1167, 1168, "Method"], [1179, 1183, "Method"], [1261, 1264, "Task"], [1265, 1266, "Method"], [1269, 1271, "Metric"], [1272, 1273, "Metric"], [1279, 1281, "Task"], [1288, 1290, "Metric"], [1291, 1292, "Metric"], [1313, 1317, "Method"], [1318, 1319, "Method"], [1330, 1332, "Task"], [1339, 1340, "Metric"], [1360, 1362, "Method"], [1376, 1380, "Metric"], [1388, 1390, "Method"], [1395, 1396, "Method"], [1401, 1402, "Metric"], [1422, 1424, "Metric"], [1459, 1462, "Method"], [1479, 1482, "Task"], [1505, 1509, "Method"], [1519, 1521, "Task"], [1522, 1525, "Task"], [1537, 1540, "Task"], [1551, 1553, "Task"], [1557, 1564, "Method"], [1571, 1572, "Method"], [1573, 1574, "Method"], [1578, 1580, "Task"], [1581, 1582, "Method"], [1588, 1590, "Method"], [1599, 1603, "Method"], [1609, 1611, "Method"], [1615, 1617, "Method"], [1618, 1619, "Method"], [1623, 1626, "Method"], [1633, 1634, "Metric"], [1642, 1646, "Method"], [1649, 1650, "Method"], [1652, 1655, "Method"], [1660, 1663, "Method"], [1665, 1670, "Method"], [1685, 1686, "Method"], [1687, 1688, "Method"], [1694, 1698, "Method"], [1718, 1720, "Method"], [1721, 1725, "Method"], [1730, 1733, "Method"], [1754, 1755, "Metric"], [1756, 1757, "Metric"], [1758, 1762, "Task"], [1785, 1788, "Task"], [1794, 1795, "Method"], [1796, 1797, "Method"], [1811, 1813, "Task"], [1814, 1815, "Method"], [1823, 1826, "Task"], [1831, 1832, "Method"], [1836, 1837, "Method"], [1842, 1843, "Method"], [1854, 1855, "Task"], [1864, 1865, "Method"], [1869, 1872, "Method"], [1913, 1916, "Method"], [1920, 1921, "Method"], [1925, 1926, "Task"], [1927, 1929, "Method"], [1933, 1935, "Task"], [1937, 1940, "Method"], [1944, 1946, "Task"], [1956, 1959, "Method"], [1960, 1961, "Method"], [1964, 1965, "Task"], [1978, 1981, "Method"], [2034, 2037, "Method"], [2072, 2075, "Method"], [2084, 2087, "Method"], [2088, 2091, "Method"], [2092, 2093, "Method"], [2100, 2104, "Method"], [2105, 2109, "Method"], [2117, 2118, "Method"], [2119, 2122, "Task"], [2154, 2157, "Method"], [2164, 2167, "Method"], [2187, 2188, "Method"], [2232, 2234, "Method"], [2236, 2238, "Method"], [2386, 2387, "Method"], [2390, 2391, "Method"], [2444, 2446, "Method"], [2475, 2479, "Method"], [2480, 2482, "Method"], [2508, 2513, "Method"], [2544, 2547, "Method"], [2568, 2571, "Method"], [2576, 2580, "Method"], [2594, 2597, "Method"], [2629, 2632, "Method"], [2647, 2649, "Method"], [2723, 2727, "Method"], [2731, 2734, "Method"], [2767, 2769, "Method"], [2876, 2878, "Task"], [2879, 2881, "Task"], [2890, 2891, "Method"], [2895, 2899, "Task"], [2901, 2905, "Method"], [2909, 2911, "Task"], [2941, 2943, "Method"], [2946, 2949, "Method"], [2950, 2951, "Method"], [2951, 2952, "Method"], [2957, 2965, "Method"], [2987, 2991, "Method"], [2999, 3002, "Method"], [3008, 3011, "Method"], [3014, 3017, "Method"], [3018, 3019, "Method"], [3020, 3021, "Task"], [3032, 3036, "Task"], [3080, 3081, "Method"], [3084, 3089, "Method"], [3091, 3092, "Method"], [3253, 3258, "Metric"], [3259, 3260, "Metric"], [3410, 3411, "Metric"], [3439, 3442, "Method"], [3445, 3448, "Method"], [3464, 3465, "Method"], [3473, 3474, "Method"], [3497, 3500, "Method"], [3501, 3505, "Method"], [3505, 3509, "Method"], [3514, 3519, "Method"], [3521, 3526, "Method"], [3527, 3528, "Method"], [3536, 3540, "Method"], [3557, 3558, "Method"], [3575, 3577, "Method"], [3584, 3586, "Method"], [3592, 3594, "Method"], [3595, 3599, "Method"], [3643, 3645, "Method"], [3651, 3657, "Material"], [3764, 3768, "Method"], [3771, 3775, "Method"], [3776, 3779, "Method"], [3812, 3817, "Method"], [3836, 3837, "Method"], [3868, 3871, "Method"], [3872, 3873, "Method"], [3879, 3880, "Method"], [3884, 3885, "Method"], [3886, 3890, "Method"], [3908, 3909, "Material"], [3916, 3918, "Method"], [3942, 3945, "Method"], [3965, 3967, "Task"], [4006, 4007, "Method"], [4051, 4053, "Method"], [4081, 4084, "Method"], [4085, 4089, "Method"], [4103, 4109, "Method"], [4110, 4111, "Method"], [4117, 4119, "Method"], [4120, 4121, "Method"], [4133, 4134, "Metric"], [4211, 4214, "Method"], [4216, 4217, "Method"], [4247, 4249, "Metric"], [4267, 4268, "Method"], [4311, 4312, "Method"], [4313, 4314, "Method"], [4316, 4317, "Method"], [4322, 4323, "Material"], [4354, 4356, "Method"], [4358, 4359, "Method"], [4360, 4361, "Metric"], [4384, 4386, "Method"], [4388, 4390, "Method"], [4401, 4403, "Method"], [4486, 4488, "Task"], [4496, 4500, "Method"], [4545, 4550, "Method"], [4557, 4561, "Method"], [4627, 4628, "Method"], [4648, 4650, "Method"], [4655, 4657, "Method"], [4692, 4694, "Method"], [4726, 4727, "Method"], [4729, 4732, "Method"], [4746, 4747, "Metric"], [4758, 4760, "Method"], [4771, 4774, "Method"], [4776, 4777, "Method"], [4840, 4843, "Method"], [4853, 4855, "Task"], [4856, 4857, "Method"], [4858, 4862, "Method"], [4865, 4866, "Method"], [4867, 4877, "Method"], [4880, 4882, "Task"], [4884, 4889, "Metric"], [4890, 4891, "Metric"], [4910, 4912, "Metric"], [4960, 4962, "Method"], [5001, 5003, "Metric"], [5033, 5037, "Method"], [5038, 5039, "Method"], [5050, 5054, "Method"], [5067, 5071, "Method"], [5097, 5098, "Method"], [5099, 5100, "Method"], [5133, 5137, "Method"], [5138, 5139, "Method"], [5173, 5175, "Method"], [5186, 5187, "Metric"], [5206, 5208, "Method"], [5225, 5226, "Metric"], [5263, 5264, "Method"], [5265, 5269, "Method"], [5284, 5285, "Metric"], [5317, 5318, "Metric"], [5330, 5332, "Method"], [5335, 5339, "Method"], [5341, 5346, "Method"], [5368, 5369, "Method"], [5389, 5390, "Metric"], [5393, 5397, "Method"], [5421, 5425, "Method"], [5473, 5477, "Method"], [5491, 5492, "Metric"], [5515, 5517, "Method"], [5520, 5524, "Method"], [5547, 5552, "Method"], [5557, 5558, "Method"], [5559, 5563, "Method"], [5573, 5575, "Task"], [5591, 5594, "Method"], [5595, 5596, "Method"], [5597, 5601, "Method"], [5630, 5631, "Method"], [5732, 5733, "Task"], [5798, 5803, "Method"], [5813, 5814, "Metric"], [5839, 5840, "Method"], [5841, 5845, "Method"], [5853, 5855, "Task"], [5857, 5861, "Method"], [5863, 5864, "Method"], [5867, 5868, "Material"], [5872, 5874, "Metric"], [5878, 5882, "Method"], [5889, 5891, "Metric"], [5901, 5905, "Method"], [5923, 5924, "Metric"], [5929, 5931, "Method"], [5934, 5936, "Metric"], [5937, 5939, "Metric"], [5941, 5943, "Method"], [5954, 5956, "Metric"], [5968, 5971, "Method"], [5976, 5979, "Task"], [6018, 6019, "Method"], [6070, 6074, "Method"], [6083, 6087, "Metric"], [6101, 6103, "Metric"], [6147, 6151, "Method"], [6188, 6191, "Method"], [6196, 6200, "Method"], [6240, 6241, "Metric"], [6268, 6270, "Method"], [6283, 6284, "Metric"], [6316, 6318, "Method"], [6322, 6325, "Method"], [6329, 6331, "Method"], [6336, 6338, "Method"], [6349, 6350, "Method"], [6353, 6354, "Metric"], [6358, 6359, "Method"], [6373, 6374, "Task"], [6375, 6377, "Task"], [6379, 6381, "Task"], [6393, 6395, "Task"], [6399, 6402, "Method"], [6410, 6412, "Task"], [6418, 6419, "Method"], [6421, 6423, "Task"], [6445, 6448, "Task"], [6449, 6455, "Task"], [6464, 6465, "Method"], [6467, 6469, "Task"], [6495, 6496, "Method"], [6504, 6507, "Method"], [6509, 6510, "Task"], [6511, 6512, "Task"], [6516, 6518, "Method"], [6543, 6545, "Method"], [6554, 6557, "Method"], [6589, 6590, "Method"], [6601, 6602, "Method"], [6609, 6610, "Method"], [6670, 6672, "Method"], [6674, 6675, "Metric"], [6684, 6685, "Method"], [6686, 6687, "Metric"], [6692, 6693, "Method"], [6695, 6696, "Metric"], [6718, 6719, "Metric"], [6728, 6729, "Metric"], [6737, 6738, "Method"], [6742, 6743, "Method"], [6748, 6749, "Method"], [6761, 6764, "Task"], [6768, 6769, "Metric"], [6785, 6786, "Metric"], [6791, 6794, "Method"], [6835, 6836, "Method"], [6848, 6849, "Metric"], [6859, 6862, "Method"], [6865, 6867, "Method"], [6869, 6874, "Task"], [6888, 6890, "Task"], [6891, 6892, "Method"], [6914, 6920, "Task"], [6941, 6943, "Method"], [6958, 6960, "Task"], [6961, 6963, "Method"], [6969, 6971, "Task"], [6974, 6977, "Method"], [6980, 6983, "Task"], [6986, 6991, "Method"], [6993, 6995, "Task"], [7045, 7046, "Task"], [7049, 7053, "Method"], [7054, 7056, "Task"], [7077, 7078, "Method"], [7118, 7119, "Method"], [7164, 7166, "Method"], [7178, 7179, "Method"], [7239, 7240, "Method"], [7242, 7243, "Method"], [7256, 7257, "Method"], [7289, 7290, "Method"], [7311, 7312, "Method"], [7347, 7348, "Method"], [7391, 7392, "Method"], [7402, 7404, "Method"], [7486, 7487, "Method"], [7503, 7504, "Method"], [7509, 7512, "Metric"], [7519, 7521, "Method"], [7528, 7531, "Method"], [7555, 7558, "Method"], [7560, 7562, "Method"], [7565, 7568, "Method"], [7571, 7573, "Method"], [7585, 7586, "Method"], [7594, 7595, "Task"], [7634, 7636, "Metric"], [7648, 7649, "Method"], [7650, 7652, "Method"], [7663, 7665, "Metric"], [7677, 7679, "Metric"], [7709, 7710, "Task"], [7711, 7715, "Method"], [7738, 7740, "Method"], [7741, 7744, "Task"], [161, 162, "Material"], [614, 615, "Method"], [1230, 1234, "Method"], [1285, 1286, "Material"], [1300, 1301, "Metric"], [1337, 1338, "Metric"], [1517, 1518, "Method"], [2969, 2970, "Method"], [2997, 2998, "Method"], [3288, 3289, "Metric"], [3296, 3297, "Metric"], [3313, 3314, "Metric"], [3620, 3621, "Method"], [3668, 3669, "Method"], [3687, 3691, "Method"], [3725, 3726, "Method"], [3852, 3853, "Method"], [3904, 3905, "Method"], [3922, 3923, "Method"], [3941, 3942, "Method"], [3974, 3975, "Material"], [4060, 4061, "Method"], [4124, 4125, "Material"], [4127, 4129, "Metric"], [4130, 4131, "Metric"], [4143, 4144, "Metric"], [4146, 4147, "Metric"], [4150, 4151, "Metric"], [4172, 4173, "Metric"], [4175, 4176, "Metric"], [4339, 4340, "Metric"], [4446, 4447, "Method"], [4630, 4631, "Metric"], [4784, 4785, "Material"], [4896, 4897, "Metric"], [4901, 4902, "Metric"], [4925, 4926, "Metric"], [4928, 4929, "Metric"], [4932, 4933, "Metric"], [5045, 5046, "Material"], [5062, 5063, "Method"], [5077, 5078, "Method"], [5078, 5081, "Method"], [5149, 5150, "Method"], [5150, 5153, "Method"], [5162, 5163, "Method"], [5211, 5212, "Method"], [5234, 5235, "Method"], [5291, 5292, "Metric"], [5440, 5441, "Metric"], [5454, 5455, "Metric"], [5469, 5470, "Method"], [5501, 5502, "Method"], [5613, 5617, "Method"], [5647, 5648, "Metric"], [5795, 5798, "Method"], [5945, 5946, "Method"], [5948, 5952, "Method"], [5991, 5994, "Method"], [6037, 6041, "Method"], [6063, 6064, "Material"], [6106, 6107, "Method"], [6107, 6110, "Method"], [6114, 6115, "Metric"], [6133, 6134, "Material"], [6180, 6181, "Material"], [6369, 6370, "Material"], [6428, 6429, "Method"], [6438, 6439, "Method"], [6645, 6646, "Metric"], [6648, 6649, "Metric"], [6665, 6666, "Method"], [6698, 6699, "Metric"], [6709, 6710, "Metric"], [6776, 6777, "Metric"], [7002, 7003, "Method"], [7016, 7017, "Method"]], "sections": [[0, 6], [6, 201], [201, 1450], [1450, 2032], [2032, 2865], [2865, 2944], [2944, 3495], [3495, 3961], [3961, 4115], [4115, 4639], [4639, 4851], [4851, 5048], [5048, 5518], [5518, 6059], [6059, 6389], [6389, 6630], [6630, 6875], [6875, 6964], [6964, 7745], [7745, 7747]], "sentences": [[0, 6], [6, 9], [9, 25], [25, 46], [46, 73], [73, 93], [93, 117], [117, 166], [166, 194], [194, 201], [201, 204], [204, 218], [218, 253], [253, 278], [278, 305], [305, 319], [319, 325], [325, 354], [354, 374], [374, 419], [419, 428], [428, 445], [445, 481], [481, 517], [517, 530], [530, 553], [553, 610], [610, 636], [636, 654], [654, 680], [680, 704], [704, 723], [723, 764], [764, 794], [794, 832], [832, 840], [840, 857], [857, 868], [868, 899], [899, 935], [935, 944], [944, 968], [968, 1001], [1001, 1056], [1056, 1090], [1090, 1107], [1107, 1176], [1176, 1203], [1203, 1228], [1228, 1253], [1253, 1319], [1319, 1323], [1323, 1356], [1356, 1391], [1391, 1414], [1414, 1431], [1431, 1442], [1442, 1450], [1450, 1454], [1454, 1463], [1463, 1483], [1483, 1504], [1504, 1529], [1529, 1542], [1542, 1546], [1546, 1570], [1570, 1599], [1599, 1604], [1604, 1635], [1635, 1660], [1660, 1687], [1687, 1714], [1714, 1758], [1758, 1774], [1774, 1779], [1779, 1796], [1796, 1814], [1814, 1827], [1827, 1864], [1864, 1890], [1890, 1947], [1947, 1951], [1951, 1966], [1966, 2000], [2000, 2002], [2002, 2012], [2012, 2032], [2032, 2037], [2037, 2070], [2070, 2096], [2096, 2110], [2110, 2114], [2114, 2125], [2125, 2127], [2127, 2158], [2158, 2188], [2188, 2192], [2192, 2220], [2220, 2225], [2225, 2258], [2258, 2282], [2282, 2296], [2296, 2324], [2324, 2341], [2341, 2362], [2362, 2420], [2420, 2435], [2435, 2443], [2443, 2466], [2466, 2483], [2483, 2507], [2507, 2534], [2534, 2536], [2536, 2548], [2548, 2575], [2575, 2608], [2608, 2620], [2620, 2642], [2642, 2670], [2670, 2716], [2716, 2755], [2755, 2775], [2775, 2796], [2796, 2816], [2816, 2843], [2843, 2865], [2865, 2868], [2868, 2882], [2882, 2912], [2912, 2944], [2944, 2951], [2951, 2966], [2966, 3003], [3003, 3031], [3031, 3053], [3053, 3057], [3057, 3078], [3078, 3093], [3093, 3118], [3118, 3146], [3146, 3159], [3159, 3173], [3173, 3205], [3205, 3208], [3208, 3232], [3232, 3243], [3243, 3324], [3324, 3365], [3365, 3382], [3382, 3412], [3412, 3430], [3430, 3459], [3459, 3485], [3485, 3495], [3495, 3505], [3505, 3536], [3536, 3552], [3552, 3572], [3572, 3587], [3587, 3615], [3615, 3647], [3647, 3673], [3673, 3681], [3681, 3714], [3714, 3718], [3718, 3758], [3758, 3787], [3787, 3800], [3800, 3843], [3843, 3891], [3891, 3910], [3910, 3931], [3931, 3952], [3952, 3961], [3961, 3967], [3967, 3981], [3981, 4018], [4018, 4042], [4042, 4075], [4075, 4094], [4094, 4097], [4097, 4112], [4112, 4115], [4115, 4121], [4121, 4161], [4161, 4179], [4179, 4182], [4182, 4195], [4195, 4209], [4209, 4218], [4218, 4233], [4233, 4246], [4246, 4265], [4265, 4300], [4300, 4324], [4324, 4330], [4330, 4353], [4353, 4366], [4366, 4374], [4374, 4391], [4391, 4412], [4412, 4432], [4432, 4454], [4454, 4489], [4489, 4515], [4515, 4528], [4528, 4534], [4534, 4556], [4556, 4569], [4569, 4593], [4593, 4623], [4623, 4639], [4639, 4645], [4645, 4651], [4651, 4687], [4687, 4706], [4706, 4726], [4726, 4751], [4751, 4771], [4771, 4788], [4788, 4795], [4795, 4819], [4819, 4835], [4835, 4851], [4851, 4862], [4862, 4878], [4878, 4907], [4907, 4943], [4943, 4946], [4946, 4960], [4960, 4972], [4972, 4987], [4987, 5000], [5000, 5019], [5019, 5032], [5032, 5048], [5048, 5059], [5059, 5088], [5088, 5125], [5125, 5144], [5144, 5183], [5183, 5196], [5196, 5222], [5222, 5253], [5253, 5270], [5270, 5296], [5296, 5322], [5322, 5325], [5325, 5347], [5347, 5370], [5370, 5412], [5412, 5436], [5436, 5463], [5463, 5488], [5488, 5518], [5518, 5529], [5529, 5544], [5544, 5577], [5577, 5602], [5602, 5653], [5653, 5679], [5679, 5689], [5689, 5702], [5702, 5770], [5770, 5795], [5795, 5798], [5798, 5809], [5809, 5823], [5823, 5826], [5826, 5846], [5846, 5852], [5852, 5869], [5869, 5892], [5892, 5929], [5929, 5937], [5937, 5940], [5940, 5980], [5980, 5983], [5983, 6006], [6006, 6027], [6027, 6043], [6043, 6059], [6059, 6066], [6066, 6088], [6088, 6112], [6112, 6124], [6124, 6142], [6142, 6167], [6167, 6201], [6201, 6221], [6221, 6257], [6257, 6290], [6290, 6303], [6303, 6344], [6344, 6356], [6356, 6382], [6382, 6389], [6389, 6395], [6395, 6413], [6413, 6430], [6430, 6436], [6436, 6456], [6456, 6473], [6473, 6484], [6484, 6490], [6490, 6501], [6501, 6513], [6513, 6522], [6522, 6529], [6529, 6563], [6563, 6599], [6599, 6611], [6611, 6630], [6630, 6635], [6635, 6642], [6642, 6663], [6663, 6678], [6678, 6690], [6690, 6700], [6700, 6721], [6721, 6732], [6732, 6765], [6765, 6778], [6778, 6790], [6790, 6830], [6830, 6851], [6851, 6875], [6875, 6878], [6878, 6893], [6893, 6906], [6906, 6929], [6929, 6964], [6964, 6971], [6971, 6995], [6995, 7017], [7017, 7023], [7023, 7061], [7061, 7079], [7079, 7120], [7120, 7135], [7135, 7152], [7152, 7154], [7154, 7160], [7160, 7176], [7176, 7196], [7196, 7241], [7241, 7295], [7295, 7309], [7309, 7343], [7343, 7349], [7349, 7406], [7406, 7424], [7424, 7466], [7466, 7502], [7502, 7516], [7516, 7549], [7549, 7570], [7570, 7593], [7593, 7624], [7624, 7637], [7637, 7659], [7659, 7687], [7687, 7708], [7708, 7731], [7731, 7745], [7745, 7747]], "words": ["Feature", "Pyramid", "Networks", "for", "Object", "Detection", "section", ":", "Abstract", "Feature", "pyramids", "are", "a", "basic", "component", "in", "recognition", "systems", "for", "detecting", "objects", "at", "different", "scales", ".", "But", "recent", "deep", "learning", "object", "detectors", "have", "avoided", "pyramid", "representations", ",", "in", "part", "because", "they", "are", "compute", "and", "memory", "intensive", ".", "In", "this", "paper", ",", "we", "exploit", "the", "inherent", "multi", "-", "scale", ",", "pyramidal", "hierarchy", "of", "deep", "convolutional", "networks", "to", "construct", "feature", "pyramids", "with", "marginal", "extra", "cost", ".", "A", "topdown", "architecture", "with", "lateral", "connections", "is", "developed", "for", "building", "high", "-", "level", "semantic", "feature", "maps", "at", "all", "scales", ".", "This", "architecture", ",", "called", "a", "Feature", "Pyramid", "Network", "(", "FPN", ")", ",", "shows", "significant", "improvement", "as", "a", "generic", "feature", "extractor", "in", "several", "applications", ".", "Using", "FPN", "in", "a", "basic", "Faster", "R", "-", "CNN", "system", ",", "our", "method", "achieves", "state", "-", "of", "-", "the", "-", "art", "singlemodel", "results", "on", "the", "COCO", "detection", "benchmark", "without", "bells", "and", "whistles", ",", "surpassing", "all", "existing", "single", "-", "model", "entries", "including", "those", "from", "the", "COCO", "2016", "challenge", "winners", ".", "In", "addition", ",", "our", "method", "can", "run", "at", "6", "FPS", "on", "a", "GPU", "and", "thus", "is", "a", "practical", "and", "accurate", "solution", "to", "multi", "-", "scale", "object", "detection", ".", "Code", "will", "be", "made", "publicly", "available", ".", "section", ":", "Introduction", "Recognizing", "objects", "at", "vastly", "different", "scales", "is", "a", "fundamental", "challenge", "in", "computer", "vision", ".", "Feature", "pyramids", "built", "upon", "image", "pyramids", "(", "for", "short", "we", "call", "these", "featurized", "image", "pyramids", ")", "form", "the", "basis", "of", "a", "standard", "solution", "[", "reference", "]", "(", "Fig", ".", "1", "(", "a", ")", ")", ".", "These", "pyramids", "are", "scale", "-", "invariant", "in", "the", "sense", "that", "an", "object", "'s", "scale", "change", "is", "offset", "by", "shifting", "its", "level", "in", "the", "pyramid", ".", "Intuitively", ",", "this", "property", "enables", "a", "model", "to", "detect", "objects", "across", "a", "large", "range", "of", "scales", "by", "scanning", "the", "model", "over", "both", "positions", "and", "pyramid", "levels", ".", "Featurized", "image", "pyramids", "were", "heavily", "used", "in", "the", "era", "of", "hand", "-", "engineered", "features", "[", "reference", "][", "reference", "]", ".", "They", "were", "so", "critical", "that", "object", "detectors", "like", "DPM", "[", "reference", "]", "required", "dense", "scale", "sampling", "to", "achieve", "good", "results", "(", "e.g.", ",", "10", "scales", "per", "octave", ")", ".", "For", "recognition", "tasks", ",", "engineered", "features", "have", "largely", "been", "replaced", "with", "features", "computed", "by", "deep", "convolutional", "networks", "(", "ConvNets", ")", "[", "reference", "][", "reference", "]", ".", "Aside", "from", "being", "capable", "of", "representing", "higher", "-", "level", "semantics", ",", "ConvNets", "are", "also", "more", "robust", "to", "variance", "in", "scale", "and", "thus", "facilitate", "recognition", "from", "features", "computed", "on", "a", "single", "input", "scale", "[", "reference", "][", "reference", "][", "reference", "]", "(", "Fig", ".", "1", "(", "b", ")", ")", ".", "But", "even", "with", "this", "robustness", ",", "pyramids", "are", "still", "needed", "to", "get", "the", "most", "accurate", "results", ".", "All", "recent", "top", "entries", "in", "the", "ImageNet", "[", "reference", "]", "and", "COCO", "[", "reference", "]", "detection", "challenges", "use", "multi", "-", "scale", "testing", "on", "featurized", "image", "pyramids", "(", "e.g.", ",", "[", "reference", "][", "reference", "]", ")", ".", "The", "principle", "advantage", "of", "featurizing", "each", "level", "of", "an", "image", "pyramid", "is", "that", "it", "produces", "a", "multi", "-", "scale", "feature", "representation", "in", "which", "all", "levels", "are", "semantically", "strong", ",", "including", "the", "high", "-", "resolution", "levels", ".", "Nevertheless", ",", "featurizing", "each", "level", "of", "an", "image", "pyramid", "has", "obvious", "limitations", ".", "Inference", "time", "increases", "considerably", "(", "e.g.", ",", "by", "four", "times", "[", "reference", "]", ")", ",", "making", "this", "approach", "impractical", "for", "real", "applications", ".", "Moreover", ",", "training", "deep", "networks", "end", "-", "to", "-", "end", "on", "an", "image", "pyramid", "is", "infeasible", "in", "terms", "of", "memory", ",", "and", "so", ",", "if", "exploited", ",", "image", "pyramids", "are", "used", "only", "at", "test", "time", "[", "reference", "][", "reference", "][", "reference", "][", "reference", "]", ",", "which", "creates", "an", "inconsistency", "between", "train", "/", "test", "-", "time", "inference", ".", "For", "these", "reasons", ",", "Fast", "and", "Faster", "R", "-", "CNN", "[", "reference", "][", "reference", "]", "opt", "to", "not", "use", "featurized", "image", "pyramids", "under", "default", "settings", ".", "However", ",", "image", "pyramids", "are", "not", "the", "only", "way", "to", "compute", "a", "multi", "-", "scale", "feature", "representation", ".", "A", "deep", "ConvNet", "computes", "a", "feature", "hierarchy", "layer", "by", "layer", ",", "and", "with", "subsampling", "layers", "the", "feature", "hierarchy", "has", "an", "inherent", "multiscale", ",", "pyramidal", "shape", ".", "This", "in", "-", "network", "feature", "hierarchy", "produces", "feature", "maps", "of", "different", "spatial", "resolutions", ",", "but", "introduces", "large", "semantic", "gaps", "caused", "by", "different", "depths", ".", "The", "high", "-", "resolution", "maps", "have", "low", "-", "level", "features", "that", "harm", "their", "representational", "capacity", "for", "object", "recognition", ".", "The", "Single", "Shot", "Detector", "(", "SSD", ")", "[", "reference", "]", "is", "one", "of", "the", "first", "attempts", "at", "using", "a", "ConvNet", "'s", "pyramidal", "feature", "hierarchy", "as", "if", "it", "were", "a", "featurized", "image", "pyramid", "(", "Fig", ".", "1", "(", "c", ")", ")", ".", "Ideally", ",", "the", "SSD", "-", "style", "pyramid", "would", "reuse", "the", "multi", "-", "scale", "feature", "maps", "from", "different", "layers", "computed", "in", "the", "forward", "pass", "and", "thus", "come", "free", "of", "cost", ".", "But", "to", "avoid", "using", "low", "-", "level", "features", "SSD", "foregoes", "reusing", "already", "computed", "layers", "and", "instead", "builds", "the", "pyramid", "starting", "from", "high", "up", "in", "the", "network", "(", "e.g.", ",", "conv4", "3", "of", "VGG", "nets", "[", "reference", "]", ")", "and", "then", "by", "adding", "several", "new", "layers", ".", "Thus", "it", "misses", "the", "opportunity", "to", "reuse", "the", "higher", "-", "resolution", "maps", "of", "the", "feature", "hierarchy", ".", "We", "show", "that", "these", "are", "important", "for", "detecting", "small", "objects", ".", "The", "goal", "of", "this", "paper", "is", "to", "naturally", "leverage", "the", "pyramidal", "shape", "of", "a", "ConvNet", "'s", "feature", "hierarchy", "while", "creating", "a", "feature", "pyramid", "that", "has", "strong", "semantics", "at", "all", "scales", ".", "To", "achieve", "this", "goal", ",", "we", "rely", "on", "an", "architecture", "that", "combines", "low", "-", "resolution", ",", "semantically", "strong", "features", "with", "high", "-", "resolution", ",", "semantically", "weak", "features", "via", "a", "top", "-", "down", "pathway", "and", "lateral", "connections", "(", "Fig", ".", "1", "(", "d", ")", ")", ".", "The", "result", "is", "a", "feature", "pyramid", "that", "has", "rich", "semantics", "at", "all", "levels", "and", "is", "built", "quickly", "from", "a", "single", "input", "image", "scale", ".", "In", "other", "words", ",", "we", "show", "how", "to", "create", "in", "-", "network", "feature", "pyramids", "that", "can", "be", "used", "to", "replace", "featurized", "image", "pyramids", "without", "sacrificing", "representational", "power", ",", "speed", ",", "or", "memory", ".", "Similar", "architectures", "adopting", "top", "-", "down", "and", "skip", "connections", "are", "popular", "in", "recent", "research", "[", "reference", "][", "reference", "][", "reference", "][", "reference", "]", ".", "Their", "goals", "are", "to", "produce", "a", "single", "high", "-", "level", "feature", "map", "of", "a", "fine", "resolution", "on", "which", "the", "predictions", "are", "to", "be", "made", "(", "Fig", ".", "2", "top", ")", ".", "On", "the", "contrary", ",", "our", "method", "leverages", "the", "architecture", "as", "a", "feature", "pyramid", "where", "predictions", "(", "e.g.", ",", "object", "detections", ")", "are", "independently", "made", "on", "each", "level", "(", "Fig", ".", "2", "bottom", ")", ".", "Our", "model", "echoes", "a", "featurized", "image", "pyramid", ",", "which", "has", "not", "been", "explored", "in", "these", "works", ".", "We", "evaluate", "our", "method", ",", "called", "a", "Feature", "Pyramid", "Network", "(", "FPN", ")", ",", "in", "various", "systems", "for", "detection", "and", "segmentation", "[", "reference", "][", "reference", "][", "reference", "]", ".", "Without", "bells", "and", "whistles", ",", "we", "report", "a", "state", "-", "of", "-", "the", "-", "art", "single", "-", "model", "result", "on", "the", "challenging", "COCO", "detection", "benchmark", "[", "reference", "]", "simply", "based", "on", "FPN", "and", "predict", "predict", "predict", "predict", "Figure", "2", ".", "Top", ":", "a", "top", "-", "down", "architecture", "with", "skip", "connections", ",", "where", "predictions", "are", "made", "on", "the", "finest", "level", "(", "e.g.", ",", "[", "reference", "]", ")", ".", "Bottom", ":", "our", "model", "that", "has", "a", "similar", "structure", "but", "leverages", "it", "as", "a", "feature", "pyramid", ",", "with", "predictions", "made", "independently", "at", "all", "levels", ".", "a", "basic", "Faster", "R", "-", "CNN", "detector", "[", "reference", "]", ",", "surpassing", "all", "existing", "heavily", "-", "engineered", "single", "-", "model", "entries", "of", "competition", "winners", ".", "In", "ablation", "experiments", ",", "we", "find", "that", "for", "bounding", "box", "proposals", ",", "FPN", "significantly", "increases", "the", "Average", "Recall", "(", "AR", ")", "by", "8.0", "points", ";", "for", "object", "detection", ",", "it", "improves", "the", "COCO", "-", "style", "Average", "Precision", "(", "AP", ")", "by", "2.3", "points", "and", "PASCAL", "-", "style", "AP", "by", "3.8", "points", ",", "over", "a", "strong", "single", "-", "scale", "baseline", "of", "Faster", "R", "-", "CNN", "on", "ResNets", "[", "reference", "]", ".", "Our", "method", "is", "also", "easily", "extended", "to", "mask", "proposals", "and", "improves", "both", "instance", "segmentation", "AR", "and", "speed", "over", "state", "-", "of", "-", "the", "-", "art", "methods", "that", "heavily", "depend", "on", "image", "pyramids", ".", "In", "addition", ",", "our", "pyramid", "structure", "can", "be", "trained", "end", "-", "toend", "with", "all", "scales", "and", "is", "used", "consistently", "at", "train", "/", "test", "time", ",", "which", "would", "be", "memory", "-", "infeasible", "using", "image", "pyramids", ".", "As", "a", "result", ",", "FPNs", "are", "able", "to", "achieve", "higher", "accuracy", "than", "all", "existing", "state", "-", "of", "-", "the", "-", "art", "methods", ".", "Moreover", ",", "this", "improvement", "is", "achieved", "without", "increasing", "testing", "time", "over", "the", "single", "-", "scale", "baseline", ".", "We", "believe", "these", "advances", "will", "facilitate", "future", "research", "and", "applications", ".", "Our", "code", "will", "be", "made", "publicly", "available", ".", "section", ":", "Related", "Work", "Hand", "-", "engineered", "features", "and", "early", "neural", "networks", ".", "SIFT", "features", "[", "reference", "]", "were", "originally", "extracted", "at", "scale", "-", "space", "extrema", "and", "used", "for", "feature", "point", "matching", ".", "HOG", "features", "[", "reference", "]", ",", "and", "later", "SIFT", "features", "as", "well", ",", "were", "computed", "densely", "over", "entire", "image", "pyramids", ".", "These", "HOG", "and", "SIFT", "pyramids", "have", "been", "used", "in", "numerous", "works", "for", "image", "classification", ",", "object", "detection", ",", "human", "pose", "estimation", ",", "and", "more", ".", "There", "has", "also", "been", "significant", "interest", "in", "computing", "featurized", "image", "pyramids", "quickly", ".", "Doll\u00e1r", "et", "al", ".", "[", "reference", "]", "demonstrated", "fast", "pyramid", "computation", "by", "first", "computing", "a", "sparsely", "sampled", "(", "in", "scale", ")", "pyramid", "and", "then", "interpolating", "missing", "levels", ".", "Before", "HOG", "and", "SIFT", ",", "early", "work", "on", "face", "detection", "with", "ConvNets", "[", "reference", "][", "reference", "]", "computed", "shallow", "networks", "over", "image", "pyramids", "to", "detect", "faces", "across", "scales", ".", "Deep", "ConvNet", "object", "detectors", ".", "With", "the", "development", "of", "modern", "deep", "ConvNets", "[", "reference", "]", ",", "object", "detectors", "like", "OverFeat", "[", "reference", "]", "and", "R", "-", "CNN", "[", "reference", "]", "showed", "dramatic", "improvements", "in", "accuracy", ".", "OverFeat", "adopted", "a", "strategy", "similar", "to", "early", "neural", "network", "face", "detectors", "by", "applying", "a", "ConvNet", "as", "a", "sliding", "window", "detector", "on", "an", "image", "pyramid", ".", "R", "-", "CNN", "adopted", "a", "region", "proposal", "-", "based", "strategy", "[", "reference", "]", "in", "which", "each", "proposal", "was", "scale", "-", "normalized", "before", "classifying", "with", "a", "ConvNet", ".", "SPPnet", "[", "reference", "]", "demonstrated", "that", "such", "region", "-", "based", "detectors", "could", "be", "applied", "much", "more", "efficiently", "on", "feature", "maps", "extracted", "on", "a", "single", "image", "scale", ".", "Recent", "and", "more", "accurate", "detection", "methods", "like", "Fast", "R", "-", "CNN", "[", "reference", "]", "and", "Faster", "R", "-", "CNN", "[", "reference", "]", "advocate", "using", "features", "computed", "from", "a", "single", "scale", ",", "because", "it", "offers", "a", "good", "trade", "-", "off", "between", "accuracy", "and", "speed", ".", "Multi", "-", "scale", "detection", ",", "however", ",", "still", "performs", "better", ",", "especially", "for", "small", "objects", ".", "Methods", "using", "multiple", "layers", ".", "A", "number", "of", "recent", "approaches", "improve", "detection", "and", "segmentation", "by", "using", "different", "layers", "in", "a", "ConvNet", ".", "FCN", "[", "reference", "]", "sums", "partial", "scores", "for", "each", "category", "over", "multiple", "scales", "to", "compute", "semantic", "segmentations", ".", "Hypercolumns", "[", "reference", "]", "uses", "a", "similar", "method", "for", "object", "instance", "segmentation", ".", "Several", "other", "approaches", "(", "HyperNet", "[", "reference", "]", ",", "ParseNet", "[", "reference", "]", ",", "and", "ION", "[", "reference", "]", ")", "concatenate", "features", "of", "multiple", "layers", "before", "computing", "predictions", ",", "which", "is", "equivalent", "to", "summing", "transformed", "features", ".", "SSD", "[", "reference", "]", "and", "MS", "-", "CNN", "[", "reference", "]", "predict", "objects", "at", "multiple", "layers", "of", "the", "feature", "hierarchy", "without", "combining", "features", "or", "scores", ".", "There", "are", "recent", "methods", "exploiting", "lateral", "/", "skip", "connections", "that", "associate", "low", "-", "level", "feature", "maps", "across", "resolutions", "and", "semantic", "levels", ",", "including", "U", "-", "Net", "[", "reference", "]", "and", "SharpMask", "[", "reference", "]", "for", "segmentation", ",", "Recombinator", "networks", "[", "reference", "]", "for", "face", "detection", ",", "and", "Stacked", "Hourglass", "networks", "[", "reference", "]", "for", "keypoint", "estimation", ".", "Ghiasi", "et", "al", ".", "[", "reference", "]", "present", "a", "Laplacian", "pyramid", "presentation", "for", "FCNs", "to", "progressively", "refine", "segmentation", ".", "Although", "these", "methods", "adopt", "architectures", "with", "pyramidal", "shapes", ",", "they", "are", "unlike", "featurized", "image", "pyramids", "[", "reference", "][", "reference", "][", "reference", "]", "where", "predictions", "are", "made", "independently", "at", "all", "levels", ",", "see", "Fig", ".", "2", ".", "In", "fact", ",", "for", "the", "pyramidal", "architecture", "in", "Fig", ".", "2", "(", "top", ")", ",", "image", "pyramids", "are", "still", "needed", "to", "recognize", "objects", "across", "multiple", "scales", "[", "reference", "]", ".", "section", ":", "Feature", "Pyramid", "Networks", "Our", "goal", "is", "to", "leverage", "a", "ConvNet", "'s", "pyramidal", "feature", "hierarchy", ",", "which", "has", "semantics", "from", "low", "to", "high", "levels", ",", "and", "build", "a", "feature", "pyramid", "with", "high", "-", "level", "semantics", "throughout", ".", "The", "resulting", "Feature", "Pyramid", "Network", "is", "generalpurpose", "and", "in", "this", "paper", "we", "focus", "on", "sliding", "window", "proposers", "(", "Region", "Proposal", "Network", ",", "RPN", "for", "short", ")", "[", "reference", "]", "and", "region", "-", "based", "detectors", "(", "Fast", "R", "-", "CNN", ")", "[", "reference", "]", ".", "We", "also", "generalize", "FPNs", "to", "instance", "segmentation", "proposals", "in", "Sec", ".", "6", ".", "Our", "method", "takes", "a", "single", "-", "scale", "image", "of", "an", "arbitrary", "size", "as", "input", ",", "and", "outputs", "proportionally", "sized", "feature", "maps", "at", "multiple", "levels", ",", "in", "a", "fully", "convolutional", "fashion", ".", "This", "process", "is", "independent", "of", "the", "backbone", "convolutional", "architectures", "(", "e.g.", ",", "[", "reference", "][", "reference", "][", "reference", "]", ")", ",", "and", "in", "this", "paper", "we", "present", "results", "using", "ResNets", "[", "reference", "]", ".", "The", "construction", "of", "our", "pyramid", "involves", "a", "bottom", "-", "up", "pathway", ",", "a", "top", "-", "down", "pathway", ",", "and", "lateral", "connections", ",", "as", "introduced", "in", "the", "following", ".", "Bottom", "-", "up", "pathway", ".", "The", "bottom", "-", "up", "pathway", "is", "the", "feedforward", "computation", "of", "the", "backbone", "ConvNet", ",", "which", "computes", "a", "feature", "hierarchy", "consisting", "of", "feature", "maps", "at", "several", "scales", "with", "a", "scaling", "step", "of", "2", ".", "There", "are", "often", "many", "layers", "producing", "output", "maps", "of", "the", "same", "size", "and", "we", "say", "these", "layers", "are", "in", "the", "same", "network", "stage", ".", "For", "our", "feature", "pyramid", ",", "we", "define", "one", "pyramid", "level", "for", "each", "stage", ".", "We", "choose", "the", "output", "of", "the", "last", "layer", "of", "each", "stage", "as", "our", "reference", "set", "of", "feature", "maps", ",", "which", "we", "will", "enrich", "to", "create", "our", "pyramid", ".", "This", "choice", "is", "natural", "since", "the", "deepest", "layer", "of", "each", "stage", "should", "have", "the", "strongest", "features", ".", "Specifically", ",", "for", "ResNets", "[", "reference", "]", "we", "use", "the", "feature", "activations", "output", "by", "each", "stage", "'s", "last", "residual", "block", ".", "We", "denote", "the", "output", "of", "these", "last", "residual", "blocks", "as", "{", "C", "2", ",", "C", "3", ",", "C", "4", ",", "C", "5", "}", "for", "conv2", ",", "conv3", ",", "conv4", ",", "and", "conv5", "outputs", ",", "and", "note", "that", "they", "have", "strides", "of", "{", "4", ",", "8", ",", "16", ",", "32", "}", "pixels", "with", "respect", "to", "the", "input", "image", ".", "We", "do", "not", "include", "conv1", "into", "the", "pyramid", "due", "to", "its", "large", "memory", "footprint", ".", "Top", "-", "down", "pathway", "and", "lateral", "connections", ".", "The", "topdown", "pathway", "hallucinates", "higher", "resolution", "features", "by", "upsampling", "spatially", "coarser", ",", "but", "semantically", "stronger", ",", "feature", "maps", "from", "higher", "pyramid", "levels", ".", "These", "features", "are", "then", "enhanced", "with", "features", "from", "the", "bottom", "-", "up", "pathway", "via", "lateral", "connections", ".", "Each", "lateral", "connection", "merges", "feature", "maps", "of", "the", "same", "spatial", "size", "from", "the", "bottom", "-", "up", "pathway", "and", "the", "top", "-", "down", "pathway", ".", "The", "bottom", "-", "up", "feature", "map", "is", "of", "lower", "-", "level", "semantics", ",", "but", "its", "activations", "are", "more", "accurately", "localized", "as", "it", "was", "subsampled", "fewer", "times", ".", "Fig", ".", "3", "shows", "the", "building", "block", "that", "constructs", "our", "topdown", "feature", "maps", ".", "With", "a", "coarser", "-", "resolution", "feature", "map", ",", "we", "upsample", "the", "spatial", "resolution", "by", "a", "factor", "of", "2", "(", "using", "nearest", "neighbor", "upsampling", "for", "simplicity", ")", ".", "The", "upsam", "-", "pled", "map", "is", "then", "merged", "with", "the", "corresponding", "bottom", "-", "up", "map", "(", "which", "undergoes", "a", "1\u00d71", "convolutional", "layer", "to", "reduce", "channel", "dimensions", ")", "by", "element", "-", "wise", "addition", ".", "This", "process", "is", "iterated", "until", "the", "finest", "resolution", "map", "is", "generated", ".", "To", "start", "the", "iteration", ",", "we", "simply", "attach", "a", "1\u00d71", "convolutional", "layer", "on", "C", "5", "to", "produce", "the", "coarsest", "resolution", "map", ".", "Finally", ",", "we", "append", "a", "3\u00d73", "convolution", "on", "each", "merged", "map", "to", "generate", "the", "final", "feature", "map", ",", "which", "is", "to", "reduce", "the", "aliasing", "effect", "of", "upsampling", ".", "This", "final", "set", "of", "feature", "maps", "is", "called", "{", "P", "2", ",", "P", "3", ",", "P", "4", ",", "P", "5", "}", ",", "corresponding", "to", "{", "C", "2", ",", "C", "3", ",", "C", "4", ",", "C", "5", "}", "that", "are", "respectively", "of", "the", "same", "spatial", "sizes", ".", "Because", "all", "levels", "of", "the", "pyramid", "use", "shared", "classifiers", "/", "regressors", "as", "in", "a", "traditional", "featurized", "image", "pyramid", ",", "we", "fix", "the", "feature", "dimension", "(", "numbers", "of", "channels", ",", "denoted", "as", "d", ")", "in", "all", "the", "feature", "maps", ".", "We", "set", "d", "=", "256", "in", "this", "paper", "and", "thus", "all", "extra", "convolutional", "layers", "have", "256", "-", "channel", "outputs", ".", "There", "are", "no", "non", "-", "linearities", "in", "these", "extra", "layers", ",", "which", "we", "have", "empirically", "found", "to", "have", "minor", "impacts", ".", "Simplicity", "is", "central", "to", "our", "design", "and", "we", "have", "found", "that", "our", "model", "is", "robust", "to", "many", "design", "choices", ".", "We", "have", "experimented", "with", "more", "sophisticated", "blocks", "(", "e.g.", ",", "using", "multilayer", "residual", "blocks", "[", "reference", "]", "as", "the", "connections", ")", "and", "observed", "marginally", "better", "results", ".", "Designing", "better", "connection", "modules", "is", "not", "the", "focus", "of", "this", "paper", ",", "so", "we", "opt", "for", "the", "simple", "design", "described", "above", ".", "section", ":", "Applications", "Our", "method", "is", "a", "generic", "solution", "for", "building", "feature", "pyramids", "inside", "deep", "ConvNets", ".", "In", "the", "following", "we", "adopt", "our", "method", "in", "RPN", "[", "reference", "]", "for", "bounding", "box", "proposal", "generation", "and", "in", "Fast", "R", "-", "CNN", "[", "reference", "]", "for", "object", "detection", ".", "To", "demonstrate", "the", "simplicity", "and", "effectiveness", "of", "our", "method", ",", "we", "make", "minimal", "modifications", "to", "the", "original", "systems", "of", "[", "reference", "][", "reference", "]", "when", "adapting", "them", "to", "our", "feature", "pyramid", ".", "section", ":", "Feature", "Pyramid", "Networks", "for", "RPN", "RPN", "[", "reference", "]", "is", "a", "sliding", "-", "window", "class", "-", "agnostic", "object", "detector", ".", "In", "the", "original", "RPN", "design", ",", "a", "small", "subnetwork", "is", "evaluated", "on", "dense", "3\u00d73", "sliding", "windows", ",", "on", "top", "of", "a", "singlescale", "convolutional", "feature", "map", ",", "performing", "object", "/", "nonobject", "binary", "classification", "and", "bounding", "box", "regression", ".", "This", "is", "realized", "by", "a", "3\u00d73", "convolutional", "layer", "followed", "by", "two", "sibling", "1\u00d71", "convolutions", "for", "classification", "and", "regression", ",", "which", "we", "refer", "to", "as", "a", "network", "head", ".", "The", "object", "/", "nonobject", "criterion", "and", "bounding", "box", "regression", "target", "are", "defined", "with", "respect", "to", "a", "set", "of", "reference", "boxes", "called", "anchors", "[", "reference", "]", ".", "The", "anchors", "are", "of", "multiple", "pre", "-", "defined", "scales", "and", "aspect", "ratios", "in", "order", "to", "cover", "objects", "of", "different", "shapes", ".", "We", "adapt", "RPN", "by", "replacing", "the", "single", "-", "scale", "feature", "map", "with", "our", "FPN", ".", "We", "attach", "a", "head", "of", "the", "same", "design", "(", "3\u00d73", "conv", "and", "two", "sibling", "1\u00d71", "convs", ")", "to", "each", "level", "on", "our", "feature", "pyramid", ".", "Because", "the", "head", "slides", "densely", "over", "all", "locations", "in", "all", "pyramid", "levels", ",", "it", "is", "not", "necessary", "to", "have", "multi", "-", "scale", "anchors", "on", "a", "specific", "level", ".", "Instead", ",", "we", "assign", "anchors", "of", "a", "single", "scale", "to", "each", "level", ".", "Formally", ",", "we", "define", "the", "anchors", "to", "have", "areas", "of", "{", "32", "2", ",", "64", "2", ",", "128", "2", ",", "256", "2", ",", "512", "2", "}", "pixels", "on", "{", "P", "2", ",", "P", "3", ",", "P", "4", ",", "P", "5", ",", "P", "6", "}", "respectively", ".", "[", "reference", "]", "As", "in", "[", "reference", "]", "we", "also", "use", "anchors", "of", "multiple", "aspect", "ratios", "{", "1:2", ",", "1:1", ",", "2:1", "}", "at", "each", "level", ".", "So", "in", "total", "there", "are", "15", "anchors", "over", "the", "pyramid", ".", "We", "assign", "training", "labels", "to", "the", "anchors", "based", "on", "their", "Intersection", "-", "over", "-", "Union", "(", "IoU", ")", "ratios", "with", "ground", "-", "truth", "bounding", "boxes", "as", "in", "[", "reference", "]", ".", "Formally", ",", "an", "anchor", "is", "assigned", "a", "positive", "label", "if", "it", "has", "the", "highest", "IoU", "for", "a", "given", "groundtruth", "box", "or", "an", "IoU", "over", "0.7", "with", "any", "ground", "-", "truth", "box", ",", "and", "a", "negative", "label", "if", "it", "has", "IoU", "lower", "than", "0.3", "for", "all", "ground", "-", "truth", "boxes", ".", "Note", "that", "scales", "of", "ground", "-", "truth", "boxes", "are", "not", "explicitly", "used", "to", "assign", "them", "to", "the", "levels", "of", "the", "pyramid", ";", "instead", ",", "ground", "-", "truth", "boxes", "are", "associated", "with", "anchors", ",", "which", "have", "been", "assigned", "to", "pyramid", "levels", ".", "As", "such", ",", "we", "introduce", "no", "extra", "rules", "in", "addition", "to", "those", "in", "[", "reference", "]", ".", "We", "note", "that", "the", "parameters", "of", "the", "heads", "are", "shared", "across", "all", "feature", "pyramid", "levels", ";", "we", "have", "also", "evaluated", "the", "alternative", "without", "sharing", "parameters", "and", "observed", "similar", "accuracy", ".", "The", "good", "performance", "of", "sharing", "parameters", "indicates", "that", "all", "levels", "of", "our", "pyramid", "share", "similar", "semantic", "levels", ".", "This", "advantage", "is", "analogous", "to", "that", "of", "using", "a", "featurized", "image", "pyramid", ",", "where", "a", "common", "head", "classifier", "can", "be", "applied", "to", "features", "computed", "at", "any", "image", "scale", ".", "With", "the", "above", "adaptations", ",", "RPN", "can", "be", "naturally", "trained", "and", "tested", "with", "our", "FPN", ",", "in", "the", "same", "fashion", "as", "in", "[", "reference", "]", ".", "We", "elaborate", "on", "the", "implementation", "details", "in", "the", "experiments", ".", "section", ":", "Feature", "Pyramid", "Networks", "for", "Fast", "R", "-", "CNN", "Fast", "R", "-", "CNN", "[", "reference", "]", "is", "a", "region", "-", "based", "object", "detector", "in", "which", "Region", "-", "of", "-", "Interest", "(", "RoI", ")", "pooling", "is", "used", "to", "extract", "features", ".", "Fast", "R", "-", "CNN", "is", "most", "commonly", "performed", "on", "a", "single", "-", "scale", "feature", "map", ".", "To", "use", "it", "with", "our", "FPN", ",", "we", "need", "to", "assign", "RoIs", "of", "different", "scales", "to", "the", "pyramid", "levels", ".", "We", "view", "our", "feature", "pyramid", "as", "if", "it", "were", "produced", "from", "an", "image", "pyramid", ".", "Thus", "we", "can", "adapt", "the", "assignment", "strategy", "of", "region", "-", "based", "detectors", "[", "reference", "][", "reference", "]", "in", "the", "case", "when", "they", "are", "run", "on", "image", "pyramids", ".", "Formally", ",", "we", "assign", "an", "RoI", "of", "width", "w", "and", "height", "h", "(", "on", "the", "input", "image", "to", "the", "network", ")", "to", "the", "level", "P", "k", "of", "our", "feature", "pyramid", "by", ":", "Here", "224", "is", "the", "canonical", "ImageNet", "pre", "-", "training", "size", ",", "and", "k", "0", "is", "the", "target", "level", "on", "which", "an", "RoI", "with", "w", "\u00d7", "h", "=", "224", "2", "should", "be", "mapped", "into", ".", "Analogous", "to", "the", "ResNet", "-", "based", "Faster", "R", "-", "CNN", "system", "[", "reference", "]", "that", "uses", "C", "4", "as", "the", "single", "-", "scale", "feature", "map", ",", "we", "set", "k", "0", "to", "4", ".", "Intuitively", ",", "Eqn", ".", "(", "1", ")", "means", "that", "if", "the", "RoI", "'s", "scale", "becomes", "smaller", "(", "say", ",", "1", "/", "2", "of", "224", ")", ",", "it", "should", "be", "mapped", "into", "a", "finer", "-", "resolution", "level", "(", "say", ",", "k", "=", "3", ")", ".", "We", "attach", "predictor", "heads", "(", "in", "Fast", "R", "-", "CNN", "the", "heads", "are", "class", "-", "specific", "classifiers", "and", "bounding", "box", "regressors", ")", "to", "all", "RoIs", "of", "all", "levels", ".", "Again", ",", "the", "heads", "all", "share", "parameters", ",", "regardless", "of", "their", "levels", ".", "In", "[", "reference", "]", ",", "a", "ResNet", "'s", "conv5", "layers", "(", "a", "9", "-", "layer", "deep", "subnetwork", ")", "are", "adopted", "as", "the", "head", "on", "top", "of", "the", "conv4", "features", ",", "but", "our", "method", "has", "already", "harnessed", "conv5", "to", "construct", "the", "feature", "pyramid", ".", "So", "unlike", "[", "reference", "]", ",", "we", "simply", "adopt", "RoI", "pooling", "to", "extract", "7\u00d77", "features", ",", "and", "attach", "two", "hidden", "1", ",", "024", "-", "d", "fully", "-", "connected", "(", "fc", ")", "layers", "(", "each", "followed", "by", "ReLU", ")", "before", "the", "final", "classification", "and", "bounding", "box", "regression", "layers", ".", "These", "layers", "are", "randomly", "initialized", ",", "as", "there", "are", "no", "pre", "-", "trained", "fc", "layers", "available", "in", "ResNets", ".", "Note", "that", "compared", "to", "the", "standard", "conv5", "head", ",", "our", "2", "-", "fc", "MLP", "head", "is", "lighter", "weight", "and", "faster", ".", "Based", "on", "these", "adaptations", ",", "we", "can", "train", "and", "test", "Fast", "R", "-", "CNN", "on", "top", "of", "the", "feature", "pyramid", ".", "Implementation", "details", "are", "given", "in", "the", "experimental", "section", ".", "section", ":", "Experiments", "on", "Object", "Detection", "We", "perform", "experiments", "on", "the", "80", "category", "COCO", "detection", "dataset", "[", "reference", "]", ".", "We", "train", "using", "the", "union", "of", "80k", "train", "images", "and", "a", "35k", "subset", "of", "val", "images", "(", "trainval35k", "[", "reference", "]", ")", ",", "and", "report", "ablations", "on", "a", "5k", "subset", "of", "val", "images", "(", "minival", ")", ".", "We", "also", "report", "final", "results", "on", "the", "standard", "test", "set", "(", "test", "-", "std", ")", "[", "reference", "]", "which", "has", "no", "disclosed", "labels", ".", "As", "is", "common", "practice", "[", "reference", "]", ",", "all", "network", "backbones", "are", "pre", "-", "trained", "on", "the", "ImageNet1k", "classification", "set", "[", "reference", "]", "and", "then", "fine", "-", "tuned", "on", "the", "detection", "dataset", ".", "We", "use", "the", "pre", "-", "trained", "ResNet", "-", "50", "and", "ResNet", "-", "101", "models", "that", "are", "publicly", "available", ".", "[", "reference", "]", "Our", "code", "is", "a", "reimplementation", "of", "py", "-", "faster", "-", "rcnn", "3", "using", "Caffe2", ".", "[", "reference", "]", "section", ":", "Region", "Proposal", "with", "RPN", "We", "evaluate", "the", "COCO", "-", "style", "Average", "Recall", "(", "AR", ")", "and", "AR", "on", "small", ",", "medium", ",", "and", "large", "objects", "(", "AR", "s", ",", "AR", "m", ",", "and", "AR", "l", ")", "following", "the", "definitions", "in", "[", "reference", "]", ".", "We", "report", "results", "for", "100", "and", "1000", "proposals", "per", "images", "(", "AR", "100", "and", "AR", "1k", ")", ".", "Implementation", "details", ".", "All", "architectures", "in", "Table", "1", "are", "trained", "end", "-", "to", "-", "end", ".", "The", "input", "image", "is", "resized", "such", "that", "its", "shorter", "side", "has", "800", "pixels", ".", "We", "adopt", "synchronized", "SGD", "training", "on", "8", "GPUs", ".", "A", "mini", "-", "batch", "involves", "2", "images", "per", "GPU", "and", "256", "anchors", "per", "image", ".", "We", "use", "a", "weight", "decay", "of", "0.0001", "and", "a", "momentum", "of", "0.9", ".", "The", "learning", "rate", "is", "0.02", "for", "the", "first", "30k", "mini", "-", "batches", "and", "0.002", "for", "the", "next", "10k", ".", "For", "all", "RPN", "experiments", "(", "including", "baselines", ")", ",", "we", "include", "the", "anchor", "boxes", "that", "are", "outside", "the", "image", "for", "training", ",", "which", "is", "unlike", "[", "reference", "]", "where", "these", "anchor", "boxes", "are", "ignored", ".", "Other", "implementation", "details", "are", "as", "in", "[", "reference", "]", ".", "Training", "RPN", "with", "FPN", "on", "8", "GPUs", "takes", "about", "8", "hours", "on", "COCO", ".", "1", "(", "a", ")", ")", ".", "In", "addition", ",", "the", "performance", "on", "small", "objects", "(", "AR", "1k", "s", ")", "is", "boosted", "by", "a", "large", "margin", "of", "12.9", "points", ".", "Our", "pyramid", "representation", "greatly", "improves", "RPN", "'s", "robustness", "to", "object", "scale", "variation", ".", "How", "important", "is", "top", "-", "down", "enrichment", "?", "Table", "1", "(", "d", ")", "shows", "the", "results", "of", "our", "feature", "pyramid", "without", "the", "topdown", "pathway", ".", "With", "this", "modification", ",", "the", "1\u00d71", "lateral", "connections", "followed", "by", "3\u00d73", "convolutions", "are", "attached", "to", "the", "bottom", "-", "up", "pyramid", ".", "This", "architecture", "simulates", "the", "effect", "of", "reusing", "the", "pyramidal", "feature", "hierarchy", "(", "Fig", ".", "1", "(", "b", ")", ")", ".", "The", "results", "in", "Table", "1", "(", "d", ")", "are", "just", "on", "par", "with", "the", "RPN", "baseline", "and", "lag", "far", "behind", "ours", ".", "We", "conjecture", "that", "this", "is", "because", "there", "are", "large", "semantic", "gaps", "between", "different", "levels", "on", "the", "bottom", "-", "up", "pyramid", "(", "Fig", ".", "1", "(", "b", ")", ")", ",", "especially", "for", "very", "deep", "ResNets", ".", "We", "have", "also", "evaluated", "a", "variant", "of", "Table", "1", "(", "d", ")", "without", "sharing", "the", "parameters", "of", "the", "heads", ",", "but", "observed", "similarly", "degraded", "performance", ".", "This", "issue", "can", "not", "be", "simply", "remedied", "by", "level", "-", "specific", "heads", ".", "How", "important", "are", "lateral", "connections", "?", "Table", "1", "(", "e", ")", "shows", "the", "ablation", "results", "of", "a", "top", "-", "down", "feature", "pyramid", "without", "the", "1\u00d71", "lateral", "connections", ".", "This", "top", "-", "down", "pyramid", "has", "strong", "semantic", "features", "and", "fine", "resolutions", ".", "But", "we", "argue", "that", "the", "locations", "of", "these", "features", "are", "not", "precise", ",", "because", "these", "maps", "have", "been", "downsampled", "and", "upsampled", "several", "times", ".", "More", "precise", "locations", "of", "features", "can", "be", "directly", "passed", "from", "the", "finer", "levels", "of", "the", "bottom", "-", "up", "maps", "via", "the", "lateral", "connections", "to", "the", "top", "-", "down", "maps", ".", "As", "a", "results", ",", "FPN", "has", "an", "AR", "1k", "score", "10", "points", "higher", "than", "Table", "1", "section", ":", "(", "e", ")", ".", "How", "important", "are", "pyramid", "representations", "?", "Instead", "of", "resorting", "to", "pyramid", "representations", ",", "one", "can", "attach", "the", "head", "to", "the", "highest", "-", "resolution", ",", "strongly", "semantic", "feature", "maps", "of", "P", "2", "(", "i.e.", ",", "the", "finest", "level", "in", "our", "pyramids", ")", ".", "Similar", "to", "the", "single", "-", "scale", "baselines", ",", "we", "assign", "all", "anchors", "to", "the", "P", "2", "feature", "map", ".", "This", "variant", "(", "Table", "1", "(", "f", ")", ")", "is", "better", "than", "the", "baseline", "but", "inferior", "to", "our", "approach", ".", "RPN", "is", "a", "sliding", "window", "detector", "with", "a", "fixed", "window", "size", ",", "so", "scanning", "over", "pyramid", "levels", "can", "increase", "its", "robustness", "to", "scale", "variance", ".", "In", "addition", ",", "we", "note", "that", "using", "P", "2", "alone", "leads", "to", "more", "anchors", "(", "750k", ",", "Table", "1", ".", "Bounding", "box", "proposal", "results", "using", "RPN", "[", "reference", "]", ",", "evaluated", "on", "the", "COCO", "minival", "set", ".", "All", "models", "are", "trained", "on", "trainval35k", ".", "The", "columns", "\"", "lateral", "\"", "and", "\"", "top", "-", "down", "\"", "denote", "the", "presence", "of", "lateral", "and", "top", "-", "down", "connections", ",", "respectively", ".", "The", "column", "\"", "feature", "\"", "denotes", "the", "feature", "maps", "on", "which", "the", "heads", "are", "attached", ".", "All", "results", "are", "based", "on", "ResNet", "-", "50", "and", "share", "the", "same", "hyper", "-", "parameters", ".", "section", ":", "Object", "Detection", "with", "Fast", "/", "Faster", "R", "-", "CNN", "Next", "we", "investigate", "FPN", "for", "region", "-", "based", "(", "non", "-", "sliding", "window", ")", "detectors", ".", "We", "evaluate", "object", "detection", "by", "the", "COCO", "-", "style", "Average", "Precision", "(", "AP", ")", "and", "PASCAL", "-", "style", "AP", "(", "at", "a", "single", "IoU", "threshold", "of", "0.5", ")", ".", "We", "also", "report", "COCO", "AP", "on", "objects", "of", "small", ",", "medium", ",", "and", "large", "sizes", "(", "namely", ",", "AP", "s", ",", "AP", "m", ",", "and", "AP", "l", ")", "following", "the", "definitions", "in", "[", "reference", "]", ".", "Implementation", "details", ".", "The", "input", "image", "is", "resized", "such", "that", "its", "shorter", "side", "has", "800", "pixels", ".", "Synchronized", "SGD", "is", "used", "to", "train", "the", "model", "on", "8", "GPUs", ".", "Each", "mini", "-", "batch", "involves", "2", "image", "per", "GPU", "and", "512", "RoIs", "per", "image", ".", "We", "use", "a", "weight", "decay", "of", "0.0001", "and", "a", "momentum", "of", "0.9", ".", "The", "learning", "rate", "is", "0.02", "for", "the", "first", "60k", "mini", "-", "batches", "and", "0.002", "for", "the", "next", "20k", ".", "We", "use", "2000", "RoIs", "per", "image", "for", "training", "and", "1000", "for", "testing", ".", "Training", "Fast", "R", "-", "CNN", "with", "FPN", "takes", "about", "10", "hours", "on", "the", "COCO", "dataset", ".", "section", ":", "Fast", "R", "-", "CNN", "(", "on", "fixed", "proposals", ")", "To", "better", "investigate", "FPN", "'s", "effects", "on", "the", "region", "-", "based", "detector", "alone", ",", "we", "conduct", "ablations", "of", "Fast", "R", "-", "CNN", "on", "a", "fixed", "set", "of", "proposals", ".", "We", "choose", "to", "freeze", "the", "proposals", "as", "computed", "by", "RPN", "on", "FPN", "(", "Table", "1", "(", "c", ")", ")", ",", "because", "it", "has", "good", "performance", "on", "small", "objects", "that", "are", "to", "be", "recognized", "by", "the", "detector", ".", "For", "simplicity", "we", "do", "not", "share", "features", "between", "Fast", "R", "-", "CNN", "and", "RPN", ",", "except", "when", "specified", ".", "As", "a", "ResNet", "-", "based", "Fast", "R", "-", "CNN", "baseline", ",", "following", "[", "reference", "]", ",", "we", "adopt", "RoI", "pooling", "with", "an", "output", "size", "of", "14\u00d714", "and", "attach", "all", "conv5", "layers", "as", "the", "hidden", "layers", "of", "the", "head", ".", "This", "gives", "an", "AP", "of", "31.9", "in", "Table", "2", "(", "a", ")", ".", "Table", "2", "(", "b", ")", "is", "a", "baseline", "exploiting", "an", "MLP", "head", "with", "2", "hidden", "fc", "layers", ",", "similar", "to", "the", "head", "in", "our", "architecture", ".", "It", "gets", "an", "AP", "of", "28.8", ",", "indicating", "that", "the", "2", "-", "fc", "head", "does", "not", "give", "us", "any", "orthogonal", "advantage", "over", "the", "baseline", "in", "Table", "2", "(", "a", ")", ".", "Table", "2", "(", "c", ")", "shows", "the", "results", "of", "our", "FPN", "in", "Fast", "R", "-", "CNN", ".", "Comparing", "with", "the", "baseline", "in", "Table", "2", "(", "a", ")", ",", "our", "method", "improves", "AP", "by", "2.0", "points", "and", "small", "object", "AP", "by", "2.1", "points", ".", "Comparing", "with", "the", "baseline", "that", "also", "adopts", "a", "2fc", "head", "(", "Table", "2", "(", "b", ")", ")", ",", "our", "method", "improves", "AP", "by", "5.1", "points", ".", "[", "reference", "]", "These", "comparisons", "indicate", "that", "our", "feature", "pyramid", "is", "superior", "to", "single", "-", "scale", "features", "for", "a", "region", "-", "based", "object", "detector", ".", "nections", "or", "removing", "lateral", "connections", "leads", "to", "inferior", "results", ",", "similar", "to", "what", "we", "have", "observed", "in", "the", "above", "subsection", "for", "RPN", ".", "It", "is", "noteworthy", "that", "removing", "top", "-", "down", "connections", "(", "Table", "2", "(", "d", ")", ")", "significantly", "degrades", "the", "accuracy", ",", "suggesting", "that", "Fast", "R", "-", "CNN", "suffers", "from", "using", "the", "low", "-", "level", "features", "at", "the", "high", "-", "resolution", "maps", ".", "In", "Table", "2", "(", "f", ")", ",", "we", "adopt", "Fast", "R", "-", "CNN", "on", "the", "single", "finest", "scale", "feature", "map", "of", "P", "2", ".", "Its", "result", "(", "33.4", "AP", ")", "is", "marginally", "worse", "than", "that", "of", "using", "all", "pyramid", "levels", "(", "33.9", "AP", ",", "Table", "2", "(", "c", ")", ")", ".", "We", "argue", "that", "this", "is", "because", "RoI", "pooling", "is", "a", "warping", "-", "like", "operation", ",", "which", "is", "less", "sensitive", "to", "the", "region", "'s", "scales", ".", "Despite", "the", "good", "accuracy", "of", "this", "variant", ",", "it", "is", "based", "on", "the", "RPN", "proposals", "of", "{", "P", "k", "}", "and", "has", "thus", "already", "benefited", "from", "the", "pyramid", "representation", ".", "section", ":", "Faster", "R", "-", "CNN", "(", "on", "consistent", "proposals", ")", "In", "the", "above", "we", "used", "a", "fixed", "set", "of", "proposals", "to", "investigate", "the", "detectors", ".", "But", "in", "a", "Faster", "R", "-", "CNN", "system", "[", "reference", "]", ",", "the", "RPN", "and", "Fast", "R", "-", "CNN", "must", "use", "the", "same", "network", "backbone", "in", "order", "to", "make", "feature", "sharing", "possible", ".", "Table", "3", "shows", "the", "comparisons", "between", "our", "method", "and", "two", "baselines", ",", "all", "using", "consistent", "backbone", "architectures", "for", "RPN", "and", "Fast", "R", "-", "CNN", ".", "Table", "3", "(", "a", ")", "shows", "our", "reproduction", "of", "the", "baseline", "Faster", "R", "-", "CNN", "system", "as", "described", "in", "[", "reference", "]", ".", "Under", "controlled", "settings", ",", "our", "FPN", "(", "Table", "3", "(", "c", ")", ")", "is", "better", "than", "this", "strong", "baseline", "by", "2.3", "points", "AP", "and", "3.8", "points", "AP@0.5", ".", "Note", "that", "Table", "3", "(", "a", ")", "and", "(", "b", ")", "are", "baselines", "that", "are", "much", "stronger", "than", "the", "baseline", "provided", "by", "He", "et", "al", ".", "[", "reference", "]", "in", "Table", "3", "(", "*", ")", ".", "We", "find", "the", "following", "implementations", "contribute", "to", "the", "gap", ":", "(", "i", ")", "We", "use", "an", "image", "scale", "of", "800", "pixels", "instead", "of", "600", "in", "[", "reference", "][", "reference", "]", ";", "(", "ii", ")", "We", "train", "with", "512", "RoIs", "per", "image", "which", "accelerate", "convergence", ",", "in", "contrast", "to", "64", "RoIs", "in", "[", "reference", "][", "reference", "]", ";", "(", "iii", ")", "We", "use", "5", "scale", "anchors", "instead", "of", "4", "in", "[", "reference", "]", "(", "adding", "32", "2", ")", ";", "(", "iv", ")", "At", "test", "time", "we", "use", "1000", "proposals", "per", "image", "instead", "of", "300", "in", "[", "reference", "]", ".", "So", "comparing", "with", "He", "et", "al", ".", "'s", "ResNet", "-", "50", "Faster", "R", "-", "CNN", "baseline", "in", "Table", "3", "(", "*", ")", ",", "our", "method", "improves", "AP", "by", "7.6", "points", "and", "AP@0.5", "by", "9.6", "points", ".", "Sharing", "features", ".", "In", "the", "above", ",", "for", "simplicity", "we", "do", "not", "share", "the", "features", "between", "RPN", "and", "Fast", "R", "-", "CNN", ".", "In", "Ta", "-", "Table", "5", ".", "More", "object", "detection", "results", "using", "Faster", "R", "-", "CNN", "and", "our", "FPNs", ",", "evaluated", "on", "minival", ".", "Sharing", "features", "increases", "train", "time", "by", "1.5\u00d7", "(", "using", "4", "-", "step", "training", "[", "reference", "]", ")", ",", "but", "reduces", "test", "time", ".", "ble", "5", ",", "we", "evaluate", "sharing", "features", "following", "the", "4", "-", "step", "training", "described", "in", "[", "reference", "]", ".", "Similar", "to", "[", "reference", "]", ",", "we", "find", "that", "sharing", "features", "improves", "accuracy", "by", "a", "small", "margin", ".", "Feature", "sharing", "also", "reduces", "the", "testing", "time", ".", "Running", "time", ".", "With", "feature", "sharing", ",", "our", "FPN", "-", "based", "Faster", "R", "-", "CNN", "system", "has", "inference", "time", "of", "0.148", "seconds", "per", "image", "on", "a", "single", "NVIDIA", "M40", "GPU", "for", "ResNet", "-", "50", ",", "and", "0.172", "seconds", "for", "ResNet", "-", "101", ".", "[", "reference", "]", "As", "a", "comparison", ",", "the", "single", "-", "scale", "ResNet", "-", "50", "baseline", "in", "Table", "3", "(", "a", ")", "runs", "at", "0.32", "seconds", ".", "Our", "method", "introduces", "small", "extra", "cost", "by", "the", "extra", "layers", "in", "the", "FPN", ",", "but", "has", "a", "lighter", "weight", "head", ".", "Overall", "our", "system", "is", "faster", "than", "the", "ResNet", "-", "based", "Faster", "R", "-", "CNN", "counterpart", ".", "We", "believe", "the", "efficiency", "and", "simplicity", "of", "our", "method", "will", "benefit", "future", "research", "and", "applications", ".", "section", ":", "Comparing", "with", "COCO", "Competition", "Winners", "We", "find", "that", "our", "ResNet", "-", "101", "model", "in", "Table", "5", "is", "not", "sufficiently", "trained", "with", "the", "default", "learning", "rate", "schedule", ".", "So", "we", "increase", "the", "number", "of", "mini", "-", "batches", "by", "2\u00d7", "at", "each", "learning", "rate", "when", "training", "the", "Fast", "R", "-", "CNN", "step", ".", "This", "increases", "AP", "on", "minival", "to", "35.6", ",", "without", "sharing", "features", ".", "This", "model", "is", "the", "one", "we", "submitted", "to", "the", "COCO", "detection", "leaderboard", ",", "shown", "in", "Table", "4", ".", "We", "have", "not", "evaluated", "its", "feature", "-", "sharing", "version", "due", "to", "limited", "time", ",", "which", "should", "be", "slightly", "better", "as", "implied", "by", "Table", "5", ".", "Table", "4", "compares", "our", "method", "with", "the", "single", "-", "model", "results", "of", "the", "COCO", "competition", "winners", ",", "including", "the", "2016", "winner", "G", "-", "RMI", "and", "the", "2015", "winner", "Faster", "R", "-", "CNN", "+++", ".", "Without", "adding", "bells", "and", "whistles", ",", "our", "single", "-", "model", "entry", "has", "surpassed", "these", "strong", ",", "heavily", "engineered", "competitors", ".", "On", "the", "test", "-", "dev", "set", ",", "our", "method", "increases", "over", "the", "existing", "best", "results", "by", "0.5", "points", "of", "AP", "(", "36.2", "vs.", "35.7", ")", "and", "3.4", "points", "of", "AP@0.5", "(", "59.1", "vs.", "55.7", ")", ".", "It", "is", "worth", "noting", "that", "our", "method", "does", "not", "rely", "on", "image", "pyramids", "and", "only", "uses", "a", "single", "input", "image", "scale", ",", "but", "still", "has", "outstanding", "AP", "on", "small", "-", "scale", "objects", ".", "This", "could", "only", "be", "achieved", "by", "highresolution", "image", "inputs", "with", "previous", "methods", ".", "Moreover", ",", "our", "method", "does", "not", "exploit", "many", "popular", "improvements", ",", "such", "as", "iterative", "regression", "[", "reference", "]", ",", "hard", "negative", "mining", "[", "reference", "]", ",", "context", "modeling", "[", "reference", "]", ",", "stronger", "data", "augmentation", "[", "reference", "]", ",", "etc", ".", "These", "improvements", "are", "complementary", "to", "FPNs", "and", "should", "boost", "accuracy", "further", ".", "Recently", ",", "FPN", "has", "enabled", "new", "top", "results", "in", "all", "tracks", "of", "the", "COCO", "competition", ",", "including", "detection", ",", "instance", "segmentation", ",", "and", "keypoint", "estimation", ".", "See", "[", "reference", "]", "for", "details", ".", "section", ":", "Extensions", ":", "Segmentation", "Proposals", "Our", "method", "is", "a", "generic", "pyramid", "representation", "and", "can", "be", "used", "in", "applications", "other", "than", "object", "detection", ".", "In", "this", "section", "we", "use", "FPNs", "to", "generate", "segmentation", "proposals", ",", "following", "the", "DeepMask", "/", "SharpMask", "framework", "[", "reference", "][", "reference", "]", ".", "DeepMask", "/", "SharpMask", "were", "trained", "on", "image", "crops", "for", "predicting", "instance", "segments", "and", "object", "/", "non", "-", "object", "scores", ".", "At", "inference", "time", ",", "these", "models", "are", "run", "convolutionally", "to", "generate", "dense", "proposals", "in", "an", "image", ".", "To", "generate", "segments", "at", "multiple", "scales", ",", "image", "pyramids", "are", "necessary", "[", "reference", "][", "reference", "]", ".", "It", "is", "easy", "to", "adapt", "FPN", "to", "generate", "mask", "proposals", ".", "We", "use", "a", "fully", "convolutional", "setup", "for", "both", "training", "and", "inference", ".", "We", "construct", "our", "feature", "pyramid", "as", "in", "Sec", ".", "5.1", "and", "set", "d", "=", "128", ".", "On", "top", "of", "each", "level", "of", "the", "feature", "pyramid", ",", "we", "apply", "a", "small", "5\u00d75", "MLP", "to", "predict", "14\u00d714", "masks", "and", "object", "scores", "in", "a", "fully", "convolutional", "fashion", ",", "see", "Fig", ".", "4", ".", "Additionally", ",", "motivated", "by", "the", "use", "of", "2", "scales", "per", "octave", "in", "the", "image", "pyramid", "of", "[", "reference", "][", "reference", "]", ",", "we", "use", "a", "second", "MLP", "of", "input", "size", "7\u00d77", "to", "handle", "half", "octaves", ".", "The", "two", "MLPs", "play", "a", "similar", "role", "as", "anchors", "in", "RPN", ".", "The", "architecture", "is", "trained", "end", "-", "to", "-", "end", ";", "full", "implementation", "details", "are", "given", "in", "the", "appendix", ".", "section", ":", "Segmentation", "Proposal", "Results", "Results", "are", "shown", "in", "Table", "6", ".", "We", "report", "segment", "AR", "and", "segment", "AR", "on", "small", ",", "medium", ",", "and", "large", "objects", ",", "always", "for", "1000", "proposals", ".", "Our", "baseline", "FPN", "model", "with", "a", "single", "5\u00d75", "MLP", "achieves", "an", "AR", "of", "43.4", ".", "Switching", "to", "a", "slightly", "larger", "7\u00d77", "MLP", "leaves", "accuracy", "largely", "unchanged", ".", "Using", "both", "MLPs", "together", "increases", "accuracy", "to", "45.7", "AR", ".", "Increasing", "mask", "output", "size", "from", "14\u00d714", "to", "28\u00d728", "increases", "AR", "another", "point", "(", "larger", "sizes", "begin", "to", "degrade", "accuracy", ")", ".", "Finally", ",", "doubling", "the", "training", "iterations", "increases", "AR", "to", "48.1", ".", "We", "also", "report", "comparisons", "to", "DeepMask", "[", "reference", "]", ",", "SharpMask", "[", "reference", "]", ",", "and", "InstanceFCN", "[", "reference", "]", ",", "the", "previous", "state", "of", "the", "art", "methods", "in", "mask", "proposal", "generation", ".", "We", "outperform", "the", "accuracy", "of", "these", "approaches", "by", "over", "8.3", "points", "AR", ".", "In", "particular", ",", "we", "nearly", "double", "the", "accuracy", "on", "small", "objects", ".", "Existing", "mask", "proposal", "methods", "[", "reference", "][", "reference", "][", "reference", "]", "are", "based", "on", "densely", "sampled", "image", "pyramids", "(", "e.g.", ",", "scaled", "by", "2", "{", "\u22122:0.5:1", "}", "in", "[", "reference", "][", "reference", "]", ")", ",", "making", "them", "computationally", "expensive", ".", "Our", "approach", ",", "based", "on", "FPNs", ",", "is", "substantially", "faster", "(", "our", "models", "run", "at", "6", "to", "7", "FPS", ")", ".", "These", "results", "demonstrate", "that", "our", "model", "is", "a", "generic", "feature", "extractor", "and", "can", "replace", "image", "pyramids", "for", "other", "multi", "-", "scale", "detection", "problems", ".", "section", ":", "Conclusion", "We", "have", "presented", "a", "clean", "and", "simple", "framework", "for", "building", "feature", "pyramids", "inside", "ConvNets", ".", "Our", "method", "shows", "significant", "improvements", "over", "several", "strong", "baselines", "and", "competition", "winners", ".", "Thus", ",", "it", "provides", "a", "practical", "solution", "for", "research", "and", "applications", "of", "feature", "pyramids", ",", "without", "the", "need", "of", "computing", "image", "pyramids", ".", "Finally", ",", "our", "study", "suggests", "that", "despite", "the", "strong", "representational", "power", "of", "deep", "ConvNets", "and", "their", "implicit", "robustness", "to", "scale", "variation", ",", "it", "is", "still", "critical", "to", "explicitly", "address", "multiscale", "problems", "using", "pyramid", "representations", ".", "section", ":", "A.", "Implementation", "of", "Segmentation", "Proposals", "We", "use", "our", "feature", "pyramid", "networks", "to", "efficiently", "generate", "object", "segment", "proposals", ",", "adopting", "an", "image", "-", "centric", "training", "strategy", "popular", "for", "object", "detection", "[", "reference", "][", "reference", "]", ".", "Our", "FPN", "mask", "generation", "model", "inherits", "many", "of", "the", "ideas", "and", "motivations", "from", "DeepMask", "/", "SharpMask", "[", "reference", "][", "reference", "]", ".", "However", ",", "in", "contrast", "to", "these", "models", ",", "which", "were", "trained", "on", "image", "crops", "and", "used", "a", "densely", "sampled", "image", "pyramid", "for", "inference", ",", "we", "perform", "fully", "-", "convolutional", "training", "for", "mask", "prediction", "on", "a", "feature", "pyramid", ".", "While", "this", "requires", "changing", "many", "of", "the", "specifics", ",", "our", "implementation", "remains", "similar", "in", "spirit", "to", "DeepMask", ".", "Specifically", ",", "to", "define", "the", "label", "of", "a", "mask", "instance", "at", "each", "sliding", "window", ",", "we", "think", "of", "this", "window", "as", "being", "a", "crop", "on", "the", "input", "image", ",", "allowing", "us", "to", "inherit", "definitions", "of", "positives", "/", "negatives", "from", "DeepMask", ".", "We", "give", "more", "details", "next", ",", "see", "also", "Fig", ".", "4", "for", "a", "visualization", ".", "We", "construct", "the", "feature", "pyramid", "with", "P", "2\u22126", "using", "the", "same", "architecture", "as", "described", "in", "Sec", ".", "5.1", ".", "We", "set", "d", "=", "128", ".", "Each", "level", "of", "our", "feature", "pyramid", "is", "used", "for", "predicting", "masks", "at", "a", "different", "scale", ".", "As", "in", "DeepMask", ",", "we", "define", "the", "scale", "of", "a", "mask", "as", "the", "max", "of", "its", "width", "and", "height", ".", "Masks", "with", "scales", "of", "{", "32", ",", "64", ",", "128", ",", "256", ",", "512", "}", "pixels", "map", "to", "{", "P", "2", ",", "P", "3", ",", "P", "4", ",", "P", "5", ",", "P", "6", "}", ",", "respectively", ",", "and", "are", "handled", "by", "a", "5\u00d75", "MLP", ".", "As", "DeepMask", "uses", "a", "pyramid", "with", "half", "octaves", ",", "we", "use", "a", "second", "slightly", "larger", "MLP", "of", "size", "7\u00d77", "(", "7", "\u2248", "5", "\u221a", "2", ")", "to", "handle", "half", "-", "octaves", "in", "our", "model", "(", "e.g.", ",", "a", "128", "\u221a", "2", "scale", "mask", "is", "predicted", "by", "the", "7\u00d77", "MLP", "on", "P", "4", ")", ".", "Objects", "at", "intermediate", "scales", "are", "mapped", "to", "the", "nearest", "scale", "in", "log", "space", ".", "As", "the", "MLP", "must", "predict", "objects", "at", "a", "range", "of", "scales", "for", "each", "pyramid", "level", "(", "specifically", "a", "half", "octave", "range", ")", ",", "some", "padding", "must", "be", "given", "around", "the", "canonical", "object", "size", ".", "We", "use", "25", "%", "padding", ".", "This", "means", "that", "the", "mask", "output", "over", "{", "P", "2", ",", "P", "3", ",", "P", "4", ",", "P", "5", ",", "P", "6", "}", "maps", "to", "{", "40", ",", "80", ",", "160", ",", "320", ",", "640", "}", "sized", "image", "regions", "for", "the", "5\u00d75", "MLP", "(", "and", "to", "\u221a", "2", "larger", "corresponding", "sizes", "for", "the", "7\u00d77", "MLP", ")", ".", "Each", "spatial", "position", "in", "the", "feature", "map", "is", "used", "to", "predict", "a", "mask", "at", "a", "different", "location", ".", "Specifically", ",", "at", "scale", "P", "k", ",", "each", "spatial", "position", "in", "the", "feature", "map", "is", "used", "to", "predict", "the", "mask", "whose", "center", "falls", "within", "2", "k", "pixels", "of", "that", "location", "(", "corresponding", "to", "\u00b11", "cell", "offset", "in", "the", "feature", "map", ")", ".", "If", "no", "object", "center", "falls", "within", "this", "range", ",", "the", "location", "is", "considered", "a", "negative", ",", "and", ",", "as", "in", "DeepMask", ",", "is", "used", "only", "for", "training", "the", "score", "branch", "and", "not", "the", "mask", "branch", ".", "The", "MLP", "we", "use", "for", "predicting", "the", "mask", "and", "score", "is", "fairly", "simple", ".", "We", "apply", "a", "5\u00d75", "kernel", "with", "512", "outputs", ",", "followed", "by", "sibling", "fully", "connected", "layers", "to", "predict", "a", "14\u00d714", "mask", "(", "14", "2", "outputs", ")", "and", "object", "score", "(", "1", "output", ")", ".", "The", "model", "is", "implemented", "in", "a", "fully", "convolutional", "manner", "(", "using", "1\u00d71", "convolutions", "in", "place", "of", "fully", "connected", "layers", ")", ".", "The", "7\u00d77", "MLP", "for", "handling", "objects", "at", "half", "octave", "scales", "is", "identical", "to", "the", "5\u00d75", "MLP", "except", "for", "its", "larger", "input", "region", ".", "During", "training", ",", "we", "randomly", "sample", "2048", "examples", "per", "mini", "-", "batch", "(", "128", "examples", "per", "image", "from", "16", "images", ")", "with", "a", "positive", "/", "negative", "sampling", "ratio", "of", "1:3", ".", "The", "mask", "loss", "is", "given", "10\u00d7", "higher", "weight", "than", "the", "score", "loss", ".", "This", "model", "is", "trained", "end", "-", "to", "-", "end", "on", "8", "GPUs", "using", "synchronized", "SGD", "(", "2", "images", "per", "GPU", ")", ".", "We", "start", "with", "a", "learning", "rate", "of", "0.03", "and", "train", "for", "80k", "mini", "-", "batches", ",", "dividing", "the", "learning", "rate", "by", "10", "after", "60k", "mini", "-", "batches", ".", "The", "image", "scale", "is", "set", "to", "800", "pixels", "during", "training", "and", "testing", "(", "we", "do", "not", "use", "scale", "jitter", ")", ".", "During", "inference", "our", "fully", "-", "convolutional", "model", "predicts", "scores", "at", "all", "positions", "and", "scales", "and", "masks", "at", "the", "1000", "highest", "scoring", "locations", ".", "We", "do", "not", "perform", "any", "non", "-", "maximum", "suppression", "or", "post", "-", "processing", ".", "section", ":"]}