{"coref": {"AWD-LSTM-MoS": [[123, 128], [1886, 1891], [1892, 1897], [1948, 1953], [2065, 2070], [2522, 2527], [2713, 2718], [6833, 6838]], "Bit_per_Character__BPC_": [[2939, 2944], [2945, 2946], [3021, 3022], [3034, 3035], [149, 154]], "Language_Modelling": [[3, 5], [20, 22], [161, 165], [190, 192], [315, 317], [504, 506], [780, 785], [1528, 1530], [1727, 1729], [6774, 6776], [7000, 7002], [7030, 7034], [7096, 7098], [2356, 2358], [2921, 2923]], "Number_of_params": [], "Params": [], "Past_Decode_Reg_": [[81, 84], [85, 86], [118, 119], [906, 909], [910, 911], [932, 933], [957, 960], [961, 962], [1513, 1514], [1626, 1627], [1709, 1710], [1725, 1726], [1982, 1983], [2013, 2014], [2425, 2426], [2598, 2599], [2787, 2788], [2877, 2878], [2892, 2893], [3053, 3054], [3060, 3061], [3085, 3086], [3096, 3097], [3132, 3133], [3151, 3152], [3157, 3158], [3293, 3294], [3355, 3356], [3365, 3366], [3382, 3383], [3393, 3394], [3697, 3698], [4127, 4128], [4141, 4142], [6438, 6439], [6502, 6503], [6541, 6542], [6633, 6634], [6685, 6686], [6697, 6698], [6721, 6722], [6747, 6748], [6844, 6845], [6887, 6888], [7112, 7113], [1350, 1353], [1900, 1901], [2849, 2850], [3330, 3331], [3936, 3937]], "Past_Decode_Reg____AWD-LSTM-MoS___dyn__eval_": [], "Penn_Treebank__Character_Level_": [[97, 99], [156, 160], [1756, 1758], [1759, 1760], [1782, 1785], [1786, 1787], [2036, 2037], [2078, 2079], [2098, 2099], [2158, 2159], [2240, 2241], [2244, 2245], [2361, 2362], [2575, 2576], [2642, 2643], [2926, 2927], [2952, 2955], [3116, 3117], [3168, 3169], [3239, 3240], [3322, 3323], [6476, 6477], [6618, 6619], [6688, 6689], [3469, 3470]], "Penn_Treebank__Word_Level_": [[97, 99], [1756, 1758], [1759, 1760], [2036, 2037], [2078, 2079], [2098, 2099], [2158, 2159], [2361, 2362], [2391, 2394], [2490, 2493], [2575, 2576], [2642, 2643], [3116, 3117], [3168, 3169], [3239, 3240], [3322, 3323], [6476, 6477], [6618, 6619], [6688, 6689], [3469, 3470]], "Test_perplexity": [[90, 93], [131, 134], [2386, 2387], [2463, 2464], [2541, 2543], [2681, 2682], [2868, 2869], [2883, 2884], [6842, 6843]], "Validation_perplexity": [[1615, 1618], [2734, 2736], [3165, 3167], [3312, 3315], [3397, 3399], [6639, 6641], [6729, 6732]], "WikiText-2": [[103, 107], [1765, 1768], [1769, 1770], [2038, 2039], [2080, 2083], [2100, 2101], [2180, 2181], [2633, 2634], [2739, 2742], [3118, 3119], [3170, 3171], [3241, 3242], [6662, 6663], [6690, 6691], [3473, 3474]], "dyn__eval_": []}, "coref_non_salient": {"0": [[2032, 2034], [2727, 2728]], "1": [[246, 249], [321, 324], [444, 447], [2211, 2214], [6982, 6985], [6988, 6989], [7054, 7058]], "10": [[787, 789], [6910, 6913], [6972, 6976]], "11": [[863, 867], [1331, 1335], [6460, 6461], [6509, 6510], [6565, 6568]], "12": [[392, 394], [401, 402], [425, 427], [1967, 1968], [3123, 3124]], "13": [[412, 413], [423, 424], [474, 476], [514, 515], [545, 546], [848, 849], [1046, 1047], [1844, 1845], [3184, 3185], [6752, 6753], [6772, 6773], [6929, 6930], [11, 12], [337, 338], [935, 936], [2108, 2109], [2141, 2142], [2164, 2165], [2252, 2253], [2274, 2275], [2794, 2795], [3934, 3935], [3940, 3941], [6816, 6817]], "14": [[770, 772], [1114, 1115], [1265, 1267], [3267, 3270], [292, 293], [818, 819], [1082, 1083]], "15": [[792, 794], [807, 808]], "16": [[2826, 2827]], "17": [[2603, 2606], [2998, 3000]], "18": [[1141, 1142], [2076, 2077], [2238, 2239], [2292, 2293], [77, 78], [1631, 1632], [1667, 1668], [1700, 1701], [2192, 2193], [2330, 2331], [2813, 2814], [2816, 2817], [3316, 3317], [6602, 6603], [6643, 6644], [6926, 6927]], "19": [[2242, 2243], [2269, 2270], [3007, 3008], [1802, 1803]], "2": [[27, 29], [390, 391], [416, 418], [498, 500], [740, 742], [1839, 1841], [1851, 1853], [1969, 1970], [1980, 1981], [1999, 2000], [2907, 2909], [3091, 3092], [3103, 3104], [3125, 3126], [3178, 3179], [3407, 3409], [6701, 6702], [6740, 6741], [6768, 6770]], "20": [[1678, 1683]], "21": [[230, 232], [511, 513], [657, 659], [710, 712], [748, 750], [760, 762], [821, 824], [979, 986], [1009, 1011], [1131, 1133], [1180, 1182], [1508, 1510], [1542, 1544], [1635, 1637], [2618, 2620], [6544, 6546], [6590, 6592], [6855, 6857], [6884, 6886], [6962, 6964], [7074, 7076]], "22": [[438, 439], [3204, 3205]], "23": [[2182, 2184], [6865, 6867]], "24": [[2217, 2218], [3319, 3320]], "25": [[2336, 2339]], "26": [[6669, 6671], [6676, 6677]], "27": [[6893, 6895]], "28": [[2209, 2210], [453, 454]], "29": [[6979, 6981]], "3": [[1049, 1051], [1409, 1411]], "30": [[370, 374], [2485, 2488], [2590, 2591]], "31": [[2050, 2052]], "32": [[487, 490]], "33": [[2503, 2508]], "34": [[366, 369]], "35": [[441, 443]], "36": [[857, 859]], "37": [[6937, 6939], [6959, 6961]], "38": [[7100, 7104]], "39": [[830, 832]], "4": [[1284, 1288], [2085, 2088], [2457, 2459], [2565, 2567], [7049, 7052]], "40": [[3208, 3209]], "41": [[1642, 1644]], "42": [[216, 221]], "43": [[2128, 2134]], "44": [[1504, 1506], [1524, 1527]], "45": [[255, 260]], "46": [[6907, 6909]], "47": [[2421, 2423]], "48": [[1792, 1796]], "5": [[1119, 1122], [1453, 1458], [2010, 2011]], "6": [[197, 200], [923, 930], [1738, 1745], [6947, 6949]], "7": [[325, 326], [518, 519], [7041, 7045]], "8": [[1860, 1863], [1876, 1881], [1926, 1932], [1938, 1945], [2002, 2005], [2059, 2063], [2089, 2095], [2202, 2206], [2309, 2314], [2324, 2328], [2378, 2383], [2448, 2451], [2531, 2538], [2653, 2658], [2719, 2726], [3014, 3019], [3037, 3040], [3326, 3329], [3332, 3335], [3693, 3696], [3699, 3702], [3840, 3843], [4123, 4126], [4131, 4134], [4137, 4140], [4145, 4148], [6434, 6437], [6440, 6443], [6681, 6684], [6781, 6785]], "9": [[110, 111], [295, 296], [1086, 1088], [1936, 1937], [2373, 2374], [2496, 2497], [2672, 2673], [6797, 6798], [6824, 6826], [6828, 6830]]}, "doc_id": "1a6b67622d04df8e245575bf8fb2066fb6729720", "method_subrelations": {"Past_Decode_Reg____AWD-LSTM-MoS___dyn__eval_": [[[0, 16], "Past_Decode_Reg_"], [[19, 31], "AWD-LSTM-MoS"], [[34, 44], "dyn__eval_"]]}, "n_ary_relations": [{"Material": "Penn_Treebank__Character_Level_", "Method": "Past_Decode_Reg____AWD-LSTM-MoS___dyn__eval_", "Metric": "Bit_per_Character__BPC_", "Task": "Language_Modelling", "score": "1.169"}, {"Material": "Penn_Treebank__Character_Level_", "Method": "Past_Decode_Reg____AWD-LSTM-MoS___dyn__eval_", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "13.8M"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "Past_Decode_Reg____AWD-LSTM-MoS___dyn__eval_", "Metric": "Params", "Task": "Language_Modelling", "score": "22M"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "Past_Decode_Reg____AWD-LSTM-MoS___dyn__eval_", "Metric": "Test_perplexity", "Task": "Language_Modelling", "score": "47.3"}, {"Material": "Penn_Treebank__Word_Level_", "Method": "Past_Decode_Reg____AWD-LSTM-MoS___dyn__eval_", "Metric": "Validation_perplexity", "Task": "Language_Modelling", "score": "48.0"}, {"Material": "WikiText-2", "Method": "Past_Decode_Reg____AWD-LSTM-MoS___dyn__eval_", "Metric": "Number_of_params", "Task": "Language_Modelling", "score": "35M"}, {"Material": "WikiText-2", "Method": "Past_Decode_Reg____AWD-LSTM-MoS___dyn__eval_", "Metric": "Test_perplexity", "Task": "Language_Modelling", "score": "40.3"}, {"Material": "WikiText-2", "Method": "Past_Decode_Reg____AWD-LSTM-MoS___dyn__eval_", "Metric": "Validation_perplexity", "Task": "Language_Modelling", "score": "42.0"}], "ner": [[3, 5, "Task"], [20, 22, "Task"], [27, 29, "Method"], [81, 84, "Method"], [85, 86, "Method"], [90, 93, "Metric"], [97, 99, "Material"], [103, 107, "Material"], [110, 111, "Method"], [118, 119, "Method"], [123, 128, "Method"], [131, 134, "Metric"], [156, 160, "Material"], [161, 165, "Task"], [190, 192, "Task"], [197, 200, "Task"], [216, 221, "Method"], [230, 232, "Method"], [246, 249, "Method"], [255, 260, "Task"], [295, 296, "Method"], [315, 317, "Task"], [321, 324, "Method"], [325, 326, "Method"], [366, 369, "Metric"], [370, 374, "Task"], [390, 391, "Method"], [392, 394, "Method"], [401, 402, "Method"], [412, 413, "Method"], [416, 418, "Method"], [423, 424, "Method"], [425, 427, "Method"], [438, 439, "Method"], [441, 443, "Method"], [444, 447, "Method"], [474, 476, "Method"], [487, 490, "Task"], [498, 500, "Method"], [504, 506, "Task"], [511, 513, "Method"], [514, 515, "Method"], [518, 519, "Method"], [545, 546, "Method"], [657, 659, "Method"], [710, 712, "Method"], [740, 742, "Method"], [748, 750, "Method"], [760, 762, "Method"], [770, 772, "Method"], [780, 785, "Task"], [787, 789, "Task"], [792, 794, "Task"], [807, 808, "Task"], [821, 824, "Method"], [830, 832, "Task"], [848, 849, "Method"], [857, 859, "Method"], [863, 867, "Metric"], [906, 909, "Method"], [910, 911, "Method"], [923, 930, "Task"], [932, 933, "Method"], [957, 960, "Method"], [961, 962, "Method"], [979, 986, "Method"], [1009, 1011, "Method"], [1046, 1047, "Method"], [1049, 1051, "Method"], [1086, 1088, "Method"], [1114, 1115, "Method"], [1119, 1122, "Method"], [1131, 1133, "Method"], [1141, 1142, "Material"], [1180, 1182, "Method"], [1265, 1267, "Method"], [1284, 1288, "Method"], [1331, 1335, "Metric"], [1409, 1411, "Method"], [1453, 1458, "Method"], [1504, 1506, "Method"], [1508, 1510, "Method"], [1513, 1514, "Method"], [1524, 1527, "Method"], [1528, 1530, "Task"], [1542, 1544, "Method"], [1615, 1618, "Metric"], [1626, 1627, "Method"], [1635, 1637, "Method"], [1642, 1644, "Task"], [1678, 1683, "Method"], [1709, 1710, "Method"], [1725, 1726, "Method"], [1727, 1729, "Task"], [1738, 1745, "Task"], [1756, 1758, "Material"], [1759, 1760, "Material"], [1765, 1768, "Material"], [1769, 1770, "Material"], [1782, 1785, "Material"], [1786, 1787, "Material"], [1792, 1796, "Material"], [1839, 1841, "Method"], [1844, 1845, "Method"], [1851, 1853, "Method"], [1860, 1863, "Method"], [1876, 1881, "Method"], [1886, 1891, "Method"], [1892, 1897, "Method"], [1926, 1932, "Method"], [1936, 1937, "Method"], [1938, 1945, "Method"], [1948, 1953, "Method"], [1967, 1968, "Method"], [1969, 1970, "Method"], [1980, 1981, "Method"], [1982, 1983, "Method"], [1999, 2000, "Method"], [2002, 2005, "Method"], [2010, 2011, "Method"], [2013, 2014, "Method"], [2032, 2034, "Method"], [2036, 2037, "Material"], [2038, 2039, "Material"], [2050, 2052, "Method"], [2059, 2063, "Method"], [2065, 2070, "Method"], [2076, 2077, "Material"], [2078, 2079, "Material"], [2080, 2083, "Material"], [2085, 2088, "Method"], [2089, 2095, "Method"], [2098, 2099, "Material"], [2100, 2101, "Material"], [2128, 2134, "Method"], [2158, 2159, "Material"], [2180, 2181, "Material"], [2182, 2184, "Method"], [2202, 2206, "Method"], [2209, 2210, "Method"], [2211, 2214, "Method"], [2217, 2218, "Method"], [2238, 2239, "Material"], [2240, 2241, "Material"], [2242, 2243, "Material"], [2244, 2245, "Material"], [2269, 2270, "Material"], [2292, 2293, "Material"], [2309, 2314, "Method"], [2324, 2328, "Method"], [2336, 2339, "Metric"], [2361, 2362, "Material"], [2373, 2374, "Method"], [2378, 2383, "Method"], [2386, 2387, "Metric"], [2391, 2394, "Material"], [2421, 2423, "Task"], [2425, 2426, "Method"], [2448, 2451, "Method"], [2457, 2459, "Method"], [2463, 2464, "Metric"], [2485, 2488, "Task"], [2490, 2493, "Material"], [2496, 2497, "Method"], [2503, 2508, "Task"], [2522, 2527, "Method"], [2531, 2538, "Method"], [2541, 2543, "Metric"], [2565, 2567, "Method"], [2575, 2576, "Material"], [2590, 2591, "Task"], [2598, 2599, "Method"], [2603, 2606, "Method"], [2618, 2620, "Method"], [2633, 2634, "Material"], [2642, 2643, "Material"], [2653, 2658, "Method"], [2672, 2673, "Method"], [2681, 2682, "Metric"], [2713, 2718, "Method"], [2719, 2726, "Method"], [2727, 2728, "Method"], [2734, 2736, "Metric"], [2739, 2742, "Material"], [2787, 2788, "Method"], [2826, 2827, "Task"], [2868, 2869, "Metric"], [2877, 2878, "Method"], [2883, 2884, "Metric"], [2892, 2893, "Method"], [2907, 2909, "Method"], [2926, 2927, "Material"], [2939, 2944, "Metric"], [2945, 2946, "Metric"], [2952, 2955, "Material"], [2998, 3000, "Method"], [3007, 3008, "Material"], [3014, 3019, "Method"], [3021, 3022, "Metric"], [3034, 3035, "Metric"], [3037, 3040, "Method"], [3053, 3054, "Method"], [3060, 3061, "Method"], [3085, 3086, "Method"], [3091, 3092, "Method"], [3096, 3097, "Method"], [3103, 3104, "Method"], [3116, 3117, "Material"], [3118, 3119, "Material"], [3123, 3124, "Method"], [3125, 3126, "Method"], [3132, 3133, "Method"], [3151, 3152, "Method"], [3157, 3158, "Method"], [3165, 3167, "Metric"], [3168, 3169, "Material"], [3170, 3171, "Material"], [3178, 3179, "Method"], [3184, 3185, "Method"], [3204, 3205, "Method"], [3208, 3209, "Task"], [3239, 3240, "Material"], [3241, 3242, "Material"], [3267, 3270, "Method"], [3293, 3294, "Method"], [3312, 3315, "Metric"], [3319, 3320, "Method"], [3322, 3323, "Material"], [3326, 3329, "Method"], [3332, 3335, "Method"], [3355, 3356, "Method"], [3365, 3366, "Method"], [3382, 3383, "Method"], [3393, 3394, "Method"], [3397, 3399, "Metric"], [3407, 3409, "Method"], [3693, 3696, "Method"], [3697, 3698, "Method"], [3699, 3702, "Method"], [3840, 3843, "Method"], [4123, 4126, "Method"], [4127, 4128, "Method"], [4131, 4134, "Method"], [4137, 4140, "Method"], [4141, 4142, "Method"], [4145, 4148, "Method"], [6434, 6437, "Method"], [6438, 6439, "Method"], [6440, 6443, "Method"], [6460, 6461, "Metric"], [6476, 6477, "Material"], [6502, 6503, "Method"], [6509, 6510, "Metric"], [6541, 6542, "Method"], [6544, 6546, "Method"], [6565, 6568, "Metric"], [6590, 6592, "Method"], [6618, 6619, "Material"], [6633, 6634, "Method"], [6639, 6641, "Metric"], [6662, 6663, "Material"], [6669, 6671, "Task"], [6676, 6677, "Task"], [6681, 6684, "Method"], [6685, 6686, "Method"], [6688, 6689, "Material"], [6690, 6691, "Material"], [6697, 6698, "Method"], [6701, 6702, "Method"], [6721, 6722, "Method"], [6729, 6732, "Metric"], [6740, 6741, "Method"], [6747, 6748, "Method"], [6752, 6753, "Method"], [6768, 6770, "Method"], [6772, 6773, "Method"], [6774, 6776, "Task"], [6781, 6785, "Method"], [6797, 6798, "Method"], [6824, 6826, "Method"], [6828, 6830, "Method"], [6833, 6838, "Method"], [6842, 6843, "Metric"], [6844, 6845, "Method"], [6855, 6857, "Method"], [6865, 6867, "Method"], [6884, 6886, "Method"], [6887, 6888, "Method"], [6893, 6895, "Method"], [6907, 6909, "Task"], [6910, 6913, "Task"], [6929, 6930, "Method"], [6937, 6939, "Task"], [6947, 6949, "Task"], [6959, 6961, "Task"], [6962, 6964, "Method"], [6972, 6976, "Task"], [6979, 6981, "Method"], [6982, 6985, "Method"], [6988, 6989, "Method"], [7000, 7002, "Task"], [7030, 7034, "Task"], [7041, 7045, "Method"], [7049, 7052, "Method"], [7054, 7058, "Method"], [7074, 7076, "Method"], [7096, 7098, "Task"], [7100, 7104, "Method"], [7112, 7113, "Method"], [11, 12, "Method"], [77, 78, "Material"], [149, 154, "Metric"], [292, 293, "Method"], [337, 338, "Method"], [453, 454, "Method"], [818, 819, "Method"], [935, 936, "Method"], [1082, 1083, "Method"], [1350, 1353, "Method"], [1631, 1632, "Material"], [1667, 1668, "Material"], [1700, 1701, "Material"], [1802, 1803, "Material"], [1900, 1901, "Method"], [2108, 2109, "Method"], [2141, 2142, "Method"], [2164, 2165, "Method"], [2192, 2193, "Material"], [2252, 2253, "Method"], [2274, 2275, "Method"], [2330, 2331, "Material"], [2356, 2358, "Task"], [2794, 2795, "Method"], [2813, 2814, "Material"], [2816, 2817, "Material"], [2849, 2850, "Method"], [2921, 2923, "Task"], [3316, 3317, "Material"], [3330, 3331, "Method"], [3469, 3470, "Material"], [3473, 3474, "Material"], [3934, 3935, "Method"], [3936, 3937, "Method"], [3940, 3941, "Method"], [6602, 6603, "Material"], [6643, 6644, "Material"], [6816, 6817, "Method"], [6926, 6927, "Material"]], "sections": [[0, 187], [187, 955], [955, 1711], [1711, 2072], [2072, 2234], [2234, 2350], [2350, 2761], [2761, 2915], [2915, 3049], [3049, 3087], [3087, 3836], [3836, 6667], [6667, 6755], [6755, 7114], [7114, 7117]], "sentences": [[0, 9], [9, 23], [23, 47], [47, 68], [68, 112], [112, 142], [142, 166], [166, 183], [183, 187], [187, 190], [190, 201], [201, 222], [222, 246], [246, 270], [270, 297], [297, 330], [330, 377], [377, 430], [430, 465], [465, 491], [491, 507], [507, 568], [568, 591], [591, 617], [617, 623], [623, 644], [644, 654], [654, 676], [676, 705], [705, 734], [734, 751], [751, 773], [773, 809], [809, 833], [833, 860], [860, 888], [888, 902], [902, 914], [914, 955], [955, 963], [963, 970], [970, 987], [987, 997], [997, 1013], [1013, 1031], [1031, 1045], [1045, 1068], [1068, 1106], [1106, 1125], [1125, 1158], [1158, 1162], [1162, 1167], [1167, 1188], [1188, 1211], [1211, 1228], [1228, 1257], [1257, 1281], [1281, 1307], [1307, 1316], [1316, 1323], [1323, 1330], [1330, 1354], [1354, 1373], [1373, 1379], [1379, 1391], [1391, 1413], [1413, 1423], [1423, 1445], [1445, 1473], [1473, 1482], [1482, 1511], [1511, 1531], [1531, 1559], [1559, 1581], [1581, 1605], [1605, 1619], [1619, 1645], [1645, 1669], [1669, 1690], [1690, 1711], [1711, 1714], [1714, 1746], [1746, 1775], [1775, 1806], [1806, 1819], [1819, 1848], [1848, 1864], [1864, 1899], [1899, 1909], [1909, 1915], [1915, 1917], [1917, 1923], [1923, 1954], [1954, 1974], [1974, 1992], [1992, 2013], [2013, 2021], [2021, 2042], [2042, 2072], [2072, 2083], [2083, 2118], [2118, 2126], [2126, 2182], [2182, 2191], [2191, 2219], [2219, 2234], [2234, 2243], [2243, 2268], [2268, 2291], [2291, 2303], [2303, 2334], [2334, 2350], [2350, 2358], [2358, 2370], [2370, 2417], [2417, 2452], [2452, 2470], [2470, 2498], [2498, 2520], [2520, 2562], [2562, 2575], [2575, 2588], [2588, 2595], [2595, 2621], [2621, 2635], [2635, 2653], [2653, 2685], [2685, 2711], [2711, 2761], [2761, 2767], [2767, 2806], [2806, 2846], [2846, 2858], [2858, 2890], [2890, 2915], [2915, 2923], [2923, 2935], [2935, 2973], [2973, 3001], [3001, 3014], [3014, 3023], [3023, 3049], [3049, 3054], [3054, 3087], [3087, 3092], [3092, 3111], [3111, 3136], [3136, 3153], [3153, 3180], [3180, 3211], [3211, 3247], [3247, 3254], [3254, 3286], [3286, 3336], [3336, 3343], [3343, 3350], [3350, 3367], [3367, 3384], [3384, 3410], [3410, 3427], [3427, 3431], [3431, 3452], [3452, 3469], [3469, 3478], [3478, 3629], [3629, 3633], [3633, 3657], [3657, 3670], [3670, 3693], [3693, 3704], [3704, 3836], [3836, 3843], [3843, 3849], [3849, 3866], [3866, 3883], [3883, 3894], [3894, 3932], [3932, 3943], [3943, 4094], [4094, 4101], [4101, 4120], [4120, 4123], [4123, 4128], [4128, 4152], [4152, 6447], [6447, 6450], [6450, 6484], [6484, 6499], [6499, 6536], [6536, 6558], [6558, 6579], [6579, 6585], [6585, 6598], [6598, 6611], [6611, 6620], [6620, 6646], [6646, 6653], [6653, 6667], [6667, 6671], [6671, 6707], [6707, 6717], [6717, 6742], [6742, 6755], [6755, 6759], [6759, 6777], [6777, 6818], [6818, 6844], [6844, 6870], [6870, 6881], [6881, 6924], [6924, 6951], [6951, 6966], [6966, 6979], [6979, 7003], [7003, 7024], [7024, 7066], [7066, 7085], [7085, 7114], [7114, 7117]], "words": ["document", ":", "Improved", "Language", "Modeling", "by", "Decoding", "the", "Past", "Highly", "regularized", "LSTMs", "achieve", "impressive", "results", "on", "several", "benchmark", "datasets", "in", "language", "modeling", ".", "We", "propose", "a", "new", "regularization", "method", "based", "on", "decoding", "the", "last", "token", "in", "the", "context", "using", "the", "predicted", "distribution", "of", "the", "next", "token", ".", "This", "biases", "the", "model", "towards", "retaining", "more", "contextual", "information", ",", "in", "turn", "improving", "its", "ability", "to", "predict", "the", "next", "token", ".", "With", "negligible", "overhead", "in", "the", "number", "of", "parameters", "and", "training", "time", ",", "our", "Past", "Decode", "Regularization", "(", "PDR", ")", "method", "achieves", "a", "word", "level", "perplexity", "of", "55.6", "on", "the", "Penn", "Treebank", "and", "63.5", "on", "the", "WikiText", "-", "2", "datasets", "using", "a", "single", "softmax", ".", "We", "also", "show", "gains", "by", "using", "PDR", "in", "combination", "with", "a", "mixture", "-", "of", "-", "softmaxes", ",", "achieving", "a", "word", "level", "perplexity", "of", "53.8", "and", "60.5", "on", "these", "datasets", ".", "In", "addition", ",", "our", "method", "achieves", "1.169", "bits", "-", "per", "-", "character", "on", "the", "Penn", "Treebank", "Character", "dataset", "for", "character", "level", "language", "modeling", ".", "These", "results", "constitute", "a", "new", "state", "-", "of", "-", "the", "-", "art", "in", "their", "respective", "settings", ".", "tickpos", "=", "left", "colorbrewer", "section", ":", "Introduction", "Language", "modeling", "is", "a", "fundamental", "task", "in", "natural", "language", "processing", ".", "Given", "a", "sequence", "of", "tokens", ",", "its", "joint", "probability", "distribution", "can", "be", "modeled", "using", "the", "auto", "-", "regressive", "conditional", "factorization", ".", "This", "leads", "to", "a", "convenient", "formulation", "where", "a", "language", "model", "has", "to", "predict", "the", "next", "token", "given", "a", "sequence", "of", "tokens", "as", "context", ".", "Recurrent", "neural", "networks", "are", "an", "effective", "way", "to", "compute", "distributed", "representations", "of", "the", "context", "by", "sequentially", "operating", "on", "the", "embeddings", "of", "the", "tokens", ".", "These", "representations", "can", "then", "be", "used", "to", "predict", "the", "next", "token", "as", "a", "probability", "distribution", "over", "a", "fixed", "vocabulary", "using", "a", "linear", "decoder", "followed", "by", "Softmax", ".", "Starting", "from", "the", "work", "of", ",", "there", "has", "been", "a", "long", "list", "of", "works", "that", "seek", "to", "improve", "language", "modeling", "performance", "using", "more", "sophisticated", "recurrent", "neural", "networks", "(", "RNNs", ")", "(", ")", ".", "However", ",", "in", "more", "recent", "work", "vanilla", "LSTMs", "(", ")", "with", "relatively", "large", "number", "of", "parameters", "have", "been", "shown", "to", "achieve", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "several", "standard", "benchmark", "datasets", "both", "in", "word", "-", "level", "and", "character", "-", "level", "perplexity", "(", ")", ".", "A", "key", "component", "in", "these", "models", "is", "the", "use", "of", "several", "forms", "of", "regularization", "e.g.", "variational", "dropout", "on", "the", "token", "embeddings", "(", ")", ",", "dropout", "on", "the", "hidden", "-", "to", "-", "hidden", "weights", "in", "the", "LSTM", "(", ")", ",", "norm", "regularization", "on", "the", "outputs", "of", "the", "LSTM", "and", "classical", "dropout", "(", ")", ".", "By", "carefully", "tuning", "the", "hyperparameters", "associated", "with", "these", "regularizers", "combined", "with", "optimization", "algorithms", "like", "NT", "-", "ASGD", "(", "a", "variant", "of", "the", "Averaged", "SGD", ")", ",", "it", "is", "possible", "to", "achieve", "very", "good", "performance", ".", "Each", "of", "these", "regularizations", "address", "different", "parts", "of", "the", "LSTM", "model", "and", "are", "general", "techniques", "that", "could", "be", "applied", "to", "any", "other", "sequence", "modeling", "problem", ".", "In", "this", "paper", ",", "we", "propose", "a", "regularization", "technique", "that", "is", "specific", "to", "language", "modeling", ".", "One", "unique", "aspect", "of", "language", "modeling", "using", "LSTMs", "(", "or", "any", "RNN", ")", "is", "that", "at", "each", "time", "step", ",", "the", "model", "takes", "as", "input", "a", "particular", "token", "from", "a", "vocabulary", "and", "using", "the", "hidden", "state", "of", "the", "LSTM", "(", "which", "encodes", "the", "context", "till", ")", "predicts", "a", "probability", "distribution", "on", "the", "next", "token", "over", "the", "same", "vocabulary", "as", "output", ".", "Since", "can", "be", "mapped", "to", "a", "trivial", "probability", "distribution", "over", ",", "this", "operation", "can", "be", "interpreted", "as", "transforming", "distributions", "over", "(", ")", ".", "Clearly", ",", "the", "output", "distribution", "is", "dependent", "on", "and", "is", "a", "function", "of", "and", "the", "context", "further", "in", "the", "past", "and", "encodes", "information", "about", "it", ".", "We", "ask", "the", "following", "question", "\u2013", "How", "much", "information", "is", "it", "possible", "to", "decode", "about", "the", "input", "distribution", "(", "and", "hence", ")", "from", "the", "output", "distribution", "?", "In", "general", ",", "it", "is", "impossible", "to", "decode", "unambiguously", ".", "Even", "if", "the", "language", "model", "is", "perfect", "and", "correctly", "predicts", "with", "probability", "1", ",", "there", "could", "be", "many", "tokens", "preceding", "it", ".", "However", ",", "in", "this", "case", "the", "number", "of", "possibilities", "for", "will", "be", "limited", ",", "as", "dictated", "by", "the", "bigram", "statistics", "of", "the", "corpus", "and", "the", "language", "in", "general", ".", "We", "argue", "that", "biasing", "the", "language", "model", "such", "that", "it", "is", "possible", "to", "decode", "more", "information", "about", "the", "past", "tokens", "from", "the", "predicted", "next", "token", "distribution", "is", "beneficial", ".", "We", "incorporate", "this", "intuition", "into", "a", "regularization", "term", "in", "the", "loss", "function", "of", "the", "language", "model", ".", "The", "symmetry", "in", "the", "inputs", "and", "outputs", "of", "the", "language", "model", "at", "each", "step", "lends", "itself", "to", "a", "simple", "decoding", "operation", ".", "It", "can", "be", "cast", "as", "a", "(", "pseudo", ")", "language", "modeling", "problem", "in", "\u201c", "reverse", "\u201d", ",", "where", "the", "future", "prediction", "acts", "as", "the", "input", "and", "the", "last", "token", "acts", "as", "the", "target", "of", "prediction", ".", "The", "token", "embedding", "matrix", "and", "weights", "of", "the", "linear", "decoder", "of", "the", "main", "language", "model", "can", "be", "reused", "in", "the", "past", "decoding", "operation", ".", "We", "only", "need", "a", "few", "extra", "parameters", "to", "model", "the", "nonlinear", "transformation", "performed", "by", "the", "LSTM", ",", "which", "we", "do", "by", "using", "a", "simple", "stateless", "layer", ".", "We", "compute", "the", "cross", "-", "entropy", "loss", "between", "the", "decoded", "distribution", "for", "the", "past", "token", "and", "and", "add", "it", "to", "the", "main", "loss", "function", "after", "suitable", "weighting", ".", "The", "extra", "parameters", "used", "in", "the", "past", "decoding", "are", "discarded", "during", "inference", "time", ".", "We", "call", "our", "method", "Past", "Decode", "Regularization", "or", "PDR", "for", "short", ".", "We", "conduct", "extensive", "experiments", "on", "four", "benchmark", "datasets", "for", "word", "level", "and", "character", "level", "language", "modeling", "by", "combining", "PDR", "with", "existing", "LSTM", "based", "language", "models", "and", "achieve", "new", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "three", "of", "them", ".", "section", ":", "Past", "Decode", "Regularization", "(", "PDR", ")", "Let", "be", "a", "sequence", "of", "tokens", ".", "In", "this", "paper", ",", "we", "will", "experiment", "with", "both", "word", "level", "and", "character", "level", "language", "modeling", ".", "Therefore", ",", "tokens", "can", "be", "either", "words", "or", "characters", ".", "The", "joint", "probability", "factorizes", "into", "Let", "denote", "the", "context", "available", "to", "the", "language", "model", "for", ".", "Let", "denote", "the", "vocabulary", "of", "tokens", ",", "each", "of", "which", "is", "embedded", "into", "a", "vector", "of", "dimension", ".", "Let", "denote", "the", "token", "embedding", "matrix", "of", "dimension", "and", "denote", "the", "embedding", "of", ".", "An", "LSTM", "computes", "a", "distributed", "representation", "of", "in", "the", "form", "of", "its", "hidden", "state", ",", "which", "we", "assume", "has", "dimension", "as", "well", ".", "The", "probability", "that", "the", "next", "token", "is", "can", "then", "be", "calculated", "using", "a", "linear", "decoder", "followed", "by", "a", "Softmax", "layer", "as", "where", "is", "the", "entry", "corresponding", "to", "in", "a", "bias", "vector", "of", "dimension", "and", "represents", "projection", "onto", ".", "Here", "we", "assume", "that", "the", "weights", "of", "the", "decoder", "are", "tied", "with", "the", "token", "embedding", "matrix", "(", ")", ".", "To", "optimize", "the", "parameters", "of", "the", "language", "model", ",", "the", "loss", "function", "to", "be", "minimized", "during", "training", "is", "set", "as", "the", "cross", "-", "entropy", "between", "the", "predicted", "distribution", "and", "the", "actual", "token", ".", "Note", "that", "Eq", ".", "(", "[", "reference", "]", ")", ",", "when", "applied", "to", "all", "produces", "a", "vector", ",", "encapsulating", "the", "prediction", "the", "language", "model", "has", "about", "the", "next", "token", ".", "Since", "this", "is", "dependent", "on", "and", "conditioned", "on", ",", "clearly", "encodes", "information", "about", "it", ";", "in", "particular", "about", "the", "last", "token", "in", ".", "In", "turn", ",", "it", "should", "be", "possible", "to", "infer", "or", "decode", "some", "limited", "information", "about", "from", ".", "We", "argue", "that", "by", "biasing", "the", "model", "to", "be", "more", "accurate", "in", "recalling", "information", "about", "past", "tokens", ",", "we", "can", "help", "it", "in", "predicting", "the", "next", "token", "better", ".", "To", "this", "end", ",", "we", "define", "the", "following", "decoding", "operation", "to", "compute", "a", "probability", "distribution", "over", "as", "the", "last", "token", "in", "the", "context", ".", "Here", "is", "a", "non", "-", "linear", "function", "that", "maps", "vectors", "in", "to", "vectors", "in", "and", "is", "a", "bias", "vector", "of", "dimension", ",", "together", "with", "parameters", ".", "In", "effect", ",", "we", "are", "decoding", "the", "past", "\u2013", "the", "last", "token", "in", "the", "context", ".", "This", "produces", "a", "vector", "of", "dimension", ".", "The", "cross", "-", "entropy", "loss", "with", "respect", "to", "the", "actual", "last", "token", "can", "then", "be", "computed", "as", "Here", "stands", "for", "Past", "Decode", "Regularization", ".", "captures", "the", "extent", "to", "which", "the", "decoded", "distribution", "of", "tokens", "differs", "from", "the", "actual", "tokens", "in", "the", "context", ".", "Note", "the", "symmetry", "between", "Eqs", ".", "(", "[", "reference", "]", ")", "and", "(", "[", "reference", "]", ")", ".", "The", "\u201c", "input", "\u201d", "in", "the", "latter", "case", "is", "and", "the", "\u201c", "context", "\u201d", "is", "provided", "by", "a", "nonlinear", "transformation", "of", ".", "Different", "from", "the", "former", ",", "the", "context", "in", "Eq", ".", "(", "[", "reference", "]", ")", "does", "not", "preserve", "any", "state", "information", "across", "time", "steps", "as", "we", "want", "to", "decode", "only", "using", ".", "The", "term", "can", "be", "interpreted", "as", "a", "\u201c", "soft", "\u201d", "token", "embedding", "lookup", ",", "where", "the", "token", "vector", "is", "a", "probability", "distribution", "instead", "of", "a", "unit", "vector", ".", "We", "add", "to", "the", "loss", "function", "in", "Eq", ".", "(", "[", "reference", "]", ")", "as", "a", "regularization", "term", ",", "where", "is", "a", "positive", "weighting", "coefficient", ",", "to", "construct", "the", "following", "new", "loss", "function", "for", "the", "language", "model", ".", "Thus", "equivalently", "PDR", "can", "also", "be", "viewed", "as", "a", "method", "of", "defining", "an", "augmented", "loss", "function", "for", "language", "modeling", ".", "The", "choice", "of", "dictates", "the", "degree", "to", "which", "we", "want", "the", "language", "model", "to", "incorporate", "our", "inductive", "bias", "i.e.", "decodability", "of", "the", "last", "token", "in", "the", "context", ".", "If", "it", "is", "too", "large", ",", "the", "model", "will", "fail", "to", "predict", "the", "next", "token", ",", "which", "is", "its", "primary", "task", ".", "If", "it", "is", "zero", "or", "too", "small", ",", "the", "model", "will", "retain", "less", "information", "about", "the", "last", "token", "which", "hampers", "its", "predictive", "performance", ".", "In", "practice", ",", "we", "choose", "by", "a", "search", "based", "on", "validation", "set", "performance", ".", "Note", "that", "the", "trainable", "parameters", "associated", "with", "PDR", "are", "used", "only", "during", "training", "to", "bias", "the", "language", "model", "and", "are", "not", "used", "at", "inference", "time", ".", "This", "also", "means", "that", "it", "is", "important", "to", "control", "the", "complexity", "of", "the", "nonlinear", "function", "so", "as", "not", "to", "overly", "bias", "the", "training", ".", "As", "a", "simple", "choice", ",", "we", "use", "a", "single", "fully", "connected", "layer", "of", "size", "followed", "by", "a", "Tanh", "nonlinearity", "as", ".", "This", "introduces", "few", "extra", "parameters", "and", "a", "small", "increase", "in", "training", "time", "as", "compared", "to", "a", "model", "not", "using", "PDR", ".", "section", ":", "Experiments", "We", "present", "extensive", "experimental", "results", "to", "show", "the", "efficacy", "of", "using", "PDR", "for", "language", "modeling", "on", "four", "standard", "benchmark", "datasets", "\u2013", "two", "each", "for", "word", "level", "and", "character", "level", "language", "modeling", ".", "For", "the", "former", ",", "we", "evaluate", "our", "method", "on", "the", "Penn", "Treebank", "(", "PTB", ")", "(", ")", "and", "the", "WikiText", "-", "2", "(", "WT2", ")", "(", ")", "datasets", ".", "For", "the", "latter", ",", "we", "use", "the", "Penn", "Treebank", "Character", "(", "PTBC", ")", "(", ")", "and", "the", "Hutter", "Prize", "Wikipedia", "Prize", "(", ")", "(", "also", "known", "as", "Enwik8", ")", "datasets", ".", "Key", "statistics", "for", "these", "datasets", "is", "presented", "in", "Table", "[", "reference", "]", ".", "As", "mentioned", "in", "the", "introduction", ",", "some", "of", "the", "best", "existing", "results", "on", "these", "datasets", "are", "obtained", "by", "using", "extensive", "regularization", "techniques", "on", "relatively", "large", "LSTMs", "(", ")", ".", "We", "apply", "our", "regularization", "technique", "to", "these", "models", ",", "the", "so", "called", "AWD", "-", "LSTM", ".", "We", "consider", "two", "versions", "of", "the", "model", "\u2013", "one", "with", "a", "single", "softmax", "(", "AWD", "-", "LSTM", ")", "and", "one", "with", "a", "mixture", "-", "of", "-", "softmaxes", "(", "AWD", "-", "LSTM", "-", "MoS", ")", ".", "The", "PDR", "regularization", "term", "is", "computed", "according", "to", "Eq", ".", "(", "[", "reference", "]", ")", "and", "Eq", ".", "(", "[", "reference", "]", ")", ".", "We", "call", "our", "model", "AWD", "-", "LSTM", "+", "PDR", "when", "using", "a", "single", "softmax", "and", "AWD", "-", "LSTM", "-", "MoS", "+", "PDR", "when", "using", "a", "mixture", "-", "of", "-", "softmaxes", ".", "We", "largely", "follow", "the", "experimental", "procedure", "of", "the", "original", "models", "and", "incorporate", "their", "dropouts", "and", "regularizations", "in", "our", "experiments", ".", "The", "relative", "contribution", "of", "these", "existing", "regularizations", "and", "PDR", "will", "be", "analyzed", "in", "Section", "[", "reference", "]", ".", "There", "are", "7", "hyperparameters", "associated", "with", "the", "regularizations", "used", "in", "AWD", "-", "LSTM", "(", "and", "one", "extra", "with", "MoS", ")", ".", "PDR", "also", "has", "an", "associated", "weighting", "coefficient", ".", "For", "our", "experiments", ",", "we", "set", "which", "was", "determined", "by", "a", "coarse", "search", "on", "the", "PTB", "and", "WT2", "validation", "sets", ".", "For", "the", "remaining", "ones", ",", "we", "perform", "light", "hyperparameter", "search", "in", "the", "vicinity", "of", "those", "reported", "for", "AWD", "-", "LSTM", "in", "and", "for", "AWD", "-", "LSTM", "-", "MoS", "in", ".", "subsection", ":", "Model", "and", "training", "for", "PTB", "and", "WikiText", "-", "2", "For", "the", "single", "softmax", "model", "(", "AWD", "-", "LSTM", "+", "PDR", ")", ",", "for", "both", "PTB", "and", "WT2", ",", "we", "use", "a", "3", "-", "layered", "LSTM", "with", "1150", ",", "1150", "and", "400", "hidden", "dimensions", ".", "The", "word", "embedding", "dimension", "is", "set", "to", ".", "For", "the", "mixture", "-", "of", "-", "softmax", "model", ",", "we", "use", "a", "3", "-", "layer", "LSTM", "with", "dimensions", "960", ",", "960", "and", "620", ",", "embedding", "dimension", "of", "280", "and", "15", "experts", "for", "PTB", "and", "a", "3", "-", "layer", "LSTM", "with", "dimensions", "1150", ",", "1150", "and", "650", ",", "embedding", "dimension", "of", "and", "15", "experts", "for", "WT2", ".", "Weight", "tying", "is", "used", "in", "all", "the", "models", ".", "For", "training", "the", "models", ",", "we", "follow", "the", "same", "procedure", "as", "AWD", "-", "LSTM", "i.e.", "a", "combination", "of", "SGD", "and", "NT", "-", "ASGD", ",", "followed", "by", "finetuning", ".", "We", "adopt", "the", "learning", "rate", "schedules", "and", "batch", "sizes", "of", "and", "in", "our", "experiments", ".", "subsection", ":", "Model", "and", "training", "for", "PTBC", "and", "Enwik8", "For", "PTBC", ",", "we", "use", "a", "3", "-", "layer", "LSTM", "with", "1000", ",", "1000", "and", "200", "hidden", "dimensions", "and", "a", "character", "embedding", "dimension", "of", ".", "For", "Enwik8", ",", "we", "use", "a", "LSTM", "with", "1850", ",", "1850", "and", "400", "hidden", "dimensions", "and", "the", "characters", "are", "embedded", "in", "dimensions", ".", "For", "training", ",", "we", "largely", "follow", "the", "procedure", "laid", "out", "in", ".", "For", "each", "of", "the", "datasets", ",", "AWD", "-", "LSTM", "+", "PDR", "has", "less", "than", "1", "%", "more", "parameters", "than", "the", "corresponding", "AWD", "-", "LSTM", "model", "(", "during", "training", "only", ")", ".", "The", "maximum", "observed", "time", "overhead", "due", "to", "the", "additional", "computation", "is", "less", "than", "3", "%", ".", "section", ":", "Results", "on", "Word", "Level", "Language", "Modeling", "The", "results", "for", "PTB", "are", "shown", "in", "Table", "[", "reference", "]", ".", "With", "a", "single", "softmax", ",", "our", "method", "(", "AWD", "-", "LSTM", "+", "PDR", ")", "achieves", "a", "perplexity", "of", "55.6", "on", "the", "PTB", "test", "set", ",", "which", "improves", "on", "the", "current", "state", "-", "of", "-", "the", "-", "art", "with", "a", "single", "softmax", "by", "an", "absolute", "1.7", "points", ".", "The", "advantages", "of", "better", "information", "retention", "due", "to", "PDR", "are", "maintained", "when", "combined", "with", "a", "continuous", "cache", "pointer", "(", ")", ",", "where", "our", "method", "yields", "an", "absolute", "improvement", "of", "1.2", "over", "AWD", "-", "LSTM", ".", "Notably", ",", "when", "coupled", "with", "dynamic", "evaluation", "(", ")", ",", "the", "perplexity", "is", "decreased", "further", "to", "49.3", ".", "To", "the", "best", "of", "our", "knowledge", ",", "ours", "is", "the", "first", "method", "to", "achieve", "a", "sub", "50", "perplexity", "on", "the", "PTB", "test", "set", "with", "a", "single", "softmax", ".", "Note", "that", ",", "for", "both", "cache", "pointer", "and", "dynamic", "evaluation", ",", "we", "coarsely", "tune", "the", "associated", "hyperparameters", "on", "the", "validation", "set", ".", "Using", "a", "mixture", "-", "of", "-", "softmaxes", ",", "our", "method", "(", "AWD", "-", "LSTM", "-", "MoS", "+", "PDR", ")", "achieves", "a", "test", "perplexity", "of", "53.8", ",", "an", "improvement", "of", "0.6", "points", "over", "the", "current", "state", "-", "of", "-", "the", "-", "art", ".", "The", "use", "of", "dynamic", "evaluation", "pushes", "the", "perplexity", "further", "down", "to", "47.3", ".", "PTB", "is", "a", "restrictive", "dataset", "with", "a", "vocabulary", "of", "10", "K", "words", ".", "Achieving", "good", "perplexity", "requires", "considerable", "regularization", ".", "The", "fact", "that", "PDR", "can", "improve", "upon", "existing", "heavily", "regularized", "models", "is", "empirical", "evidence", "of", "its", "distinctive", "nature", "and", "its", "effectiveness", "in", "improving", "language", "models", ".", "Table", "[", "reference", "]", "shows", "the", "perplexities", "achieved", "by", "our", "model", "on", "WT2", ".", "This", "dataset", "is", "considerably", "more", "complex", "than", "PTB", "with", "a", "vocabulary", "of", "more", "than", "33", "K", "words", ".", "AWD", "-", "LSTM", "+", "PDR", "improves", "over", "the", "current", "state", "-", "of", "-", "the", "-", "art", "with", "a", "single", "softmax", "by", "a", "significant", "2.3", "points", ",", "achieving", "a", "perplexity", "of", "63.5", ".", "The", "gains", "are", "maintained", "with", "the", "use", "of", "cache", "pointer", "(", "2.4", "points", ")", "and", "with", "the", "use", "of", "dynamic", "evaluation", "(", "1.7", "points", ")", ".", "Using", "a", "mixture", "-", "of", "-", "softmaxes", ",", "AWD", "-", "LSTM", "-", "MoS", "+", "PDR", "achieves", "perplexities", "of", "60.5", "and", "40.3", "(", "with", "dynamic", "evaluation", ")", "on", "the", "WT2", "test", "set", ",", "improving", "upon", "the", "current", "state", "-", "of", "-", "the", "-", "art", "by", "1.0", "and", "0.4", "points", "respectively", ".", "subsection", ":", "Performance", "on", "Larger", "Datasets", "We", "consider", "the", "Gigaword", "dataset", "with", "a", "truncated", "vocabulary", "of", "about", "100", "K", "tokens", "with", "the", "highest", "frequency", "and", "apply", "PDR", "to", "a", "baseline", "2", "-", "layer", "LSTM", "language", "model", "with", "embedding", "and", "hidden", "dimensions", "set", "to", "1024", ".", "We", "use", "all", "the", "shards", "from", "the", "training", "set", "for", "training", "and", "a", "few", "shards", "from", "the", "heldout", "set", "for", "validation", "(", "heldout", "-", "0", ",", "10", ")", "and", "test", "(", "heldout", "-", "20", ",", "30", ",", "40", ")", ".", "We", "tuned", "the", "PDR", "coefficient", "coarsely", "in", "the", "vicinity", "of", "0.001", ".", "While", "the", "baseline", "model", "achieved", "a", "validation", "(", "test", ")", "perplexity", "of", "44.3", "(", "43.1", ")", ",", "on", "applying", "PDR", ",", "the", "model", "achieved", "a", "perplexity", "of", "44.0", "(", "42.5", ")", ".", "Thus", ",", "PDR", "is", "relatively", "less", "effective", "on", "larger", "datasets", ",", "a", "fact", "also", "observed", "for", "other", "regularization", "techniques", "on", "such", "datasets", "(", ")", ".", "section", ":", "Results", "on", "Character", "Level", "Language", "Modeling", "The", "results", "on", "PTBC", "are", "shown", "in", "Table", "[", "reference", "]", ".", "Our", "method", "achieves", "a", "bits", "-", "per", "-", "character", "(", "BPC", ")", "performance", "of", "1.169", "on", "the", "PTBC", "test", "set", ",", "improving", "on", "the", "current", "state", "-", "of", "-", "the", "-", "art", "by", "0.006", "or", "0.5", "%", ".", "It", "is", "notable", "that", "even", "with", "this", "highly", "processed", "dataset", "and", "a", "small", "vocabulary", "of", "only", "51", "tokens", ",", "our", "method", "improves", "on", "already", "highly", "regularized", "models", ".", "Finally", ",", "we", "present", "results", "on", "Enwik8", "in", "Table", "[", "reference", "]", ".", "AWD", "-", "LSTM", "+", "PDR", "achieves", "1.245", "BPC", ".", "This", "is", "0.012", "or", "about", "1", "%", "less", "than", "the", "1.257", "BPC", "achieved", "by", "AWD", "-", "LSTM", "in", "our", "experiments", "(", "with", "hyperparameters", "from", ")", ".", "section", ":", "Analysis", "of", "PDR", "In", "this", "section", ",", "we", "analyze", "PDR", "by", "probing", "its", "performance", "in", "several", "ways", "and", "comparing", "it", "with", "current", "state", "-", "of", "-", "the", "-", "art", "models", "that", "do", "not", "use", "PDR", ".", "subsection", ":", "A", "Valid", "Regularization", "To", "verify", "that", "indeed", "PDR", "can", "act", "as", "a", "form", "of", "regularization", ",", "we", "perform", "the", "following", "experiment", ".", "We", "take", "the", "models", "for", "PTB", "and", "WT2", "and", "turn", "off", "all", "dropouts", "and", "regularization", "and", "compare", "its", "performance", "with", "only", "PDR", "turned", "on", ".", "The", "results", ",", "as", "shown", "in", "Table", "[", "reference", "]", ",", "validate", "the", "premise", "of", "PDR", ".", "The", "model", "with", "only", "PDR", "turned", "on", "achieves", "2.4", "and", "5.1", "better", "validation", "perplexity", "on", "PTB", "and", "WT2", "as", "compared", "to", "the", "model", "without", "any", "regularization", ".", "Thus", ",", "biasing", "the", "LSTM", "by", "decoding", "the", "distribution", "of", "past", "tokens", "from", "the", "predicted", "next", "-", "token", "distribution", "can", "indeed", "act", "as", "a", "regularizer", "leading", "to", "better", "generalization", "performance", ".", "Next", ",", "we", "plot", "histograms", "of", "the", "negative", "log", "-", "likelihoods", "of", "the", "correct", "context", "tokens", "in", "the", "past", "decoded", "vector", "computed", "using", "our", "best", "models", "on", "the", "PTB", "and", "WT2", "validation", "sets", "in", "Fig", ".", "[", "reference", "]", "(", "a", ")", ".", "The", "NLL", "values", "are", "significantly", "peaked", "near", "0", ",", "which", "means", "that", "the", "past", "decoding", "operation", "is", "able", "to", "decode", "significant", "amount", "of", "information", "about", "the", "last", "token", "in", "the", "context", ".", "To", "investigate", "the", "effect", "of", "hyperparameters", "on", "PDR", ",", "we", "pick", "60", "sets", "of", "random", "hyperparameters", "in", "the", "vicinity", "of", "those", "reported", "by", "and", "compute", "the", "validation", "set", "perplexity", "after", "training", "(", "without", "finetuning", ")", "on", "PTB", ",", "for", "both", "AWD", "-", "LSTM", "+", "PDR", "and", "AWD", "-", "LSTM", ".", "Their", "histograms", "are", "plotted", "in", "Fig", ".", "[", "reference", "]", "(", "b", ")", ".", "The", "perplexities", "for", "models", "with", "PDR", "are", "distributed", "slightly", "to", "the", "left", "of", "those", "without", "PDR", ".", "There", "appears", "to", "be", "more", "instances", "of", "perplexities", "in", "the", "higher", "range", "for", "models", "without", "PDR", ".", "Note", "that", "there", "are", "certainly", "hyperparameter", "settings", "where", "adding", "PDR", "leads", "to", "lower", "validation", "complexity", ",", "as", "is", "generally", "the", "case", "for", "any", "regularization", "method", ".", "[", "scale=0.80", "]", "patterns", "[", "ybar", ",", "ymin=0", ",", "bar", "width=2", ",", "x", "tick", "label", "style", "=", "rotate=0", ",", "xlabel", "=", "Negative", "log", "-", "likelihood", ",", "ylabel", "=", "Normalized", "frequency", ",", "y", "label", "style", "=", "at=", "(", "0.05", ",", "0.5", ")", ",", "every", "axis", "plot", "/", ".append", "style", "=", "fill", ",", "legend", "pos=", "north", "east", ",", "legend", "entries", "=", "PTB", "-", "Valid", ",", "WT2", "-", "Valid", ",", "]", "[", "magenta", "]", "coordinates", "(", "0.33", ",", "0.316464626105", ")(", "1.0", ",", "0.0851737740793", ")(", "1.67", ",", "0.0652768579573", ")(", "2.33", ",", "0.057819113709", ")(", "3.0", ",", "0.0520170462726", ")(", "3.67", ",", "0.0518154856172", ")(", "4.33", ",", "0.050044631288", ")(", "5.0", ",", "0.0517866912379", ")(", "5.67", ",", "0.0515851305825", ")(", "6.33", ",", "0.0497854818739", ")(", "7.0", ",", "0.0443865357482", ")(", "7.67", ",", "0.0388580149155", ")(", "8.33", ",", "0.0341789282732", ")(", "9.0", ",", "0.0278297676294", ")(", "9.67", ",", "0.022977914711", ")", ";", "[", "black", "]", "coordinates", "(", "0.33", ",", "0.30860908651", ")(", "1.0", ",", "0.0787424358073", ")(", "1.67", ",", "0.0643498909958", ")(", "2.33", ",", "0.059959790672", ")(", "3.0", ",", "0.0559238916244", ")(", "3.67", ",", "0.0553451965817", ")(", "4.33", ",", "0.0522072726003", ")(", "5.0", ",", "0.0524417438676", ")(", "5.67", ",", "0.0500670986924", ")(", "6.33", ",", "0.0488797761049", ")(", "7.0", ",", "0.0446293607914", ")(", "7.67", ",", "0.0396455991739", ")(", "8.33", ",", "0.0349711400791", ")(", "9.0", ",", "0.0289646846361", ")(", "9.67", ",", "0.0252630318631", ")", ";", "[", "scale=0.80", "]", "patterns", "[", "ybar", ",", "ymin=0", ",", "bar", "width=2", ",", "ymax=0.3", ",", "x", "tick", "label", "style", "=", "rotate=0", ",", "xlabel", "=", "Perplexity", ",", "ylabel", "=", "Normalized", "frequency", ",", "y", "label", "style", "=", "at=", "(", "0.02", ",", "0.5", ")", ",", "legend", "cell", "align", "=", "left", ",", "every", "axis", "plot", "/", ".append", "style", "=", "fill", ",", "y", "tick", "label", "style=", "/", "pgf", "/", "number", "format", "/", ".cd", ",", "fixed", ",", "fixed", "zerofill", ",", "precision=2", ",", "legend", "pos=", "north", "west", ",", "legend", "entries", "=", "AWD", "-", "LSTM", "+", "PDR", ",", "AWD", "-", "LSTM", ",", "]", "[", "red", "]", "coordinates", "(", "60.17", ",", "0.016393442623", ")(", "60.32", ",", "0.0", ")(", "60.47", ",", "0.016393442623", ")(", "60.61", ",", "0.0655737704918", ")(", "60.76", ",", "0.114754098361", ")(", "60.91", ",", "0.131147540984", ")(", "61.05", ",", "0.114754098361", ")(", "61.2", ",", "0.147540983607", ")(", "61.35", ",", "0.229508196721", ")(", "61.49", ",", "0.0655737704918", ")(", "61.64", ",", "0.0655737704918", ")(", "61.79", ",", "0.0", ")(", "61.93", ",", "0.016393442623", ")(", "62.08", ",", "0.0", ")(", "62.23", ",", "0.016393442623", ")", ";", "[", "black!60!green", "]", "coordinates", "(", "60.17", ",", "0.0", ")(", "60.32", ",", "0.0", ")(", "60.47", ",", "0.0", ")(", "60.61", ",", "0.0655737704918", ")(", "60.76", ",", "0.0819672131148", ")(", "60.91", ",", "0.16393442623", ")(", "61.05", ",", "0.180327868852", ")(", "61.2", ",", "0.131147540984", ")(", "61.35", ",", "0.0983606557377", ")(", "61.49", ",", "0.114754098361", ")(", "61.64", ",", "0.131147540984", ")(", "61.79", ",", "0.0327868852459", ")(", "61.93", ",", "0.0", ")(", "62.08", ",", "0.0", ")(", "62.23", ",", "0.0", ")", ";", "subsection", ":", "Comparison", "with", "AWD", "-", "LSTM", "cycle", "list", "/", "Set1", "-", "4", "[", "scale=0.80", "]", "patterns", "[", "ybar", ",", "ymin=0", ",", "bar", "width=2", ",", "x", "tick", "label", "style", "=", "rotate=0", ",", "xlabel", "=", "Predicted", "token", "entropy", ",", "ylabel", "=", "Normalized", "frequency", ",", "y", "label", "style", "=", "at=", "(", "0.02", ",", "0.5", ")", ",", "y", "tick", "label", "style=", "/", "pgf", "/", "number", "format", "/", ".cd", ",", "fixed", ",", "fixed", "zerofill", ",", "precision=2", ",", "legend", "cell", "align", "=", "left", ",", "every", "axis", "plot", "/", ".append", "style", "=", "fill", ",", "legend", "pos=", "north", "west", ",", "legend", "entries", "=", "AWD", "-", "LSTM", "+", "PDR", ",", "AWD", "-", "LSTM", ",", "]", "[", "red", "]", "coordinates", "(", "0.33", ",", "0.0668799739693", ")(", "1.0", ",", "0.031575807698", ")(", "1.67", ",", "0.0282406214835", ")(", "2.33", ",", "0.0319960953917", ")(", "3.0", ",", "0.037310701067", ")(", "3.67", ",", "0.045865589284", ")(", "4.33", ",", "0.064331132472", ")(", "5.0", ",", "0.0876367629713", ")(", "5.67", ",", "0.108068167952", ")(", "6.33", ",", "0.133922639949", ")(", "7.0", ",", "0.145975406391", ")(", "7.67", ",", "0.117490746892", ")(", "8.33", ",", "0.0765737062596", ")(", "9.0", ",", "0.0230073618135", ")(", "9.67", ",", "0.00112528640573", ")", ";", "[", "black!60!green", "]", "coordinates", "(", "0.33", ",", "0.0684582220475", ")(", "1.0", ",", "0.0332840738079", ")(", "1.67", ",", "0.031372442685", ")(", "2.33", ",", "0.0344093602137", ")(", "3.0", ",", "0.0409305982999", ")(", "3.67", ",", "0.0500684662211", ")(", "4.33", ",", "0.0660529562494", ")(", "5.0", ",", "0.084057538741", ")(", "5.67", ",", "0.103553464662", ")(", "6.33", ",", "0.123117178921", ")(", "7.0", ",", "0.133583698261", ")(", "7.67", ",", "0.11149825784", ")(", "8.33", ",", "0.083824279071", ")(", "9.0", ",", "0.0334982171667", ")(", "9.67", ",", "0.00229124581407", ")", ";", "[", "scale=0.80", "]", "[", "xmax=1200", ",", "xmin=50", ",", "ymax=85", ",", "x", "tick", "label", "style", "=", "rotate=0", ",", "xlabel", "=", "No", ".", "of", "epochs", ",", "ylabel", "=", "Perplexity", ",", "y", "label", "style", "=", "at=", "(", "0.05", ",", "0.5", ")", ",", "legend", "cell", "align", "=", "left", ",", "legend", "entries", "=", "AWD", "-", "LSTM", "+", "PDR", "(", "Train", "),", "AWD", "-", "LSTM", "(", "Train", "),", "AWD", "-", "LSTM", "+", "PDR", "(", "Valid", "),", "AWD", "-", "LSTM", "(", "Valid", ")", "]", "[", "red", ",", "thick", ",", "dashed", "]", "coordinates", "(", "10", ",", "155.13", ")(", "20", ",", "107.08", ")(", "30", ",", "88.67", ")(", "40", ",", "78.86", ")(", "50", ",", "72.14", ")(", "60", ",", "68.24", ")(", "70", ",", "66.26", ")(", "80", ",", "62.77", ")(", "90", ",", "61.43", ")(", "100", ",", "59.24", ")(", "110", ",", "57.73", ")(", "120", ",", "56.89", ")(", "130", ",", "55.47", ")(", "140", ",", "54.97", ")(", "150", ",", "53.56", ")(", "160", ",", "53.39", ")(", "170", ",", "51.40", ")(", "180", ",", "50.83", ")(", "190", ",", "51.02", ")(", "200", ",", "50.42", ")(", "210", ",", "49.81", ")(", "220", ",", "49.46", ")(", "230", ",", "49.05", ")(", "240", ",", "48.19", ")(", "250", ",", "48.29", ")(", "260", ",", "48.05", ")(", "270", ",", "47.82", ")(", "280", ",", "47.44", ")(", "290", ",", "47.52", ")(", "300", ",", "46.70", ")(", "310", ",", "46.44", ")(", "320", ",", "46.24", ")(", "330", ",", "46.49", ")(", "340", ",", "45.73", ")(", "350", ",", "45.62", ")(", "360", ",", "45.44", ")(", "370", ",", "44.94", ")(", "380", ",", "45.05", ")(", "390", ",", "44.54", ")(", "400", ",", "44.91", ")(", "410", ",", "44.52", ")(", "420", ",", "44.00", ")(", "430", ",", "43.94", ")(", "440", ",", "43.95", ")(", "450", ",", "44.13", ")(", "460", ",", "43.84", ")(", "470", ",", "43.88", ")(", "480", ",", "43.63", ")(", "490", ",", "43.73", ")(", "500", ",", "43.57", ")(", "510", ",", "42.99", ")(", "520", ",", "42.78", ")(", "530", ",", "42.89", ")(", "540", ",", "43.10", ")(", "550", ",", "43.06", ")(", "560", ",", "42.55", ")(", "570", ",", "42.55", ")(", "580", ",", "42.27", ")(", "590", ",", "41.90", ")(", "600", ",", "42.71", ")(", "610", ",", "42.08", ")(", "620", ",", "42.40", ")(", "630", ",", "42.15", ")(", "640", ",", "42.14", ")(", "650", ",", "42.57", ")(", "660", ",", "41.67", ")(", "670", ",", "41.60", ")(", "680", ",", "41.43", ")(", "690", ",", "41.55", ")(", "700", ",", "41.68", ")(", "710", ",", "41.68", ")(", "720", ",", "41.44", ")(", "730", ",", "41.21", ")(", "740", ",", "41.70", ")(", "750", ",", "41.69", ")(", "760", ",", "39.79", ")(", "770", ",", "41.44", ")(", "780", ",", "41.96", ")(", "790", ",", "42.13", ")(", "800", ",", "41.67", ")(", "810", ",", "41.85", ")(", "820", ",", "42.46", ")(", "830", ",", "41.82", ")(", "840", ",", "41.82", ")(", "850", ",", "41.76", ")(", "860", ",", "41.43", ")(", "870", ",", "41.65", ")(", "880", ",", "41.61", ")(", "890", ",", "41.94", ")(", "900", ",", "41.35", ")(", "910", ",", "41.76", ")(", "920", ",", "41.30", ")(", "930", ",", "41.34", ")(", "940", ",", "41.24", ")(", "950", ",", "41.09", ")(", "960", ",", "41.11", ")(", "970", ",", "40.72", ")(", "980", ",", "41.14", ")(", "990", ",", "40.53", ")(", "1000", ",", "41.03", ")(", "1010", ",", "41.11", ")(", "1020", ",", "41.06", ")(", "1030", ",", "40.65", ")(", "1040", ",", "41.14", ")(", "1050", ",", "40.73", ")(", "1060", ",", "40.62", ")(", "1070", ",", "40.48", ")(", "1080", ",", "40.83", ")(", "1090", ",", "41.12", ")(", "1100", ",", "40.41", ")(", "1110", ",", "40.65", ")(", "1120", ",", "40.17", ")(", "1130", ",", "40.44", ")(", "1140", ",", "40.28", ")(", "1150", ",", "40.05", ")(", "1160", ",", "40.44", ")(", "1170", ",", "39.93", ")(", "1180", ",", "39.90", ")(", "1190", ",", "39.59", ")(", "1200", ",", "40.16", ")(", "1210", ",", "40.28", ")(", "1220", ",", "39.82", ")(", "1230", ",", "40.00", ")(", "1240", ",", "40.08", ")(", "1250", ",", "39.93", ")(", "1260", ",", "39.62", ")(", "1270", ",", "39.45", ")(", "1280", ",", "39.85", ")(", "1290", ",", "39.82", ")(", "1300", ",", "40.09", ")(", "1310", ",", "39.63", ")(", "1320", ",", "39.64", ")(", "1330", ",", "39.34", ")(", "1340", ",", "39.05", ")(", "1350", ",", "39.43", ")(", "1360", ",", "39.12", ")(", "1370", ",", "39.32", ")(", "1380", ",", "39.37", ")(", "1390", ",", "39.63", ")(", "1400", ",", "39.71", ")", ";", "[", "black!60!green", ",", "thick", ",", "dashed", "]", "coordinates", "(", "10", ",", "140.66", ")(", "20", ",", "95.19", ")(", "30", ",", "79.04", ")(", "40", ",", "69.99", ")(", "50", ",", "64.20", ")(", "60", ",", "60.38", ")(", "70", ",", "58.07", ")(", "80", ",", "55.14", ")(", "90", ",", "53.71", ")(", "100", ",", "51.55", ")(", "110", ",", "50.41", ")(", "120", ",", "49.34", ")(", "130", ",", "48.23", ")(", "140", ",", "47.76", ")(", "150", ",", "46.76", ")(", "160", ",", "46.68", ")(", "170", ",", "44.84", ")(", "180", ",", "44.30", ")(", "190", ",", "44.08", ")(", "200", ",", "43.60", ")(", "210", ",", "43.48", ")(", "220", ",", "43.03", ")(", "230", ",", "42.56", ")(", "240", ",", "41.78", ")(", "250", ",", "41.93", ")(", "260", ",", "41.61", ")(", "270", ",", "41.81", ")(", "280", ",", "41.40", ")(", "290", ",", "41.20", ")(", "300", ",", "40.69", ")(", "310", ",", "40.43", ")(", "320", ",", "40.17", ")(", "330", ",", "40.40", ")(", "340", ",", "39.86", ")(", "350", ",", "39.66", ")(", "360", ",", "39.46", ")(", "370", ",", "39.03", ")(", "380", ",", "38.83", ")(", "390", ",", "38.53", ")(", "400", ",", "38.91", ")(", "410", ",", "38.74", ")(", "420", ",", "38.21", ")(", "430", ",", "37.93", ")(", "440", ",", "38.15", ")(", "450", ",", "38.09", ")(", "460", ",", "37.83", ")(", "470", ",", "37.85", ")(", "480", ",", "37.75", ")(", "490", ",", "37.72", ")(", "500", ",", "37.27", ")(", "510", ",", "37.09", ")(", "520", ",", "37.19", ")(", "530", ",", "36.76", ")(", "540", ",", "37.15", ")(", "550", ",", "37.02", ")(", "560", ",", "36.77", ")(", "570", ",", "36.77", ")(", "580", ",", "36.53", ")(", "590", ",", "36.16", ")(", "600", ",", "36.76", ")(", "610", ",", "36.43", ")(", "620", ",", "36.24", ")(", "630", ",", "36.26", ")(", "640", ",", "36.12", ")(", "650", ",", "36.44", ")(", "660", ",", "35.96", ")(", "670", ",", "35.79", ")(", "680", ",", "35.75", ")(", "690", ",", "35.62", ")(", "700", ",", "35.79", ")(", "710", ",", "35.62", ")(", "720", ",", "35.97", ")(", "730", ",", "35.30", ")(", "740", ",", "35.43", ")(", "750", ",", "35.72", ")(", "760", ",", "36.88", ")(", "770", ",", "36.87", ")(", "780", ",", "37.12", ")(", "790", ",", "36.91", ")(", "800", ",", "36.36", ")(", "810", ",", "36.07", ")(", "820", ",", "36.33", ")(", "830", ",", "35.65", ")(", "840", ",", "35.58", ")(", "850", ",", "35.48", ")(", "860", ",", "35.18", ")(", "870", ",", "35.29", ")(", "880", ",", "34.86", ")(", "890", ",", "35.3", ")(", "900", ",", "34.87", ")(", "910", ",", "35.37", ")(", "920", ",", "34.76", ")(", "930", ",", "34.68", ")(", "940", ",", "34.69", ")(", "950", ",", "34.31", ")(", "960", ",", "34.56", ")(", "970", ",", "34.15", ")(", "980", ",", "34.4", ")(", "990", ",", "33.95", ")(", "1000", ",", "34.02", ")(", "1010", ",", "34.12", ")(", "1020", ",", "34.24", ")(", "1030", ",", "33.9", ")(", "1040", ",", "34.11", ")(", "1050", ",", "33.79", ")(", "1060", ",", "33.91", ")(", "1070", ",", "33.84", ")(", "1080", ",", "34.06", ")(", "1090", ",", "34.3", ")(", "1100", ",", "33.75", ")(", "1110", ",", "33.54", ")(", "1120", ",", "33.57", ")(", "1130", ",", "33.55", ")(", "1140", ",", "33.42", ")(", "1150", ",", "33.17", ")(", "1160", ",", "33.78", ")(", "1170", ",", "33.1", ")(", "1180", ",", "33.01", ")(", "1190", ",", "32.9", ")(", "1200", ",", "33.38", ")(", "1210", ",", "33.12", ")(", "1220", ",", "32.83", ")(", "1230", ",", "32.94", ")(", "1240", ",", "32.95", ")(", "1250", ",", "33.04", ")(", "1260", ",", "32.57", ")(", "1270", ",", "32.57", ")(", "1280", ",", "32.63", ")(", "1290", ",", "32.93", ")(", "1300", ",", "32.83", ")(", "1310", ",", "32.68", ")(", "1320", ",", "32.54", ")(", "1330", ",", "32.72", ")(", "1340", ",", "32.24", ")(", "1350", ",", "32.65", ")(", "1360", ",", "32.42", ")(", "1370", ",", "32.24", ")(", "1380", ",", "32.53", ")(", "1390", ",", "32.42", ")(", "1400", ",", "32.45", ")", ";", "[", "red", ",", "thick", "]", "coordinates", "(", "10", ",", "121.40", ")(", "20", ",", "89.75", ")(", "30", ",", "81.34", ")(", "40", ",", "75.91", ")(", "50", ",", "73.53", ")(", "60", ",", "68.18", ")(", "70", ",", "66.82", ")(", "80", ",", "66.04", ")(", "90", ",", "65.49", ")(", "100", ",", "65.03", ")(", "110", ",", "64.64", ")(", "120", ",", "64.29", ")(", "130", ",", "63.97", ")(", "140", ",", "63.70", ")(", "150", ",", "63.46", ")(", "160", ",", "63.25", ")(", "170", ",", "63.04", ")(", "180", ",", "62.85", ")(", "190", ",", "62.69", ")(", "200", ",", "62.54", ")(", "210", ",", "62.40", ")(", "220", ",", "62.27", ")(", "230", ",", "62.15", ")(", "240", ",", "62.04", ")(", "250", ",", "61.93", ")(", "260", ",", "61.84", ")(", "270", ",", "61.76", ")(", "280", ",", "61.68", ")(", "290", ",", "61.60", ")(", "300", ",", "61.53", ")(", "310", ",", "61.46", ")(", "320", ",", "61.40", ")(", "330", ",", "61.35", ")(", "340", ",", "61.30", ")(", "350", ",", "61.25", ")(", "360", ",", "61.20", ")(", "370", ",", "61.15", ")(", "380", ",", "61.11", ")(", "390", ",", "61.06", ")(", "400", ",", "61.03", ")(", "410", ",", "60.99", ")(", "420", ",", "60.95", ")(", "430", ",", "60.92", ")(", "440", ",", "60.88", ")(", "450", ",", "60.85", ")(", "460", ",", "60.82", ")(", "470", ",", "60.80", ")(", "480", ",", "60.77", ")(", "490", ",", "60.75", ")(", "500", ",", "60.73", ")(", "510", ",", "60.71", ")(", "520", ",", "60.68", ")(", "530", ",", "60.66", ")(", "540", ",", "60.65", ")(", "550", ",", "60.63", ")(", "560", ",", "60.61", ")(", "570", ",", "60.59", ")(", "580", ",", "60.58", ")(", "590", ",", "60.56", ")(", "600", ",", "60.54", ")(", "610", ",", "60.53", ")(", "620", ",", "60.51", ")(", "630", ",", "60.50", ")(", "640", ",", "60.49", ")(", "650", ",", "60.48", ")(", "660", ",", "60.47", ")(", "670", ",", "60.46", ")(", "680", ",", "60.44", ")(", "690", ",", "60.43", ")(", "700", ",", "60.42", ")(", "710", ",", "60.41", ")(", "720", ",", "60.40", ")(", "730", ",", "60.40", ")(", "740", ",", "60.39", ")(", "750", ",", "60.39", ")(", "760", ",", "59.97", ")(", "770", ",", "59.78", ")(", "780", ",", "59.64", ")(", "790", ",", "59.51", ")(", "800", ",", "59.41", ")(", "810", ",", "59.32", ")(", "820", ",", "59.25", ")(", "830", ",", "59.18", ")(", "840", ",", "59.13", ")(", "850", ",", "59.08", ")(", "860", ",", "59.03", ")(", "870", ",", "59.00", ")(", "880", ",", "58.96", ")(", "890", ",", "58.93", ")(", "900", ",", "58.90", ")(", "910", ",", "58.88", ")(", "920", ",", "58.85", ")(", "930", ",", "58.83", ")(", "940", ",", "58.80", ")(", "950", ",", "58.78", ")(", "960", ",", "58.75", ")(", "970", ",", "58.73", ")(", "980", ",", "58.71", ")(", "990", ",", "58.69", ")(", "1000", ",", "58.67", ")(", "1010", ",", "58.65", ")(", "1020", ",", "58.63", ")(", "1030", ",", "58.61", ")(", "1040", ",", "58.59", ")(", "1050", ",", "58.57", ")(", "1060", ",", "58.56", ")(", "1070", ",", "58.54", ")(", "1080", ",", "58.52", ")(", "1090", ",", "58.50", ")(", "1100", ",", "58.48", ")(", "1110", ",", "58.47", ")(", "1120", ",", "58.45", ")(", "1130", ",", "58.44", ")(", "1140", ",", "58.42", ")(", "1150", ",", "58.41", ")(", "1160", ",", "58.39", ")(", "1170", ",", "58.38", ")(", "1180", ",", "58.37", ")(", "1190", ",", "58.35", ")(", "1200", ",", "58.34", ")(", "1210", ",", "58.33", ")(", "1220", ",", "58.31", ")(", "1230", ",", "58.30", ")(", "1240", ",", "58.29", ")(", "1250", ",", "58.28", ")(", "1260", ",", "58.27", ")(", "1270", ",", "58.26", ")(", "1280", ",", "58.25", ")(", "1290", ",", "58.24", ")(", "1300", ",", "58.23", ")(", "1310", ",", "58.22", ")(", "1320", ",", "58.21", ")(", "1330", ",", "58.21", ")(", "1340", ",", "58.20", ")(", "1350", ",", "58.19", ")(", "1360", ",", "58.18", ")(", "1370", ",", "58.18", ")(", "1380", ",", "58.17", ")(", "1390", ",", "58.16", ")(", "1400", ",", "58.15", ")", ";", "[", "black!60!green", ",", "thick", "]", "coordinates", "(", "10", ",", "115.36", ")(", "20", ",", "87.02", ")(", "30", ",", "79.04", ")(", "40", ",", "74.46", ")(", "50", ",", "72.82", ")(", "60", ",", "67.61", ")(", "70", ",", "66.66", ")(", "80", ",", "65.95", ")(", "90", ",", "65.42", ")(", "100", ",", "64.98", ")(", "110", ",", "64.60", ")(", "120", ",", "64.27", ")(", "130", ",", "63.96", ")(", "140", ",", "63.70", ")(", "150", ",", "63.48", ")(", "160", ",", "63.29", ")(", "170", ",", "63.12", ")(", "180", ",", "62.96", ")(", "190", ",", "62.81", ")(", "200", ",", "62.68", ")(", "210", ",", "62.56", ")(", "220", ",", "62.45", ")(", "230", ",", "62.35", ")(", "240", ",", "62.26", ")(", "250", ",", "62.17", ")(", "260", ",", "62.09", ")(", "270", ",", "62.02", ")(", "280", ",", "61.95", ")(", "290", ",", "61.89", ")(", "300", ",", "61.83", ")(", "310", ",", "61.77", ")(", "320", ",", "61.72", ")(", "330", ",", "61.66", ")(", "340", ",", "61.62", ")(", "350", ",", "61.57", ")(", "360", ",", "61.53", ")(", "370", ",", "61.48", ")(", "380", ",", "61.45", ")(", "390", ",", "61.41", ")(", "400", ",", "61.38", ")(", "410", ",", "61.35", ")(", "420", ",", "61.32", ")(", "430", ",", "61.29", ")(", "440", ",", "61.26", ")(", "450", ",", "61.23", ")(", "460", ",", "61.21", ")(", "470", ",", "61.18", ")(", "480", ",", "61.16", ")(", "490", ",", "61.14", ")(", "500", ",", "61.13", ")(", "510", ",", "61.11", ")(", "520", ",", "61.09", ")(", "530", ",", "61.07", ")(", "540", ",", "61.06", ")(", "550", ",", "61.04", ")(", "560", ",", "61.02", ")(", "570", ",", "61.01", ")(", "580", ",", "61.00", ")(", "590", ",", "60.98", ")(", "600", ",", "60.97", ")(", "610", ",", "60.96", ")(", "620", ",", "60.94", ")(", "630", ",", "60.93", ")(", "640", ",", "60.92", ")(", "650", ",", "60.91", ")(", "660", ",", "60.90", ")(", "670", ",", "60.89", ")(", "680", ",", "60.88", ")(", "690", ",", "60.87", ")(", "700", ",", "60.86", ")(", "710", ",", "60.85", ")(", "720", ",", "60.84", ")(", "730", ",", "60.83", ")(", "740", ",", "60.83", ")(", "750", ",", "60.82", ")(", "760", ",", "60.37", ")(", "770", ",", "60.30", ")(", "780", ",", "60.25", ")(", "790", ",", "60.18", ")(", "800", ",", "60.13", ")(", "810", ",", "60.07", ")(", "820", ",", "60.01", ")(", "830", ",", "59.97", ")(", "840", ",", "59.93", ")(", "850", ",", "59.91", ")(", "860", ",", "59.89", ")(", "870", ",", "59.86", ")(", "880", ",", "59.83", ")(", "890", ",", "59.81", ")(", "900", ",", "59.78", ")(", "910", ",", "59.76", ")(", "920", ",", "59.75", ")(", "930", ",", "59.73", ")(", "940", ",", "59.72", ")(", "950", ",", "59.70", ")(", "960", ",", "59.69", ")(", "970", ",", "59.68", ")(", "980", ",", "59.67", ")(", "990", ",", "59.66", ")(", "1000", ",", "59.65", ")(", "1010", ",", "59.63", ")(", "1020", ",", "59.62", ")(", "1030", ",", "59.61", ")(", "1040", ",", "59.60", ")(", "1050", ",", "59.58", ")(", "1060", ",", "59.57", ")(", "1070", ",", "59.56", ")(", "1080", ",", "59.55", ")(", "1090", ",", "59.54", ")(", "1100", ",", "59.52", ")(", "1110", ",", "59.51", ")(", "1120", ",", "59.49", ")(", "1130", ",", "59.48", ")(", "1140", ",", "59.47", ")(", "1150", ",", "59.46", ")(", "1160", ",", "59.45", ")(", "1170", ",", "59.44", ")(", "1180", ",", "59.43", ")(", "1190", ",", "59.43", ")(", "1200", ",", "59.42", ")(", "1210", ",", "59.41", ")(", "1220", ",", "59.40", ")(", "1230", ",", "59.39", ")(", "1240", ",", "59.39", ")(", "1250", ",", "59.38", ")(", "1260", ",", "59.37", ")(", "1270", ",", "59.37", ")(", "1280", ",", "59.36", ")(", "1290", ",", "59.36", ")(", "1300", ",", "59.35", ")(", "1310", ",", "59.35", ")(", "1320", ",", "59.34", ")(", "1330", ",", "59.34", ")(", "1340", ",", "59.34", ")(", "1350", ",", "59.33", ")(", "1360", ",", "59.33", ")(", "1370", ",", "59.33", ")(", "1380", ",", "59.32", ")(", "1390", ",", "59.32", ")(", "1400", ",", "59.31", ")", ";", "To", "show", "the", "qualitative", "difference", "between", "AWD", "-", "LSTM", "+", "PDR", "and", "AWD", "-", "LSTM", ",", "in", "Fig", ".", "[", "reference", "]", "(", "a", ")", ",", "we", "plot", "a", "histogram", "of", "the", "entropy", "of", "the", "predicted", "next", "token", "distribution", "for", "all", "the", "tokens", "in", "the", "validation", "set", "of", "PTB", "achieved", "by", "their", "respective", "best", "models", ".", "The", "distributions", "for", "the", "two", "models", "is", "slightly", "different", ",", "with", "some", "identifiable", "patterns", ".", "The", "use", "of", "PDR", "has", "the", "effect", "of", "reducing", "the", "entropy", "of", "the", "predicted", "distribution", "when", "it", "is", "in", "the", "higher", "range", "of", "8", "and", "above", ",", "pushing", "it", "into", "the", "range", "of", "5", "-", "8", ".", "This", "shows", "that", "one", "way", "PDR", "biases", "the", "language", "model", "is", "by", "reducing", "the", "entropy", "of", "the", "predicted", "next", "token", "distribution", ".", "Indeed", ",", "one", "way", "to", "reduce", "the", "cross", "-", "entropy", "between", "and", "is", "by", "making", "less", "spread", "out", "in", "Eq", ".", "(", "[", "reference", "]", ")", ".", "This", "tends", "to", "benefits", "the", "language", "model", "when", "the", "predictions", "are", "correct", ".", "We", "also", "compare", "the", "training", "curves", "for", "the", "two", "models", "in", "Fig", ".", "[", "reference", "]", "(", "b", ")", "on", "PTB", ".", "Although", "the", "two", "models", "use", "slightly", "different", "hyperparameters", ",", "the", "regularization", "effect", "of", "PDR", "is", "apparent", "with", "a", "lower", "validation", "perplexity", "but", "higher", "training", "perplexity", ".", "The", "corresponding", "trends", "shown", "in", "Fig", ".", "[", "reference", "]", "(", "a", ",", "b", ")", "for", "WT2", "have", "similar", "characteristics", ".", "subsection", ":", "Ablation", "Studies", "We", "perform", "a", "set", "of", "ablation", "experiments", "on", "the", "best", "AWD", "-", "LSTM", "+", "PDR", "models", "for", "PTB", "and", "WT2", "to", "understand", "the", "relative", "contribution", "of", "PDR", "and", "the", "other", "regularizations", "used", "in", "the", "model", ".", "The", "results", "are", "shown", "in", "Table", "[", "reference", "]", ".", "In", "both", "cases", ",", "PDR", "has", "a", "significant", "effect", "in", "decreasing", "the", "validation", "set", "performance", ",", "albeit", "lesser", "than", "the", "other", "forms", "of", "regularization", ".", "This", "is", "not", "surprising", "as", "PDR", "does", "not", "influence", "the", "LSTM", "directly", ".", "section", ":", "Related", "Work", "Our", "method", "builds", "on", "the", "work", "of", "using", "sophisticated", "regularization", "techniques", "to", "train", "LSTMs", "for", "language", "modeling", ".", "In", "particular", ",", "the", "AWD", "-", "LSTM", "model", "achieves", "state", "-", "of", "-", "the", "-", "art", "performance", "with", "a", "single", "softmax", "on", "the", "four", "datasets", "considered", "in", "this", "paper", "(", ")", ".", "also", "achieve", "similar", "results", "with", "highly", "regularized", "LSTMs", ".", "By", "addressing", "the", "so", "-", "called", "softmax", "bottleneck", "in", "single", "softmax", "models", ",", "use", "a", "mixture", "-", "of", "-", "softmaxes", "to", "achieve", "significantly", "lower", "perplexities", ".", "PDR", "utilizes", "the", "symmetry", "between", "the", "inputs", "and", "outputs", "of", "a", "language", "model", ",", "a", "fact", "that", "is", "also", "exploited", "in", "weight", "tying", "(", ")", ".", "Our", "method", "can", "be", "used", "with", "untied", "weights", "as", "well", ".", "Although", "motivated", "by", "language", "modeling", ",", "PDR", "can", "also", "be", "applied", "to", "seq2seq", "models", "with", "shared", "input", "-", "output", "vocabularies", ",", "such", "as", "those", "used", "for", "text", "summarization", "and", "neural", "machine", "translation", "(", "with", "byte", "pair", "encoding", "of", "words", ")", "(", ")", ".", "Regularizing", "the", "training", "of", "an", "LSTM", "by", "combining", "the", "main", "objective", "function", "with", "auxiliary", "tasks", "has", "been", "successfully", "applied", "to", "several", "tasks", "in", "NLP", "(", ")", ".", "In", "fact", ",", "a", "popular", "choice", "for", "the", "auxiliary", "task", "is", "language", "modeling", "itself", ".", "This", "in", "turn", "is", "related", "to", "multi", "-", "task", "learning", "(", ")", ".", "Specialized", "architectures", "like", "Recurrent", "Highway", "Networks", "(", ")", "and", "NAS", "(", ")", "have", "been", "successfully", "used", "to", "achieve", "competitive", "performance", "in", "language", "modeling", ".", "The", "former", "one", "makes", "the", "hidden", "-", "to", "-", "hidden", "transition", "function", "more", "complex", "allowing", "for", "more", "refined", "information", "flow", ".", "Such", "architectures", "are", "especially", "important", "for", "character", "level", "language", "modeling", "where", "strong", "results", "have", "been", "shown", "using", "Fast", "-", "Slow", "RNNs", "(", ")", ",", "a", "two", "level", "architecture", "where", "the", "slowly", "changing", "recurrent", "network", "tries", "to", "capture", "more", "long", "range", "dependencies", ".", "The", "use", "of", "historical", "information", "can", "greatly", "help", "language", "models", "deal", "with", "long", "range", "dependencies", "as", "shown", "by", ".", "Finally", ",", "in", "a", "recent", "paper", ",", "achieve", "improved", "performance", "for", "language", "modeling", "by", "using", "frequency", "agnostic", "word", "embeddings", ",", "a", "technique", "orthogonal", "to", "and", "combinable", "with", "PDR", ".", "bibliography", ":", "References"]}