{"coref": {"BLEU": [[188, 189], [203, 204], [912, 913], [925, 926], [2650, 2651], [3130, 3131]], "GCNSEQ": [[2580, 2581], [2842, 2843], [3008, 3009], [3057, 3058], [3045, 3046], [3159, 3160]], "Graph-to-Sequence": [], "LDC2015E86_": [[190, 191], [907, 909], [2692, 2693], [2787, 2789], [3070, 3071], [2664, 2665]]}, "coref_non_salient": {"0": [[1422, 1423], [1457, 1458], [2229, 2230], [2242, 2243], [2265, 2266], [2469, 2470], [2496, 2497], [2582, 2583], [2828, 2829], [2840, 2841], [2864, 2865], [2978, 2979], [1410, 1411], [1760, 1761], [2224, 2225], [2482, 2483], [2567, 2568], [2895, 2896], [2966, 2967]], "1": [[600, 602], [835, 837], [882, 884], [892, 894], [1350, 1351], [1895, 1897], [3017, 3019], [3163, 3165], [3202, 3204], [3227, 3229], [3248, 3250], [3391, 3393], [3412, 3414], [4235, 4237], [4576, 4578], [4682, 4684], [4730, 4732]], "10": [[2958, 2960], [4339, 4341]], "11": [[1782, 1786], [1786, 1789]], "12": [[151, 153], [759, 761], [847, 849], [2210, 2212], [2877, 2879], [3438, 3440], [4231, 4233], [4585, 4587]], "13": [[1840, 1847], [2494, 2495], [2830, 2831]], "14": [[621, 622], [726, 727], [764, 765], [3059, 3060]], "15": [[680, 681], [706, 712]], "16": [[1187, 1188], [4416, 4418]], "17": [[938, 942], [1124, 1128], [4132, 4136]], "18": [[1412, 1421], [1790, 1791], [1862, 1863], [1917, 1918], [2057, 2058], [2159, 2160], [2222, 2223], [2467, 2468], [2866, 2867], [1997, 1998], [2104, 2105], [2123, 2124], [2155, 2156], [2194, 2195], [2227, 2228], [2480, 2481], [2565, 2566], [2696, 2697], [2869, 2870], [2899, 2900], [2924, 2925], [4689, 4690]], "19": [[2277, 2280], [3013, 3014], [3051, 3052]], "2": [[916, 917], [929, 930], [2652, 2653], [3860, 3861], [3375, 3376], [3408, 3409]], "20": [[2142, 2143], [2146, 2148]], "21": [[1363, 1365], [1563, 1565]], "22": [[2723, 2725]], "23": [[4328, 4332]], "24": [[2681, 2682]], "25": [[1904, 1905], [2407, 2408]], "26": [[4243, 4248]], "27": [[1271, 1272], [1316, 1318]], "28": [[45, 51], [77, 83], [575, 581]], "29": [[107, 109], [3090, 3092]], "3": [[1649, 1650], [1899, 1900], [2010, 2012], [4354, 4356]], "30": [[37, 40], [438, 441]], "31": [[1869, 1870]], "32": [[4033, 4035]], "33": [[1366, 1367], [1377, 1378], [2250, 2251], [2435, 2436], [2457, 2458], [2475, 2476], [2525, 2526], [2574, 2575], [2594, 2595], [2225, 2226], [2226, 2227], [2287, 2288], [2328, 2329], [2363, 2364], [2486, 2487], [4693, 4694]], "34": [[545, 547], [1465, 1467], [1483, 1484]], "35": [[3468, 3470], [3636, 3638], [3721, 3725]], "36": [[2550, 2552]], "37": [[561, 562], [1724, 1725], [1830, 1831], [3803, 3804]], "38": [[1821, 1822], [2244, 2245], [2267, 2268]], "39": [[3807, 3809]], "4": [[2, 5], [148, 150], [180, 182], [741, 742], [769, 771], [822, 824], [1329, 1330], [1336, 1340], [1343, 1347], [2200, 2202], [2274, 2276], [2764, 2766], [2885, 2887], [2994, 2998], [3054, 3056], [3149, 3153], [3182, 3184], [4613, 4617]], "40": [[1199, 1203]], "41": [[1181, 1186], [3924, 3926]], "42": [[6, 12], [12, 18], [140, 146], [530, 536], [858, 864], [1883, 1889], [4630, 4636]], "43": [[3518, 3520]], "44": [[632, 633], [730, 731], [1454, 1456], [1836, 1838]], "45": [[379, 380]], "46": [[686, 689]], "47": [[1989, 1991]], "48": [[2654, 2656]], "49": [[1913, 1915]], "5": [[2677, 2680], [2801, 2802], [3040, 3041]], "50": [[1293, 1295]], "51": [[3891, 3892]], "52": [[826, 830]], "53": [[90, 92]], "54": [[2707, 2709]], "55": [[2398, 2402]], "56": [[3063, 3064], [3338, 3340], [3464, 3466], [3527, 3529], [3556, 3558], [3584, 3586], [3651, 3653], [3684, 3685], [3752, 3754], [4485, 4487]], "57": [[2062, 2064]], "58": [[2051, 2056]], "59": [[1817, 1820]], "6": [[1171, 1173], [1876, 1882]], "60": [[694, 701]], "61": [[1119, 1121]], "62": [[2856, 2858]], "63": [[1288, 1289]], "64": [[934, 936]], "65": [[2719, 2720]], "66": [[2220, 2222]], "67": [[1798, 1801]], "68": [[343, 344]], "69": [[1505, 1506]], "7": [[1541, 1543], [1973, 1975]], "70": [[807, 809], [2310, 2312], [2336, 2338], [2528, 2530], [2557, 2559], [2910, 2912]], "71": [[205, 206], [920, 922], [2666, 2667], [3072, 3073], [4170, 4171]], "72": [[2861, 2862], [2914, 2915], [2941, 2942], [4369, 4370]], "73": [[448, 451]], "74": [[540, 544]], "75": [[1499, 1503]], "76": [[1384, 1389]], "77": [[1605, 1609]], "78": [[2712, 2715]], "79": [[629, 630]], "8": [[1826, 1829], [1832, 1835]], "80": [[548, 553]], "81": [[25, 27]], "82": [[557, 560]], "83": [[947, 951]], "84": [[2673, 2674]], "85": [[2805, 2808]], "86": [[4582, 4583], [645, 646], [747, 748], [841, 842], [1356, 1357], [2247, 2248], [2298, 2299], [2460, 2461], [2790, 2791], [2798, 2799], [2819, 2820], [2851, 2852], [2950, 2951], [3000, 3001], [3038, 3039], [3186, 3187], [3232, 3233], [3426, 3427], [3617, 3618], [3687, 3688], [3702, 3703], [3741, 3742], [3760, 3761], [4212, 4213], [4239, 4240], [4592, 4593], [4644, 4645]], "9": [[41, 44], [60, 62], [86, 88], [442, 443], [477, 478], [619, 620], [743, 744], [942, 943], [973, 974], [1144, 1146], [1449, 1450], [2541, 2543], [4386, 4387], [4430, 4431], [4466, 4468]]}, "doc_id": "31e5dab321066712cdc8b30943f7950066840ee1", "method_subrelations": {"GCNSEQ": [[[0, 6], "GCNSEQ"]]}, "n_ary_relations": [{"Material": "LDC2015E86_", "Method": "GCNSEQ", "Metric": "BLEU", "Task": "Graph-to-Sequence", "score": "23.95"}], "ner": [[2, 5, "Method"], [6, 12, "Task"], [12, 18, "Task"], [25, 27, "Task"], [37, 40, "Method"], [41, 44, "Method"], [45, 51, "Method"], [60, 62, "Method"], [77, 83, "Method"], [86, 88, "Method"], [90, 92, "Method"], [107, 109, "Method"], [140, 146, "Task"], [148, 150, "Method"], [151, 153, "Method"], [180, 182, "Method"], [188, 189, "Metric"], [190, 191, "Material"], [203, 204, "Metric"], [205, 206, "Material"], [343, 344, "Method"], [379, 380, "Method"], [438, 441, "Method"], [442, 443, "Method"], [448, 451, "Method"], [477, 478, "Method"], [530, 536, "Task"], [540, 544, "Task"], [545, 547, "Task"], [548, 553, "Method"], [557, 560, "Task"], [561, 562, "Task"], [575, 581, "Method"], [600, 602, "Method"], [619, 620, "Method"], [621, 622, "Method"], [629, 630, "Task"], [632, 633, "Task"], [680, 681, "Method"], [686, 689, "Task"], [694, 701, "Method"], [706, 712, "Method"], [726, 727, "Method"], [730, 731, "Task"], [741, 742, "Method"], [743, 744, "Method"], [759, 761, "Method"], [764, 765, "Method"], [769, 771, "Method"], [807, 809, "Method"], [822, 824, "Method"], [826, 830, "Method"], [835, 837, "Method"], [847, 849, "Method"], [858, 864, "Task"], [882, 884, "Method"], [892, 894, "Method"], [907, 909, "Material"], [912, 913, "Metric"], [916, 917, "Metric"], [920, 922, "Material"], [925, 926, "Metric"], [929, 930, "Metric"], [934, 936, "Method"], [938, 942, "Method"], [942, 943, "Method"], [947, 951, "Method"], [973, 974, "Method"], [1119, 1121, "Method"], [1124, 1128, "Method"], [1144, 1146, "Method"], [1171, 1173, "Method"], [1181, 1186, "Method"], [1187, 1188, "Method"], [1199, 1203, "Method"], [1271, 1272, "Method"], [1288, 1289, "Task"], [1293, 1295, "Method"], [1316, 1318, "Method"], [1329, 1330, "Method"], [1336, 1340, "Method"], [1343, 1347, "Method"], [1350, 1351, "Method"], [1363, 1365, "Method"], [1366, 1367, "Method"], [1377, 1378, "Method"], [1384, 1389, "Method"], [1412, 1421, "Method"], [1422, 1423, "Method"], [1449, 1450, "Method"], [1454, 1456, "Task"], [1457, 1458, "Method"], [1465, 1467, "Task"], [1483, 1484, "Task"], [1499, 1503, "Method"], [1505, 1506, "Method"], [1541, 1543, "Method"], [1563, 1565, "Method"], [1605, 1609, "Method"], [1649, 1650, "Method"], [1724, 1725, "Task"], [1782, 1786, "Method"], [1786, 1789, "Method"], [1790, 1791, "Method"], [1798, 1801, "Method"], [1817, 1820, "Task"], [1821, 1822, "Method"], [1826, 1829, "Task"], [1830, 1831, "Task"], [1832, 1835, "Task"], [1836, 1838, "Task"], [1840, 1847, "Method"], [1862, 1863, "Method"], [1869, 1870, "Method"], [1876, 1882, "Method"], [1883, 1889, "Task"], [1895, 1897, "Method"], [1899, 1900, "Method"], [1904, 1905, "Method"], [1913, 1915, "Method"], [1917, 1918, "Method"], [1973, 1975, "Method"], [1989, 1991, "Method"], [2010, 2012, "Method"], [2051, 2056, "Method"], [2057, 2058, "Method"], [2062, 2064, "Task"], [2142, 2143, "Method"], [2146, 2148, "Method"], [2159, 2160, "Method"], [2200, 2202, "Method"], [2210, 2212, "Method"], [2220, 2222, "Method"], [2222, 2223, "Method"], [2229, 2230, "Method"], [2242, 2243, "Method"], [2244, 2245, "Method"], [2250, 2251, "Method"], [2265, 2266, "Method"], [2267, 2268, "Method"], [2274, 2276, "Method"], [2277, 2280, "Method"], [2310, 2312, "Method"], [2336, 2338, "Method"], [2398, 2402, "Method"], [2407, 2408, "Method"], [2435, 2436, "Method"], [2457, 2458, "Method"], [2467, 2468, "Method"], [2469, 2470, "Method"], [2475, 2476, "Method"], [2494, 2495, "Method"], [2496, 2497, "Method"], [2525, 2526, "Method"], [2528, 2530, "Method"], [2541, 2543, "Method"], [2550, 2552, "Method"], [2557, 2559, "Method"], [2574, 2575, "Method"], [2580, 2581, "Method"], [2582, 2583, "Method"], [2594, 2595, "Method"], [2650, 2651, "Metric"], [2652, 2653, "Metric"], [2654, 2656, "Metric"], [2666, 2667, "Material"], [2673, 2674, "Method"], [2677, 2680, "Method"], [2681, 2682, "Method"], [2692, 2693, "Material"], [2707, 2709, "Method"], [2712, 2715, "Method"], [2719, 2720, "Method"], [2723, 2725, "Metric"], [2764, 2766, "Method"], [2787, 2789, "Material"], [2801, 2802, "Method"], [2805, 2808, "Method"], [2828, 2829, "Method"], [2830, 2831, "Method"], [2840, 2841, "Method"], [2842, 2843, "Method"], [2856, 2858, "Method"], [2861, 2862, "Method"], [2864, 2865, "Method"], [2866, 2867, "Method"], [2877, 2879, "Method"], [2885, 2887, "Method"], [2910, 2912, "Method"], [2914, 2915, "Method"], [2941, 2942, "Method"], [2958, 2960, "Method"], [2978, 2979, "Method"], [2994, 2998, "Method"], [3008, 3009, "Method"], [3013, 3014, "Method"], [3017, 3019, "Method"], [3051, 3052, "Method"], [3054, 3056, "Method"], [3057, 3058, "Method"], [3059, 3060, "Method"], [3063, 3064, "Method"], [3070, 3071, "Material"], [3072, 3073, "Material"], [3090, 3092, "Method"], [3149, 3153, "Method"], [3163, 3165, "Method"], [3182, 3184, "Method"], [3202, 3204, "Method"], [3227, 3229, "Method"], [3248, 3250, "Method"], [3338, 3340, "Method"], [3391, 3393, "Method"], [3412, 3414, "Method"], [3438, 3440, "Method"], [3464, 3466, "Method"], [3468, 3470, "Method"], [3518, 3520, "Task"], [3527, 3529, "Method"], [3556, 3558, "Method"], [3584, 3586, "Method"], [3636, 3638, "Method"], [3651, 3653, "Method"], [3684, 3685, "Method"], [3721, 3725, "Method"], [3752, 3754, "Method"], [3807, 3809, "Task"], [3860, 3861, "Metric"], [3891, 3892, "Method"], [3924, 3926, "Method"], [4033, 4035, "Method"], [4132, 4136, "Method"], [4170, 4171, "Material"], [4231, 4233, "Method"], [4235, 4237, "Method"], [4243, 4248, "Task"], [4328, 4332, "Task"], [4339, 4341, "Method"], [4354, 4356, "Method"], [4369, 4370, "Method"], [4386, 4387, "Method"], [4416, 4418, "Method"], [4430, 4431, "Method"], [4466, 4468, "Method"], [4485, 4487, "Method"], [4576, 4578, "Method"], [4582, 4583, "Method"], [4585, 4587, "Method"], [4613, 4617, "Method"], [4630, 4636, "Task"], [4682, 4684, "Method"], [4730, 4732, "Method"], [645, 646, "Method"], [747, 748, "Method"], [841, 842, "Method"], [1356, 1357, "Method"], [1410, 1411, "Method"], [1760, 1761, "Method"], [1997, 1998, "Method"], [2104, 2105, "Method"], [2123, 2124, "Method"], [2155, 2156, "Method"], [2194, 2195, "Method"], [2224, 2225, "Method"], [2225, 2226, "Method"], [2226, 2227, "Method"], [2227, 2228, "Method"], [2247, 2248, "Method"], [2287, 2288, "Method"], [2298, 2299, "Method"], [2328, 2329, "Method"], [2363, 2364, "Method"], [2460, 2461, "Method"], [2480, 2481, "Method"], [2482, 2483, "Method"], [2486, 2487, "Method"], [2565, 2566, "Method"], [2567, 2568, "Method"], [2664, 2665, "Material"], [2696, 2697, "Method"], [2790, 2791, "Method"], [2798, 2799, "Method"], [2819, 2820, "Method"], [2851, 2852, "Method"], [2869, 2870, "Method"], [2895, 2896, "Method"], [2899, 2900, "Method"], [2924, 2925, "Method"], [2950, 2951, "Method"], [2966, 2967, "Method"], [3000, 3001, "Method"], [3038, 3039, "Method"], [3040, 3041, "Method"], [3045, 3046, "Method"], [3130, 3131, "Metric"], [3159, 3160, "Method"], [3186, 3187, "Method"], [3232, 3233, "Method"], [3375, 3376, "Metric"], [3408, 3409, "Metric"], [3426, 3427, "Method"], [3617, 3618, "Method"], [3687, 3688, "Method"], [3702, 3703, "Method"], [3741, 3742, "Method"], [3760, 3761, "Method"], [3803, 3804, "Task"], [4212, 4213, "Method"], [4239, 4240, "Method"], [4592, 4593, "Method"], [4644, 4645, "Method"], [4689, 4690, "Method"], [4693, 4694, "Method"]], "sections": [[0, 217], [217, 932], [932, 936], [936, 1122], [1122, 1169], [1169, 1319], [1319, 1341], [1341, 1408], [1408, 1780], [1780, 2218], [2218, 2424], [2424, 2498], [2498, 2644], [2644, 3218], [3218, 3516], [3516, 3781], [3781, 4295], [4295, 4623], [4623, 4747], [4747, 4808], [4808, 4811]], "sentences": [[0, 12], [12, 45], [45, 65], [65, 93], [93, 123], [123, 160], [160, 183], [183, 217], [217, 220], [220, 230], [230, 232], [232, 243], [243, 253], [253, 286], [286, 322], [322, 334], [334, 342], [342, 345], [345, 369], [369, 379], [379, 408], [408, 416], [416, 437], [437, 477], [477, 502], [502, 530], [530, 548], [548, 571], [571, 600], [600, 616], [616, 634], [634, 670], [670, 717], [717, 732], [732, 772], [772, 810], [810, 865], [865, 885], [885, 932], [932, 936], [936, 942], [942, 969], [969, 1000], [1000, 1049], [1049, 1082], [1082, 1104], [1104, 1122], [1122, 1128], [1128, 1147], [1147, 1169], [1169, 1173], [1173, 1187], [1187, 1217], [1217, 1233], [1233, 1243], [1243, 1271], [1271, 1285], [1285, 1309], [1309, 1319], [1319, 1322], [1322, 1341], [1341, 1347], [1347, 1372], [1372, 1408], [1408, 1412], [1412, 1457], [1457, 1496], [1496, 1518], [1518, 1544], [1544, 1581], [1581, 1637], [1637, 1671], [1671, 1712], [1712, 1754], [1754, 1780], [1780, 1786], [1786, 1816], [1816, 1839], [1839, 1853], [1853, 1871], [1871, 1890], [1890, 1901], [1901, 1968], [1968, 1984], [1984, 2000], [2000, 2014], [2014, 2039], [2039, 2065], [2065, 2095], [2095, 2136], [2136, 2149], [2149, 2158], [2158, 2183], [2183, 2218], [2218, 2222], [2222, 2230], [2230, 2254], [2254, 2269], [2269, 2313], [2313, 2355], [2355, 2366], [2366, 2380], [2380, 2393], [2393, 2424], [2424, 2431], [2431, 2452], [2452, 2463], [2463, 2490], [2490, 2498], [2498, 2505], [2505, 2553], [2553, 2564], [2564, 2576], [2576, 2584], [2584, 2610], [2610, 2644], [2644, 2647], [2647, 2657], [2657, 2668], [2668, 2677], [2677, 2681], [2681, 2694], [2694, 2710], [2710, 2716], [2716, 2733], [2733, 2740], [2740, 2774], [2774, 2797], [2797, 2811], [2811, 2845], [2845, 2869], [2869, 2893], [2893, 2919], [2919, 2953], [2953, 2971], [2971, 2987], [2987, 3003], [3003, 3028], [3028, 3074], [3074, 3100], [3100, 3137], [3137, 3162], [3162, 3176], [3176, 3198], [3198, 3218], [3218, 3221], [3221, 3247], [3247, 3269], [3269, 3287], [3287, 3330], [3330, 3351], [3351, 3381], [3381, 3407], [3407, 3455], [3455, 3485], [3485, 3499], [3499, 3516], [3516, 3520], [3520, 3548], [3548, 3565], [3565, 3574], [3574, 3599], [3599, 3615], [3615, 3643], [3643, 3676], [3676, 3701], [3701, 3713], [3713, 3746], [3746, 3781], [3781, 3785], [3785, 3814], [3814, 3839], [3839, 3859], [3859, 3885], [3885, 3911], [3911, 3927], [3927, 3955], [3955, 3977], [3977, 4019], [4019, 4025], [4025, 4048], [4048, 4102], [4102, 4124], [4124, 4165], [4165, 4201], [4201, 4211], [4211, 4234], [4234, 4249], [4249, 4270], [4270, 4295], [4295, 4301], [4301, 4325], [4325, 4342], [4342, 4371], [4371, 4401], [4401, 4425], [4425, 4457], [4457, 4469], [4469, 4504], [4504, 4529], [4529, 4555], [4555, 4566], [4566, 4575], [4575, 4588], [4588, 4599], [4599, 4623], [4623, 4626], [4626, 4651], [4651, 4660], [4660, 4680], [4680, 4708], [4708, 4727], [4727, 4747], [4747, 4750], [4750, 4787], [4787, 4808], [4808, 4811]], "words": ["document", ":", "Structural", "Neural", "Encoders", "for", "AMR", "-", "to", "-", "text", "Generation", "AMR", "-", "to", "-", "text", "generation", "is", "a", "problem", "recently", "introduced", "to", "the", "NLP", "community", ",", "in", "which", "the", "goal", "is", "to", "generate", "sentences", "from", "Abstract", "Meaning", "Representation", "(", "AMR", ")", "graphs", ".", "Sequence", "-", "to", "-", "sequence", "models", "can", "be", "used", "to", "this", "end", "by", "converting", "the", "AMR", "graphs", "to", "strings", ".", "Approaching", "the", "problem", "while", "working", "directly", "with", "graphs", "requires", "the", "use", "of", "graph", "-", "to", "-", "sequence", "models", "that", "encode", "the", "AMR", "graph", "into", "a", "vector", "representation", ".", "Such", "encoding", "has", "been", "shown", "to", "be", "beneficial", "in", "the", "past", ",", "and", "unlike", "sequential", "encoding", ",", "it", "allows", "us", "to", "explicitly", "capture", "reentrant", "structures", "in", "the", "AMR", "graphs", ".", "We", "investigate", "the", "extent", "to", "which", "reentrancies", "(", "nodes", "with", "multiple", "parents", ")", "have", "an", "impact", "on", "AMR", "-", "to", "-", "text", "generation", "by", "comparing", "graph", "encoders", "to", "tree", "encoders", ",", "where", "reentrancies", "are", "not", "preserved", ".", "We", "show", "that", "improvements", "in", "the", "treatment", "of", "reentrancies", "and", "long", "-", "range", "dependencies", "contribute", "to", "higher", "overall", "scores", "for", "graph", "encoders", ".", "Our", "best", "model", "achieves", "24.40", "BLEU", "on", "LDC2015E86", ",", "outperforming", "the", "state", "of", "the", "art", "by", "1.1", "points", "and", "24.54", "BLEU", "on", "LDC2017T10", ",", "outperforming", "the", "state", "of", "the", "art", "by", "1.24", "points", ".", "section", ":", "Introduction", "(", "a", ")", "eat", "-", "01", "he", "pizza", "finger", ":", "arg0", ":", "arg1", ":", "instrument", "part", "-", "of", "[", "theme", "=", "simple", "]", "eat", "-", "01", "&", ":", "arg0", "&", "he", "&", ":", "arg1", "&", "pizza", "&", ":", "instrument", "&", "finger", "&", ":", "part", "-", "of", "&", "he", "(", "tmp", ")", "[", "below", "left", "of", "=", "11", ",", "xshift", "=", "0.5", "cm", ",", "yshift=1.2", "cm", "]", "(", "b", ")", ";", "[", "theme", "=", "simple", "]", "eat", "-", "01", "&", ":", "arg0", "&", "he", "&", ":", "arg1", "&", "pizza", "&", ":", "instrument", "&", "finger", "&", ":", "part", "-", "of", "&", "he", "12", "23", "14", "45", "16", "67", "[", "edge", "style", "=", "very", "thick", "]", "78", "[", "edge", "style", "=", "very", "thick", "]", "89", "(", "tmp", ")", "[", "below", "left", "of", "=", "11", ",", "xshift", "=", "0.5", "cm", ",", "yshift=2", "cm", "]", "(", "c", ")", ";", "[", "theme", "=", "simple", "]", "eat", "-", "01", "&", ":", "arg0", "&", "he", "&", ":", "arg1", "&", "pizza", "&", ":", "instrument", "&", "finger", "&", ":", "part", "-", "of", "&", "he", "12", "23", "14", "45", "16", "67", "[", "edge", "style", "=", "very", "thick", "]", "78", "[", "edge", "style", "=", "very", "thick", "]", "83", "(", "tmp", ")", "[", "below", "left", "of", "=", "11", ",", "xshift", "=", "0.5", "cm", ",", "yshift=2", "cm", "]", "(", "d", ")", ";", "Abstract", "Meaning", "Representation", "(", "AMR", ";", "Banarescu13abstractmeaning", ")", "is", "a", "semantic", "graph", "representation", "that", "abstracts", "away", "from", "the", "syntactic", "realization", "of", "a", "sentence", ",", "where", "nodes", "in", "the", "graph", "represent", "concepts", "and", "edges", "represent", "semantic", "relations", "between", "them", ".", "AMRs", "are", "graphs", ",", "rather", "than", "trees", ",", "because", "co", "-", "references", "and", "control", "structures", "result", "in", "nodes", "with", "multiple", "parents", ",", "called", "reentrancies", ".", "For", "instance", ",", "the", "AMR", "of", "Figure", "[", "reference", "]", "(", "a", ")", "contains", "a", "reentrancy", "between", "finger", "and", "he", ",", "caused", "by", "the", "possessive", "pronoun", "his", ".", "AMR", "-", "to", "-", "text", "generation", "is", "the", "task", "of", "automatically", "generating", "natural", "language", "from", "AMR", "graphs", ".", "Attentive", "encoder", "/", "decoder", "architectures", ",", "commonly", "used", "for", "Neural", "Machine", "Translation", "(", "NMT", ")", ",", "have", "been", "explored", "for", "this", "task", ".", "In", "order", "to", "use", "sequence", "-", "to", "-", "sequence", "models", ",", "konstas2017neural", "reduce", "the", "AMR", "graphs", "to", "sequences", ",", "while", "song", "and", "beck", "directly", "encode", "them", "as", "graphs", ".", "Graph", "encoding", "allows", "the", "model", "to", "explicitly", "encode", "reentrant", "structures", "present", "in", "the", "AMR", "graphs", ".", "While", "central", "to", "AMR", ",", "reentrancies", "are", "often", "hard", "to", "treat", "both", "in", "parsing", "and", "in", "generation", ".", "Previous", "work", "either", "removed", "them", "from", "the", "graphs", ",", "hence", "obtaining", "sequential", "or", "tree", "-", "structured", "data", ",", "while", "other", "work", "maintained", "them", "but", "did", "not", "analyze", "their", "impact", "on", "performance", "]", "song", ",", "beck", ".", "damonte2016incremental", "showed", "that", "state", "-", "of", "-", "the", "-", "art", "parsers", "do", "not", "perform", "well", "in", "predicting", "reentrant", "structures", ",", "while", "van2017dealing", "compared", "different", "pre", "-", "and", "post", "-", "processing", "techniques", "to", "improve", "the", "performance", "of", "sequence", "-", "to", "-", "sequence", "parsers", "with", "respect", "to", "reentrancies", ".", "It", "is", "not", "yet", "clear", "whether", "explicit", "encoding", "of", "reentrancies", "is", "beneficial", "for", "generation", ".", "In", "this", "paper", ",", "we", "compare", "three", "types", "of", "encoders", "for", "AMR", ":", "1", ")", "sequential", "encoders", ",", "which", "reduce", "AMR", "graphs", "to", "sequences", ";", "2", ")", "tree", "encoders", ",", "which", "ignore", "reentrancies", ";", "and", "3", ")", "graph", "encoders", ".", "We", "pay", "particular", "attention", "to", "two", "phenomena", ":", "reentrancies", ",", "which", "mark", "co", "-", "reference", "and", "control", "structures", ",", "and", "long", "-", "range", "dependencies", "in", "the", "AMR", "graphs", ",", "which", "are", "expected", "to", "benefit", "from", "structural", "encoding", ".", "The", "contributions", "of", "the", "paper", "are", "two", "-", "fold", ":", "We", "present", "structural", "encoders", "for", "the", "encoder", "/", "decoder", "framework", "and", "show", "the", "benefits", "of", "graph", "encoders", "not", "only", "compared", "to", "sequential", "encoders", "but", "also", "compared", "to", "tree", "encoders", ",", "which", "have", "not", "been", "studied", "so", "far", "for", "AMR", "-", "to", "-", "text", "generation", ".", "We", "show", "that", "better", "treatment", "of", "reentrancies", "and", "long", "-", "range", "dependencies", "contributes", "to", "improvements", "in", "the", "graph", "encoders", ".", "Our", "best", "model", ",", "based", "on", "a", "graph", "encoder", ",", "achieves", "state", "-", "of", "-", "the", "-", "art", "results", "for", "both", "the", "LDC2015E86", "dataset", "(", "24.40", "on", "BLEU", "and", "23.79", "on", "Meteor", ")", "and", "the", "LDC2017T10", "dataset", "(", "24.54", "on", "BLEU", "and", "24.07", "on", "Meteor", ")", ".", "section", ":", "Input", "Representations", "paragraph", ":", "Graph", "-", "structured", "AMRs", "AMRs", "are", "normally", "represented", "as", "rooted", "and", "directed", "graphs", ":", "where", "are", "the", "graph", "vertices", "(", "or", "nodes", ")", "and", "is", "a", "designated", "root", "node", "in", ".", "The", "edges", "in", "the", "AMR", "are", "labeled", ":", "Each", "edge", "is", "a", "triple", ":", ",", "where", "is", "the", "parent", "node", ",", "is", "the", "edge", "label", "and", "is", "the", "child", "node", ".", "In", "order", "to", "obtain", "unlabeled", "edges", ",", "thus", "decreasing", "the", "total", "number", "of", "parameters", "required", "by", "the", "models", ",", "we", "replace", "each", "labeled", "edge", "with", "two", "unlabeled", "edges", ":", ":", "Each", "unlabeled", "edge", "is", "a", "pair", ":", ",", "where", "one", "of", "the", "following", "holds", ":", "and", ";", "and", ".", "For", "instance", ",", "the", "edge", "between", "eat", "-", "01", "and", "he", "with", "label", ":", "arg0", "of", "Figure", "[", "reference", "]", "(", "a", ")", "is", "replaced", "by", "two", "edges", "in", "Figure", "[", "reference", "]", "(", "d", ")", ":", "an", "edge", "between", "eat", "-", "01", "and", ":", "arg0", "and", "another", "one", "between", ":", "arg0", "and", "he", ".", "The", "process", ",", "also", "used", "in", "beck", ",", "tranforms", "the", "input", "graph", "into", "its", "equivalent", "Levi", "graph", ".", "paragraph", ":", "Tree", "-", "structured", "AMRs", "In", "order", "to", "obtain", "tree", "structures", ",", "it", "is", "necessary", "to", "discard", "the", "reentrancies", "from", "the", "AMR", "graphs", ".", "Similarly", "to", "takase2016neural", ",", "we", "replace", "nodes", "with", "incoming", "edges", "with", "identically", "labeled", "nodes", ",", "each", "with", "a", "single", "incoming", "edge", ".", "paragraph", ":", "Sequential", "AMRs", "Following", "konstas2017neural", ",", "the", "input", "sequence", "is", "a", "linearized", "and", "anonymized", "AMR", "graph", ".", "Linearization", "is", "used", "to", "convert", "the", "graph", "into", "a", "sequence", ":", "The", "depth", "-", "first", "traversal", "of", "the", "graph", "defines", "the", "indexing", "between", "nodes", "and", "tokens", "in", "the", "sequence", ".", "For", "instance", ",", "the", "root", "node", "is", ",", "its", "leftmost", "child", "is", "and", "so", "on", ".", "Nodes", "with", "multiple", "parents", "are", "visited", "more", "than", "once", ".", "At", "each", "visit", ",", "their", "labels", "are", "repeated", "in", "the", "sequence", ",", "effectively", "losing", "reentrancy", "information", ",", "as", "shown", "in", "Figure", "[", "reference", "]", "(", "b", ")", ".", "Anonymization", "removes", "names", "and", "rare", "words", "with", "coarse", "categories", "to", "reduce", "data", "sparsity", ".", "An", "alternative", "to", "anonymization", "is", "to", "employ", "a", "copy", "mechanism", ",", "where", "the", "models", "learn", "to", "copy", "rare", "words", "from", "the", "input", "itself", ".", "In", "this", "paper", ",", "we", "follow", "the", "anonymization", "approach", ".", "section", ":", "Encoders", "In", "this", "section", ",", "we", "review", "the", "encoders", "adopted", "as", "building", "blocks", "for", "our", "tree", "and", "graph", "encoders", ".", "subsection", ":", "Recurrent", "Neural", "Network", "Encoders", "We", "reimplement", "the", "encoder", "of", "konstas2017neural", ",", "where", "the", "sequential", "linearization", "is", "the", "input", "to", "a", "bidirectional", "LSTM", "(", "BiLSTM", ";", "graves2013speech", ")", "network", ".", "The", "hidden", "state", "of", "the", "BiLSTM", "at", "step", "is", "used", "as", "a", "context", "-", "aware", "word", "representation", "of", "the", "-", "th", "token", "in", "the", "sequence", ":", "where", ",", "is", "the", "size", "of", "the", "output", "embeddings", ".", "subsection", ":", "TreeLSTM", "Encoders", "Tree", "-", "Structured", "Long", "Short", "-", "Term", "Memory", "Networks", "(", "TreeLSTM", ";", "tai2015improved", ")", "have", "been", "introduced", "primarily", "as", "a", "way", "to", "encode", "the", "hierarchical", "structure", "of", "syntactic", "trees", ",", "but", "they", "have", "also", "been", "applied", "to", "AMR", "for", "the", "task", "of", "headline", "generation", ".", "TreeLSTMs", "assume", "tree", "-", "structured", "input", ",", "so", "AMR", "graphs", "must", "be", "preprocessed", "to", "respect", "this", "constraint", ":", "reentrancies", ",", "which", "play", "an", "essential", "role", "in", "AMR", ",", "must", "be", "removed", ",", "thereby", "transforming", "the", "graphs", "into", "trees", ".", "We", "use", "the", "Child", "-", "Sum", "variant", "introduced", "by", "tai2015improved", ",", "which", "processes", "the", "tree", "in", "a", "bottom", "-", "up", "pass", ".", "When", "visiting", "a", "node", ",", "the", "hidden", "states", "of", "its", "children", "are", "summed", "up", "in", "a", "single", "vector", "which", "is", "then", "passed", "into", "recurrent", "gates", ".", "In", "order", "to", "use", "information", "from", "both", "incoming", "and", "outgoing", "edges", "(", "parents", "and", "children", ")", ",", "we", "employ", "bidirectional", "TreeLSTMs", ",", "where", "the", "bottom", "-", "up", "pass", "is", "followed", "by", "a", "top", "-", "down", "pass", ".", "The", "top", "-", "down", "state", "of", "the", "root", "node", "is", "obtained", "by", "feeding", "the", "bottom", "-", "up", "state", "of", "the", "root", "node", "through", "a", "feed", "-", "forward", "layer", ":", "where", "is", "the", "hidden", "state", "of", "node", "for", "the", "bottom", "-", "up", "pass", "and", "is", "the", "hidden", "state", "of", "node", "for", "the", "top", "-", "down", "pass", ".", "The", "bottom", "up", "states", "for", "all", "other", "nodes", "are", "computed", "with", "an", "LSTM", ",", "with", "the", "cell", "state", "given", "by", "their", "parent", "nodes", ":", "where", "is", "the", "parent", "of", "node", "in", "the", "tree", ".", "The", "final", "hidden", "states", "are", "obtained", "by", "concatenating", "the", "states", "from", "the", "bottom", "-", "up", "pass", "and", "the", "top", "-", "down", "pass", ":", "The", "hidden", "state", "of", "the", "root", "node", "is", "usually", "used", "as", "a", "representation", "for", "the", "entire", "tree", ".", "In", "order", "to", "use", "attention", "over", "all", "nodes", ",", "as", "in", "traditional", "NMT", ",", "we", "can", "however", "build", "node", "embeddings", "by", "extracting", "the", "hidden", "states", "of", "each", "node", "in", "the", "tree", ":", "where", ",", "is", "the", "size", "of", "the", "output", "embeddings", ".", "The", "encoder", "is", "related", "to", "the", "TreeLSTM", "encoder", "of", "takase2016neural", ",", "which", "however", "encodes", "labeled", "trees", "and", "does", "not", "use", "a", "top", "-", "down", "pass", ".", "subsection", ":", "Graph", "Convolutional", "Network", "Encoders", "Graph", "Convolutional", "Network", "(", "GCN", ";", "duvenaud2015convolutional", ",", "kipf2016semi", ")", "is", "a", "neural", "network", "architecture", "that", "learns", "embeddings", "of", "nodes", "in", "a", "graph", "by", "looking", "at", "its", "nearby", "nodes", ".", "In", "Natural", "Language", "Processing", ",", "GCNs", "have", "been", "used", "for", "Semantic", "Role", "Labeling", ",", "NMT", ",", "Named", "Entity", "Recognition", "and", "text", "generation", ".", "A", "graph", "-", "to", "-", "sequence", "neural", "network", "was", "first", "introduced", "by", "xu2018graph2seq", ".", "The", "authors", "review", "the", "similarities", "between", "their", "approach", ",", "GCN", "and", "another", "approach", ",", "based", "on", "GRUs", ".", "The", "latter", "recently", "inspired", "a", "graph", "-", "to", "-", "sequence", "architecture", "for", "AMR", "-", "to", "-", "text", "generation", ".", "Simultaneously", ",", "song", "proposed", "a", "graph", "encoder", "based", "on", "LSTMs", ".", "The", "architectures", "of", "song", "and", "beck", "are", "both", "based", "on", "the", "same", "core", "computation", "of", "a", "GCN", ",", "which", "sums", "over", "the", "embeddings", "of", "the", "immediate", "neighborhood", "of", "each", "node", ":", "where", "is", "the", "embeddings", "of", "node", "at", "layer", ",", "is", "a", "non", "-", "linear", "activation", "function", ",", "is", "the", "set", "of", "the", "immediate", "neighbors", "of", ",", "and", ",", "with", "being", "the", "size", "of", "the", "embeddings", ".", "It", "is", "possible", "to", "use", "recurrent", "networks", "to", "model", "the", "update", "of", "the", "node", "embeddings", ".", "Specifically", ",", "beck", "uses", "a", "GRU", "layer", "where", "the", "gates", "are", "modeled", "as", "GCN", "layers", ".", "song", "did", "not", "use", "the", "activation", "function", "and", "perform", "an", "LSTM", "update", "instead", ".", "The", "systems", "of", "song", "and", "beck", "further", "differ", "in", "design", "and", "implementation", "decisions", "such", "as", "in", "the", "use", "of", "edge", "label", "and", "edge", "directionality", ".", "Throughout", "the", "rest", "of", "the", "paper", ",", "we", "follow", "the", "traditional", ",", "non", "-", "recurrent", ",", "implementation", "of", "GCN", "also", "adopted", "in", "other", "NLP", "tasks", ".", "In", "our", "experiments", ",", "the", "node", "embeddings", "are", "computed", "as", "follows", ":", "where", "indicates", "the", "direction", "of", "the", "edge", "between", "and", "(", "i.e.", ",", "outgoing", "or", "incoming", "edge", ")", ".", "The", "hidden", "vectors", "from", "the", "last", "layer", "of", "the", "GCN", "network", "are", "finally", "used", "to", "represent", "each", "node", "in", "the", "graph", ":", "where", "K", "is", "the", "number", "of", "GCN", "layers", "used", ",", ",", "is", "the", "size", "of", "the", "output", "embeddings", ".", "To", "regularize", "the", "models", "we", "apply", "dropout", "as", "well", "as", "edge", "dropout", ".", "We", "also", "include", "highway", "connections", "between", "GCN", "layers", ".", "While", "GCN", "can", "naturally", "be", "used", "to", "encode", "graphs", ",", "they", "can", "also", "be", "applied", "to", "trees", "by", "removing", "reentrancies", "from", "the", "input", "graphs", ".", "In", "the", "experiments", "of", "Section", "[", "reference", "]", ",", "we", "explore", "GCN", "-", "based", "models", "both", "as", "graph", "encoders", "(", "reentrancies", "are", "maintained", ")", "as", "well", "as", "tree", "encoders", "(", "reentrancies", "are", "ignored", ")", ".", "section", ":", "Stacking", "Encoders", "GCN", "/", "TreeLSTM", "BiLSTM", "BiLSTM", "GCN", "/", "TreeLSTM", "We", "aimed", "at", "stacking", "the", "explicit", "source", "of", "structural", "information", "provided", "by", "TreeLSTMs", "and", "GCNs", "with", "the", "sequential", "information", "which", "BiLSTMs", "extract", "well", ".", "This", "was", "shown", "to", "be", "effective", "for", "other", "tasks", "with", "both", "TreeLSTMs", "and", "GCNs", ".", "In", "previous", "work", ",", "the", "structural", "encoders", "(", "tree", "or", "graph", ")", "were", "used", "on", "top", "of", "the", "BiLSTM", "network", ":", "first", ",", "the", "input", "is", "passed", "through", "the", "sequential", "encoder", ",", "the", "output", "of", "which", "is", "then", "fed", "into", "the", "structural", "encoder", ".", "While", "we", "experiment", "with", "this", "approach", ",", "we", "also", "propose", "an", "alternative", "solution", "where", "the", "BiLSTM", "network", "is", "used", "on", "top", "of", "the", "structural", "encoder", ":", "the", "input", "embeddings", "are", "refined", "by", "exploiting", "the", "explicit", "structural", "information", "given", "by", "the", "graph", ".", "The", "refined", "embeddings", "are", "then", "fed", "into", "the", "BiLSTM", "networks", ".", "See", "Figure", "[", "reference", "]", "for", "a", "graphical", "representation", "of", "the", "two", "approaches", ".", "In", "our", "experiments", ",", "we", "found", "this", "approach", "to", "be", "more", "effective", ".", "Compared", "to", "models", "that", "interleave", "structural", "and", "recurrent", "components", "such", "as", "the", "systems", "of", "song", "and", "beck", ",", "stacking", "the", "components", "allows", "us", "to", "test", "for", "their", "contributions", "more", "easily", ".", "subsection", ":", "Structure", "on", "Top", "of", "Sequence", "In", "this", "setup", ",", "BiLSTMs", "are", "used", "as", "in", "Section", "[", "reference", "]", "to", "encode", "the", "linearized", "and", "anonymized", "AMR", ".", "The", "context", "provided", "by", "the", "BiLSTM", "is", "a", "sequential", "one", ".", "We", "then", "apply", "either", "GCN", "or", "TreeLSTM", "on", "the", "output", "of", "the", "BiLSTM", ",", "by", "initializing", "the", "GCN", "or", "TreeLSTM", "embeddings", "with", "the", "BiLSTM", "hidden", "states", ".", "We", "call", "these", "models", "SeqGCN", "and", "SeqTreeLSTM", ".", "subsection", ":", "Sequence", "on", "Top", "of", "Structure", "We", "also", "propose", "a", "different", "approach", "for", "integrating", "graph", "information", "into", "the", "encoder", ",", "by", "swapping", "the", "order", "of", "the", "BiLSTM", "and", "the", "structural", "encoder", ":", "we", "aim", "at", "using", "the", "structured", "information", "provided", "by", "the", "AMR", "graph", "as", "a", "way", "to", "refine", "the", "original", "word", "representations", ".", "We", "first", "apply", "the", "structural", "encoder", "to", "the", "input", "graphs", ".", "The", "GCN", "or", "TreeLSTM", "representations", "are", "then", "fed", "into", "the", "BiLSTM", ".", "We", "call", "these", "models", "GCNSeq", "and", "TreeLSTMSeq", ".", "The", "motivation", "behind", "this", "approach", "is", "that", "we", "know", "that", "BiLSTMs", ",", "given", "appropriate", "input", "embeddings", ",", "are", "very", "effective", "at", "encoding", "the", "input", "sequences", ".", "In", "order", "to", "exploit", "their", "strength", ",", "we", "do", "not", "amend", "their", "output", "but", "rather", "provide", "them", "with", "better", "input", "embeddings", "to", "start", "with", ",", "by", "explicitly", "taking", "the", "graph", "relations", "into", "account", ".", "section", ":", "Experiments", "We", "use", "both", "BLEU", "and", "Meteor", "as", "evaluation", "metrics", ".", "We", "report", "results", "on", "the", "AMR", "dataset", "LDC2015E86", "and", "LDC2017T10", ".", "All", "systems", "are", "implemented", "in", "PyTorch", "using", "the", "framework", "OpenNMT", "-", "py", ".", "Hyperparameters", "of", "each", "model", "were", "tuned", "on", "the", "development", "set", "of", "LDC2015E86", ".", "For", "the", "GCN", "components", ",", "we", "use", "two", "layers", ",", "activations", ",", "and", "highway", "layers", ".", "We", "use", "single", "layer", "LSTMs", ".", "We", "train", "with", "SGD", "with", "the", "initial", "learning", "rate", "set", "to", "1", "and", "decay", "to", "0.8", ".", "Batch", "size", "is", "set", "to", "100", ".", "We", "first", "evaluate", "the", "overall", "performance", "of", "the", "models", ",", "after", "which", "we", "focus", "on", "two", "phenomena", "that", "we", "expect", "to", "benefit", "most", "from", "structural", "encoders", ":", "reentrancies", "and", "long", "-", "range", "dependencies", ".", "Table", "[", "reference", "]", "shows", "the", "comparison", "on", "the", "development", "split", "of", "the", "LDC2015E86", "dataset", "between", "sequential", ",", "tree", "and", "graph", "encoders", ".", "The", "sequential", "encoder", "(", "Seq", ")", "is", "a", "re", "-", "implementation", "of", "konstas2017neural", ".", "We", "test", "both", "approaches", "of", "stacking", "structural", "and", "sequential", "components", ":", "structure", "on", "top", "of", "sequence", "(", "SeqTreeLSTM", "and", "SeqGCN", ")", ",", "and", "sequence", "on", "top", "of", "structure", "(", "TreeLSTMSeq", "and", "GCNSeq", ")", ".", "To", "inspect", "the", "effect", "of", "the", "sequential", "component", ",", "we", "run", "ablation", "tests", "by", "removing", "the", "RNNs", "altogether", "(", "TreeLSTM", "and", "GCN", ")", ".", "GCN", "-", "based", "models", "are", "used", "both", "as", "tree", "encoders", "(", "reentrancies", "are", "removed", ")", "and", "graph", "encoders", "(", "reentrancies", "are", "maintained", ")", ".", "For", "both", "TreeLSTM", "-", "based", "and", "GCN", "-", "based", "models", ",", "our", "proposed", "approach", "of", "applying", "the", "structural", "encoder", "before", "the", "RNN", "achieves", "better", "scores", ".", "This", "is", "especially", "true", "for", "GCN", "-", "based", "models", ",", "for", "which", "we", "also", "note", "a", "drastic", "drop", "in", "performance", "when", "the", "RNN", "is", "removed", ",", "highlighting", "the", "importance", "of", "a", "sequential", "component", ".", "On", "the", "other", "hand", ",", "RNN", "layers", "seem", "to", "have", "less", "impact", "on", "TreeLSTM", "-", "based", "models", ".", "This", "outcome", "is", "not", "unexpected", ",", "as", "TreeLSTMs", "already", "use", "LSTM", "gates", "in", "their", "computation", ".", "The", "results", "show", "a", "clear", "advantage", "of", "tree", "and", "graph", "encoders", "over", "the", "sequential", "encoder", ".", "The", "best", "performing", "model", "is", "GCNSeq", ",", "both", "as", "a", "tree", "and", "as", "a", "graph", "encoder", ",", "with", "the", "latter", "obtaining", "the", "highest", "results", ".", "Table", "[", "reference", "]", "shows", "the", "comparison", "between", "our", "best", "sequential", "(", "Seq", ")", ",", "tree", "(", "GCNSeq", "without", "reentrancies", ",", "henceforth", "called", "Tree", ")", "and", "graph", "encoders", "(", "GCNSeq", "with", "reentrancies", ",", "henceforth", "called", "Graph", ")", "on", "the", "test", "set", "of", "LDC2015E86", "and", "LDC2017T10", ".", "We", "also", "include", "state", "-", "of", "-", "the", "-", "art", "results", "reported", "on", "these", "datasets", "for", "sequential", "encoding", "konstas2017neural", "and", "graph", "encoding", "song", ",", "beck", ".", "In", "order", "to", "mitigate", "the", "effects", "of", "random", "seeds", ",", "we", "train", "five", "models", "with", "different", "random", "seeds", "and", "report", "the", "results", "of", "the", "median", "model", ",", "according", "to", "their", "BLEU", "score", "on", "the", "development", "set", ".", "We", "achieve", "state", "-", "of", "-", "the", "-", "art", "results", "with", "both", "tree", "and", "graph", "encoders", ",", "demonstrating", "the", "efficacy", "of", "our", "GCNSeq", "approach", ".", "The", "graph", "encoder", "outperforms", "the", "other", "systems", "and", "previous", "work", "on", "both", "datasets", ".", "These", "results", "demonstrate", "the", "benefit", "of", "structural", "encoders", "over", "purely", "sequential", "ones", "as", "well", "as", "the", "advantage", "of", "explicitly", "including", "reentrancies", ".", "The", "differences", "between", "our", "graph", "encoder", "and", "that", "of", "song", "and", "beck", "were", "discussed", "in", "Section", "[", "reference", "]", ".", "subsection", ":", "Reentrancies", "Overall", "scores", "show", "an", "advantage", "of", "graph", "encoder", "over", "tree", "and", "sequential", "encoders", ",", "but", "they", "do", "not", "shed", "light", "into", "how", "this", "is", "achieved", ".", "Because", "graph", "encoders", "are", "the", "only", "ones", "to", "model", "reentrancies", "explicitly", ",", "we", "expect", "them", "to", "deal", "better", "with", "these", "structures", ".", "It", "is", ",", "however", ",", "possible", "that", "the", "other", "models", "are", "capable", "of", "handling", "these", "structures", "implicitly", ".", "Moreover", ",", "the", "dataset", "contains", "a", "large", "number", "of", "examples", "that", "do", "not", "involve", "any", "reentrancies", ",", "as", "shown", "in", "Table", "[", "reference", "]", ",", "so", "that", "the", "overall", "scores", "may", "not", "be", "representative", "of", "the", "ability", "of", "models", "to", "capture", "reentrancies", ".", "It", "is", "expected", "that", "the", "benefit", "of", "the", "graph", "models", "will", "be", "more", "evident", "for", "those", "examples", "containing", "more", "reentrancies", ".", "To", "test", "this", "hypothesis", ",", "we", "evaluate", "the", "various", "scenarios", "as", "a", "function", "of", "the", "number", "of", "reentrancies", "in", "each", "example", ",", "using", "the", "Meteor", "score", "as", "a", "metric", ".", "Table", "[", "reference", "]", "shows", "that", "the", "gap", "between", "the", "graph", "encoder", "and", "the", "other", "encoders", "is", "widest", "for", "examples", "with", "more", "than", "six", "reentrancies", ".", "The", "Meteor", "score", "of", "the", "graph", "encoder", "for", "these", "cases", "is", "3.1", "%", "higher", "than", "the", "one", "for", "the", "sequential", "encoder", "and", "2.3", "%", "higher", "than", "the", "score", "achieved", "by", "the", "tree", "encoder", ",", "demonstrating", "that", "explicitly", "encoding", "reentrancies", "is", "more", "beneficial", "than", "the", "overall", "scores", "suggest", ".", "Interestingly", ",", "it", "can", "also", "be", "observed", "that", "the", "graph", "model", "outperforms", "the", "tree", "model", "also", "for", "examples", "with", "no", "reentrancies", ",", "where", "tree", "and", "graph", "structures", "are", "identical", ".", "This", "suggests", "that", "preserving", "reentrancies", "in", "the", "training", "data", "has", "other", "beneficial", "effects", ".", "In", "Section", "[", "reference", "]", "we", "explore", "one", ":", "better", "handling", "of", "long", "-", "range", "dependencies", ".", "subsubsection", ":", "Manual", "Inspection", "In", "order", "to", "further", "explore", "how", "the", "graph", "model", "handles", "reentrancies", "differently", "from", "the", "other", "models", ",", "we", "performed", "a", "manual", "inspection", "of", "the", "models", "\u2019", "output", ".", "We", "selected", "examples", "containing", "reentrancies", ",", "where", "the", "graph", "model", "performs", "better", "than", "the", "other", "models", ".", "These", "are", "shown", "in", "Table", "[", "reference", "]", ".", "In", "Example", "(", "1", ")", ",", "we", "note", "that", "the", "graph", "model", "is", "the", "only", "one", "that", "correctly", "predicts", "the", "phrase", "he", "finds", "out", ".", "The", "wrong", "verb", "tense", "is", "due", "to", "the", "lack", "of", "tense", "information", "in", "AMR", "graphs", ".", "In", "the", "sequential", "model", ",", "the", "pronoun", "is", "chosen", "correctly", ",", "but", "the", "wrong", "verb", "is", "predicted", ",", "while", "in", "the", "tree", "model", "the", "pronoun", "is", "missing", ".", "In", "Example", "(", "2", ")", ",", "only", "the", "graph", "model", "correctly", "generates", "the", "phrase", "you", "tell", "them", ",", "while", "none", "of", "the", "models", "use", "people", "as", "the", "subject", "of", "the", "predicate", "can", ".", "In", "Example", "(", "3", ")", ",", "both", "the", "graph", "and", "the", "sequential", "models", "deal", "well", "with", "the", "control", "structure", "caused", "by", "the", "recommend", "predicate", ".", "The", "sequential", "model", ",", "however", ",", "overgenerates", "a", "wh", "-", "clause", ".", "Finally", ",", "in", "Example", "(", "4", ")", "the", "tree", "and", "graph", "models", "deal", "correctly", "with", "the", "possessive", "pronoun", "to", "generate", "the", "phrase", "tell", "your", "ex", ",", "while", "the", "sequential", "model", "does", "not", ".", "Overall", ",", "we", "note", "that", "the", "graph", "model", "produces", "a", "more", "accurate", "output", "than", "sequential", "and", "tree", "models", "by", "generating", "the", "correct", "pronouns", "and", "mentions", "when", "control", "verbs", "and", "co", "-", "references", "are", "involved", ".", "subsubsection", ":", "Contrastive", "Pairs", "For", "a", "quantitative", "analysis", "of", "how", "the", "different", "models", "handle", "pronouns", ",", "we", "use", "a", "method", "to", "inspect", "NMT", "output", "for", "specific", "linguistic", "analysis", "based", "on", "contrastive", "pairs", ".", "Given", "a", "reference", "output", "sentence", ",", "a", "contrastive", "sentence", "is", "generated", "by", "introducing", "a", "mistake", "related", "to", "the", "phenomenon", "we", "are", "interested", "in", "evaluating", ".", "The", "probability", "that", "the", "model", "assigns", "to", "the", "reference", "sentence", "is", "then", "compared", "to", "that", "of", "the", "contrastive", "sentence", ".", "The", "accuracy", "of", "a", "model", "is", "determined", "by", "the", "percentage", "of", "examples", "in", "which", "the", "reference", "sentence", "has", "a", "higher", "probability", "than", "the", "contrastive", "sentence", ".", "We", "produce", "contrastive", "examples", "by", "running", "CoreNLP", "to", "identify", "co", "-", "references", ",", "which", "are", "the", "primary", "cause", "of", "reentrancies", ",", "and", "introducing", "a", "mistake", ".", "When", "an", "expression", "has", "multiple", "mentions", ",", "the", "antecedent", "is", "repeated", "in", "the", "linearized", "AMR", ".", "For", "instance", ",", "the", "linearization", "of", "Figure", "[", "reference", "]", "(", "b", ")", "contains", "the", "token", "he", "twice", ",", "which", "instead", "appears", "only", "once", "in", "the", "sentence", ".", "This", "repetition", "may", "result", "in", "generating", "the", "token", "he", "twice", ",", "rather", "than", "using", "a", "pronoun", "to", "refer", "back", "to", "it", ".", "To", "investigate", "this", "possible", "mistake", ",", "we", "replace", "one", "of", "the", "mentions", "with", "the", "antecedent", "(", "e.g.", ",", "John", "ate", "the", "pizza", "with", "his", "fingers", "is", "replaced", "with", "John", "ate", "the", "pizza", "with", "John", "fingers", ",", "which", "is", "ungrammatical", "and", "as", "such", "should", "be", "less", "likely", ")", ".", "An", "alternative", "hypothesis", "is", "that", "even", "when", "the", "generation", "system", "correctly", "decides", "to", "predict", "a", "pronoun", ",", "it", "selects", "the", "wrong", "one", ".", "To", "test", "for", "this", ",", "we", "produce", "contrastive", "examples", "where", "a", "pronoun", "is", "replaced", "by", "either", "a", "different", "type", "of", "pronoun", "(", "e.g.", ",", "John", "ate", "the", "pizza", "with", "his", "fingers", "is", "replaced", "with", "John", "ate", "the", "pizza", "with", "him", "fingers", ")", "or", "by", "the", "same", "type", "of", "pronoun", "but", "for", "a", "different", "number", "(", "John", "ate", "the", "pizza", "with", "their", "fingers", ")", "or", "different", "gender", "(", "John", "ate", "the", "pizza", "with", "her", "fingers", ")", ".", "Note", "from", "Figure", "[", "reference", "]", "that", "the", "graph", "-", "structured", "AMR", "is", "the", "one", "that", "more", "directly", "captures", "the", "relation", "between", "finger", "and", "he", ",", "and", "as", "such", "it", "is", "expected", "to", "deal", "better", "with", "this", "type", "of", "mistakes", ".", "From", "the", "test", "split", "of", "LDC2017T10", ",", "we", "generated", "251", "contrastive", "examples", "due", "to", "antecedent", "replacements", ",", "912", "due", "to", "pronoun", "type", "replacements", ",", "1840", "due", "to", "number", "replacements", "and", "95", "due", "to", "gender", "replacements", ".", "The", "results", "are", "shown", "in", "Table", "[", "reference", "]", ".", "The", "sequential", "encoder", "performs", "surprisingly", "well", "at", "this", "task", ",", "with", "better", "or", "on", "par", "performance", "with", "respect", "to", "the", "tree", "encoder", ".", "The", "graph", "encoder", "outperforms", "the", "sequential", "encoder", "only", "for", "pronoun", "number", "and", "gender", "replacements", ".", "Future", "work", "is", "required", "to", "more", "precisely", "analyze", "if", "the", "different", "models", "cope", "with", "pronomial", "mentions", "in", "significantly", "different", "ways", ".", "Other", "approaches", "to", "inspect", "phenomena", "of", "co", "-", "reference", "and", "control", "verbs", "can", "also", "be", "explored", ",", "for", "instance", "by", "devising", "specific", "training", "objectives", ".", "subsection", ":", "Long", "-", "range", "Dependencies", "When", "we", "encode", "a", "long", "sequence", ",", "interactions", "between", "items", "that", "appear", "distant", "from", "each", "other", "in", "the", "sequence", "are", "difficult", "to", "capture", ".", "The", "problem", "of", "long", "-", "range", "dependencies", "in", "natural", "language", "is", "well", "known", "for", "RNN", "architectures", ".", "Indeed", ",", "the", "need", "to", "solve", "this", "problem", "motivated", "the", "introduction", "of", "LSTM", "models", ",", "which", "are", "known", "to", "model", "long", "-", "range", "dependencies", "better", "than", "traditional", "RNNs", ".", "Because", "the", "nodes", "in", "the", "graphs", "are", "not", "aligned", "with", "words", "in", "the", "sentence", ",", "AMR", "has", "no", "notion", "of", "distance", "between", "the", "nodes", "taking", "part", "in", "an", "edge", ".", "In", "order", "to", "define", "the", "length", "of", "an", "AMR", "edge", ",", "we", "resort", "to", "the", "AMR", "linearization", "discussed", "in", "Section", "[", "reference", "]", ".", "Given", "the", "linearization", "of", "the", "AMR", ",", "as", "discussed", "in", "Section", "[", "reference", "]", ",", "and", "an", "edge", "between", "two", "nodes", "and", ",", "the", "length", "of", "the", "edge", "is", "defined", "as", ".", "We", "then", "compute", "the", "maximum", "dependency", "length", "for", "each", "AMR", "graph", ".", "In", "order", "to", "verify", "the", "hypothesis", "that", "long", "-", "range", "dependencies", "contribute", "to", "the", "improvements", "of", "graph", "models", ",", "we", "compare", "the", "models", "as", "a", "function", "of", "the", "maximum", "dependency", "length", "in", "each", "example", ".", "Longer", "dependencies", "are", "sometimes", "caused", "by", "reentrancies", ",", "as", "in", "the", "dependency", "between", ":", "part", "-", "of", "and", "he", "in", "Figure", "[", "reference", "]", ".", "To", "verify", "that", "the", "contribution", "in", "terms", "of", "longer", "dependencies", "is", "complementary", "to", "that", "of", "reentrancies", ",", "we", "exclude", "sentences", "with", "reentrancies", "from", "this", "analysis", ".", "Table", "[", "reference", "]", "shows", "the", "statistics", "for", "this", "measure", ".", "Results", "are", "shown", "in", "Table", "[", "reference", "]", ".", "The", "graph", "encoder", "always", "outperforms", "both", "the", "sequential", "and", "the", "tree", "encoder", ".", "The", "gap", "with", "the", "sequential", "encoder", "increases", "for", "longer", "dependencies", ".", "This", "indicates", "that", "longer", "dependencies", "are", "an", "important", "factor", "in", "improving", "results", "for", "both", "tree", "and", "graph", "encoders", ",", "especially", "for", "the", "latter", ".", "section", ":", "Conclusions", "We", "introduced", "models", "for", "AMR", "-", "to", "-", "text", "generation", "with", "the", "purpose", "of", "investigating", "the", "difference", "between", "sequential", ",", "tree", "and", "graph", "encoders", ".", "We", "showed", "that", "encoding", "reentrancies", "improves", "overall", "performance", ".", "We", "observed", "bigger", "benefits", "when", "the", "input", "AMR", "graphs", "have", "a", "larger", "number", "of", "reentrant", "structures", "and", "longer", "dependencies", ".", "Our", "best", "graph", "encoder", ",", "which", "consists", "of", "a", "GCN", "wired", "to", "a", "BiLSTM", "network", ",", "improves", "over", "the", "state", "of", "the", "art", "on", "all", "tested", "datasets", ".", "We", "inspected", "the", "differences", "between", "the", "models", ",", "especially", "in", "terms", "of", "co", "-", "references", "and", "control", "structures", ".", "Further", "exploration", "of", "graph", "encoders", "is", "left", "to", "future", "work", ",", "which", "may", "result", "crucial", "to", "improve", "performance", "further", ".", "section", ":", "Acknowledgments", "The", "authors", "would", "like", "to", "thank", "the", "three", "anonymous", "reviewers", "and", "Adam", "Lopez", ",", "Ioannis", "Konstas", ",", "Diego", "Marcheggiani", ",", "Sorcha", "Gilroy", ",", "Sameer", "Bansal", ",", "Ida", "Szubert", "and", "Clara", "Vania", "for", "their", "help", "and", "comments", ".", "This", "research", "was", "supported", "by", "a", "grant", "from", "Bloomberg", "and", "by", "the", "H2020", "project", "SUMMA", ",", "under", "grant", "agreement", "688139", ".", "bibliography", ":", "References"]}