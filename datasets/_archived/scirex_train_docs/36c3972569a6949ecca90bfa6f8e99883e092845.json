{"coref": {"Accuracy": [[674, 675]], "Pythia_v0_1": [[16, 18], [212, 214], [253, 254], [312, 313], [338, 339], [362, 364], [2, 4]], "VQA_v2": [[107, 110], [176, 179], [607, 613], [1263, 1265], [1491, 1493], [1605, 1607], [1715, 1717], [1777, 1779], [799, 801]], "Visual_Question_Answering": [[10, 12], [219, 223], [234, 236], [327, 328], [36, 38]]}, "coref_non_salient": {"0": [[332, 334], [449, 451]], "1": [[680, 684], [819, 823], [1247, 1250]], "10": [[170, 174], [1603, 1604], [1773, 1776]], "11": [[814, 815]], "12": [[522, 524], [586, 590]], "13": [[51, 63], [102, 106], [370, 382], [433, 437], [665, 669], [1707, 1712]], "14": [[1182, 1184], [1188, 1189], [1210, 1212], [1236, 1237]], "15": [[745, 747]], "16": [[592, 595]], "17": [[1048, 1051]], "18": [[194, 195], [1650, 1651]], "19": [[79, 82], [867, 869], [875, 877], [884, 886], [911, 913], [936, 938], [1143, 1145], [1309, 1311]], "2": [[483, 487], [749, 752]], "20": [[1038, 1039], [1731, 1733]], "21": [[1027, 1029]], "22": [[1052, 1053], [1054, 1055]], "23": [[699, 701]], "24": [[807, 809]], "25": [[1449, 1450]], "26": [[1057, 1059], [1474, 1475]], "27": [[1133, 1138]], "28": [[1528, 1530]], "29": [[1014, 1015], [1366, 1367]], "3": [[149, 150], [1610, 1612], [1745, 1747]], "30": [[1162, 1165], [1494, 1497]], "31": [[702, 706]], "32": [[424, 425]], "33": [[275, 277]], "34": [[199, 201]], "35": [[284, 287]], "36": [[897, 904]], "37": [[671, 673]], "38": [[691, 692]], "39": [[75, 77]], "4": [[474, 477], [1176, 1181]], "40": [[572, 576]], "41": [[718, 722]], "42": [[322, 326]], "43": [[216, 218]], "44": [[540, 542]], "45": [[772, 774]], "46": [[1117, 1118], [1208, 1209], [1234, 1235]], "47": [[468, 470]], "48": [[505, 507]], "49": [[188, 189]], "5": [[265, 268], [269, 272]], "50": [[525, 526]], "51": [[581, 583]], "52": [[829, 834]], "53": [[972, 975], [1356, 1359], [1594, 1597], [1766, 1769]], "54": [[980, 985]], "55": [[281, 283]], "56": [[299, 300]], "57": [[891, 894]], "58": [[1031, 1034]], "59": [[726, 728]], "6": [[489, 494], [1035, 1036]], "60": [[464, 466]], "61": [[687, 689]], "7": [[985, 991]], "8": [[190, 193], [1168, 1170], [1255, 1257], [1337, 1339]], "9": [[91, 93], [426, 427], [1720, 1722], [1736, 1738]]}, "doc_id": "36c3972569a6949ecca90bfa6f8e99883e092845", "method_subrelations": {"Pythia_v0_1": [[[0, 11], "Pythia_v0_1"]]}, "n_ary_relations": [{"Material": "VQA_v2", "Method": "Pythia_v0_1", "Metric": "Accuracy", "Task": "Visual_Question_Answering", "score": "70.24%"}], "ner": [[10, 12, "Task"], [16, 18, "Method"], [51, 63, "Method"], [75, 77, "Method"], [79, 82, "Metric"], [91, 93, "Method"], [102, 106, "Method"], [107, 110, "Material"], [149, 150, "Method"], [170, 174, "Metric"], [176, 179, "Material"], [188, 189, "Task"], [190, 193, "Task"], [194, 195, "Task"], [199, 201, "Method"], [212, 214, "Method"], [216, 218, "Method"], [219, 223, "Task"], [234, 236, "Task"], [253, 254, "Method"], [265, 268, "Method"], [269, 272, "Method"], [275, 277, "Method"], [281, 283, "Task"], [284, 287, "Task"], [299, 300, "Method"], [312, 313, "Method"], [322, 326, "Task"], [327, 328, "Task"], [332, 334, "Task"], [338, 339, "Method"], [362, 364, "Method"], [370, 382, "Method"], [424, 425, "Method"], [426, 427, "Method"], [433, 437, "Method"], [449, 451, "Task"], [464, 466, "Method"], [468, 470, "Method"], [474, 477, "Material"], [483, 487, "Method"], [489, 494, "Method"], [505, 507, "Method"], [522, 524, "Method"], [525, 526, "Task"], [540, 542, "Method"], [572, 576, "Task"], [581, 583, "Method"], [586, 590, "Method"], [592, 595, "Method"], [607, 613, "Material"], [665, 669, "Method"], [671, 673, "Metric"], [674, 675, "Metric"], [680, 684, "Method"], [687, 689, "Method"], [691, 692, "Method"], [699, 701, "Method"], [702, 706, "Method"], [718, 722, "Task"], [726, 728, "Method"], [745, 747, "Method"], [749, 752, "Method"], [772, 774, "Metric"], [807, 809, "Method"], [814, 815, "Method"], [819, 823, "Method"], [829, 834, "Method"], [867, 869, "Metric"], [875, 877, "Metric"], [884, 886, "Metric"], [891, 894, "Method"], [897, 904, "Task"], [911, 913, "Metric"], [936, 938, "Metric"], [972, 975, "Metric"], [980, 985, "Task"], [985, 991, "Task"], [1014, 1015, "Method"], [1027, 1029, "Method"], [1031, 1034, "Method"], [1035, 1036, "Method"], [1038, 1039, "Method"], [1048, 1051, "Method"], [1052, 1053, "Method"], [1054, 1055, "Method"], [1057, 1059, "Task"], [1117, 1118, "Material"], [1133, 1138, "Metric"], [1143, 1145, "Metric"], [1162, 1165, "Method"], [1168, 1170, "Task"], [1176, 1181, "Material"], [1182, 1184, "Material"], [1188, 1189, "Material"], [1208, 1209, "Material"], [1210, 1212, "Material"], [1247, 1250, "Method"], [1255, 1257, "Task"], [1263, 1265, "Material"], [1309, 1311, "Metric"], [1337, 1339, "Task"], [1356, 1359, "Metric"], [1366, 1367, "Method"], [1449, 1450, "Material"], [1474, 1475, "Task"], [1491, 1493, "Material"], [1494, 1497, "Method"], [1528, 1530, "Method"], [1594, 1597, "Metric"], [1603, 1604, "Metric"], [1605, 1607, "Material"], [1610, 1612, "Method"], [1650, 1651, "Task"], [1707, 1712, "Method"], [1715, 1717, "Material"], [1720, 1722, "Method"], [1731, 1733, "Method"], [1736, 1738, "Method"], [1745, 1747, "Method"], [1766, 1769, "Metric"], [1773, 1776, "Metric"], [1777, 1779, "Material"], [2, 4, "Method"], [36, 38, "Task"], [799, 801, "Material"], [1234, 1235, "Material"], [1236, 1237, "Material"]], "sections": [[0, 207], [207, 412], [412, 654], [654, 805], [805, 976], [976, 1166], [1166, 1360], [1360, 1608], [1608, 1780], [1780, 1865], [1865, 1868]], "sentences": [[0, 13], [13, 29], [29, 40], [40, 64], [64, 118], [118, 162], [162, 180], [180, 207], [207, 210], [210, 244], [244, 250], [250, 265], [265, 306], [306, 335], [335, 337], [337, 358], [358, 383], [383, 412], [412, 422], [422, 452], [452, 495], [495, 527], [527, 546], [546, 572], [572, 601], [601, 624], [624, 654], [654, 658], [658, 676], [676, 696], [696, 723], [723, 758], [758, 778], [778, 805], [805, 809], [809, 824], [824, 845], [845, 870], [870, 881], [881, 905], [905, 930], [930, 959], [959, 976], [976, 985], [985, 1012], [1012, 1060], [1060, 1105], [1105, 1130], [1130, 1146], [1146, 1166], [1166, 1170], [1170, 1187], [1187, 1206], [1206, 1251], [1251, 1266], [1266, 1284], [1284, 1300], [1300, 1333], [1333, 1360], [1360, 1366], [1366, 1387], [1387, 1417], [1417, 1436], [1436, 1451], [1451, 1476], [1476, 1498], [1498, 1524], [1524, 1571], [1571, 1608], [1608, 1612], [1612, 1625], [1625, 1645], [1645, 1652], [1652, 1678], [1678, 1695], [1695, 1739], [1739, 1756], [1756, 1780], [1780, 1783], [1783, 1839], [1839, 1865], [1865, 1868]], "words": ["document", ":", "Pythia", "v0.1", ":", "the", "Winning", "Entry", "to", "the", "VQA", "Challenge", "2018", "This", "document", "describes", "Pythia", "v0.1", ",", "the", "winning", "entry", "from", "Facebook", "AI", "Research", "(", "FAIR", ")", "\u2019s", "A", "-", "STAR", "team", "to", "the", "VQA", "Challenge", "2018", ".", "Our", "starting", "point", "is", "a", "modular", "re", "-", "implementation", "of", "the", "bottom", "-", "up", "top", "-", "down", "(", "up", "-", "down", ")", "model", ".", "We", "demonstrate", "that", "by", "making", "subtle", "but", "important", "changes", "to", "the", "model", "architecture", "and", "the", "learning", "rate", "schedule", ",", "fine", "-", "tuning", "image", "features", ",", "and", "adding", "data", "augmentation", ",", "we", "can", "significantly", "improve", "the", "performance", "of", "the", "up", "-", "down", "model", "on", "VQA", "v2.0", "dataset", "\u2013", "from", "65.67", "%", "to", "70.24", "%", ".", "Furthermore", ",", "by", "using", "a", "diverse", "ensemble", "of", "models", "trained", "with", "different", "features", "and", "on", "different", "datasets", ",", "we", "are", "able", "to", "significantly", "improve", "over", "the", "\u2018", "standard", "\u2019", "way", "of", "ensembling", "(", "same", "model", "with", "different", "random", "seeds", ")", "by", "1.31", "%", ".", "Overall", ",", "we", "achieve", "72.27", "%", "on", "the", "test", "-", "std", "split", "of", "the", "VQA", "v2.0", "dataset", ".", "Our", "code", "in", "its", "entirety", "(", "training", ",", "evaluation", ",", "data", "-", "augmentation", ",", "ensembling", ")", "and", "pre", "-", "trained", "models", "are", "publicly", "available", "at", ":", ".", "section", ":", "Introduction", "We", "present", "Pythia", "v0.1", ",", "a", "modular", "framework", "for", "Visual", "Question", "Answering", "research", ",", "which", "formed", "the", "basis", "for", "the", "winning", "entry", "to", "the", "VQA", "Challenge", "2018", "from", "Facebook", "AI", "Research", "(", "FAIR", ")", "\u2019s", "A", "-", "STAR", "team", ".", "The", "motivation", "for", "Pythia", "comes", "from", "the", "following", "observation", "\u2013", "a", "majority", "of", "today", "\u2019s", "Visual", "Question", "Answering", "(", "VQA", ")", "models", "fit", "a", "particular", "design", "paradigm", ",", "with", "modules", "for", "question", "encoding", ",", "image", "feature", "extraction", ",", "fusion", "of", "the", "two", "(", "typically", "with", "attention", ")", ",", "and", "classification", "over", "the", "space", "of", "answers", ".", "The", "long", "-", "term", "goal", "of", "Pythia", "is", "to", "serve", "as", "a", "platform", "for", "easy", "and", "modular", "research", "&", "development", "in", "VQA", "and", "related", "directions", "like", "visual", "dialog", ".", "The", "name", "\u2018", "Pythia", "\u2019", "is", "an", "homage", "to", "the", "Oracle", "of", "Apollo", "at", "Delphi", ",", "who", "answered", "questions", "in", "Ancient", "Greece", ".", "The", "starting", "point", "for", "Pythia", "v0.1", "is", "a", "modular", "reimplementation", "of", "the", "bottom", "-", "up", "top", "-", "down", "(", "up", "-", "down", ")", "model", ".", "In", "this", "study", ",", "we", "demonstrate", "that", "by", "making", "a", "sequence", "of", "subtle", "but", "important", "changes", ",", "we", "can", "significantly", "improve", "the", "performance", "as", "summarized", "in", "Table", "1", ".", "section", ":", "Bottom", "-", "Up", "and", "Top", "-", "Down", "Attention", "We", "perform", "ablations", "and", "augmentations", "over", "the", "baseline", "system", "of", "the", "up", "-", "down", "model", ",", "which", "was", "the", "basis", "of", "the", "winning", "entry", "to", "the", "2017", "VQA", "challenge", ".", "The", "key", "idea", "in", "up", "-", "down", "is", "the", "use", "of", "an", "object", "detector", "\u2013", "Faster", "RCNN", "pre", "-", "trained", "on", "the", "Visual", "Genome", "dataset", "\u2013", "to", "extract", "image", "features", "with", "bottom", "-", "up", "attention", ",", ",", "visual", "feed", "-", "forward", "attention", ".", "Specifically", ",", "a", "ResNet", "-", "101", "was", "chosen", "as", "the", "backbone", "network", ",", "and", "its", "entire", "Res", "-", "5", "block", "was", "used", "as", "the", "second", "-", "stage", "region", "classifier", "for", "detection", ".", "After", "training", ",", "each", "region", "was", "then", "represented", "by", "the", "2048", "feature", "after", "average", "pooling", "from", "a", "grid", ".", "The", "question", "text", "is", "then", "used", "to", "compute", "the", "top", "-", "down", "attention", ",", ",", "task", "specific", "attention", ",", "for", "each", "object", "in", "the", "image", ".", "Multi", "-", "modal", "fusion", "is", "done", "through", "a", "simple", "Hadamard", "product", "followed", "by", "a", "multi", "-", "label", "classifier", "using", "a", "sigmoid", "activation", "function", "to", "predict", "the", "answer", "scores", ".", "Their", "performance", "reached", "70.34", "%", "on", "VQA", "2.0", "test", "-", "std", "split", "with", "an", "ensemble", "of", "30", "models", "trained", "with", "different", "seeds", ".", "For", "presentation", "clarity", ",", "we", "present", "our", "proposed", "changes", "(", "and", "the", "respective", "improvements", ")", "in", "a", "sequence", ";", "however", ",", "we", "also", "found", "them", "to", "be", "independently", "useful", ".", "subsection", ":", "Model", "Architecture", "We", "made", "a", "few", "changes", "to", "the", "up", "-", "down", "model", "to", "improve", "training", "speed", "and", "accuracy", ".", "Instead", "of", "using", "the", "gated", "hyperbolic", "tangent", "activation", ",", "we", "use", "weight", "normalization", "followed", "by", "ReLU", "to", "reduce", "computation", ".", "We", "also", "replaced", "feature", "concatenation", "with", "element", "-", "wise", "multiplication", "to", "combine", "the", "features", "from", "text", "and", "visual", "modalities", "when", "computing", "the", "top", "-", "down", "attention", ".", "To", "compute", "the", "question", "representation", ",", "we", "used", "300", "GloVe", "vectors", "to", "initialize", "the", "word", "embeddings", "and", "then", "passed", "it", "to", "a", "GRU", "network", "and", "a", "question", "attention", "module", "to", "extract", "attentive", "text", "features", ".", "For", "fusing", "the", "image", "and", "text", "information", ",", "we", "found", "the", "best", "-", "performing", "hidden", "size", "to", "be", "5000", ".", "With", "these", "modifications", ",", "we", "were", "able", "to", "improve", "the", "performance", "of", "the", "model", "from", "65.32", "%", "to", "66.91", "%", "on", "VQA", "v2.0", "test", "-", "dev", ".", "subsection", ":", "Learning", "Schedule", "Our", "model", "is", "optimized", "by", "Adamax", ",", "a", "variant", "of", "Adam", "with", "infinite", "norm", ".", "In", "one", "popular", "implementation", "of", "up", "-", "down", "learning", "rate", "is", "set", "to", "0.002", "with", "a", "batch", "size", "of", "512", ".", "We", "found", "that", "reducing", "the", "batch", "size", "improves", "performance", "\u2013", "which", "suggests", "that", "there", "is", "potential", "for", "improving", "performance", "by", "increasing", "the", "learning", "rate", ".", "However", ",", "naively", "increasing", "the", "learning", "rate", "resulted", "in", "divergence", ".", "To", "increase", "the", "learning", "rate", ",", "we", "thus", "deployed", "the", "warm", "up", "strategy", "commonly", "used", "for", "large", "learning", "-", "rate", "training", "of", "networks", ".", "Specifically", ",", "we", "begin", "with", "a", "learning", "rate", "of", "0.002", ",", "linearly", "increasing", "it", "at", "each", "iteration", "till", "it", "reaches", "0.01", "at", "iteration", "1000", ".", "Next", ",", "we", "first", "reduce", "the", "learning", "rate", "by", "a", "factor", "of", "0.1", "at", "5", "and", "then", "reduce", "it", "every", "2", "iterations", ",", "and", "stop", "training", "at", "12", ".", "With", "this", "we", "increase", "the", "performance", "from", "66.91", "%", "to", "68.05", "%", "on", "test", "-", "dev", ".", "subsection", ":", "Fine", "-", "Tuning", "Bottom", "-", "Up", "Features", "Fine", "tuning", "pre", "-", "trained", "features", "is", "a", "well", "known", "technique", "to", "better", "tailor", "the", "features", "to", "the", "task", "at", "hand", "and", "thus", "improve", "model", "performance", ".", "Different", "from", "Anderson", ",", "we", "also", "used", "the", "new", "state", "-", "of", "-", "the", "-", "art", "detectors", "based", "on", "feature", "pyramid", "networks", "(", "FPN", ")", "from", "Detectron", ",", "which", "uses", "ResNeXt", "as", "backbone", "and", "has", "two", "fully", "connected", "layers", "(", "fc6", "and", "fc7", ")", "for", "region", "classification", ".", "This", "allows", "us", "to", "extract", "the", "2048", "fc6", "features", "and", "fine", "-", "tune", "the", "fc7", "parameters", ",", "as", "opposed", "to", "the", "original", "up", "-", "down", ",", "where", "fine", "-", "tuning", "previous", "layers", "requires", "significantly", "more", "storage", "/", "IO", "and", "computation", "on", "convolutional", "feature", "maps", ".", "Similar", "to", "up", "-", "down", ",", "we", "also", "used", "Visual", "Genome", "(", "VG", ")", "with", "both", "objects", "and", "attributes", "annotations", "to", "train", "the", "detector", ".", "We", "set", "the", "fine", "-", "tune", "learning", "rate", "as", "0.1", "times", "the", "overall", "learning", "rate", ".", "We", "are", "able", "to", "reach", "a", "performance", "of", "68.49", "%", "on", "test", "-", "dev", "with", "this", "fine", "-", "tuning", ".", "subsection", ":", "Data", "Augmentation", "We", "added", "additional", "training", "data", "from", "Visual", "Genome", "and", "Visual", "Dialog", "(", "VisDial", "v0.9", ")", "datasets", ".", "For", "VisDial", ",", "we", "converted", "the", "10", "turns", "in", "a", "dialog", "to", "10", "independent", "question", "-", "answer", "pairs", ".", "Since", "both", "VG", "and", "VisDial", "datasets", "only", "have", "a", "single", "ground", "-", "truth", "answer", "while", "VQA", "has", "10", ",", "we", "simply", "replicated", "the", "answer", "to", "each", "question", "in", "VG", "and", "VisDial", "10", "times", "to", "make", "the", "data", "format", "compatible", "with", "the", "VQA", "evaluation", "protocol", ".", "We", "also", "performed", "additional", "data", "augmentation", "by", "mirroring", "the", "images", "in", "the", "VQA", "dataset", ".", "We", "do", "some", "basic", "processing", "of", "the", "questions", "and", "answers", "for", "the", "mirrored", "images", "by", "interchanging", "the", "tokens", "\u201c", "left", "\u201d", "and", "\u201c", "right", "\u201d", "in", "the", "questions", "and", "answers", "which", "contain", "them", ".", "When", "adding", "these", "additional", "datasets", ",", "we", "reduce", "the", "learning", "rate", "as", "we", "described", "in", "Section", "[", "reference", "]", "first", "at", "15", "iterations", ",", "respectively", ",", "and", "stop", "training", "at", "22", "iterations", ".", "As", "a", "result", "of", "data", "augmentation", ",", "we", "are", "able", "to", "improve", "our", "single", "model", "performance", "from", "68.49", "%", "to", "69.24", "%", "on", "test", "-", "dev", ".", "subsection", ":", "Post", "-", "Challenge", "Improvements", "Anderson", "uses", "only", "the", "features", "pooled", "from", "object", "proposals", "(", "called", "bottom", "-", "up", "features", ")", "to", "represent", "an", "image", ".", "Our", "hypothesis", "is", "that", "such", "a", "representation", "does", "not", "fully", "capture", "a", "holistic", "spatial", "information", "about", "the", "image", "and", "visual", "representations", "from", "image", "regions", "not", "covered", "by", "the", "proposals", ".", "To", "test", "this", "hypothesis", ",", "we", "combined", "grid", "-", "level", "image", "features", "together", "with", "bottom", "-", "up", "features", ".", "We", "follow", "the", "same", "procedure", "as", "to", "extract", "grid", "-", "level", "features", "from", "ResNet152", ".", "Object", "-", "level", "features", "and", "grid", "-", "level", "features", "are", "separately", "fused", "with", "features", "from", "questions", "and", "then", "are", "concatenated", "to", "fed", "to", "classification", ".", "Before", "the", "challenge", "deadline", ",", "we", "had", "experimented", "with", "this", "only", "on", "images", "from", "the", "VQA", "dataset", "without", "fine", "-", "tuning", ".", "After", "the", "challenge", ",", "we", "performed", "more", "comprehensive", "experiments", "and", "found", "that", "adding", "grid", "level", "features", "helps", "to", "further", "improve", "the", "performance", "to", "69.81", "%", ".", "Instead", "of", "using", "an", "adaptive", "protocol", "for", "choosing", "the", "number", "of", "object", "proposals", "(", "between", "10", "and", "100", ")", "per", "image", "as", "as", "done", "in", ",", "we", "also", "experimented", "with", "using", "a", "simpler", "(", "but", "slower", ")", "strategy", "of", "using", "100", "objects", "proposals", "for", "all", "images", ".", "As", "can", "be", "seen", "in", "Table", "[", "reference", "]", ",", "with", "features", "from", "100", "bounding", "-", "boxes", ",", "we", "reach", "70.01", "%", "for", "test", "-", "dev", "and", "70.24", "%", "for", "test", "-", "std", "on", "VQA", "2.0", ".", "subsection", ":", "Model", "Ensembling", "All", "ensembling", "experiments", "described", "below", "involve", "models", "trained", "before", "the", "challenge", "deadline", ".", "That", "is", ",", "they", "do", "not", "include", "the", "two", "after", "-", "challenge", "experiments", "described", "in", "Section", "[", "reference", "]", ".", "We", "tried", "two", "strategies", "for", "ensembling", ".", "First", ",", "we", "choose", "our", "best", "single", "model", "and", "train", "the", "same", "network", "with", "different", "seeds", ",", "and", "finally", "average", "the", "predictions", "from", "each", "model", ".", "As", "can", "be", "seen", "from", "Fig", "[", "reference", "]", ",", "the", "performance", "plateaus", "at", "70.96", "%", ".", "Second", ",", "we", "choose", "models", "trained", "with", "different", "settings", ",", ",", "the", "tweaked", "up", "-", "down", "model", "trained", "on", "the", "VQA", "dataset", "with", "/", "without", "data", "augmentation", "and", "models", "trained", "with", "image", "features", "extracted", "from", "different", "Detectron", "models", "with", "/", "without", "data", "augmentation", ".", "As", "can", "be", "seen", ",", "this", "ensembling", "strategy", "is", "much", "more", "effective", "than", "the", "previous", "one", ".", "Ensembling", "30", "diverse", "models", ",", "we", "reach", "72.18", "%", "on", "test", "-", "dev", "and", "72.27", "%", "on", "test", "-", "std", "of", "VQA", "v2.0", ".", "section", ":", "Acknowledgements", "We", "would", "like", "to", "thank", "Peter", "Anderson", ",", "Abhishek", "Das", ",", "Stefan", "Lee", ",", "Jiasen", "Lu", ",", "Jianwei", "Yang", ",", "Licheng", "Yu", ",", "Luowei", "Zhou", "for", "helpful", "discussions", ",", "Peter", "Anderson", "for", "providing", "training", "data", "for", "the", "Visual", "Genome", "detector", ",", "Deshraj", "Yadav", "for", "responses", "on", "EvalAI", "related", "questions", ",", "Stefan", "Lee", "for", "suggesting", "the", "name", "\u2018", "Pythia", "\u2019", ",", "Abhishek", "Das", ",", "Abhishek", "Kadian", "for", "feedback", "on", "our", "codebase", "and", "Meet", "Shah", "for", "making", "a", "docker", "image", "for", "our", "demo", ".", "bibliography", ":", "References"]}