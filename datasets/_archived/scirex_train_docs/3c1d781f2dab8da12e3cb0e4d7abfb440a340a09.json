{"coref": {"450D_DR-BiLSTM": [[2, 5], [55, 60], [61, 64], [121, 124], [422, 426], [427, 430], [530, 533], [1002, 1005], [1023, 1026], [1122, 1124], [1125, 1126], [1168, 1169], [1175, 1176], [1682, 1683], [3016, 3019], [3049, 3052], [3184, 3187], [3274, 3277], [3425, 3428], [4002, 4005], [4010, 4013], [4057, 4060], [4076, 4079], [4130, 4133], [4440, 4443], [4612, 4615], [4642, 4645], [4670, 4673], [4685, 4688], [4723, 4726], [4776, 4779], [4795, 4798], [4807, 4810], [4898, 4901], [4910, 4913], [5234, 5237], [5270, 5273], [5300, 5303], [5403, 5406], [1238, 1239], [1270, 1271], [1755, 1756], [1878, 1879], [1888, 1889], [3002, 3005], [3173, 3176], [3238, 3241], [3307, 3310], [3316, 3319], [3368, 3369], [3722, 3723], [4509, 4512], [4936, 4939]], "450D_DR-BiLSTM_Ensemble": [[86, 88], [130, 132], [539, 541], [608, 610], [613, 615], [625, 627], [2118, 2119], [2231, 2233], [2233, 2235], [2438, 2440], [2486, 2488], [3082, 3084], [3087, 3089], [3117, 3119], [3121, 3123], [3188, 3189], [3674, 3675], [4014, 4015], [4061, 4062], [4472, 4474], [4533, 4540], [4545, 4547], [4608, 4610], [4627, 4630], [4773, 4775], [4780, 4781], [4821, 4824], [4842, 4844], [4924, 4927]], "Natural_Language_Inference": [[11, 14], [24, 27], [28, 29], [79, 80], [153, 156], [157, 158], [182, 183], [226, 227], [396, 397], [666, 667], [689, 690], [701, 703], [961, 962], [1040, 1041], [1674, 1675], [1749, 1751], [2123, 2124], [2193, 2195], [2840, 2842], [2940, 2943], [268, 269], [1058, 1059], [3076, 3077], [4435, 4438]], "Parameters": [], "SNLI": [[146, 149], [215, 219], [220, 221], [247, 248], [2002, 2006], [2007, 2008], [2086, 2087], [2517, 2518], [2751, 2752], [2762, 2763], [3094, 3095], [3381, 3382], [3410, 3411], [3618, 3619], [4968, 4969], [526, 527], [581, 582], [2294, 2295], [2565, 2566], [2808, 2809], [3219, 3220], [3393, 3394], [3766, 3767], [3989, 3990], [4464, 4465], [5059, 5060]], "__Test_Accuracy": [[598, 599], [2458, 2459], [2741, 2742], [3023, 3024], [3136, 3137], [3609, 3610], [3632, 3633], [3997, 3998], [2815, 2816], [3473, 3474], [3640, 3641], [4885, 4886], [5030, 5031]], "__Train_Accuracy": [[598, 599], [2458, 2459], [2741, 2742], [3023, 3024], [3136, 3137], [3609, 3610], [3632, 3633], [3997, 3998], [2815, 2816], [3473, 3474], [3640, 3641], [4885, 4886], [5030, 5031]]}, "coref_non_salient": {"0": [[738, 741], [1104, 1106]], "1": [[38, 40], [287, 289], [351, 353], [956, 959]], "10": [[271, 273], [753, 755], [778, 786], [928, 930]], "11": [[1744, 1747], [4678, 4680], [4731, 4733], [4803, 4805]], "12": [[3065, 3069], [3453, 3456]], "13": [[317, 321], [950, 953]], "14": [[4000, 4001], [4086, 4087], [4139, 4140], [4192, 4193], [5238, 5239], [5278, 5279], [5289, 5290]], "15": [[77, 78], [388, 390], [3553, 3555], [3567, 3569]], "16": [[1035, 1037], [2120, 2122]], "17": [[250, 253], [998, 1001], [1377, 1380], [2785, 2788], [2792, 2795], [2831, 2834], [2852, 2855]], "18": [[2249, 2251], [2471, 2473], [4598, 4601]], "19": [[464, 467], [1388, 1391]], "2": [[1603, 1606], [2339, 2340]], "20": [[491, 494], [771, 774], [2996, 2999], [3541, 3544], [4227, 4230], [4448, 4451]], "21": [[576, 578], [3155, 3156], [3209, 3211], [3268, 3270], [4505, 4507]], "22": [[1043, 1044], [1948, 1949]], "23": [[344, 346], [1344, 1346], [3503, 3505], [3563, 3565]], "24": [[1038, 1039], [1355, 1356], [5316, 5318]], "25": [[1811, 1814], [3493, 3495]], "26": [[2818, 2819]], "27": [[1696, 1698], [3753, 3755]], "28": [[484, 486], [4698, 4700]], "29": [[560, 564], [3224, 3228], [3260, 3264], [3325, 3329]], "3": [[2474, 2476], [4833, 4835], [4871, 4874], [4957, 4960]], "30": [[2408, 2409], [2988, 2989]], "31": [[3802, 3803]], "32": [[3340, 3342]], "33": [[2333, 2336]], "34": [[4949, 4953]], "35": [[3414, 3417]], "36": [[127, 129], [536, 538]], "37": [[2870, 2874], [2930, 2934], [2965, 2969]], "38": [[1323, 1327], [1930, 1934]], "39": [[2758, 2760]], "4": [[18, 21], [683, 688]], "40": [[4852, 4856]], "41": [[2953, 2960]], "42": [[4520, 4524]], "43": [[1112, 1116]], "44": [[2162, 2163]], "45": [[3664, 3668]], "46": [[2022, 2024]], "47": [[161, 164]], "48": [[1668, 1670]], "49": [[822, 825]], "5": [[2883, 2891], [2901, 2909], [2920, 2927]], "50": [[2072, 2073]], "51": [[2804, 2806]], "52": [[2189, 2191], [4235, 4237]], "53": [[1599, 1602]], "54": [[2110, 2113]], "55": [[1548, 1552]], "56": [[1646, 1647]], "57": [[2169, 2170]], "58": [[794, 796]], "59": [[921, 923]], "6": [[509, 514], [1961, 1963]], "60": [[4838, 4841]], "61": [[2241, 2242]], "62": [[735, 737]], "63": [[2146, 2148]], "64": [[166, 168]], "65": [[896, 901]], "66": [[476, 479]], "67": [[1300, 1302]], "68": [[1359, 1362]], "69": [[902, 903]], "7": [[2275, 2281], [2478, 2482]], "70": [[730, 733]], "71": [[1648, 1650]], "72": [[3338, 3339]], "73": [[3281, 3282]], "74": [[6, 10]], "75": [[2609, 2613]], "76": [[2773, 2777]], "77": [[704, 707]], "78": [[4182, 4187]], "79": [[175, 178]], "8": [[2337, 2338], [4635, 4638], [4649, 4650], [4791, 4794], [4894, 4897]], "80": [[2617, 2619]], "81": [[1106, 1107]], "82": [[1294, 1297]], "83": [[1970, 1972]], "84": [[2151, 2153]], "85": [[2137, 2140]], "86": [[694, 698]], "9": [[514, 515], [1964, 1965]]}, "doc_id": "3c1d781f2dab8da12e3cb0e4d7abfb440a340a09", "method_subrelations": {"450D_DR-BiLSTM": [[[0, 14], "450D_DR-BiLSTM"]], "450D_DR-BiLSTM_Ensemble": [[[0, 23], "450D_DR-BiLSTM_Ensemble"]]}, "n_ary_relations": [{"Material": "SNLI", "Method": "450D_DR-BiLSTM", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "88.5"}, {"Material": "SNLI", "Method": "450D_DR-BiLSTM_Ensemble", "Metric": "__Test_Accuracy", "Task": "Natural_Language_Inference", "score": "89.3"}, {"Material": "SNLI", "Method": "450D_DR-BiLSTM", "Metric": "__Train_Accuracy", "Task": "Natural_Language_Inference", "score": "94.1"}, {"Material": "SNLI", "Method": "450D_DR-BiLSTM_Ensemble", "Metric": "__Train_Accuracy", "Task": "Natural_Language_Inference", "score": "94.8"}, {"Material": "SNLI", "Method": "450D_DR-BiLSTM", "Metric": "Parameters", "Task": "Natural_Language_Inference", "score": "7.5m"}, {"Material": "SNLI", "Method": "450D_DR-BiLSTM_Ensemble", "Metric": "Parameters", "Task": "Natural_Language_Inference", "score": "45m"}], "ner": [[2, 5, "Method"], [6, 10, "Method"], [11, 14, "Task"], [18, 21, "Method"], [24, 27, "Task"], [28, 29, "Task"], [38, 40, "Method"], [55, 60, "Method"], [61, 64, "Method"], [77, 78, "Task"], [79, 80, "Task"], [86, 88, "Method"], [121, 124, "Method"], [127, 129, "Method"], [130, 132, "Method"], [146, 149, "Material"], [153, 156, "Task"], [157, 158, "Task"], [161, 164, "Task"], [166, 168, "Task"], [175, 178, "Task"], [182, 183, "Task"], [215, 219, "Material"], [220, 221, "Material"], [226, 227, "Task"], [247, 248, "Material"], [250, 253, "Method"], [271, 273, "Method"], [287, 289, "Method"], [317, 321, "Task"], [344, 346, "Task"], [351, 353, "Method"], [388, 390, "Task"], [396, 397, "Task"], [422, 426, "Method"], [427, 430, "Method"], [464, 467, "Method"], [476, 479, "Method"], [484, 486, "Method"], [491, 494, "Method"], [509, 514, "Method"], [514, 515, "Method"], [530, 533, "Method"], [536, 538, "Method"], [539, 541, "Method"], [560, 564, "Method"], [576, 578, "Method"], [598, 599, "Metric"], [608, 610, "Method"], [613, 615, "Method"], [625, 627, "Method"], [666, 667, "Task"], [683, 688, "Method"], [689, 690, "Task"], [694, 698, "Method"], [701, 703, "Task"], [704, 707, "Task"], [730, 733, "Method"], [735, 737, "Method"], [738, 741, "Method"], [753, 755, "Method"], [771, 774, "Method"], [778, 786, "Method"], [794, 796, "Method"], [822, 825, "Method"], [896, 901, "Method"], [902, 903, "Method"], [921, 923, "Method"], [928, 930, "Method"], [950, 953, "Task"], [956, 959, "Method"], [961, 962, "Task"], [998, 1001, "Method"], [1002, 1005, "Method"], [1023, 1026, "Method"], [1035, 1037, "Task"], [1038, 1039, "Task"], [1040, 1041, "Task"], [1043, 1044, "Task"], [1104, 1106, "Method"], [1106, 1107, "Method"], [1112, 1116, "Task"], [1122, 1124, "Method"], [1125, 1126, "Method"], [1168, 1169, "Method"], [1175, 1176, "Method"], [1294, 1297, "Method"], [1300, 1302, "Method"], [1323, 1327, "Method"], [1344, 1346, "Task"], [1355, 1356, "Task"], [1359, 1362, "Method"], [1377, 1380, "Method"], [1388, 1391, "Method"], [1548, 1552, "Metric"], [1599, 1602, "Method"], [1603, 1606, "Method"], [1646, 1647, "Metric"], [1648, 1650, "Method"], [1668, 1670, "Method"], [1674, 1675, "Task"], [1682, 1683, "Method"], [1696, 1698, "Method"], [1744, 1747, "Method"], [1749, 1751, "Task"], [1811, 1814, "Method"], [1930, 1934, "Method"], [1948, 1949, "Task"], [1961, 1963, "Method"], [1964, 1965, "Method"], [1970, 1972, "Method"], [2002, 2006, "Material"], [2007, 2008, "Material"], [2022, 2024, "Material"], [2072, 2073, "Task"], [2086, 2087, "Material"], [2110, 2113, "Method"], [2118, 2119, "Method"], [2120, 2122, "Task"], [2123, 2124, "Task"], [2137, 2140, "Metric"], [2146, 2148, "Method"], [2151, 2153, "Metric"], [2162, 2163, "Method"], [2169, 2170, "Task"], [2189, 2191, "Method"], [2193, 2195, "Task"], [2231, 2233, "Method"], [2233, 2235, "Method"], [2241, 2242, "Task"], [2249, 2251, "Method"], [2275, 2281, "Method"], [2333, 2336, "Method"], [2337, 2338, "Method"], [2339, 2340, "Method"], [2408, 2409, "Task"], [2438, 2440, "Method"], [2458, 2459, "Metric"], [2471, 2473, "Method"], [2474, 2476, "Method"], [2478, 2482, "Method"], [2486, 2488, "Method"], [2517, 2518, "Material"], [2609, 2613, "Method"], [2617, 2619, "Method"], [2741, 2742, "Metric"], [2751, 2752, "Material"], [2758, 2760, "Method"], [2762, 2763, "Material"], [2773, 2777, "Method"], [2785, 2788, "Method"], [2792, 2795, "Method"], [2804, 2806, "Metric"], [2818, 2819, "Metric"], [2831, 2834, "Method"], [2840, 2842, "Task"], [2852, 2855, "Method"], [2870, 2874, "Method"], [2883, 2891, "Method"], [2901, 2909, "Method"], [2920, 2927, "Method"], [2930, 2934, "Method"], [2940, 2943, "Task"], [2953, 2960, "Method"], [2965, 2969, "Method"], [2988, 2989, "Task"], [2996, 2999, "Method"], [3016, 3019, "Method"], [3023, 3024, "Metric"], [3049, 3052, "Method"], [3065, 3069, "Metric"], [3082, 3084, "Method"], [3087, 3089, "Method"], [3094, 3095, "Material"], [3117, 3119, "Method"], [3121, 3123, "Method"], [3136, 3137, "Metric"], [3155, 3156, "Method"], [3184, 3187, "Method"], [3188, 3189, "Method"], [3209, 3211, "Method"], [3224, 3228, "Method"], [3260, 3264, "Method"], [3268, 3270, "Method"], [3274, 3277, "Method"], [3281, 3282, "Method"], [3325, 3329, "Method"], [3338, 3339, "Task"], [3340, 3342, "Task"], [3381, 3382, "Material"], [3410, 3411, "Material"], [3414, 3417, "Metric"], [3425, 3428, "Method"], [3453, 3456, "Metric"], [3493, 3495, "Method"], [3503, 3505, "Task"], [3541, 3544, "Method"], [3553, 3555, "Task"], [3563, 3565, "Task"], [3567, 3569, "Task"], [3609, 3610, "Metric"], [3618, 3619, "Material"], [3632, 3633, "Metric"], [3664, 3668, "Task"], [3674, 3675, "Method"], [3753, 3755, "Method"], [3802, 3803, "Material"], [3997, 3998, "Metric"], [4000, 4001, "Method"], [4002, 4005, "Method"], [4010, 4013, "Method"], [4014, 4015, "Method"], [4057, 4060, "Method"], [4061, 4062, "Method"], [4076, 4079, "Method"], [4086, 4087, "Method"], [4130, 4133, "Method"], [4139, 4140, "Method"], [4182, 4187, "Task"], [4192, 4193, "Method"], [4227, 4230, "Method"], [4235, 4237, "Method"], [4440, 4443, "Method"], [4448, 4451, "Method"], [4472, 4474, "Method"], [4505, 4507, "Method"], [4520, 4524, "Method"], [4533, 4540, "Method"], [4545, 4547, "Method"], [4598, 4601, "Method"], [4608, 4610, "Method"], [4612, 4615, "Method"], [4627, 4630, "Method"], [4635, 4638, "Method"], [4642, 4645, "Method"], [4649, 4650, "Method"], [4670, 4673, "Method"], [4678, 4680, "Method"], [4685, 4688, "Method"], [4698, 4700, "Method"], [4723, 4726, "Method"], [4731, 4733, "Method"], [4773, 4775, "Method"], [4776, 4779, "Method"], [4780, 4781, "Method"], [4791, 4794, "Method"], [4795, 4798, "Method"], [4803, 4805, "Method"], [4807, 4810, "Method"], [4821, 4824, "Method"], [4833, 4835, "Method"], [4838, 4841, "Method"], [4842, 4844, "Method"], [4852, 4856, "Method"], [4871, 4874, "Method"], [4894, 4897, "Method"], [4898, 4901, "Method"], [4910, 4913, "Method"], [4924, 4927, "Method"], [4949, 4953, "Method"], [4957, 4960, "Method"], [4968, 4969, "Material"], [5234, 5237, "Method"], [5238, 5239, "Method"], [5270, 5273, "Method"], [5278, 5279, "Method"], [5289, 5290, "Method"], [5300, 5303, "Method"], [5316, 5318, "Task"], [5403, 5406, "Method"], [268, 269, "Task"], [526, 527, "Material"], [581, 582, "Material"], [1058, 1059, "Task"], [1238, 1239, "Method"], [1270, 1271, "Method"], [1755, 1756, "Method"], [1878, 1879, "Method"], [1888, 1889, "Method"], [2294, 2295, "Material"], [2565, 2566, "Material"], [2808, 2809, "Material"], [2815, 2816, "Metric"], [3002, 3005, "Method"], [3076, 3077, "Task"], [3173, 3176, "Method"], [3219, 3220, "Material"], [3238, 3241, "Method"], [3307, 3310, "Method"], [3316, 3319, "Method"], [3368, 3369, "Method"], [3393, 3394, "Material"], [3473, 3474, "Metric"], [3640, 3641, "Metric"], [3722, 3723, "Method"], [3766, 3767, "Material"], [3989, 3990, "Material"], [4435, 4438, "Task"], [4464, 4465, "Material"], [4509, 4512, "Method"], [4885, 4886, "Metric"], [4936, 4939, "Method"], [5030, 5031, "Metric"], [5059, 5060, "Material"]], "sections": [[0, 150], [150, 650], [650, 1016], [1016, 1102], [1102, 1353], [1353, 1672], [1672, 1946], [1946, 1993], [1993, 1998], [1998, 2095], [2095, 2229], [2229, 2507], [2507, 2732], [2732, 3336], [3336, 3728], [3728, 4428], [4428, 4593], [4593, 4596], [4596, 5045], [5045, 5222], [5222, 5314], [5314, 5416]], "sentences": [[0, 14], [14, 32], [32, 49], [49, 81], [81, 100], [100, 117], [117, 150], [150, 153], [153, 161], [161, 179], [179, 205], [205, 224], [224, 249], [249, 264], [264, 283], [283, 297], [297, 334], [334, 347], [347, 368], [368, 398], [398, 419], [419, 437], [437, 458], [458, 475], [475, 501], [501, 522], [522, 567], [567, 584], [584, 633], [633, 650], [650, 654], [654, 668], [668, 691], [691, 713], [713, 728], [728, 729], [729, 749], [749, 756], [756, 775], [775, 816], [816, 837], [837, 869], [869, 893], [893, 894], [894, 920], [920, 943], [943, 960], [960, 986], [986, 1007], [1007, 1016], [1016, 1019], [1019, 1045], [1045, 1061], [1061, 1085], [1085, 1102], [1102, 1106], [1106, 1133], [1133, 1147], [1147, 1159], [1159, 1170], [1170, 1192], [1192, 1212], [1212, 1225], [1225, 1248], [1248, 1270], [1270, 1282], [1282, 1298], [1298, 1321], [1321, 1340], [1340, 1353], [1353, 1356], [1356, 1376], [1376, 1392], [1392, 1445], [1445, 1470], [1470, 1487], [1487, 1508], [1508, 1538], [1538, 1553], [1553, 1577], [1577, 1596], [1596, 1632], [1632, 1651], [1651, 1672], [1672, 1675], [1675, 1705], [1705, 1730], [1730, 1752], [1752, 1781], [1781, 1842], [1842, 1865], [1865, 1888], [1888, 1900], [1900, 1915], [1915, 1946], [1946, 1949], [1949, 1980], [1980, 1993], [1993, 1998], [1998, 2001], [2001, 2016], [2016, 2047], [2047, 2077], [2077, 2095], [2095, 2099], [2099, 2114], [2114, 2130], [2130, 2149], [2149, 2156], [2156, 2179], [2179, 2196], [2196, 2214], [2214, 2229], [2229, 2233], [2233, 2244], [2244, 2270], [2270, 2298], [2298, 2358], [2358, 2383], [2383, 2410], [2410, 2428], [2428, 2446], [2446, 2464], [2464, 2483], [2483, 2507], [2507, 2510], [2510, 2536], [2536, 2564], [2564, 2579], [2579, 2599], [2599, 2625], [2625, 2674], [2674, 2676], [2676, 2683], [2683, 2703], [2703, 2732], [2732, 2735], [2735, 2753], [2753, 2768], [2768, 2778], [2778, 2799], [2799, 2826], [2826, 2843], [2843, 2916], [2916, 2940], [2940, 2953], [2953, 2974], [2974, 3007], [3007, 3016], [3016, 3044], [3044, 3070], [3070, 3085], [3085, 3100], [3100, 3120], [3120, 3138], [3138, 3166], [3166, 3191], [3191, 3204], [3204, 3230], [3230, 3271], [3271, 3281], [3281, 3298], [3298, 3336], [3336, 3342], [3342, 3361], [3361, 3383], [3383, 3396], [3396, 3429], [3429, 3457], [3457, 3482], [3482, 3506], [3506, 3534], [3534, 3556], [3556, 3598], [3598, 3620], [3620, 3652], [3652, 3669], [3669, 3695], [3695, 3715], [3715, 3728], [3728, 3731], [3731, 3741], [3741, 3770], [3770, 3792], [3792, 3804], [3804, 3814], [3814, 3826], [3826, 3835], [3835, 3844], [3844, 3855], [3855, 3869], [3869, 3880], [3880, 3889], [3889, 3932], [3932, 3956], [3956, 3976], [3976, 4017], [4017, 4053], [4053, 4074], [4074, 4126], [4126, 4145], [4145, 4188], [4188, 4222], [4222, 4269], [4269, 4298], [4298, 4327], [4327, 4337], [4337, 4346], [4346, 4353], [4353, 4376], [4376, 4428], [4428, 4431], [4431, 4467], [4467, 4481], [4481, 4500], [4500, 4525], [4525, 4541], [4541, 4563], [4563, 4593], [4593, 4596], [4596, 4601], [4601, 4635], [4635, 4670], [4670, 4701], [4701, 4723], [4723, 4750], [4750, 4829], [4829, 4862], [4862, 4880], [4880, 4944], [4944, 4978], [4978, 5015], [5015, 5045], [5045, 5049], [5049, 5072], [5072, 5124], [5124, 5139], [5139, 5157], [5157, 5194], [5194, 5222], [5222, 5226], [5226, 5249], [5249, 5262], [5262, 5285], [5285, 5314], [5314, 5318], [5318, 5346], [5346, 5377], [5377, 5403], [5403, 5416]], "words": ["document", ":", "DR", "-", "BiLSTM", ":", "Dependent", "Reading", "Bidirectional", "LSTM", "for", "Natural", "Language", "Inference", "We", "present", "a", "novel", "deep", "learning", "architecture", "to", "address", "the", "natural", "language", "inference", "(", "NLI", ")", "task", ".", "Existing", "approaches", "mostly", "rely", "on", "simple", "reading", "mechanisms", "for", "independent", "encoding", "of", "the", "premise", "and", "hypothesis", ".", "Instead", ",", "we", "propose", "a", "novel", "dependent", "reading", "bidirectional", "LSTM", "network", "(", "DR", "-", "BiLSTM", ")", "to", "efficiently", "model", "the", "relationship", "between", "a", "premise", "and", "a", "hypothesis", "during", "encoding", "and", "inference", ".", "We", "also", "introduce", "a", "sophisticated", "ensemble", "strategy", "to", "combine", "our", "proposed", "models", ",", "which", "noticeably", "improves", "final", "predictions", ".", "Finally", ",", "we", "demonstrate", "how", "the", "results", "can", "be", "improved", "further", "with", "an", "additional", "preprocessing", "step", ".", "Our", "evaluation", "shows", "that", "DR", "-", "BiLSTM", "obtains", "the", "best", "single", "model", "and", "ensemble", "model", "results", "achieving", "the", "new", "state", "-", "of", "-", "the", "-", "art", "scores", "on", "the", "Stanford", "NLI", "dataset", ".", "section", ":", "Introduction", "Natural", "Language", "Inference", "(", "NLI", ";", "a.k.a", ".", "Recognizing", "Textual", "Entailment", ",", "or", "RTE", ")", "is", "an", "important", "and", "challenging", "task", "for", "natural", "language", "understanding", ".", "The", "goal", "of", "NLI", "is", "to", "identify", "the", "logical", "relationship", "(", "entailment", ",", "neutral", ",", "or", "contradiction", ")", "between", "a", "premise", "and", "a", "corresponding", "hypothesis", ".", "Table", "[", "reference", "]", "shows", "few", "example", "relationships", "from", "the", "Stanford", "Natural", "Language", "Inference", "(", "SNLI", ")", "dataset", ".", "Recently", ",", "NLI", "has", "received", "a", "lot", "of", "attention", "from", "the", "researchers", ",", "especially", "due", "to", "the", "availability", "of", "large", "annotated", "datasets", "like", "SNLI", ".", "Various", "deep", "learning", "models", "have", "been", "proposed", "that", "achieve", "successful", "results", "for", "this", "task", ".", "Most", "of", "these", "existing", "NLI", "models", "use", "attention", "mechanism", "to", "jointly", "interpret", "and", "align", "the", "premise", "and", "hypothesis", ".", "Such", "models", "use", "simple", "reading", "mechanisms", "to", "encode", "the", "premise", "and", "hypothesis", "independently", ".", "However", ",", "such", "a", "complex", "task", "require", "explicit", "modeling", "of", "dependency", "relationships", "between", "the", "premise", "and", "the", "hypothesis", "during", "the", "encoding", "and", "inference", "processes", "to", "prevent", "the", "network", "from", "the", "loss", "of", "relevant", ",", "contextual", "information", ".", "In", "this", "paper", ",", "we", "refer", "to", "such", "strategies", "as", "dependent", "reading", ".", "There", "are", "some", "alternative", "reading", "mechanisms", "available", "in", "the", "literature", "that", "consider", "dependency", "aspects", "of", "the", "premise", "-", "hypothesis", "relationships", ".", "However", ",", "these", "mechanisms", "have", "two", "major", "limitations", ":", "So", "far", ",", "they", "have", "only", "explored", "dependency", "aspects", "during", "the", "encoding", "stage", ",", "while", "ignoring", "its", "benefit", "during", "inference", ".", "Such", "models", "only", "consider", "encoding", "a", "hypothesis", "depending", "on", "the", "premise", ",", "disregarding", "the", "dependency", "aspects", "in", "the", "opposite", "direction", ".", "We", "propose", "a", "dependent", "reading", "bidirectional", "LSTM", "(", "DR", "-", "BiLSTM", ")", "model", "to", "address", "these", "limitations", ".", "Given", "a", "premise", "and", "a", "hypothesis", ",", "our", "model", "first", "encodes", "them", "considering", "dependency", "on", "each", "other", "(", "and", ")", ".", "Next", ",", "the", "model", "employs", "a", "soft", "attention", "mechanism", "to", "extract", "relevant", "information", "from", "these", "encodings", ".", "The", "augmented", "sentence", "representations", "are", "then", "passed", "to", "the", "inference", "stage", ",", "which", "uses", "a", "similar", "dependent", "reading", "strategy", "in", "both", "directions", ",", "i.e.", "and", ".", "Finally", ",", "a", "decision", "is", "made", "through", "a", "multi", "-", "layer", "perceptron", "(", "MLP", ")", "based", "on", "the", "aggregated", "information", ".", "Our", "experiments", "on", "the", "SNLI", "dataset", "show", "that", "DR", "-", "BiLSTM", "achieves", "the", "best", "single", "model", "and", "ensemble", "model", "performance", "obtaining", "improvements", "of", "a", "considerable", "margin", "of", "and", "over", "the", "previous", "state", "-", "of", "-", "the", "-", "art", "single", "and", "ensemble", "models", ",", "respectively", ".", "Furthermore", ",", "we", "demonstrate", "the", "importance", "of", "a", "simple", "preprocessing", "step", "performed", "on", "the", "SNLI", "dataset", ".", "Evaluation", "results", "show", "that", "such", "preprocessing", "allows", "our", "single", "model", "to", "achieve", "the", "same", "accuracy", "as", "the", "state", "-", "of", "-", "the", "-", "art", "ensemble", "model", "and", "improves", "our", "ensemble", "model", "to", "outperform", "the", "state", "-", "of", "-", "the", "-", "art", "ensemble", "model", "by", "a", "remarkable", "margin", "of", ".", "Finally", ",", "we", "perform", "an", "extensive", "analysis", "to", "clarify", "the", "strengths", "and", "weaknesses", "of", "our", "models", ".", "section", ":", "Related", "Work", "Early", "studies", "use", "small", "datasets", "while", "leveraging", "lexical", "and", "syntactic", "features", "for", "NLI", ".", "The", "recent", "availability", "of", "large", "-", "scale", "annotated", "datasets", "has", "enabled", "researchers", "to", "develop", "various", "deep", "learning", "-", "based", "architectures", "for", "NLI", ".", "google2016", "propose", "an", "attention", "-", "based", "model", "that", "decomposes", "the", "NLI", "task", "into", "sub", "-", "problems", "to", "solve", "them", "in", "parallel", ".", "They", "further", "show", "the", "benefit", "of", "adding", "intra", "-", "sentence", "attention", "to", "input", "representations", ".", "him2017", "explore", "sequential", "inference", "models", "based", "on", "chain", "LSTMs", "with", "attentional", "input", "encoding", "and", "demonstrate", "the", "effectiveness", "of", "syntactic", "information", ".", "We", "also", "use", "similar", "attention", "mechanisms", ".", "However", ",", "our", "model", "is", "distinct", "from", "these", "models", "as", "they", "do", "not", "benefit", "from", "dependent", "reading", "strategies", ".", "Rocktaschel2015", "use", "a", "word", "-", "by", "-", "word", "neural", "attention", "mechanism", "while", "re", "-", "read", "propose", "re", "-", "read", "LSTM", "units", "by", "considering", "the", "dependency", "of", "a", "hypothesis", "on", "the", "information", "of", "its", "premise", "(", ")", "to", "achieve", "promising", "results", ".", "However", ",", "these", "models", "suffer", "from", "weak", "inferencing", "methods", "by", "disregarding", "the", "dependency", "aspects", "from", "the", "opposite", "direction", "(", ")", ".", "Intuitively", ",", "when", "a", "human", "judges", "a", "premise", "-", "hypothesis", "relationship", ",", "s", "/", "he", "might", "consider", "back", "-", "and", "-", "forth", "reading", "of", "both", "sentences", "before", "coming", "to", "a", "conclusion", ".", "Therefore", ",", "it", "is", "essential", "to", "encode", "the", "premise", "-", "hypothesis", "dependency", "relations", "from", "both", "directions", "to", "optimize", "the", "understanding", "of", "their", "relationship", ".", "ibm2017", "propose", "a", "bilateral", "multi", "-", "perspective", "matching", "(", "BiMPM", ")", "model", ",", "which", "resembles", "the", "concept", "of", "matching", "a", "premise", "and", "hypothesis", "from", "both", "directions", ".", "Their", "matching", "strategy", "is", "essentially", "similar", "to", "our", "attention", "mechanism", "that", "utilizes", "relevant", "information", "from", "the", "other", "sentence", "for", "each", "word", "sequence", ".", "They", "use", "similar", "methods", "as", "him2017", "for", "encoding", "and", "inference", ",", "without", "any", "dependent", "reading", "mechanism", ".", "Although", "NLI", "is", "well", "studied", "in", "the", "literature", ",", "the", "potential", "of", "dependent", "reading", "and", "interaction", "between", "a", "premise", "and", "hypothesis", "is", "not", "rigorously", "explored", ".", "In", "this", "paper", ",", "we", "address", "this", "gap", "by", "proposing", "a", "novel", "deep", "learning", "model", "(", "DR", "-", "BiLSTM", ")", ".", "Experimental", "results", "demonstrate", "the", "effectiveness", "of", "our", "model", ".", "section", ":", "Model", "Our", "proposed", "model", "(", "DR", "-", "BiLSTM", ")", "is", "composed", "of", "the", "following", "major", "components", ":", "input", "encoding", ",", "attention", ",", "inference", ",", "and", "classification", ".", "Figure", "[", "reference", "]", "demonstrates", "a", "high", "-", "level", "view", "of", "our", "proposed", "NLI", "framework", ".", "Let", "and", "be", "the", "given", "premise", "with", "length", "and", "hypothesis", "with", "length", "respectively", ",", "where", "is", "an", "word", "embedding", "of", "-", "dimensional", "vector", ".", "The", "task", "is", "to", "predict", "a", "label", "that", "indicates", "the", "logical", "relationship", "between", "premise", "and", "hypothesis", ".", "subsection", ":", "Input", "Encoding", "RNNs", "are", "the", "natural", "solution", "for", "variable", "length", "sequence", "modeling", ",", "consequently", ",", "we", "utilize", "a", "bidirectional", "LSTM", "(", "BiLSTM", ")", "for", "encoding", "the", "given", "sentences", ".", "For", "ease", "of", "presentation", ",", "we", "only", "describe", "how", "we", "encode", "depending", "on", ".", "The", "same", "procedure", "is", "utilized", "for", "the", "reverse", "direction", "(", ")", ".", "To", "dependently", "encode", ",", "we", "first", "process", "using", "the", "BiLSTM", ".", "Then", "we", "read", "through", "the", "BiLSTM", "that", "is", "initialized", "with", "previous", "reading", "final", "states", "(", "memory", "cell", "and", "hidden", "state", ")", ".", "Here", "we", "represent", "a", "word", "(", "e.g.", ")", "and", "its", "context", "depending", "on", "the", "other", "sentence", "(", "e.g.", ")", ".", "Equations", "[", "reference", "]", "and", "[", "reference", "]", "formally", "represent", "this", "component", ".", "where", "and", "are", "the", "independent", "reading", "sequences", ",", "dependent", "reading", "sequences", ",", "and", "BiLSTM", "final", "state", "of", "independent", "reading", "of", "and", "respectively", ".", "Note", "that", ",", "\u201c", "\u201d", "in", "these", "equations", "means", "that", "we", "do", "not", "care", "about", "the", "associated", "variable", "and", "its", "value", ".", "BiLSTM", "inputs", "are", "the", "word", "embedding", "sequences", "and", "initial", "state", "vectors", ".", "and", "are", "passed", "to", "the", "next", "layer", "as", "the", "output", "of", "the", "input", "encoding", "component", ".", "The", "proposed", "encoding", "mechanism", "yields", "a", "richer", "representation", "for", "both", "premise", "and", "hypothesis", "by", "taking", "the", "history", "of", "each", "other", "into", "account", ".", "Using", "a", "max", "or", "average", "pooling", "over", "the", "independent", "and", "dependent", "readings", "does", "not", "further", "improve", "our", "model", ".", "This", "was", "expected", "since", "dependent", "reading", "produces", "more", "promising", "and", "relevant", "encodings", ".", "subsection", ":", "Attention", "We", "employ", "a", "soft", "alignment", "method", "to", "associate", "the", "relevant", "sub", "-", "components", "between", "the", "given", "premise", "and", "hypothesis", ".", "In", "deep", "learning", "models", ",", "such", "purpose", "is", "often", "achieved", "with", "a", "soft", "attention", "mechanism", ".", "Here", "we", "compute", "the", "unnormalized", "attention", "weights", "as", "the", "similarity", "of", "hidden", "states", "of", "the", "premise", "and", "hypothesis", "with", "Equation", "[", "reference", "]", "(", "energy", "function", ")", ".", "where", "and", "are", "the", "dependent", "reading", "hidden", "representations", "of", "and", "respectively", "which", "are", "computed", "earlier", "in", "Equations", "[", "reference", "]", "and", "[", "reference", "]", ".", "Next", ",", "for", "each", "word", "in", "either", "premise", "or", "hypothesis", ",", "the", "relevant", "semantics", "in", "the", "other", "sentence", "is", "extracted", "and", "composed", "according", "to", ".", "Equations", "[", "reference", "]", "and", "[", "reference", "]", "provide", "formal", "and", "specific", "details", "of", "this", "procedure", ".", "where", "represents", "the", "extracted", "relevant", "information", "of", "by", "attending", "to", "while", "represents", "the", "extracted", "relevant", "information", "of", "by", "attending", "to", ".", "To", "further", "enrich", "the", "collected", "attentional", "information", ",", "a", "trivial", "next", "step", "would", "be", "to", "pass", "the", "concatenation", "of", "the", "tuples", "or", "which", "provides", "a", "linear", "relationship", "between", "them", ".", "However", ",", "the", "model", "would", "suffer", "from", "the", "absence", "of", "similarity", "and", "closeness", "measures", ".", "Therefore", ",", "we", "calculate", "the", "difference", "and", "element", "-", "wise", "product", "for", "the", "tuples", "and", "that", "represent", "the", "similarity", "and", "closeness", "information", "respectively", ".", "The", "difference", "and", "element", "-", "wise", "product", "are", "then", "concatenated", "with", "the", "computed", "vectors", ",", "or", ",", "respectively", ".", "Finally", ",", "a", "feedforward", "neural", "layer", "with", "ReLU", "activation", "function", "projects", "the", "concatenated", "vectors", "from", "-", "dimensional", "vector", "space", "into", "a", "-", "dimensional", "vector", "space", "(", "Equations", "[", "reference", "]", "and", "[", "reference", "]", ")", ".", "This", "helps", "the", "model", "to", "capture", "deeper", "dependencies", "between", "the", "sentences", "besides", "lowering", "the", "complexity", "of", "vector", "representations", ".", "Here", "stands", "for", "element", "-", "wise", "product", "while", "and", "are", "the", "trainable", "weights", "and", "biases", "of", "the", "projector", "layer", "respectively", ".", "subsection", ":", "Inference", "During", "this", "phase", ",", "we", "use", "another", "BiLSTM", "to", "aggregate", "the", "two", "sequences", "of", "computed", "matching", "vectors", ",", "and", "from", "the", "attention", "stage", "(", "Section", "[", "reference", "]", ")", ".", "This", "aggregation", "is", "performed", "in", "a", "sequential", "manner", "to", "avoid", "losing", "effect", "of", "latent", "variables", "that", "might", "rely", "on", "the", "sequence", "of", "matching", "vectors", ".", "Instead", "of", "aggregating", "the", "sequences", "of", "matching", "vectors", "individually", ",", "we", "propose", "a", "similar", "dependent", "reading", "approach", "for", "the", "inference", "stage", ".", "We", "employ", "a", "BiLSTM", "reading", "process", "(", "Equations", "[", "reference", "]", "and", "[", "reference", "]", ")", "similar", "to", "the", "input", "encoding", "step", "discussed", "in", "Section", "[", "reference", "]", ".", "But", "rather", "than", "passing", "just", "the", "dependent", "reading", "information", "to", "the", "next", "step", ",", "we", "feed", "both", "independent", "reading", "(", "and", ")", "and", "dependent", "reading", "(", "and", ")", "to", "a", "max", "pooling", "layer", ",", "which", "selects", "maximum", "values", "from", "each", "sequence", "of", "independent", "and", "dependent", "readings", "(", "and", ")", "as", "shown", "in", "Equations", "[", "reference", "]", "and", "[", "reference", "]", ".", "The", "main", "intuition", "behind", "this", "architecture", "is", "to", "maximize", "the", "inferencing", "ability", "of", "the", "model", "by", "considering", "both", "independent", "and", "dependent", "readings", ".", "Here", "and", "are", "the", "independent", "reading", "sequences", ",", "dependent", "reading", "sequences", ",", "and", "BiLSTM", "final", "state", "of", "independent", "reading", "of", "and", "respectively", ".", "BiLSTM", "inputs", "are", "the", "word", "embedding", "sequences", "and", "initial", "state", "vectors", ".", "Finally", ",", "we", "convert", "and", "to", "fixed", "-", "length", "vectors", "with", "pooling", ",", "and", ".", "As", "shown", "in", "Equations", "[", "reference", "]", "and", "[", "reference", "]", ",", "we", "employ", "both", "max", "and", "average", "pooling", "and", "describe", "the", "overall", "inference", "relationship", "with", "concatenation", "of", "their", "outputs", ".", "subsection", ":", "Classification", "Here", ",", "we", "feed", "the", "concatenation", "of", "and", "(", ")", "into", "a", "multilayer", "perceptron", "(", "MLP", ")", "classifier", "that", "includes", "a", "hidden", "layer", "with", "tanh", "activation", "and", "softmax", "output", "layer", ".", "The", "model", "is", "trained", "in", "an", "end", "-", "to", "-", "end", "manner", ".", "section", ":", "Experiments", "and", "Evaluation", "subsection", ":", "Dataset", "The", "Stanford", "Natural", "Language", "Inference", "(", "SNLI", ")", "dataset", "contains", "human", "annotated", "sentence", "pairs", ".", "The", "premises", "are", "drawn", "from", "the", "Flickr30k", "corpus", ",", "and", "then", "the", "hypotheses", "are", "manually", "composed", "for", "each", "relationship", "class", "(", "entailment", ",", "neutral", ",", "contradiction", ",", "and", "-", ")", ".", "The", "\u201c", "-", "\u201d", "class", "indicates", "that", "there", "is", "no", "consensus", "decision", "among", "the", "annotators", ",", "consequently", ",", "we", "remove", "them", "during", "the", "training", "and", "evaluation", "following", "the", "literature", ".", "We", "use", "the", "same", "data", "split", "as", "provided", "in", "snli", "to", "report", "comparable", "results", "with", "other", "models", ".", "subsection", ":", "Experimental", "Setup", "We", "use", "pre", "-", "trained", "-", "Glove", "vectors", "to", "initialize", "our", "word", "embedding", "vectors", ".", "All", "hidden", "states", "of", "BiLSTMs", "during", "input", "encoding", "and", "inference", "have", "dimensions", "(", "and", ")", ".", "The", "weights", "are", "learned", "by", "minimizing", "the", "log", "-", "loss", "on", "the", "training", "data", "via", "the", "Adam", "optimizer", ".", "The", "initial", "learning", "rate", "is", "0.0004", ".", "To", "avoid", "overfitting", ",", "we", "use", "dropout", "with", "the", "rate", "of", "0.4", "for", "regularization", ",", "which", "is", "applied", "to", "all", "feedforward", "connections", ".", "During", "training", ",", "the", "word", "embeddings", "are", "updated", "to", "learn", "effective", "representations", "for", "the", "NLI", "task", ".", "We", "use", "a", "fairly", "small", "batch", "size", "of", "32", "to", "provide", "more", "exploration", "power", "to", "the", "model", ".", "Our", "observation", "indicates", "that", "using", "larger", "batch", "sizes", "hurts", "the", "performance", "of", "our", "model", ".", "subsection", ":", "Ensemble", "Strategy", "Ensemble", "methods", "use", "multiple", "models", "to", "obtain", "better", "predictive", "performance", ".", "Previous", "works", "typically", "utilize", "trivial", "ensemble", "strategies", "by", "either", "using", "majority", "votes", "or", "averaging", "the", "probability", "distributions", "over", "the", "same", "model", "with", "different", "initialization", "seeds", ".", "By", "contrast", ",", "we", "use", "weighted", "averaging", "of", "the", "probability", "distributions", "where", "the", "weight", "of", "each", "model", "is", "learned", "through", "its", "performance", "on", "the", "SNLI", "development", "set", ".", "Furthermore", ",", "the", "differences", "between", "our", "models", "in", "the", "ensemble", "originate", "from", ":", "1", ")", "variations", "in", "the", "number", "of", "dependent", "readings", "(", "i.e.", "1", "and", "3", "rounds", "of", "dependent", "reading", ")", ",", "2", ")", "projection", "layer", "activation", "(", "tanh", "and", "ReLU", "in", "Equations", "[", "reference", "]", "and", "[", "reference", "]", ")", ",", "and", "3", ")", "different", "initialization", "seeds", ".", "The", "main", "intuition", "behind", "this", "design", "is", "that", "the", "effectiveness", "of", "a", "model", "may", "depend", "on", "the", "complexity", "of", "a", "premise", "-", "hypothesis", "instance", ".", "For", "a", "simple", "instance", ",", "a", "simple", "model", "could", "perform", "better", "than", "a", "complex", "one", ",", "while", "a", "complex", "instance", "may", "need", "further", "consideration", "toward", "disambiguation", ".", "Consequently", ",", "using", "models", "with", "different", "rounds", "of", "dependent", "readings", "in", "the", "encoding", "stage", "should", "be", "beneficial", ".", "Figure", "[", "reference", "]", "demonstrates", "the", "observed", "performance", "of", "our", "ensemble", "method", "with", "different", "number", "of", "models", ".", "The", "performance", "of", "the", "models", "are", "reported", "based", "on", "the", "best", "obtained", "accuracy", "on", "the", "development", "set", ".", "We", "also", "study", "the", "effectiveness", "of", "other", "ensemble", "strategies", "e.g.", "majority", "voting", ",", "and", "averaging", "the", "probability", "distributions", ".", "But", ",", "our", "ensemble", "strategy", "performs", "the", "best", "among", "them", "(", "see", "Section", "[", "reference", "]", "in", "the", "Appendix", "for", "additional", "details", ")", ".", "subsection", ":", "Preprocessing", "We", "perform", "a", "trivial", "preprocessing", "step", "on", "SNLI", "to", "recover", "some", "out", "-", "of", "-", "vocabulary", "words", "found", "in", "the", "development", "set", "and", "test", "set", ".", "Note", "that", "our", "vocabulary", "contains", "all", "words", "that", "are", "seen", "in", "the", "training", "set", ",", "so", "there", "is", "no", "out", "-", "of", "-", "vocabulary", "word", "in", "it", ".", "The", "SNLI", "dataset", "is", "not", "immune", "to", "human", "errors", ",", "specifically", ",", "misspelled", "words", ".", "We", "noticed", "that", "misspelling", "is", "the", "main", "reason", "for", "some", "of", "the", "observed", "out", "-", "of", "-", "vocabulary", "words", ".", "Consequently", ",", "we", "simply", "fix", "the", "unseen", "misspelled", "words", "using", "Microsoft", "spell", "-", "checker", "(", "other", "approaches", "like", "edit", "distance", "can", "also", "be", "used", ")", ".", "Moreover", ",", "while", "dealing", "with", "an", "unseen", "word", "during", "evaluation", ",", "we", "try", "to", ":", "1", ")", "replace", "it", "with", "its", "lower", "case", ",", "or", "2", ")", "split", "the", "word", "when", "it", "contains", "a", "\u201c", "-", "\u201d", "(", "e.g.", "\u201c", "marsh", "-", "like", "\u201d", ")", "or", "starts", "with", "\u201c", "un", "\u201d", "(", "e.g.", "\u201c", "unloading", "\u201d", ")", ".", "If", "we", "still", "could", "not", "find", "the", "word", "in", "our", "vocabulary", ",", "we", "consider", "it", "as", "an", "unknown", "word", ".", "In", "the", "next", "subsection", ",", "we", "demonstrate", "the", "importance", "and", "impact", "of", "such", "trivial", "preprocessing", "(", "see", "Section", "[", "reference", "]", "in", "the", "Appendix", "for", "additional", "details", ")", ".", "subsection", ":", "Results", "Table", "[", "reference", "]", "shows", "the", "accuracy", "of", "the", "models", "on", "training", "and", "test", "sets", "of", "SNLI", ".", "The", "first", "row", "represents", "a", "baseline", "classifier", "presented", "by", "snli", "that", "utilizes", "handcrafted", "features", ".", "All", "other", "listed", "models", "are", "deep", "-", "learning", "based", ".", "The", "gap", "between", "the", "traditional", "model", "and", "deep", "learning", "models", "demonstrates", "the", "effectiveness", "of", "deep", "learning", "methods", "for", "this", "task", ".", "We", "also", "report", "the", "estimated", "human", "performance", "on", "the", "SNLI", "dataset", ",", "which", "is", "the", "average", "accuracy", "of", "five", "annotators", "in", "comparison", "to", "the", "gold", "labels", ".", "It", "is", "noteworthy", "that", "recent", "deep", "learning", "models", "surpass", "the", "human", "performance", "in", "the", "NLI", "task", ".", "As", "shown", "in", "Table", "[", "reference", "]", ",", "previous", "deep", "learning", "models", "(", "rows", "2", "-", "19", ")", "can", "be", "divided", "into", "three", "categories", ":", "1", ")", "sentence", "encoding", "based", "models", "(", "rows", "2", "-", "7", ")", ",", "2", ")", "single", "inter", "-", "sentence", "attention", "-", "based", "models", "(", "rows", "8", "-", "16", ")", ",", "and", "3", ")", "ensemble", "inter", "-", "sentence", "attention", "-", "based", "models", "(", "rows", "17", "-", "19", ")", ".", "We", "can", "see", "that", "inter", "-", "sentence", "attention", "-", "based", "models", "perform", "better", "than", "sentence", "encoding", "based", "models", ",", "which", "supports", "our", "intuition", ".", "Natural", "language", "inference", "requires", "a", "deep", "interaction", "between", "the", "premise", "and", "hypothesis", ".", "Inter", "-", "sentence", "attention", "-", "based", "approaches", "can", "provide", "such", "interaction", "while", "sentence", "encoding", "based", "models", "fail", "to", "do", "so", ".", "To", "further", "enhance", "the", "modeling", "of", "interaction", "between", "the", "premise", "and", "hypothesis", "for", "efficient", "disambiguation", "of", "their", "relationship", ",", "we", "introduce", "the", "dependent", "reading", "strategy", "in", "our", "proposed", "DR", "-", "BiLSTM", "model", ".", "The", "results", "demonstrate", "the", "effectiveness", "of", "our", "model", ".", "DR", "-", "BiLSTM", "(", "Single", ")", "achieves", "accuracy", "on", "the", "test", "set", "which", "is", "noticeably", "the", "best", "reported", "result", "among", "the", "existing", "single", "models", "for", "this", "task", ".", "Note", "that", "the", "difference", "between", "DR", "-", "BiLSTM", "and", "him2017", "is", "statistically", "significant", "with", "a", "p", "-", "value", "of", "over", "the", "Chi", "-", "square", "test", ".", "To", "further", "improve", "the", "performance", "of", "NLI", "systems", ",", "researchers", "have", "built", "ensemble", "models", ".", "Previously", ",", "ensemble", "systems", "obtained", "the", "best", "performance", "on", "SNLI", "with", "a", "huge", "margin", ".", "Table", "[", "reference", "]", "shows", "that", "our", "proposed", "single", "model", "achieves", "competitive", "results", "compared", "to", "these", "reported", "ensemble", "models", ".", "Our", "ensemble", "model", "considerably", "outperforms", "the", "current", "state", "-", "of", "-", "the", "-", "art", "by", "obtaining", "accuracy", ".", "Up", "until", "this", "point", ",", "we", "discussed", "the", "performance", "of", "our", "models", "where", "we", "have", "not", "considered", "preprocessing", "for", "recovering", "the", "out", "-", "of", "-", "vocabulary", "words", ".", "In", "Table", "[", "reference", "]", ",", "\u201c", "DR", "-", "BiLSTM", "(", "Single", ")", "Process", "\u201d", ",", "and", "\u201c", "DR", "-", "BiLSTM", "(", "Ensem", ".", ")", "Process", "\u201d", "represent", "the", "performance", "of", "our", "models", "on", "the", "preprocessed", "dataset", ".", "We", "can", "see", "that", "our", "preprocessing", "mechanism", "leads", "to", "further", "improvements", "of", "and", "on", "the", "SNLI", "test", "set", "for", "our", "single", "and", "ensemble", "models", "respectively", ".", "In", "fact", ",", "our", "single", "model", "(", "\u201c", "DR", "-", "BiLSTM", "(", "Single", ")", "Process", "\u201d", ")", "obtains", "the", "state", "-", "of", "-", "the", "-", "art", "performance", "over", "both", "reported", "single", "and", "ensemble", "models", "by", "performing", "a", "simple", "preprocessing", "step", ".", "Furthermore", ",", "\u201c", "DR", "-", "BiLSTM", "(", "Ensem", ".", ")", "Process", "\u201d", "outperforms", "the", "existing", "state", "-", "of", "-", "the", "-", "art", "remarkably", "(", "improvement", ")", ".", "For", "more", "comparison", "and", "analyses", ",", "we", "use", "\u201c", "DR", "-", "BiLSTM", "(", "Single", ")", "\u201d", "and", "\u201c", "DR", "-", "BiLSTM", "(", "Ensemble", ")", "\u201d", "as", "our", "single", "and", "ensemble", "models", "in", "the", "rest", "of", "the", "paper", ".", "subsection", ":", "Ablation", "and", "Configuration", "Study", "We", "conducted", "an", "ablation", "study", "on", "our", "model", "to", "examine", "the", "importance", "and", "effect", "of", "each", "major", "component", ".", "Then", ",", "we", "study", "the", "impact", "of", "BiLSTM", "dimensionality", "on", "the", "performance", "of", "the", "development", "set", "and", "training", "set", "of", "SNLI", ".", "We", "investigate", "all", "settings", "on", "the", "development", "set", "of", "the", "SNLI", "dataset", ".", "Table", "[", "reference", "]", "shows", "the", "ablation", "study", "results", "on", "the", "development", "set", "of", "SNLI", "along", "with", "the", "statistical", "significance", "test", "results", "in", "comparison", "to", "the", "proposed", "model", ",", "DR", "-", "BiLSTM", ".", "We", "can", "see", "that", "all", "modifications", "lead", "to", "a", "new", "model", "and", "their", "differences", "are", "statistically", "significant", "with", "a", "p", "-", "value", "of", "over", "Chi", "square", "test", ".", "Table", "[", "reference", "]", "shows", "that", "removing", "any", "part", "from", "our", "model", "hurts", "the", "development", "set", "accuracy", "which", "indicates", "the", "effectiveness", "of", "these", "components", ".", "Among", "all", "components", ",", "three", "of", "them", "have", "noticeable", "influences", ":", "max", "pooling", ",", "difference", "in", "the", "attention", "stage", ",", "and", "dependent", "reading", ".", "Most", "importantly", ",", "the", "last", "four", "study", "cases", "in", "Table", "[", "reference", "]", "(", "rows", "8", "-", "11", ")", "verify", "the", "main", "intuitions", "behind", "our", "proposed", "model", ".", "They", "illustrate", "the", "importance", "of", "our", "proposed", "dependent", "reading", "strategy", "which", "leads", "to", "significant", "improvement", ",", "specifically", "in", "the", "encoding", "stage", ".", "We", "are", "convinced", "that", "the", "importance", "of", "dependent", "reading", "in", "the", "encoding", "stage", "originates", "from", "its", "ability", "to", "focus", "on", "more", "important", "and", "relevant", "aspects", "of", "the", "sentences", "due", "to", "its", "prior", "knowledge", "of", "the", "other", "sentence", "during", "the", "encoding", "procedure", ".", "Figure", "[", "reference", "]", "shows", "the", "behavior", "of", "the", "proposed", "model", "accuracy", "on", "the", "training", "set", "and", "development", "set", "of", "SNLI", ".", "Since", "the", "models", "are", "selected", "based", "on", "the", "best", "observed", "development", "set", "accuracy", "during", "the", "training", "procedure", ",", "the", "training", "accuracy", "curve", "(", "red", ",", "top", ")", "is", "not", "strictly", "increasing", ".", "Figure", "[", "reference", "]", "demonstrates", "that", "we", "achieve", "the", "best", "performance", "with", "450", "-", "dimensional", "BiLSTMs", ".", "In", "other", "words", ",", "using", "BiLSTMs", "with", "lower", "dimensionality", "causes", "the", "model", "to", "suffer", "from", "the", "lack", "of", "space", "for", "capturing", "proper", "information", "and", "dependencies", ".", "On", "the", "other", "hand", ",", "using", "higher", "dimensionality", "leads", "to", "overfitting", "which", "hurts", "the", "performance", "on", "the", "development", "set", ".", "Hence", ",", "we", "use", "450", "-", "dimensional", "BiLSTM", "in", "our", "proposed", "model", ".", "subsection", ":", "Analysis", "We", "first", "investigate", "the", "performance", "of", "our", "models", "categorically", ".", "Then", ",", "we", "show", "a", "visualization", "of", "the", "energy", "function", "in", "the", "attention", "stage", "(", "Equation", "[", "reference", "]", ")", "for", "an", "instance", "from", "the", "SNLI", "test", "set", ".", "To", "qualitatively", "evaluate", "the", "performance", "of", "our", "models", ",", "we", "design", "a", "set", "of", "annotation", "tags", "that", "can", "be", "extracted", "automatically", ".", "This", "design", "is", "inspired", "by", "the", "reported", "annotation", "tags", "in", "multinli", ".", "The", "specifications", "of", "our", "annotation", "tags", "are", "as", "follows", ":", "High", "Overlap", ":", "premise", "and", "hypothesis", "sentences", "share", "more", "than", "tokens", ".", "Regular", "Overlap", ":", "sentences", "share", "between", "and", "tokens", ".", "Low", "Overlap", ":", "sentences", "share", "less", "than", "tokens", ".", "Long", "Sentence", ":", "either", "sentence", "is", "longer", "than", "20", "tokens", ".", "Regular", "Sentence", ":", "premise", "or", "hypothesis", "length", "is", "between", "5", "and", "20", "tokens", ".", "Short", "Sentence", ":", "either", "sentence", "is", "shorter", "than", "5", "tokens", ".", "Negation", ":", "negation", "is", "present", "in", "a", "sentence", ".", "Quantifier", ":", "either", "of", "the", "sentences", "contains", "one", "of", "the", "following", "quantifiers", ":", "much", ",", "enough", ",", "more", ",", "most", ",", "less", ",", "least", ",", "no", ",", "none", ",", "some", ",", "any", ",", "many", ",", "few", ",", "several", ",", "almost", ",", "nearly", ".", "Belief", ":", "either", "of", "the", "sentences", "contains", "one", "of", "the", "following", "belief", "verbs", ":", "know", ",", "believe", ",", "understand", ",", "doubt", ",", "think", ",", "suppose", ",", "recognize", ",", "forget", ",", "remember", ",", "imagine", ",", "mean", ",", "agree", ",", "disagree", ",", "deny", ",", "promise", ".", "Table", "[", "reference", "]", "shows", "the", "frequency", "of", "aforementioned", "annotation", "tags", "in", "the", "SNLI", "test", "set", "along", "with", "the", "performance", "(", "accuracy", ")", "of", "ESIM", ",", "DR", "-", "BiLSTM", "(", "Single", ")", ",", "and", "DR", "-", "BiLSTM", "(", "Ensemble", ")", ".", "Table", "[", "reference", "]", "can", "be", "divided", "into", "four", "major", "categories", ":", "1", ")", "gold", "label", "data", ",", "2", ")", "word", "overlap", ",", "3", ")", "sentence", "length", ",", "and", "4", ")", "occurrence", "of", "special", "words", ".", "We", "can", "see", "that", "DR", "-", "BiLSTM", "(", "Ensemble", ")", "performs", "the", "best", "in", "all", "categories", "which", "matches", "our", "expectation", ".", "Moreover", ",", "DR", "-", "BiLSTM", "(", "Single", ")", "performs", "noticeably", "better", "than", "ESIM", "in", "most", "of", "the", "categories", "except", "\u201c", "Entailment", "\u201d", ",", "\u201c", "High", "Overlap", "\u201d", ",", "and", "\u201c", "Long", "Sentence", "\u201d", ",", "for", "which", "our", "model", "is", "not", "far", "behind", "(", "gaps", "of", ",", ",", "and", ",", "respectively", ")", ".", "It", "is", "noteworthy", "that", "DR", "-", "BiLSTM", "(", "Single", ")", "performs", "better", "than", "ESIM", "in", "more", "frequent", "categories", ".", "Specifically", ",", "the", "performance", "of", "our", "model", "in", "\u201c", "Neutral", "\u201d", ",", "\u201c", "Negation", "\u201d", ",", "and", "\u201c", "Quantifier", "\u201d", "categories", "(", "improvements", "of", ",", ",", "and", ",", "respectively", ")", "indicates", "the", "superiority", "of", "our", "model", "in", "understanding", "and", "disambiguating", "complex", "samples", ".", "Our", "investigations", "indicate", "that", "ESIM", "generates", "somewhat", "uniform", "attention", "for", "most", "of", "the", "word", "pairs", "while", "our", "model", "could", "effectively", "attend", "to", "specific", "parts", "of", "the", "given", "sentences", "and", "provide", "more", "meaningful", "attention", ".", "In", "other", "words", ",", "the", "dependent", "reading", "strategy", "enables", "our", "model", "to", "achieve", "meaningful", "representations", ",", "which", "leads", "to", "better", "attention", "to", "obtain", "further", "gains", "on", "such", "categories", "like", "Negation", "and", "Quantifier", "sentences", "(", "see", "Section", "[", "reference", "]", "in", "the", "Appendix", "for", "additional", "details", ")", ".", "Finally", ",", "we", "show", "a", "visualization", "of", "the", "normalized", "attention", "weights", "(", "energy", "function", ",", "Equation", "[", "reference", "]", ")", "of", "our", "model", "in", "Figure", "[", "reference", "]", ".", "We", "show", "a", "sentence", "pair", ",", "where", "the", "premise", "is", "\u201c", "Male", "in", "a", "blue", "jacket", "decides", "to", "lay", "the", "grass", ".", "\u201d", ",", "and", "the", "hypothesis", "is", "\u201c", "The", "guy", "in", "yellow", "is", "rolling", "on", "the", "grass", ".", "\u201d", ",", "and", "its", "logical", "relationship", "is", "contradiction", ".", "Figure", "[", "reference", "]", "indicates", "the", "model", "\u2019s", "ability", "in", "attending", "to", "critical", "pairs", "of", "words", "like", "Male", ",", "guy", ",", "decides", ",", "rolling", ",", "and", "lay", ",", "rolling", ".", "Finally", ",", "high", "attention", "between", "{", "decides", ",", "lay", "}", "and", "{", "rolling", "}", ",", "and", "{", "Male", "}", "and", "{", "guy", "}", "leads", "the", "model", "to", "correctly", "classify", "the", "sentence", "pair", "as", "contradiction", "(", "for", "more", "samples", "with", "attention", "visualizations", ",", "see", "Section", "[", "reference", "]", "of", "the", "Appendix", ")", ".", "section", ":", "Conclusion", "We", "propose", "a", "novel", "natural", "language", "inference", "model", "(", "DR", "-", "BiLSTM", ")", "that", "benefits", "from", "a", "dependent", "reading", "strategy", "and", "achieves", "the", "state", "-", "of", "-", "the", "-", "art", "results", "on", "the", "SNLI", "dataset", ".", "We", "also", "introduce", "a", "sophisticated", "ensemble", "strategy", "and", "illustrate", "its", "effectiveness", "through", "experimentation", ".", "Moreover", ",", "we", "demonstrate", "the", "importance", "of", "a", "simple", "preprocessing", "step", "on", "the", "performance", "of", "our", "proposed", "models", ".", "Evaluation", "results", "show", "that", "the", "preprocessing", "step", "allows", "our", "DR", "-", "BiLSTM", "(", "single", ")", "model", "to", "outperform", "all", "previous", "single", "and", "ensemble", "methods", ".", "Similar", "superior", "performance", "is", "also", "observed", "for", "our", "DR", "-", "BiLSTM", "(", "ensemble", ")", "model", ".", "We", "show", "that", "our", "ensemble", "model", "outperforms", "the", "existing", "state", "-", "of", "-", "the", "-", "art", "by", "a", "considerable", "margin", "of", ".", "Finally", ",", "we", "perform", "an", "extensive", "analysis", "to", "demonstrate", "the", "strength", "and", "weakness", "of", "the", "proposed", "model", ",", "which", "would", "pave", "the", "way", "for", "further", "improvements", "in", "this", "domain", ".", "bibliography", ":", "References", "appendix", ":", "Ensemble", "Strategy", "Study", "We", "use", "the", "following", "configurations", "in", "our", "ensemble", "model", "study", ":", "DR", "-", "BiLSTM", "(", "with", "different", "initialization", "seeds", ")", ":", "here", ",", "we", "consider", "6", "DR", "-", "BiLSTMs", "with", "different", "initialization", "seeds", ".", "tanh", "-", "Projection", ":", "same", "configuration", "as", "DR", "-", "BiLSTM", ",", "but", "we", "use", "tanh", "instead", "of", "ReLU", "as", "the", "activation", "function", "in", "Equations", "[", "reference", "]", "and", "[", "reference", "]", "in", "the", "paper", ":", "DR", "-", "BiLSTM", "(", "with", "1", "round", "of", "dependent", "reading", ")", ":", "same", "configuration", "as", "DR", "-", "BiLSTM", ",", "but", "we", "do", "not", "use", "dependent", "reading", "during", "the", "inference", "process", ".", "In", "other", "words", ",", "we", "use", "and", "instead", "of", "Equations", "[", "reference", "]", "and", "[", "reference", "]", "in", "the", "paper", "respectively", ".", "DR", "-", "BiLSTM", "(", "with", "3", "rounds", "of", "dependent", "reading", ")", ":", "same", "configuration", "as", "the", "above", ",", "but", "we", "use", "3", "rounds", "of", "dependent", "reading", ".", "Formally", ",", "we", "replace", "Equations", "[", "reference", "]", "and", "[", "reference", "]", "in", "the", "paper", "with", "the", "following", "equations", "respectively", ":", "Our", "final", "ensemble", "model", ",", "DR", "-", "BiLSTM", "(", "Ensemble", ")", "is", "the", "combination", "of", "the", "following", "6", "models", ":", "tanh", "-", "Projection", ",", "DR", "-", "BiLSTM", "(", "with", "1", "round", "of", "dependent", "reading", ")", ",", "DR", "-", "BiLSTM", "(", "with", "3", "rounds", "of", "dependent", "reading", ")", ",", "and", "3", "DR", "-", "BiLSTMs", "with", "different", "initialization", "seeds", ".", "We", "also", "experiment", "with", "majority", "voting", "and", "averaging", "the", "probability", "distribution", "strategies", "for", "ensemble", "models", "using", "the", "same", "set", "of", "models", "as", "our", "weighted", "averaging", "ensemble", "method", "(", "as", "described", "above", ")", ".", "Figure", "[", "reference", "]", "shows", "the", "behavior", "of", "the", "majority", "voting", "strategy", "with", "different", "number", "of", "models", ".", "Interestingly", ",", "the", "best", "development", "accuracy", "is", "also", "observed", "using", "6", "individual", "models", "including", "tanh", "-", "Projection", ",", "DR", "-", "BiLSTM", "(", "with", "1", "round", "of", "dependent", "reading", ")", ",", "DR", "-", "BiLSTM", "(", "with", "3", "rounds", "of", "dependent", "reading", ")", ",", "and", "3", "DR", "-", "BiLSTMs", "with", "varying", "initialization", "seeds", "that", "are", "different", "from", "our", "DR", "-", "BiLSTM", "(", "Ensemble", ")", "model", ".", "We", "should", "note", "that", "our", "weighted", "averaging", "ensemble", "strategy", "performs", "better", "than", "the", "majority", "voting", "method", "in", "both", "development", "set", "and", "test", "set", "of", "SNLI", ",", "which", "indicates", "the", "effectiveness", "of", "our", "approach", ".", "Furthermore", ",", "our", "method", "could", "show", "more", "consistent", "behavior", "for", "training", "and", "test", "sets", "when", "we", "increased", "the", "number", "of", "models", "(", "see", "Figure", "[", "reference", "]", "in", "Section", "[", "reference", "]", "of", "the", "paper", ")", ".", "According", "to", "our", "observations", ",", "averaging", "the", "probability", "distributions", "fails", "to", "improve", "the", "development", "set", "accuracy", "using", "two", "and", "three", "models", ",", "so", "we", "did", "not", "study", "it", "further", ".", "appendix", ":", "Preprocessing", "Study", "Table", "[", "reference", "]", "shows", "some", "erroneous", "sentences", "from", "the", "SNLI", "test", "set", "along", "with", "their", "corrected", "equivalents", "(", "after", "preprocessing", ")", ".", "Furthermore", ",", "we", "show", "the", "energy", "function", "(", "Equation", "[", "reference", "]", "in", "the", "paper", ")", "visualizations", "of", "6", "examples", "from", "the", "aforementioned", "data", "samples", "in", "Figures", "[", "reference", "]", ",", "[", "reference", "]", ",", "[", "reference", "]", ",", "[", "reference", "]", ",", "[", "reference", "]", ",", "and", "[", "reference", "]", ".", "Each", "figure", "presents", "the", "visualization", "of", "an", "original", "erroneous", "sample", "along", "its", "corrected", "version", ".", "These", "figures", "clearly", "illustrate", "that", "fixing", "the", "erroneous", "words", "leads", "to", "producing", "correct", "attentions", "over", "the", "sentences", ".", "This", "can", "be", "observed", "by", "comparing", "the", "attention", "for", "the", "erroneous", "words", "and", "corrected", "words", ",", "e.g.", "\u201c", "daschunds", "\u201d", "and", "\u201c", "dachshunds", "\u201d", "in", "the", "premise", "of", "Figures", "[", "reference", "]", "and", "[", "reference", "]", ".", "Note", "that", "we", "add", "two", "dummy", "notations", "(", "i.e.", "_", "FOL", "_", ",", "and", "_", "EOL", "_", ")", "to", "all", "sentences", "which", "indicate", "their", "beginning", "and", "end", ".", "appendix", ":", "Category", "Study", "Here", "we", "investigate", "the", "normalized", "attention", "weights", "of", "DR", "-", "BiLSTM", "and", "ESIM", "for", "four", "samples", "that", "belong", "to", "Negation", "and", "/", "or", "Quantifier", "categories", "(", "Figures", "[", "reference", "]", "-", "[", "reference", "]", ")", ".", "Each", "figure", "illustrates", "the", "normalized", "energy", "function", "of", "DR", "-", "BiLSTM", "(", "left", "diagram", ")", "and", "ESIM", "(", "right", "diagram", ")", "respectively", ".", "Provided", "figures", "indicate", "that", "ESIM", "assigns", "somewhat", "similar", "attention", "to", "most", "of", "the", "pairs", "while", "DR", "-", "BiLSTM", "focuses", "on", "specific", "parts", "of", "the", "given", "premise", "and", "hypothesis", ".", "appendix", ":", "Attention", "Study", "In", "this", "section", ",", "we", "show", "visualizations", "of", "18", "samples", "of", "normalized", "attention", "weights", "(", "energy", "function", ",", "see", "Equation", "[", "reference", "]", "in", "the", "paper", ")", ".", "Each", "column", "in", "Figures", "[", "reference", "]", ",", "[", "reference", "]", ",", "and", "[", "reference", "]", ",", "represents", "three", "data", "samples", "that", "share", "the", "same", "premise", "but", "differ", "in", "hypothesis", ".", "Also", ",", "each", "row", "is", "allocated", "to", "a", "specific", "logical", "relationship", "(", "Top", ":", "Entailment", ",", "Middle", ":", "Neutral", ",", "and", "Bottom", ":", "Contradiction", ")", ".", "DR", "-", "BiLSTM", "classifies", "all", "data", "samples", "reported", "in", "these", "figures", "correctly", "."]}