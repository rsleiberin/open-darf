{"coref": {"Accuracy": [[359, 360], [938, 939], [1091, 1092], [2416, 2417], [2522, 2523], [2549, 2550], [2597, 2598], [3008, 3009], [3217, 3218], [3237, 3240], [3360, 3361], [3862, 3863], [3875, 3876], [3946, 3947], [4025, 4026], [4203, 4204], [4388, 4389], [4478, 4479], [4498, 4499], [4552, 4553], [4564, 4565], [4700, 4701], [197, 198], [1194, 1195], [2402, 2403], [3764, 3765]], "Meta_BiLSTM": [[4, 8], [552, 554], [2047, 2050], [3720, 3721], [3837, 3840], [4107, 4108]], "Part-Of-Speech_Tagging": [[169, 174], [175, 177], [654, 659], [660, 662], [846, 847], [1078, 1079], [1285, 1287], [2972, 2976], [2977, 2979], [3078, 3084], [3295, 3301], [3380, 3382], [3388, 3390], [3557, 3559], [3814, 3815], [3895, 3897], [4145, 4149], [4674, 4676], [1192, 1194], [3023, 3028], [3100, 3105], [3527, 3532], [4267, 4272]], "Penn_Treebank": [[696, 699], [3309, 3311]]}, "coref_non_salient": {"0": [[3043, 3044], [3884, 3887]], "1": [[2809, 2812], [3961, 3962]], "10": [[278, 283], [1800, 1804]], "100": [[151, 153]], "101": [[476, 478], [789, 791]], "102": [[2019, 2022]], "103": [[155, 158]], "104": [[304, 310]], "105": [[4340, 4344]], "106": [[3052, 3053]], "107": [[1113, 1115]], "108": [[2310, 2313]], "109": [[379, 386]], "11": [[9, 13], [219, 225], [1582, 1586], [4220, 4223]], "110": [[1517, 1522]], "111": [[3213, 3215]], "112": [[1716, 1718]], "113": [[540, 545]], "114": [[1085, 1087]], "12": [[33, 38], [2835, 2837]], "13": [[4064, 4068], [4128, 4132], [4157, 4161], [4208, 4212], [4601, 4605], [4649, 4653]], "14": [[4136, 4138], [4152, 4154]], "15": [[567, 569], [3373, 3375], [3434, 3437]], "16": [[634, 639], [1202, 1206], [2683, 2688], [2872, 2876], [3121, 3125], [3146, 3150], [3457, 3461], [3669, 3673]], "17": [[2644, 2646], [4440, 4442], [4575, 4577]], "18": [[479, 485], [535, 537], [736, 740], [1211, 1213]], "19": [[2838, 2840], [4056, 4058]], "2": [[72, 77], [261, 267], [1229, 1233]], "20": [[3857, 3859], [3866, 3869]], "21": [[1322, 1327], [1390, 1395], [1404, 1406], [1791, 1796], [1808, 1810], [1825, 1830], [3596, 3601], [3723, 3728], [3841, 3843], [3974, 3979], [4045, 4050], [4430, 4432]], "22": [[3613, 3614], [4089, 4090]], "23": [[2031, 2033], [2197, 2199], [2460, 2464]], "24": [[1729, 1730], [3004, 3006]], "25": [[3844, 3846], [4312, 4314], [4382, 4386], [4434, 4436], [4510, 4514]], "26": [[3710, 3712], [3742, 3743], [3759, 3760], [3792, 3793]], "27": [[3366, 3367], [3474, 3475]], "28": [[4678, 4683]], "29": [[4236, 4239]], "3": [[147, 150], [237, 241], [325, 329], [410, 416]], "30": [[4216, 4218]], "31": [[1346, 1347], [2824, 2825], [4379, 4380], [1027, 1028], [1075, 1076], [1238, 1239], [1442, 1443], [1453, 1454], [1850, 1851], [4470, 4471]], "32": [[128, 134], [2258, 2265]], "33": [[2390, 2392], [2457, 2459]], "34": [[1254, 1256], [1861, 1863]], "35": [[3834, 3836]], "36": [[3630, 3631], [3641, 3642]], "37": [[64, 69], [1051, 1054], [1129, 1132]], "38": [[750, 751], [1095, 1097]], "39": [[4488, 4490]], "4": [[2731, 2733], [2921, 2923], [4353, 4355]], "40": [[4637, 4640]], "41": [[4228, 4230]], "42": [[3615, 3618]], "43": [[3611, 3612]], "44": [[24, 27], [118, 121], [206, 209], [1116, 1119]], "45": [[19, 21], [843, 845]], "46": [[293, 295], [1247, 1249]], "47": [[2176, 2180]], "48": [[3502, 3503], [3506, 3507]], "49": [[252, 256], [1221, 1225]], "5": [[211, 212], [333, 334], [1138, 1139], [1463, 1465], [1978, 1980], [2171, 2172], [454, 455], [1494, 1495], [2077, 2078], [2131, 2132], [2143, 2144], [2282, 2283], [2385, 2386], [2423, 2424], [2452, 2453], [2501, 2502], [2527, 2528], [2560, 2561], [4121, 4122], [4611, 4612], [4659, 4660], [4690, 4691]], "50": [[3302, 3303], [3265, 3266]], "51": [[1342, 1345]], "52": [[1705, 1706], [2008, 2009], [2187, 2188]], "53": [[3284, 3285]], "54": [[2924, 2926], [3789, 3791]], "55": [[3288, 3290]], "56": [[3500, 3501]], "57": [[2372, 2381]], "58": [[2934, 2936]], "59": [[1250, 1251]], "6": [[3871, 3872], [3898, 3900], [3901, 3903]], "60": [[2711, 2713]], "61": [[4104, 4106]], "62": [[894, 904]], "63": [[4527, 4528]], "64": [[3032, 3033], [2986, 2987]], "65": [[2051, 2053]], "66": [[854, 856], [1031, 1035], [1047, 1049], [1126, 1128]], "67": [[2785, 2787]], "68": [[2790, 2792]], "69": [[721, 722], [3608, 3609]], "7": [[3286, 3287], [3291, 3292]], "70": [[708, 714]], "71": [[2331, 2333]], "72": [[2510, 2512]], "73": [[98, 100], [391, 393], [994, 996]], "74": [[3633, 3636]], "75": [[366, 370], [2904, 2907], [3397, 3401], [3539, 3543]], "76": [[4074, 4076]], "77": [[873, 875]], "78": [[3504, 3505], [4357, 4358]], "79": [[4351, 4352]], "8": [[1570, 1572], [1588, 1590], [1931, 1933], [2039, 2042], [2055, 2057], [2110, 2118], [2161, 2165], [4539, 4541], [4542, 4544], [4684, 4686], [54, 56], [340, 342], [1143, 1145], [1360, 1362], [1927, 1929], [4284, 4286]], "80": [[3602, 3603]], "81": [[3623, 3625]], "82": [[0, 2]], "83": [[1734, 1736]], "84": [[3967, 3968]], "85": [[1702, 1704]], "86": [[557, 559]], "87": [[917, 920]], "88": [[1726, 1728]], "89": [[2997, 2998]], "9": [[1913, 1918], [4028, 4033], [4036, 4040], [4095, 4100], [4110, 4115]], "90": [[4070, 4073]], "91": [[2296, 2297]], "92": [[2830, 2832]], "93": [[970, 973]], "94": [[1178, 1183]], "95": [[1088, 1090]], "96": [[760, 765]], "97": [[747, 749]], "98": [[2194, 2196]], "99": [[2769, 2770]]}, "doc_id": "1e5b9e512c01e244287fe7afb05e03c96d5c1cd0", "method_subrelations": {"Meta_BiLSTM": [[[0, 11], "Meta_BiLSTM"]]}, "n_ary_relations": [{"Material": "Penn_Treebank", "Method": "Meta_BiLSTM", "Metric": "Accuracy", "Task": "Part-Of-Speech_Tagging", "score": "97.96"}], "ner": [[0, 2, "Method"], [4, 8, "Method"], [9, 13, "Method"], [19, 21, "Method"], [24, 27, "Method"], [33, 38, "Metric"], [64, 69, "Method"], [72, 77, "Method"], [98, 100, "Method"], [118, 121, "Method"], [128, 134, "Method"], [147, 150, "Method"], [151, 153, "Method"], [155, 158, "Method"], [169, 174, "Task"], [175, 177, "Task"], [206, 209, "Method"], [211, 212, "Method"], [219, 225, "Method"], [237, 241, "Method"], [252, 256, "Method"], [261, 267, "Method"], [278, 283, "Method"], [293, 295, "Method"], [304, 310, "Method"], [325, 329, "Method"], [333, 334, "Method"], [359, 360, "Metric"], [366, 370, "Task"], [379, 386, "Method"], [391, 393, "Method"], [410, 416, "Method"], [476, 478, "Method"], [479, 485, "Method"], [535, 537, "Method"], [540, 545, "Method"], [552, 554, "Method"], [557, 559, "Method"], [567, 569, "Task"], [634, 639, "Material"], [654, 659, "Task"], [660, 662, "Task"], [696, 699, "Material"], [708, 714, "Metric"], [721, 722, "Metric"], [736, 740, "Method"], [747, 749, "Method"], [750, 751, "Task"], [760, 765, "Method"], [789, 791, "Method"], [843, 845, "Method"], [846, 847, "Task"], [854, 856, "Method"], [873, 875, "Task"], [894, 904, "Method"], [917, 920, "Task"], [938, 939, "Metric"], [970, 973, "Task"], [994, 996, "Method"], [1031, 1035, "Method"], [1047, 1049, "Method"], [1051, 1054, "Method"], [1078, 1079, "Task"], [1085, 1087, "Method"], [1088, 1090, "Method"], [1091, 1092, "Metric"], [1095, 1097, "Task"], [1113, 1115, "Method"], [1116, 1119, "Method"], [1126, 1128, "Method"], [1129, 1132, "Method"], [1138, 1139, "Method"], [1178, 1183, "Method"], [1202, 1206, "Material"], [1211, 1213, "Method"], [1221, 1225, "Method"], [1229, 1233, "Method"], [1247, 1249, "Method"], [1250, 1251, "Method"], [1254, 1256, "Method"], [1285, 1287, "Task"], [1322, 1327, "Method"], [1342, 1345, "Method"], [1346, 1347, "Method"], [1390, 1395, "Method"], [1404, 1406, "Method"], [1463, 1465, "Method"], [1517, 1522, "Method"], [1570, 1572, "Method"], [1582, 1586, "Method"], [1588, 1590, "Method"], [1702, 1704, "Method"], [1705, 1706, "Method"], [1716, 1718, "Method"], [1726, 1728, "Method"], [1729, 1730, "Method"], [1734, 1736, "Method"], [1791, 1796, "Method"], [1800, 1804, "Method"], [1808, 1810, "Method"], [1825, 1830, "Method"], [1861, 1863, "Method"], [1913, 1918, "Method"], [1931, 1933, "Method"], [1978, 1980, "Method"], [2008, 2009, "Method"], [2019, 2022, "Method"], [2031, 2033, "Task"], [2039, 2042, "Method"], [2047, 2050, "Method"], [2051, 2053, "Method"], [2055, 2057, "Method"], [2110, 2118, "Method"], [2161, 2165, "Method"], [2171, 2172, "Method"], [2176, 2180, "Method"], [2187, 2188, "Method"], [2194, 2196, "Method"], [2197, 2199, "Task"], [2258, 2265, "Method"], [2296, 2297, "Method"], [2310, 2313, "Method"], [2331, 2333, "Method"], [2372, 2381, "Task"], [2390, 2392, "Task"], [2416, 2417, "Metric"], [2457, 2459, "Task"], [2460, 2464, "Task"], [2510, 2512, "Method"], [2522, 2523, "Metric"], [2549, 2550, "Metric"], [2597, 2598, "Metric"], [2644, 2646, "Method"], [2683, 2688, "Material"], [2711, 2713, "Method"], [2731, 2733, "Method"], [2769, 2770, "Method"], [2785, 2787, "Method"], [2790, 2792, "Method"], [2809, 2812, "Method"], [2824, 2825, "Method"], [2830, 2832, "Method"], [2835, 2837, "Metric"], [2838, 2840, "Metric"], [2872, 2876, "Material"], [2904, 2907, "Task"], [2921, 2923, "Method"], [2924, 2926, "Task"], [2934, 2936, "Task"], [2972, 2976, "Task"], [2977, 2979, "Task"], [2997, 2998, "Task"], [3004, 3006, "Method"], [3008, 3009, "Metric"], [3032, 3033, "Method"], [3043, 3044, "Task"], [3052, 3053, "Method"], [3078, 3084, "Task"], [3121, 3125, "Material"], [3146, 3150, "Material"], [3213, 3215, "Method"], [3217, 3218, "Metric"], [3237, 3240, "Metric"], [3284, 3285, "Material"], [3286, 3287, "Material"], [3288, 3290, "Material"], [3291, 3292, "Material"], [3295, 3301, "Task"], [3302, 3303, "Material"], [3309, 3311, "Material"], [3360, 3361, "Metric"], [3366, 3367, "Metric"], [3373, 3375, "Task"], [3380, 3382, "Task"], [3388, 3390, "Task"], [3397, 3401, "Task"], [3434, 3437, "Task"], [3457, 3461, "Material"], [3474, 3475, "Metric"], [3500, 3501, "Material"], [3502, 3503, "Material"], [3504, 3505, "Material"], [3506, 3507, "Material"], [3539, 3543, "Task"], [3557, 3559, "Task"], [3596, 3601, "Method"], [3602, 3603, "Method"], [3608, 3609, "Metric"], [3611, 3612, "Method"], [3613, 3614, "Method"], [3615, 3618, "Method"], [3623, 3625, "Method"], [3630, 3631, "Method"], [3633, 3636, "Method"], [3641, 3642, "Method"], [3669, 3673, "Material"], [3710, 3712, "Task"], [3720, 3721, "Method"], [3723, 3728, "Method"], [3742, 3743, "Task"], [3759, 3760, "Task"], [3789, 3791, "Task"], [3792, 3793, "Task"], [3814, 3815, "Task"], [3834, 3836, "Method"], [3837, 3840, "Method"], [3841, 3843, "Method"], [3844, 3846, "Method"], [3857, 3859, "Method"], [3862, 3863, "Metric"], [3866, 3869, "Method"], [3871, 3872, "Method"], [3875, 3876, "Metric"], [3884, 3887, "Task"], [3895, 3897, "Task"], [3898, 3900, "Method"], [3901, 3903, "Method"], [3946, 3947, "Metric"], [3961, 3962, "Method"], [3967, 3968, "Task"], [3974, 3979, "Method"], [4025, 4026, "Metric"], [4028, 4033, "Method"], [4036, 4040, "Method"], [4045, 4050, "Method"], [4056, 4058, "Metric"], [4064, 4068, "Method"], [4070, 4073, "Task"], [4074, 4076, "Task"], [4089, 4090, "Method"], [4095, 4100, "Method"], [4104, 4106, "Method"], [4107, 4108, "Method"], [4110, 4115, "Method"], [4128, 4132, "Method"], [4136, 4138, "Method"], [4145, 4149, "Task"], [4152, 4154, "Method"], [4157, 4161, "Method"], [4203, 4204, "Metric"], [4208, 4212, "Method"], [4216, 4218, "Method"], [4220, 4223, "Method"], [4228, 4230, "Method"], [4236, 4239, "Method"], [4312, 4314, "Method"], [4340, 4344, "Method"], [4351, 4352, "Metric"], [4353, 4355, "Method"], [4357, 4358, "Material"], [4379, 4380, "Method"], [4382, 4386, "Method"], [4388, 4389, "Metric"], [4430, 4432, "Method"], [4434, 4436, "Method"], [4440, 4442, "Method"], [4478, 4479, "Metric"], [4488, 4490, "Task"], [4498, 4499, "Metric"], [4510, 4514, "Method"], [4527, 4528, "Method"], [4539, 4541, "Method"], [4542, 4544, "Method"], [4552, 4553, "Metric"], [4564, 4565, "Metric"], [4575, 4577, "Method"], [4601, 4605, "Method"], [4637, 4640, "Method"], [4649, 4653, "Method"], [4674, 4676, "Task"], [4678, 4683, "Method"], [4684, 4686, "Method"], [4700, 4701, "Metric"], [54, 56, "Method"], [197, 198, "Metric"], [340, 342, "Method"], [454, 455, "Method"], [1027, 1028, "Method"], [1075, 1076, "Method"], [1143, 1145, "Method"], [1192, 1194, "Task"], [1194, 1195, "Metric"], [1238, 1239, "Method"], [1360, 1362, "Method"], [1442, 1443, "Method"], [1453, 1454, "Method"], [1494, 1495, "Method"], [1850, 1851, "Method"], [1927, 1929, "Method"], [2077, 2078, "Method"], [2131, 2132, "Method"], [2143, 2144, "Method"], [2282, 2283, "Method"], [2385, 2386, "Method"], [2402, 2403, "Metric"], [2423, 2424, "Method"], [2452, 2453, "Method"], [2501, 2502, "Method"], [2527, 2528, "Method"], [2560, 2561, "Method"], [2986, 2987, "Method"], [3023, 3028, "Task"], [3100, 3105, "Task"], [3265, 3266, "Material"], [3527, 3532, "Task"], [3764, 3765, "Metric"], [4121, 4122, "Method"], [4267, 4272, "Task"], [4284, 4286, "Method"], [4470, 4471, "Method"], [4611, 4612, "Method"], [4659, 4660, "Method"], [4690, 4691, "Method"]], "sections": [[0, 13], [13, 192], [192, 731], [731, 1300], [1300, 1320], [1320, 1789], [1789, 1911], [1911, 2045], [2045, 2246], [2246, 2657], [2657, 2699], [2699, 2855], [2855, 3076], [3076, 3293], [3293, 3371], [3371, 3708], [3708, 3820], [3820, 3969], [3969, 4214], [4214, 4666], [4666, 4708], [4708, 4710], [4710, 4766], [4766, 4768]], "sentences": [[0, 13], [13, 16], [16, 38], [38, 57], [57, 78], [78, 109], [109, 135], [135, 165], [165, 192], [192, 195], [195, 228], [228, 303], [303, 312], [312, 350], [350, 370], [370, 374], [374, 394], [394, 410], [410, 448], [448, 470], [470, 499], [499, 522], [522, 546], [546, 570], [570, 605], [605, 627], [627, 663], [663, 688], [688, 731], [731, 735], [735, 770], [770, 801], [801, 835], [835, 848], [848, 871], [871, 905], [905, 949], [949, 989], [989, 1012], [1012, 1036], [1036, 1068], [1068, 1080], [1080, 1098], [1098, 1120], [1120, 1146], [1146, 1171], [1171, 1206], [1206, 1261], [1261, 1271], [1271, 1300], [1300, 1303], [1303, 1320], [1320, 1327], [1327, 1363], [1363, 1386], [1386, 1403], [1403, 1417], [1417, 1438], [1438, 1466], [1466, 1493], [1493, 1496], [1496, 1523], [1523, 1548], [1548, 1568], [1568, 1587], [1587, 1610], [1610, 1668], [1668, 1685], [1685, 1708], [1708, 1731], [1731, 1747], [1747, 1783], [1783, 1789], [1789, 1796], [1796, 1841], [1841, 1874], [1874, 1885], [1885, 1911], [1911, 1918], [1918, 1934], [1934, 1940], [1940, 1951], [1951, 2009], [2009, 2045], [2045, 2053], [2053, 2099], [2099, 2139], [2139, 2181], [2181, 2200], [2200, 2222], [2222, 2241], [2241, 2246], [2246, 2250], [2250, 2284], [2284, 2302], [2302, 2326], [2326, 2338], [2338, 2365], [2365, 2387], [2387, 2416], [2416, 2437], [2437, 2465], [2465, 2521], [2521, 2544], [2544, 2552], [2552, 2585], [2585, 2599], [2599, 2622], [2622, 2634], [2634, 2657], [2657, 2662], [2662, 2699], [2699, 2703], [2703, 2719], [2719, 2728], [2728, 2756], [2756, 2769], [2769, 2789], [2789, 2809], [2809, 2812], [2812, 2826], [2826, 2855], [2855, 2859], [2859, 2876], [2876, 2896], [2896, 2908], [2908, 2927], [2927, 2945], [2945, 2964], [2964, 2999], [2999, 3016], [3016, 3042], [3042, 3076], [3076, 3085], [3085, 3107], [3107, 3132], [3132, 3151], [3151, 3164], [3164, 3190], [3190, 3206], [3206, 3222], [3222, 3249], [3249, 3257], [3257, 3263], [3263, 3269], [3269, 3293], [3293, 3303], [3303, 3323], [3323, 3345], [3345, 3371], [3371, 3376], [3376, 3391], [3391, 3399], [3399, 3419], [3419, 3438], [3438, 3444], [3444, 3480], [3480, 3515], [3515, 3566], [3566, 3613], [3613, 3619], [3619, 3652], [3652, 3674], [3674, 3691], [3691, 3708], [3708, 3712], [3712, 3736], [3736, 3753], [3753, 3771], [3771, 3792], [3792, 3820], [3820, 3827], [3827, 3852], [3852, 3870], [3870, 3898], [3898, 3924], [3924, 3967], [3967, 3969], [3969, 3979], [3979, 4004], [4004, 4016], [4016, 4024], [4024, 4051], [4051, 4077], [4077, 4116], [4116, 4124], [4124, 4141], [4141, 4172], [4172, 4193], [4193, 4214], [4214, 4223], [4223, 4255], [4255, 4287], [4287, 4295], [4295, 4323], [4323, 4331], [4331, 4351], [4351, 4355], [4355, 4393], [4393, 4417], [4417, 4454], [4454, 4480], [4480, 4515], [4515, 4529], [4529, 4581], [4581, 4614], [4614, 4629], [4629, 4666], [4666, 4669], [4669, 4708], [4708, 4710], [4710, 4713], [4713, 4766], [4766, 4768]], "words": ["Morphosyntactic", "Tagging", "with", "a", "Meta", "-", "BiLSTM", "Model", "over", "Context", "Sensitive", "Token", "Encodings", "section", ":", "Abstract", "The", "rise", "of", "neural", "networks", ",", "and", "particularly", "recurrent", "neural", "networks", ",", "has", "produced", "significant", "advances", "in", "part", "-", "ofspeech", "tagging", "accuracy", "[", "reference", "]", ".", "One", "characteristic", "common", "among", "these", "models", "is", "the", "presence", "of", "rich", "initial", "word", "encodings", ".", "These", "encodings", "typically", "are", "composed", "of", "a", "recurrent", "character", "-", "based", "representation", "with", "learned", "and", "pre", "-", "trained", "word", "embeddings", ".", "However", ",", "these", "encodings", "do", "not", "consider", "a", "context", "wider", "than", "a", "single", "word", "and", "it", "is", "only", "through", "subsequent", "recurrent", "layers", "that", "word", "or", "sub", "-", "word", "information", "interacts", ".", "In", "this", "paper", ",", "we", "investigate", "models", "that", "use", "recurrent", "neural", "networks", "with", "sentence", "-", "level", "context", "for", "initial", "character", "and", "word", "-", "based", "representations", ".", "In", "particular", "we", "show", "that", "optimal", "results", "are", "obtained", "by", "integrating", "these", "context", "sensitive", "representations", "through", "synchronized", "training", "with", "a", "meta", "-", "model", "that", "learns", "to", "combine", "their", "states", ".", "We", "present", "results", "on", "part", "-", "of", "-", "speech", "and", "morphological", "tagging", "with", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "a", "number", "of", "languages", ".", "section", ":", "Introduction", "Morphosyntactic", "tagging", "accuracy", "has", "seen", "dramatic", "improvements", "through", "the", "adoption", "of", "recurrent", "neural", "networks", "-", "specifically", "BiLSTMs", "[", "reference", "][", "reference", "]", "to", "create", "sentence", "-", "level", "context", "sensitive", "encodings", "of", "words", ".", "A", "successful", "recipe", "is", "to", "first", "create", "an", "initial", "context", "insensitive", "word", "representation", ",", "which", "usually", "has", "three", "main", "parts", ":", "1", ")", "A", "dynamically", "trained", "word", "embedding", ";", "2", ")", "a", "fixed", "pre", "-", "trained", "word", "-", "embedding", ",", "induced", "from", "a", "large", "corpus", ";", "and", "3", ")", "a", "sub", "-", "word", "character", "model", ",", "which", "itself", "is", "usually", "the", "final", "state", "of", "a", "recurrent", "model", "that", "ingests", "one", "character", "at", "a", "time", ".", "Such", "word", "/", "sub", "-", "word", "models", "originated", "with", "[", "reference", "]", ".", "Recently", ",", "[", "reference", "]", "used", "precisely", "such", "a", "context", "insensitive", "word", "representation", "as", "input", "to", "a", "BiLSTM", "in", "order", "to", "obtain", "context", "sensitive", "word", "encodings", "used", "to", "predict", "partof", "-", "speech", "tags", ".", "The", "Dozat", "et", "al", ".", "model", "had", "the", "highest", "accuracy", "of", "all", "participating", "systems", "in", "the", "CoNLL", "2017", "shared", "task", "[", "reference", "]", ".", "In", "such", "a", "model", ",", "sub", "-", "word", "character", "-", "based", "representations", "only", "interact", "indirectly", "via", "subsequent", "recurrent", "layers", ".", "For", "example", ",", "consider", "the", "sentence", "I", "had", "shingles", ",", "which", "is", "a", "painful", "disease", ".", "Context", "insensitive", "character", "and", "word", "representations", "may", "have", "learned", "that", "for", "unknown", "or", "infrequent", "words", "like", "'", "shingles", "'", ",", "'s", "'", "and", "more", "so", "'", "es", "'", "is", "a", "common", "way", "to", "end", "a", "plural", "noun", ".", "It", "is", "up", "to", "the", "subsequent", "BiLSTM", "layer", "to", "override", "this", "once", "it", "sees", "the", "singular", "verb", "is", "to", "the", "right", ".", "Note", "that", "this", "differs", "from", "traditional", "linear", "models", "where", "word", "and", "sub", "-", "word", "representations", "are", "directly", "concatenated", "with", "similar", "features", "in", "the", "surrounding", "context", "[", "reference", "]", ".", "In", "this", "paper", "we", "aim", "to", "investigate", "to", "what", "extent", "having", "initial", "sub", "-", "word", "and", "word", "context", "insensitive", "representations", "affects", "performance", ".", "We", "propose", "a", "novel", "model", "where", "we", "learn", "context", "sensitive", "initial", "character", "and", "word", "representations", "through", "two", "separate", "sentence", "-", "level", "recurrent", "models", ".", "These", "are", "then", "combined", "via", "a", "metaBiLSTM", "model", "that", "builds", "a", "unified", "representation", "of", "each", "word", "that", "is", "then", "used", "for", "syntactic", "tagging", ".", "Critically", ",", "while", "each", "of", "these", "three", "models", "-", "character", ",", "word", "and", "meta", "-", "are", "trained", "synchronously", ",", "they", "are", "ultimately", "separate", "models", "using", "different", "network", "configurations", ",", "training", "hyperparameters", "and", "loss", "functions", ".", "Empirically", ",", "we", "found", "this", "optimal", "as", "it", "allowed", "control", "over", "the", "fact", "that", "each", "representation", "has", "a", "different", "learning", "capacity", ".", "We", "tested", "the", "system", "on", "the", "2017", "CoNLL", "shared", "task", "data", "sets", "and", "gain", "improvements", "compared", "to", "the", "top", "performing", "systems", "for", "the", "majority", "of", "languages", "for", "part", "-", "of", "-", "speech", "and", "morphological", "tagging", ".", "As", "we", "will", "see", ",", "a", "pattern", "emerged", "where", "gains", "were", "largest", "for", "morphologically", "rich", "languages", ",", "especially", "those", "in", "the", "Slavic", "family", "group", ".", "We", "also", "applied", "the", "approach", "to", "the", "benchmark", "English", "PTB", "data", ",", "where", "our", "model", "achieved", "97.9", "using", "the", "standard", "train", "/", "dev", "/", "test", "split", ",", "which", "constitutes", "a", "relative", "reduction", "in", "error", "of", "12", "%", "over", "the", "previous", "best", "system", ".", "section", ":", "Related", "Work", "While", "sub", "-", "word", "representations", "are", "often", "attributed", "to", "the", "advent", "of", "deep", "learning", "in", "NLP", ",", "it", "was", ",", "in", "fact", ",", "commonplace", "for", "linear", "featurized", "machine", "learning", "methods", "to", "incorporate", "such", "representations", ".", "While", "the", "literature", "is", "too", "large", "to", "enumerate", ",", "[", "reference", "]", "is", "a", "good", "example", "of", "an", "accurate", "linear", "model", "that", "uses", "both", "word", "and", "sub", "-", "word", "features", ".", "Specifically", ",", "like", "most", "systems", "of", "the", "time", ",", "they", "use", "ngram", "affix", "features", ",", "which", "were", "made", "context", "sensitive", "via", "manually", "constructed", "conjunctions", "with", "features", "from", "other", "words", "in", "a", "fixed", "window", ".", "[", "reference", "]", "was", "perhaps", "the", "first", "modern", "neural", "network", "for", "tagging", ".", "While", "this", "first", "study", "used", "only", "word", "embeddings", ",", "a", "subsequent", "model", "extended", "the", "representation", "to", "include", "suffix", "embeddings", "[", "reference", "]", ".", "The", "seminal", "dependency", "parsing", "paper", "of", "[", "reference", "]", "led", "to", "a", "number", "of", "tagging", "papers", "that", "used", "their", "basic", "architecture", "of", "highly", "featurized", "(", "and", "embedded", ")", "feed", "-", "forward", "neural", "networks", ".", "[", "reference", "]", ",", "for", "example", ",", "studied", "this", "architecture", "in", "a", "low", "resource", "setting", "using", "word", ",", "sub", "-", "word", "(", "prefix", "/", "suffix", ")", "and", "induced", "cluster", "features", "to", "obtain", "competitive", "accuracy", "with", "the", "state", "-", "of", "-", "the", "-", "art", ".", "[", "reference", "]", ",", "[", "reference", "]", "and", "[", "reference", "]", "extended", "the", "work", "of", "Chen", "et", "al", ".", "to", "a", "structured", "prediction", "setting", ",", "the", "later", "two", "use", "again", "a", "mix", "of", "word", "and", "sub", "-", "word", "features", ".", "The", "idea", "of", "using", "a", "recurrent", "layer", "over", "characters", "to", "induce", "a", "complementary", "view", "of", "a", "word", "has", "occurred", "in", "numerous", "papers", ".", "Perhaps", "the", "earliest", "is", "Santos", "and", "Zadrozny", "(", "2014", ")", "who", "compare", "character", "-", "based", "LSTM", "encodings", "to", "traditional", "word", "-", "based", "embeddings", ".", "[", "reference", "]", "take", "this", "a", "step", "further", "and", "combine", "the", "word", "embeddings", "with", "a", "recurrent", "character", "encoding", "of", "the", "word", "-", "instead", "of", "just", "relying", "on", "one", "or", "the", "other", ".", "[", "reference", "]", "use", "a", "sentencelevel", "character", "LSTM", "encoding", "for", "parsing", ".", "[", "reference", "]", "show", "that", "contextual", "embeddings", "using", "character", "convolutions", "improve", "accuracy", "for", "number", "of", "NLP", "tasks", ".", "[", "reference", "]", "is", "probably", "the", "jumping", "-", "off", "point", "for", "most", "current", "architectures", "for", "tagging", "models", "with", "recurrent", "neural", "networks", ".", "Specifically", ",", "they", "used", "a", "combined", "word", "embedding", "and", "recurrent", "character", "encoding", "as", "the", "initial", "input", "to", "a", "BiLSTM", "that", "generated", "context", "sensitive", "word", "encodings", ".", "Though", ",", "like", "most", "previous", "studies", ",", "these", "initial", "encodings", "were", "context", "insensitive", "and", "relied", "on", "subsequent", "layers", "to", "encode", "sentence", "-", "level", "interactions", ".", "Finally", ",", "[", "reference", "]", "showed", "that", "subword", "/", "word", "combination", "representations", "lead", "to", "state", "-", "of", "-", "the", "-", "art", "morphosyntactic", "tagging", "accuracy", "across", "a", "number", "of", "languages", "in", "the", "CoNLL", "2017", "shared", "task", "[", "reference", "]", ".", "Their", "word", "representation", "consisted", "of", "three", "parts", ":", "1", ")", "A", "dynamically", "trained", "word", "embedding", ";", "2", ")", "a", "fixed", "pretrained", "word", "embedding", ";", "3", ")", "a", "character", "LSTM", "encoding", "that", "summed", "the", "final", "state", "of", "the", "recurrent", "model", "with", "vector", "constructed", "using", "an", "attention", "mechanism", "over", "all", "character", "states", ".", "Again", ",", "the", "initial", "representations", "are", "all", "context", "insensitive", ".", "As", "this", "model", "is", "currently", "the", "state", "-", "of", "-", "the", "-", "art", "in", "morphosyntactic", "tagging", ",", "it", "will", "serve", "as", "a", "baseline", "during", "our", "discussion", "and", "experiments", ".", "section", ":", "Models", "In", "this", "section", ",", "we", "introduce", "models", "that", "we", "investigate", "and", "experiment", "with", "in", "\u00a7", "4", ".", "section", ":", "Sentence", "-", "based", "Character", "Model", "The", "feature", "that", "distinguishes", "our", "model", "most", "from", "previous", "work", "is", "that", "we", "apply", "a", "bidirectional", "recurrent", "layer", "(", "LSTM", ")", "on", "all", "characters", "of", "a", "sentence", "to", "induce", "fully", "context", "sensitive", "initial", "word", "encodings", ".", "That", "is", ",", "we", "do", "not", "restrict", "the", "context", "of", "this", "layer", "to", "the", "words", "themselves", "(", "as", "in", "Figure", "1b", ")", ".", "Figure", "1a", "shows", "the", "sentence", "-", "based", "character", "model", "applied", "to", "an", "example", "token", "in", "context", ".", "The", "character", "model", "uses", ",", "as", "input", ",", "sentences", "split", "into", "UTF8", "characters", ".", "We", "include", "the", "spaces", "between", "the", "tokens", "1", "in", "the", "input", "and", "map", "each", "character", "to", "a", "dynamically", "learned", "embedding", ".", "Next", ",", "a", "forward", "LSTM", "reads", "the", "characters", "from", "left", "to", "right", "and", "a", "backward", "LSTM", "reads", "sentences", "from", "right", "to", "left", ",", "in", "standard", "BiLSTM", "fashion", ".", "More", "formally", ",", "for", "an", "n", "-", "character", "sentence", ",", "we", "apply", "for", "each", "character", "embedding", "(", "e", "char", "1", ",", "...", ",", "e", "char", "n", ")", "a", "BiLSTM", ":", "As", "is", "also", "typical", ",", "we", "can", "have", "multiple", "such", "layers", "(", "l", ")", "that", "feed", "into", "each", "other", "through", "the", "concatenation", "of", "previous", "layer", "encodings", ".", "The", "last", "layer", "l", "has", "both", "forward", "(", "f", "l", "c", ",", "1", ",", "...", ",", "f", "l", "c", ",", "n", ")", "and", "backward", "(", "b", "l", "c", ",", "1", ",", "...", ",", "b", "l", "c", ",", "n", ")", "output", "vectors", "for", "each", "character", ".", "To", "create", "word", "encodings", ",", "we", "need", "to", "combine", "a", "relevant", "subset", "of", "these", "context", "sensitive", "character", "encodings", ".", "These", "word", "encodings", "can", "then", "be", "used", "in", "a", "model", "that", "assigns", "morphosyntactic", "tags", "to", "each", "word", "directly", "or", "via", "subsequent", "layers", ".", "To", "accomplish", "this", ",", "the", "model", "concatenates", "up", "to", "four", "character", "output", "vectors", ":", "the", "{", "forward", ",", "backward", "}", "output", "of", "the", "{", "first", ",", "last", "}", "character", "in", "the", "token", "(", "F", "1st", "(", "w", ")", ",", "F", "last", "(", "w", ")", ",", "B", "1st", "(", "w", ")", ",", "B", "last", "(", "w", ")", ")", ".", "In", "Figure", "1a", ",", "the", "four", "shaded", "boxes", "indicate", "these", "four", "outputs", "for", "the", "example", "token", ".", "Thus", ",", "the", "proposed", "model", "concatenates", "all", "four", "of", "these", "and", "passes", "it", "as", "input", "to", "an", "multilayer", "perceptron", "(", "MLP", ")", ":", "A", "tag", "can", "then", "be", "predicted", "with", "a", "linear", "classifier", "that", "takes", "as", "input", "the", "output", "of", "the", "MLP", "enized", "/", "segmented", ".", ",", "applies", "a", "softmax", "function", "and", "chooses", "for", "each", "word", "the", "tag", "with", "highest", "probability", ".", "Table", "8", "investigates", "the", "empirical", "impact", "of", "alternative", "definitions", "of", "g", "i", "that", "concatenate", "only", "subsets", "of", "{", "F", "1st", "(", "w", ")", ",", "F", "last", "(", "w", ")", ",", "B", "1st", "(", "w", ")", ",", "B", "last", "(", "w", ")", "}.", "section", ":", "Word", "-", "based", "Character", "Model", "To", "investigate", "whether", "a", "sentence", "sensitive", "character", "model", "is", "better", "than", "a", "character", "model", "where", "the", "context", "is", "restricted", "to", "the", "characters", "of", "a", "word", ",", "we", "reimplemented", "the", "word", "-", "based", "character", "model", "of", "[", "reference", "]", "as", "shown", "in", "[", "reference", "]", ".", "This", "model", "uses", "the", "final", "state", "of", "a", "unidirectional", "LSTM", "over", "the", "characters", "of", "the", "word", ",", "combined", "with", "the", "attention", "mechanism", "of", "Cao", "and", "Rei", "(", "2016", ")", "over", "all", "characters", ".", "We", "refer", "the", "reader", "to", "those", "works", "for", "more", "details", ".", "Critically", ",", "however", ",", "all", "the", "information", "fed", "to", "this", "representation", "comes", "from", "the", "word", "itself", ",", "and", "not", "a", "wider", "sentence", "-", "level", "context", ".", "section", ":", "Sentence", "-", "based", "Word", "Model", "We", "used", "a", "similar", "setup", "for", "our", "context", "sensitive", "word", "encodings", "as", "the", "character", "encodings", ".", "There", "are", "a", "few", "differences", ".", "Obviously", ",", "the", "inputs", "are", "the", "words", "of", "the", "sentence", ".", "For", "each", "of", "the", "words", ",", "we", "use", "pretrained", "word", "embeddings", "(", "p", "word", "The", "summed", "embeddings", "in", "i", "are", "passed", "as", "input", "to", "one", "or", "more", "BiLSTM", "layers", "whose", "output", "f", "l", "w", ",", "i", ",", "b", "l", "w", ",", "i", "is", "concatenated", "and", "used", "as", "the", "final", "encoding", ",", "which", "is", "then", "passed", "to", "an", "MLP", "It", "should", "be", "noted", ",", "that", "the", "output", "of", "this", "BiL", "-", "STM", "is", "essentially", "the", "Dozat", "et", "al", ".", "model", "before", "tag", "prediction", ",", "with", "the", "exception", "that", "the", "wordbased", "character", "encodings", "are", "excluded", ".", "section", ":", "Meta", "-", "BiLSTM", ":", "Model", "Combination", "Given", "initial", "word", "encodings", ",", "both", "character", "and", "word", "-", "based", ",", "a", "common", "strategy", "is", "to", "pass", "these", "through", "a", "sentence", "-", "level", "BiLSTM", "to", "create", "context", "sensitive", "encodings", ",", "e.g.", ",", "this", "is", "precisely", "what", "[", "reference", "]", "and", "[", "reference", "]", "do", ".", "However", ",", "we", "found", "that", "if", "we", "trained", "each", "of", "the", "character", "-", "based", "and", "word", "-", "based", "encodings", "with", "their", "own", "loss", ",", "and", "combined", "them", "using", "an", "additional", "meta", "-", "BiLSTM", "model", ",", "we", "obtained", "optimal", "performance", ".", "In", "the", "meta", "-", "BiLSTM", "model", ",", "we", "concatenate", "the", "output", ",", "for", "each", "word", ",", "of", "its", "context", "sensitive", "character", "and", "word", "-", "based", "encodings", ",", "and", "put", "this", "through", "another", "BiLSTM", "to", "create", "an", "additional", "combined", "context", "sensitive", "encoding", ".", "This", "is", "followed", "by", "a", "final", "MLP", "whose", "output", "is", "passed", "to", "a", "linear", "layer", "for", "tag", "prediction", ".", "With", "this", "setup", ",", "each", "of", "the", "models", "can", "be", "optimized", "independently", "which", "we", "describe", "in", "more", "detail", "in", "\u00a7", "3.5", ".", "Figure", "2b", "depicts", "the", "architecture", "of", "the", "combined", "system", "and", "contrasts", "it", "with", "that", "of", "the", "[", "reference", "]", "(", "Figure", "2a", ")", ".", "section", ":", "Training", "Schema", "As", "mentioned", "in", "the", "previous", "section", ",", "the", "character", "and", "word", "-", "based", "encoding", "models", "have", "their", "own", "tagging", "loss", "functions", ",", "which", "are", "trained", "independently", "and", "joined", "via", "the", "meta", "-", "BiLSTM", ".", "I.e.", ",", "the", "loss", "of", "each", "model", "is", "minimized", "independently", "by", "separate", "optimizers", "with", "their", "own", "hyperparameters", ".", "Thus", ",", "it", "is", "in", "some", "sense", "a", "multitask", "learning", "model", "and", "we", "must", "define", "a", "schedule", "in", "which", "individual", "models", "are", "updated", ".", "We", "opted", "for", "a", "simple", "synchronous", "schedule", "outline", "in", "Algorithm", "1", ".", "Here", ",", "during", "each", "epoch", ",", "we", "update", "each", "of", "the", "models", "in", "sequence", "-", "character", ",", "word", "and", "meta", "-", "using", "the", "entire", "training", "data", ".", "Algorithm", "1", ":", "Training", "procedure", "for", "learning", "initial", "character", "and", "word", "-", "based", "context", "sensitive", "encodings", "synchronously", "with", "meta", "-", "BiLSTM", ".", "In", "terms", "of", "model", "selection", ",", "after", "each", "epoch", ",", "the", "algorithm", "evaluates", "the", "tagging", "accuracy", "of", "the", "development", "set", "and", "keeps", "the", "parameters", "of", "the", "best", "model", ".", "Accuracy", "is", "measured", "using", "the", "meta", "-", "BiLSTM", "tagging", "layer", ",", "which", "requires", "a", "forward", "pass", "through", "all", "three", "models", ".", "Though", "we", "use", "all", "three", "losses", "to", "update", "the", "models", ",", "only", "the", "meta", "-", "BiLSTM", "layer", "is", "used", "for", "model", "selection", "and", "test", "-", "time", "prediction", ".", "While", "each", "of", "the", "three", "models", "-", "character", ",", "word", "and", "meta", "-", "are", "trained", "with", "their", "own", "loss", "functions", ",", "it", "should", "be", "emphasized", "that", "training", "is", "synchronous", "in", "the", "sense", "that", "the", "meta", "-", "BiLSTM", "model", "is", "trained", "in", "tandem", "with", "the", "two", "encoding", "models", ",", "and", "not", "after", "those", "models", "have", "converged", ".", "Since", "accuracy", "from", "the", "meta", "-", "BiLSTM", "model", "on", "the", "development", "set", "determines", "the", "best", "parameters", ",", "training", "is", "not", "completely", "independent", ".", "We", "found", "this", "to", "improve", "accuracy", "overall", ".", "Crucially", ",", "when", "we", "allowed", "the", "meta", "-", "BiLSTM", "to", "back", "-", "propagate", "through", "the", "whole", "network", ",", "per", "-", "formance", "degraded", "regardless", "of", "whether", "one", "or", "multiple", "loss", "functions", "were", "used", ".", "Each", "language", "could", "in", "theory", "use", "separate", "hyperparameters", ",", "optimized", "for", "highest", "accuracy", ".", "However", ",", "for", "our", "main", "experiments", "we", "use", "identical", "settings", "for", "each", "language", "which", "worked", "well", "for", "large", "corpora", "and", "simplified", "things", ".", "We", "provide", "an", "overview", "of", "the", "selected", "hyperparameters", "in", "\u00a7", "4.1", ".", "We", "explored", "more", "settings", "for", "selected", "individual", "languages", "with", "a", "grid", "search", "and", "ablation", "experiments", "and", "present", "the", "results", "in", "\u00a7", "5", ".", "section", ":", "Experiments", "and", "Results", "In", "this", "section", ",", "we", "present", "the", "experimental", "setup", "and", "the", "selected", "hyperparameter", "for", "the", "main", "experiments", "where", "we", "use", "the", "CoNLL", "Shared", "Task", "2017", "treebanks", "and", "compare", "with", "the", "best", "systems", "of", "the", "shared", "task", ".", "section", ":", "Experimental", "Setup", "For", "our", "main", "results", ",", "we", "selected", "one", "network", "configuration", "and", "set", "of", "the", "hyperparameters", ".", "These", "settings", "are", "not", "optimal", "for", "all", "languages", ".", "However", ",", "since", "hyperparameter", "exploration", "is", "computationally", "demanding", "due", "to", "the", "number", "of", "languages", "we", "optimized", "these", "hyperparameters", "on", "initial", "development", "data", "experiments", "over", "a", "few", "languages", ".", "Table", "1", ":", "Selected", "hyperparameters", "and", "initialization", "of", "parameters", "for", "our", "models", ".", "Chr", ",", "Wrd", ",", "and", "Mt", "are", "used", "to", "indicate", "the", "character", ",", "word", ",", "and", "meta", "models", "respectively", ".", "The", "Gaussian", "distribution", "is", "used", "with", "a", "mean", "of", "0", "and", "variance", "of", "1", "to", "generate", "the", "random", "values", ".", "single", "dropout", "mask", "and", "we", "use", "dropout", "on", "the", "input", "and", "the", "states", "of", "the", "LSTM", ".", "As", "is", "standard", ",", "model", "selection", "was", "done", "measuring", "development", "accuracy", "/", "F1", "score", "after", "each", "epoch", "and", "taking", "the", "model", "with", "maximum", "value", "on", "the", "development", "set", ".", "section", ":", "Data", "Sets", "For", "the", "experiments", ",", "we", "use", "the", "data", "sets", "as", "provided", "by", "the", "CoNLL", "Shared", "Task", "2017", "[", "reference", "]", ".", "For", "training", ",", "we", "use", "the", "training", "sets", "which", "were", "denoted", "as", "big", "treebanks", "2", ".", "We", "followed", "the", "same", "methodology", "used", "in", "the", "CoNLL", "Shared", "Task", ".", "We", "use", "the", "training", "treebank", "for", "training", "only", "and", "the", "development", "sets", "for", "hyperparameter", "tuning", "and", "early", "stopping", ".", "To", "keep", "our", "results", "comparable", "with", "the", "Shared", "Task", ",", "we", "use", "the", "provided", "precomputed", "word", "embeddings", ".", "We", "excluded", "Gothic", "from", "our", "experiments", "as", "the", "available", "downloadable", "content", "did", "not", "include", "embeddings", "for", "this", "language", ".", "As", "input", "to", "our", "system", "-", "for", "both", "part", "-", "ofspeech", "tagging", "and", "morphological", "tagging", "-", "we", "use", "the", "output", "of", "the", "UDPipe", "-", "base", "baseline", "system", "[", "reference", "]", ")", "which", "provides", "segmentation", ".", "The", "segmentation", "differs", "from", "the", "gold", "segmentation", "and", "impacts", "accuracy", "negatively", "for", "a", "number", "of", "languages", ".", "Most", "of", "the", "top", "performing", "systems", "for", "part", "-", "of", "-", "speech", "tagging", "used", "as", "input", "UDPipe", "to", "obtain", "the", "segmentation", "for", "the", "input", "data", ".", "For", "morphology", ",", "the", "top", "system", "for", "most", "languages", "(", "IMS", ")", "used", "its", "own", "segmentation", "[", "reference", "]", ".", "For", "the", "evaluation", ",", "we", "used", "the", "official", "evaluation", "script", "[", "reference", "]", ".", "section", ":", "Part", "-", "of", "-", "Speech", "Tagging", "Results", "In", "this", "section", ",", "we", "present", "the", "results", "of", "the", "application", "of", "our", "model", "to", "part", "-", "of", "-", "speech", "tagging", ".", "In", "our", "first", "experiment", ",", "we", "used", "our", "model", "in", "the", "setting", "of", "the", "CoNLL", "2017", "Shared", "Task", "to", "annotate", "words", "with", "XPOS", "3", "tags", "[", "reference", "]", ".", "We", "compare", "our", "results", "against", "the", "top", "systems", "of", "the", "CoNLL", "2017", "Shared", "Task", ".", "Table", "2", "contains", "the", "results", "of", "this", "task", "for", "the", "large", "treebanks", ".", "Because", "[", "reference", "]", "won", "the", "challenge", "for", "the", "majority", "of", "the", "languages", ",", "we", "first", "compare", "our", "results", "with", "the", "performance", "of", "their", "system", ".", "Our", "model", "outperforms", "[", "reference", "]", "in", "32", "of", "the", "54", "treebanks", "with", "13", "ties", ".", "These", "ties", "correspond", "mostly", "to", "languages", "where", "XPOS", "tagging", "anyhow", "obtains", "accuracies", "above", "99", "%", ".", "Our", "model", "tends", "to", "produce", "better", "results", ",", "especially", "for", "morphologically", "rich", "languages", "(", "e.g.", "Slavic", "System", "Accuracy", "S\u00f8gaard", "(", "2011", ")", "97.50", "[", "reference", "]", "97.64", "[", "reference", "]", ".", "97.44", "[", "reference", "]", "97.41", "ours", "97.96", "Table", "3", ":", "Results", "on", "WSJ", "test", "set", ".", "languages", ")", ",", "whereas", "[", "reference", "]", "showed", "higher", "performance", "in", "10", "languages", "in", "particular", "English", ",", "Greek", ",", "Brazilian", "Portuguese", "and", "Estonian", ".", "section", ":", "Part", "-", "of", "-", "Speech", "Tagging", "on", "WSJ", "We", "also", "performed", "experiments", "on", "the", "Penn", "Treebank", "with", "the", "usual", "split", "in", "train", ",", "development", "and", "test", "set", ".", "Table", "3", "shows", "the", "results", "of", "our", "model", "in", "comparison", "to", "the", "results", "reported", "in", "state", "-", "ofthe", "-", "art", "literature", ".", "Our", "model", "significantly", "outperforms", "these", "systems", ",", "with", "an", "absolute", "difference", "of", "0.32", "%", "in", "accuracy", ",", "which", "corresponds", "to", "a", "RRIE", "of", "12", "%", ".", "section", ":", "Morphological", "Tagging", "Results", "In", "addition", "to", "the", "XPOS", "tagging", "experiments", ",", "we", "performed", "experiments", "with", "morphological", "tagging", ".", "This", "annotation", "was", "part", "of", "the", "CONLL", "2017", "Shared", "Task", "and", "the", "objective", "was", "to", "predict", "a", "bundle", "of", "morphological", "features", "for", "each", "token", "in", "the", "text", ".", "Our", "model", "treats", "the", "morphological", "bundle", "as", "one", "tag", "making", "the", "problem", "equivalent", "to", "a", "sequential", "tagging", "problem", ".", "Table", "4", "shows", "the", "results", ".", "Our", "models", "tend", "to", "produce", "significantly", "better", "results", "than", "the", "winners", "of", "the", "CoNLL", "2017", "Shared", "Task", "(", "i.e.", ",", "1.8", "%", "absolute", "improvement", "on", "average", ",", "corresponding", "to", "a", "RRIE", "of", "21.20", "%", ")", ".", "The", "only", "cases", "for", "which", "this", "is", "not", "true", "are", "again", "languages", "that", "require", "significant", "segmentation", "efforts", "(", "i.e.", ",", "Hebrew", ",", "Chinese", ",", "Vietnamese", "and", "Japanese", ")", "or", "when", "the", "task", "was", "trivial", ".", "Given", "the", "fact", "that", "[", "reference", "]", "obtained", "the", "best", "results", "in", "part", "-", "of", "-", "speech", "tagging", "by", "a", "significant", "margin", "in", "the", "CoNLL", "2017", "Shared", "Task", ",", "it", "would", "be", "expected", "that", "their", "model", "would", "also", "perform", "significantly", "well", "in", "morphological", "tagging", "since", "the", "tasks", "are", "very", "similar", ".", "Since", "they", "did", "not", "participate", "in", "this", "particular", "challenge", ",", "we", "decided", "to", "reimplement", "their", "system", "to", "serve", "[", "reference", "]", ",", "the", "column", "ours", "shows", "our", "system", "with", "a", "sentence", "-", "based", "character", "model", ";", "RRIE", "gives", "the", "relative", "reduction", "in", "error", "between", "the", "Reimpl", ".", "DQM", "and", "sentencebased", "character", "system", ".", "Our", "system", "outperforms", "the", "CoNLL", "Winner", "by", "48", "out", "of", "54", "treebanks", "and", "the", "reimplementation", "of", "DQM", ",", "by", "43", "of", "54", "treebanks", ",", "with", "6", "ties", ".", "as", "a", "strong", "baseline", ".", "As", "expected", ",", "our", "reimplementation", "of", "[", "reference", "]", "tends", "to", "significantly", "outperform", "the", "winners", "of", "the", "CONLL", "2017", "Shared", "Task", ".", "However", ",", "in", "general", ",", "our", "models", "still", "obtain", "better", "results", ",", "outperforming", "Dozat", "et", "al", ".", "on", "43", "of", "the", "54", "treebanks", ",", "with", "an", "absolute", "difference", "of", "0.42", "%", "on", "average", ".", "section", ":", "Ablation", "Study", "The", "model", "proposed", "in", "this", "paper", "of", "a", "MetaBiLSTM", "with", "a", "sentence", "-", "based", "character", "model", "differs", "from", "prior", "work", "in", "multiple", "aspects", ".", "In", "this", "section", ",", "we", "perform", "ablations", "to", "determine", "the", "relative", "impact", "of", "each", "modeling", "decision", ".", "For", "the", "experimental", "setup", "of", "the", "ablation", "experiments", ",", "we", "report", "accuracy", "scores", "for", "the", "development", "sets", ".", "We", "split", "off", "5", "%", "of", "the", "sentences", "from", "each", "training", "corpus", "and", "we", "use", "this", "part", "for", "early", "stopping", ".", "Ablation", "experiments", "are", "either", "performed", "on", "a", "few", "selected", "treebanks", "to", "show", "individual", "language", "results", "or", "averaged", "across", "all", "treebanks", "for", "which", "tagging", "is", "non", "-", "trivial", ".", "section", ":", "Impact", "of", "the", "Training", "Schema", "We", "first", "compare", "jointly", "training", "the", "three", "model", "components", "(", "Meta", "-", "BiLSTM", ",", "character", "model", ",", "word", "model", ")", "to", "training", "each", "separately", ".", "Table", "5", "shows", "that", "separately", "optimized", "models", "are", "significantly", "more", "accurate", "on", "average", "than", "jointly", "optimized", "models", ".", "Separate", "optimization", "leads", "to", "better", "accuracy", "for", "34", "out", "of", "40", "treebanks", "for", "the", "morphological", "features", "task", "and", "for", "30", "out", "of", "39", "treebanks", "for", "xpos", "tagging", ".", "Separate", "optimization", "outperformed", "joint", "optimization", "by", "up", "to", "2.1", "percent", "absolute", ",", "while", "joint", "never", "out", "-", "performed", "separate", "by", "more", "than", "0.5", "%", "absolute", ".", "We", "hypothesize", "that", "separately", "training", "the", "models", "forces", "each", "submodel", "(", "word", "and", "character", ")", "to", "be", "strong", "enough", "to", "make", "high", "accuracy", "predictions", "and", "in", "some", "sense", "serves", "as", "a", "regularizer", "in", "the", "same", "way", "that", "dropout", "does", "for", "individual", "neurons", ".", "optimization", ".", "section", ":", "Impact", "of", "the", "Sentence", "-", "based", "Character", "Model", "We", "compared", "the", "setup", "with", "sentence", "-", "based", "character", "context", "(", "Figure", "1a", ")", "to", "word", "-", "based", "character", "context", "(", "Figure", "1b", ")", ".", "We", "selected", "for", "these", "experiments", "a", "number", "of", "morphological", "rich", "languages", ".", "The", "results", "are", "shown", "in", "Table", "6", ".", "The", "accuracy", "of", "the", "word", "-", "based", "character", "model", "joint", "with", "a", "word", "-", "based", "model", "were", "significantly", "lower", "than", "a", "sentence", "-", "based", "character", "model", ".", "We", "conclude", "Table", "6", ":", "F1", "score", "for", "selected", "languages", "on", "sentence", "vs.", "word", "level", "character", "models", "for", "the", "prediction", "of", "morphology", "using", "late", "integration", ".", "also", "from", "these", "results", "and", "comparing", "with", "results", "of", "the", "reimplementation", "of", "DQM", "that", "early", "integration", "of", "the", "word", "-", "based", "character", "model", "performs", "much", "better", "as", "late", "integration", "via", "MetaBiLSTM", "for", "a", "word", "-", "based", "character", "model", ".", "Impact", "of", "the", "Meta", "-", "BiLSTM", "Model", "Combination", "The", "proposed", "model", "trains", "word", "and", "character", "models", "independently", "while", "training", "a", "joint", "model", "on", "top", ".", "Here", "we", "investigate", "the", "part", "-", "ofspeech", "tagging", "performance", "of", "the", "joint", "model", "compared", "with", "the", "word", "and", "character", "models", "on", "their", "own", "(", "using", "hyperparameters", "from", "in", "4.1", ")", ".", "Table", "7", "shows", ",", "for", "selected", "languages", ",", "the", "results", "averaged", "over", "10", "runs", "in", "order", "to", "measure", "standard", "deviation", ".", "The", "examples", "show", "that", "the", "combined", "model", "has", "significantly", "higher", "accuracy", "compared", "with", "either", "the", "character", "and", "word", "models", "individually", ".", "section", ":", "Concatenation", "Strategies", "for", "the", "ContextSensitive", "Character", "Encodings", "The", "proposed", "model", "bases", "a", "token", "encoding", "on", "both", "the", "forward", "and", "the", "backward", "character", "representations", "of", "both", "the", "first", "and", "last", "character", "in", "the", "token", "(", "see", "Equation", "1", ")", ".", "Table", "8", "reports", ",", "for", "a", "few", "morphological", "rich", "languages", ",", "the", "part", "-", "of", "-", "speech", "tagging", "performance", "of", "different", "strategies", "to", "gather", "the", "characters", "when", "creating", "initial", "word", "encodings", ".", "The", "strategies", "were", "defined", "in", "\u00a7", "3.1", ".", "The", "Table", "also", "reimplementation", "of", "[", "reference", "]", ".", "We", "removed", ",", "for", "all", "systems", ",", "the", "word", "model", "in", "order", "to", "assess", "each", "strategy", "in", "isolation", ".", "The", "performance", "is", "quite", "different", "per", "language", ".", "E.g.", ",", "for", "Latin", ",", "the", "outputs", "of", "the", "forward", "and", "backward", "LSTMs", "of", "the", "last", "character", "scored", "highest", ".", "Sensitivity", "to", "Hyperparameter", "Search", "We", "picked", "Vietnamese", "for", "a", "more", "in", "-", "depth", "analysis", "since", "it", "did", "not", "perform", "well", "and", "investigated", "the", "influence", "of", "the", "sizes", "of", "LSTMs", "for", "the", "word", "and", "character", "model", "on", "the", "accuracy", "of", "development", "set", ".", "With", "larger", "network", "sizes", ",", "the", "capacity", "of", "the", "network", "increases", ",", "however", ",", "on", "the", "other", "hand", "it", "is", "prune", "to", "overfitting", ".", "We", "fixed", "all", "the", "hyperparameters", "except", "those", "for", "the", "network", "size", "of", "the", "character", "model", "and", "the", "word", "model", ",", "and", "ran", "a", "grid", "search", "over", "dimension", "sizes", "from", "200", "to", "500", "in", "steps", "of", "50", ".", "The", "surface", "plot", "in", "3", "shows", "that", "the", "grid", "peaks", "with", "more", "moderate", "settings", "around", "350", "LSTM", "cells", "which", "might", "lead", "to", "a", "higher", "accuracy", ".", "For", "all", "of", "the", "network", "sizes", "in", "the", "grid", "search", ",", "we", "still", "observed", "during", "training", "that", "the", "accuracy", "reach", "a", "high", "value", "and", "degrades", "with", "more", "iterations", "for", "the", "character", "and", "word", "model", ".", "This", "suggests", "that", "future", "variants", "of", "this", "model", "might", "benefit", "from", "higher", "regularization", ".", "Discussion", "Generally", ",", "the", "fact", "that", "different", "techniques", "for", "creating", "word", "encodings", "from", "character", "encodings", "and", "different", "network", "sizes", "can", "lead", "to", "different", "accuracies", "per", "language", "suggests", "that", "it", "should", "be", "possible", "to", "increase", "the", "accuracy", "of", "our", "model", "on", "a", "per", "language", "basis", "via", "a", "grid", "search", "over", "all", "possibilities", ".", "In", "fact", ",", "there", "are", "many", "variations", "on", "the", "models", "we", "presented", "in", "this", "work", "(", "e.g.", ",", "how", "the", "character", "and", "word", "models", "are", "combined", "with", "the", "meta", "-", "BiLSTM", ")", ".", "Since", "we", "are", "using", "separate", "losses", ",", "we", "could", "also", "change", "our", "training", "schema", ".", "For", "example", ",", "one", "could", "use", "methods", "like", "stack", "-", "propagation", "[", "reference", "]", "where", "we", "burn", "-", "in", "the", "character", "and", "word", "models", "and", "then", "train", "the", "meta", "-", "BiLSTM", "backpropagating", "throughout", "the", "entire", "network", ".", "section", ":", "Conclusions", "We", "presented", "an", "approach", "to", "morphosyntactic", "tagging", "that", "combines", "context", "-", "sensitive", "initial", "character", "and", "word", "encodings", "with", "a", "meta", "-", "BiLSTM", "layer", "to", "obtain", "state", "-", "of", "-", "the", "art", "accuracies", "for", "a", "wide", "variety", "of", "languages", ".", "section", ":", "section", ":", "Acknowledgments", "We", "would", "like", "to", "thank", "the", "anonymous", "reviewers", "as", "well", "as", "Terry", "Koo", ",", "Slav", "Petrov", ",", "Vera", "Axelrod", ",", "Kellie", "Websterk", ",", "Jan", "Botha", ",", "Kuzman", "Ganchev", ",", "Zhuoran", "Yu", ",", "Yuan", "Zhang", ",", "Eva", "Schlinger", ",", "Ji", "Ma", ",", "and", "John", "Alex", "for", "their", "helpful", "suggestions", ",", "comments", "and", "discussions", ".", "section", ":"]}