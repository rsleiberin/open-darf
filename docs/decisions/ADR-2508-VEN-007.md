---
id: ADR-2508-VEN-007
legacy_id: 0007-vector-store
type: VEN
implements_concept: null  # Will create CON ADR for vector storage
status: accepted
date: 2025-08-03
title: "Qdrant v1 selected for vector storage"

decision_confidence: 9
time_investment: "5_hours"
main_tradeoff: "performance vs ecosystem_maturity"
alternatives_rejected: ["weaviate", "milvus", "pgvector", "chroma", "pinecone"]
reevaluate_when: "vector_scale_exceeds_single_node OR gpu_acceleration_required"

supersedes: null
superseded_by: null
research_basis: "Janus Backend Architecture – Onboarding Brief"
linked_evidence:
  - "../reference/Janus Backend Architecture – Onboarding Brief.pdf"
  - "../reference/Best Vector Database Options for a Python-Based AI Stack.pdf"

tags: ["vector", "embeddings", "rag", "similarity", "rust"]
---

# ADR 0007 – Qdrant v1 selected for vector storage

## Decision

Qdrant selected as the vector database for semantic similarity search in Janus's Retrieval-Augmented Generation (RAG) pipeline.

## Context

Janus requires vector storage for semantic similarity search on embeddings generated from unstructured content (documents, knowledge snippets, etc.). When agents need relevant information based on semantic similarity, content is retrieved by vector distance rather than keyword matching.

## Rationale

**Lightweight, High-Performance Architecture**: Written in Rust, Qdrant delivers strong performance with minimal resource usage - critical for edge deployment scenarios.

**Local-First Design Philosophy**: Designed explicitly for embedded and offline deployments, with optional GPU acceleration when available. Recent updates optimized for embedded devices align perfectly with offline-first requirements.

**Developer-Friendly Integration**:
- Simple REST API for ease of use
- Payload filtering capabilities (metadata-based search constraints)
- Python client libraries with LangChain connectors
- "Live filter" capability for contextual search (e.g., "search only technical docs")

**Competitive Performance**: Benchmarks showed superior throughput and latency for similarity search tasks compared to alternatives, with efficient indexing strategies and quantization options.

## Research Foundation

Extensive analysis in "Janus Backend Architecture – Onboarding Brief" evaluated:

- **Weaviate**: Rejected due to higher memory footprint (Go-based), more complex deployment unsuitable for edge scenarios
- **Milvus**: Highly scalable but over-engineered for initial requirements, complex multi-service architecture inappropriate for single-node deployment
- **pgvector**: Simpler but dedicated vector databases outperform SQL for similarity search at scale; mixing OLTP with vector workloads creates performance bottlenecks
- **Chroma**: Too early-stage for production use, focused on small-scale scenarios
- **Pinecone**: Managed SaaS violates offline-first principle

Research emphasized Qdrant's "local-first ethos" with explicit edge device targeting.

## Consequences

### Positive
- High-performance semantic search with low resource overhead
- Seamless offline operation without external dependencies
- Rich metadata filtering enables contextual retrieval
- GPU acceleration available when hardware permits
- Strong integration with embedding generation pipeline

### Negative
- Smaller ecosystem compared to more established alternatives
- Rust-based debugging may require different expertise
- Single-vendor dependency for specialized workload

### Neutral
- REST API interface - simple but requires network calls
- Relatively new in the vector database landscape

## Implementation Notes

- **Embedding Pipeline**: Integrates with local embedding model for offline vector generation
- **Metadata Strategy**: Rich payload storage for filtering and cross-referencing
- **Scaling Path**: Single-node to start, clustering available for future growth
- **Cross-System IDs**: Maintain consistent entity references with Neo4j and PostgreSQL

## Success Criteria

- [ ] Sub-100ms similarity search for typical query sizes
- [ ] Successful offline embedding generation and storage
- [ ] Metadata filtering enhances retrieval relevance
- [ ] Vector index maintains performance as dataset grows
- [ ] Backup/restore procedures for vector collections

## Relationships

- **ENABLES**: RAG pipeline, semantic document retrieval, agent memory systems
- **INTEGRATES_WITH**: Local embedding model, LangChain retrieval chains, GraphRAG
- **SUPPORTS**: Agent question-answering, knowledge discovery, context generation
